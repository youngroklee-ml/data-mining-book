<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 계층적 군집방법 | 데이터마이닝 with R</title>
  <meta name="description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 계층적 군집방법 | 데이터마이닝 with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://youngroklee-ml.github.io/data-mining-book/" />
  
  <meta property="og:description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  <meta name="github-repo" content="youngroklee-ml/data-mining-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 계층적 군집방법 | 데이터마이닝 with R" />
  
  <meta name="twitter:description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  

<meta name="author" content="전치혁, 이혜선, 이종석, 이영록" />


<meta name="date" content="2020-12-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="clustering-overview.html"/>
<link rel="next" href="nonhierarchical-clustering.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">데이터마이닝 with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>개요</a></li>
<li class="chapter" data-level="1" data-path="datamining-overview.html"><a href="datamining-overview.html"><i class="fa fa-check"></i><b>1</b> 데이터마이닝 개요</a></li>
<li class="part"><span><b>I 1부 - 예측</b></span></li>
<li class="chapter" data-level="2" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>2</b> 회귀분석</a><ul>
<li class="chapter" data-level="2.1" data-path="regression.html"><a href="regression.html#regression-packages-install"><i class="fa fa-check"></i><b>2.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="2.2" data-path="regression.html"><a href="regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>2.2</b> 다중회귀모형</a></li>
<li class="chapter" data-level="2.3" data-path="regression.html"><a href="regression.html#regression-response-confidence-prediction"><i class="fa fa-check"></i><b>2.3</b> 반응치에 대한 추정 및 예측</a><ul>
<li class="chapter" data-level="2.3.1" data-path="regression.html"><a href="regression.html#regression-response-confidence"><i class="fa fa-check"></i><b>2.3.1</b> 평균반응치의 추정</a></li>
<li class="chapter" data-level="2.3.2" data-path="regression.html"><a href="regression.html#regression-response-prediction"><i class="fa fa-check"></i><b>2.3.2</b> 미래반응치의 예측</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="regression.html"><a href="regression.html#regression-indicator-variable"><i class="fa fa-check"></i><b>2.4</b> 지시변수와 회귀모형</a><ul>
<li class="chapter" data-level="2.4.1" data-path="regression.html"><a href="regression.html#regression-indicator-variable-basic-script"><i class="fa fa-check"></i><b>2.4.1</b> 기본 R 스트립트</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>3</b> 주성분분석</a><ul>
<li class="chapter" data-level="3.1" data-path="pca.html"><a href="pca.html#pca-packages-install"><i class="fa fa-check"></i><b>3.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="3.2" data-path="pca.html"><a href="pca.html#pca-matrix-factorization"><i class="fa fa-check"></i><b>3.2</b> 행렬의 분해</a><ul>
<li class="chapter" data-level="3.2.1" data-path="pca.html"><a href="pca.html#pca-matrix-factorization-basic-script"><i class="fa fa-check"></i><b>3.2.1</b> 기본 R 스트립트</a></li>
<li class="chapter" data-level="3.2.2" data-path="pca.html"><a href="pca.html#pca-ss"><i class="fa fa-check"></i><b>3.2.2</b> 변수의 변동과 제곱합</a></li>
<li class="chapter" data-level="3.2.3" data-path="pca.html"><a href="pca.html#pca-intro"><i class="fa fa-check"></i><b>3.2.3</b> 주성분의 이해 및 행렬의 분해</a></li>
<li class="chapter" data-level="3.2.4" data-path="pca.html"><a href="pca.html#pca-svd"><i class="fa fa-check"></i><b>3.2.4</b> 특이치분해 (Singular Value Decomposition)</a></li>
<li class="chapter" data-level="3.2.5" data-path="pca.html"><a href="pca.html#pca-spectral"><i class="fa fa-check"></i><b>3.2.5</b> 분광분해 (Spectral Decomposition)</a></li>
<li class="chapter" data-level="3.2.6" data-path="pca.html"><a href="pca.html#pca-nipals"><i class="fa fa-check"></i><b>3.2.6</b> NIPALS 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="pca.html"><a href="pca.html#pca-regression"><i class="fa fa-check"></i><b>3.3</b> 주성분 회귀분석</a><ul>
<li class="chapter" data-level="3.3.1" data-path="pca.html"><a href="pca.html#pcr-basic-script"><i class="fa fa-check"></i><b>3.3.1</b> 기본 R 스트립트</a></li>
<li class="chapter" data-level="3.3.2" data-path="pca.html"><a href="pca.html#pcr-regression-coefficient"><i class="fa fa-check"></i><b>3.3.2</b> 주성분 회귀계수 추정</a></li>
<li class="chapter" data-level="3.3.3" data-path="pca.html"><a href="pca.html#pcr-regression-transform"><i class="fa fa-check"></i><b>3.3.3</b> 회귀계수 선형변환</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="plsr.html"><a href="plsr.html"><i class="fa fa-check"></i><b>4</b> 부분최소자승법</a><ul>
<li class="chapter" data-level="4.1" data-path="plsr.html"><a href="plsr.html#plsr-packages-install"><i class="fa fa-check"></i><b>4.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="4.2" data-path="plsr.html"><a href="plsr.html#plsr-single-target"><i class="fa fa-check"></i><b>4.2</b> 하나의 종속변수의 경우</a><ul>
<li class="chapter" data-level="4.2.1" data-path="plsr.html"><a href="plsr.html#plsr-basic-script"><i class="fa fa-check"></i><b>4.2.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="4.2.2" data-path="plsr.html"><a href="plsr.html#plsr-model"><i class="fa fa-check"></i><b>4.2.2</b> PLS 모형</a></li>
<li class="chapter" data-level="4.2.3" data-path="plsr.html"><a href="plsr.html#plsr-single-nipals"><i class="fa fa-check"></i><b>4.2.3</b> NIPALS 알고리즘</a></li>
<li class="chapter" data-level="4.2.4" data-path="plsr.html"><a href="plsr.html#plsr-single-transform"><i class="fa fa-check"></i><b>4.2.4</b> 회귀식 변환</a></li>
<li class="chapter" data-level="4.2.5" data-path="plsr.html"><a href="plsr.html#plsr-sst"><i class="fa fa-check"></i><b>4.2.5</b> 제곱합 분해</a></li>
<li class="chapter" data-level="4.2.6" data-path="plsr.html"><a href="plsr.html#plsr-variable-importance"><i class="fa fa-check"></i><b>4.2.6</b> 독립변수의 중요도</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-target"><i class="fa fa-check"></i><b>4.3</b> 다수의 종속변수의 경우</a><ul>
<li class="chapter" data-level="4.3.1" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-basic-script"><i class="fa fa-check"></i><b>4.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="4.3.2" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-model"><i class="fa fa-check"></i><b>4.3.2</b> PLS 모형</a></li>
<li class="chapter" data-level="4.3.3" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-nipals"><i class="fa fa-check"></i><b>4.3.3</b> NIPALS 알고리즘</a></li>
<li class="chapter" data-level="4.3.4" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-transform"><i class="fa fa-check"></i><b>4.3.4</b> 회귀식 변환</a></li>
<li class="chapter" data-level="4.3.5" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-sst"><i class="fa fa-check"></i><b>4.3.5</b> 제곱합 분해</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II 2부 - 분류분석</b></span></li>
<li class="chapter" data-level="5" data-path="classification-analysis.html"><a href="classification-analysis.html"><i class="fa fa-check"></i><b>5</b> 분류분석 개요</a><ul>
<li class="chapter" data-level="5.1" data-path="classification-analysis.html"><a href="classification-analysis.html#classification-packages-install"><i class="fa fa-check"></i><b>5.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="5.2" data-path="classification-analysis.html"><a href="classification-analysis.html#classification-problem-methods"><i class="fa fa-check"></i><b>5.2</b> 분류문제 및 분류기법</a></li>
<li class="chapter" data-level="5.3" data-path="classification-analysis.html"><a href="classification-analysis.html#simple-classification-methods"><i class="fa fa-check"></i><b>5.3</b> 기본적인 분류기법</a><ul>
<li class="chapter" data-level="5.3.1" data-path="classification-analysis.html"><a href="classification-analysis.html#nearest-neighbor-classification"><i class="fa fa-check"></i><b>5.3.1</b> 인접객체법</a></li>
<li class="chapter" data-level="5.3.2" data-path="classification-analysis.html"><a href="classification-analysis.html#naive-bayes"><i class="fa fa-check"></i><b>5.3.2</b> 나이브 베이지안 분류법</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>6</b> 로지스틱 회귀분석</a><ul>
<li class="chapter" data-level="6.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-packages-install"><i class="fa fa-check"></i><b>6.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="6.2" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-regression"><i class="fa fa-check"></i><b>6.2</b> 이분 로지스틱 회귀모형</a><ul>
<li class="chapter" data-level="6.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#bianry-logistic-reg-basic-script"><i class="fa fa-check"></i><b>6.2.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="6.2.2" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-reg-model"><i class="fa fa-check"></i><b>6.2.2</b> 회귀모형</a></li>
<li class="chapter" data-level="6.2.3" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-reg-estimation"><i class="fa fa-check"></i><b>6.2.3</b> 회귀계수 추정</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="logistic-regression.html"><a href="logistic-regression.html#nominal-logistic-regression"><i class="fa fa-check"></i><b>6.3</b> 명목 로지스틱 회귀모형</a><ul>
<li class="chapter" data-level="6.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#nominal-logistic-reg-basic-script"><i class="fa fa-check"></i><b>6.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="6.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#baseline-category-logit-model"><i class="fa fa-check"></i><b>6.3.2</b> 기준범주 로짓모형</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="logistic-regression.html"><a href="logistic-regression.html#ordinal-logistic-regression"><i class="fa fa-check"></i><b>6.4</b> 서열 로지스틱 회귀모형</a><ul>
<li class="chapter" data-level="6.4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#ordinal-logistic-basic-script"><i class="fa fa-check"></i><b>6.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="6.4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#cumulative-logit-model"><i class="fa fa-check"></i><b>6.4.2</b> 누적 로짓모형</a></li>
<li class="chapter" data-level="6.4.3" data-path="logistic-regression.html"><a href="logistic-regression.html#adjacent-categories-logit-model"><i class="fa fa-check"></i><b>6.4.3</b> 인근범주 로짓모형</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="da.html"><a href="da.html"><i class="fa fa-check"></i><b>7</b> 판별분석</a><ul>
<li class="chapter" data-level="7.1" data-path="da.html"><a href="da.html#da-overview"><i class="fa fa-check"></i><b>7.1</b> 개요</a></li>
<li class="chapter" data-level="7.2" data-path="da.html"><a href="da.html#da-packages-install"><i class="fa fa-check"></i><b>7.2</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="7.3" data-path="da.html"><a href="da.html#da-fisher"><i class="fa fa-check"></i><b>7.3</b> 피셔 방법</a><ul>
<li class="chapter" data-level="7.3.1" data-path="da.html"><a href="da.html#da-fisher-basic-script"><i class="fa fa-check"></i><b>7.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.3.2" data-path="da.html"><a href="da.html#피셔-판별함수"><i class="fa fa-check"></i><b>7.3.2</b> 피셔 판별함수</a></li>
<li class="chapter" data-level="7.3.3" data-path="da.html"><a href="da.html#분류-규칙"><i class="fa fa-check"></i><b>7.3.3</b> 분류 규칙</a></li>
<li class="chapter" data-level="7.3.4" data-path="da.html"><a href="da.html#r-패키지를-이용한-분류규칙-도출"><i class="fa fa-check"></i><b>7.3.4</b> R 패키지를 이용한 분류규칙 도출</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="da.html"><a href="da.html#lda"><i class="fa fa-check"></i><b>7.4</b> 의사결정론에 의한 선형분류규칙</a><ul>
<li class="chapter" data-level="7.4.1" data-path="da.html"><a href="da.html#lda-basic-script"><i class="fa fa-check"></i><b>7.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.4.2" data-path="da.html"><a href="da.html#lda-function"><i class="fa fa-check"></i><b>7.4.2</b> 선형판별함수</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="da.html"><a href="da.html#lda-misclassification-cost"><i class="fa fa-check"></i><b>7.5</b> 오분류비용을 고려한 분류규칙</a></li>
<li class="chapter" data-level="7.6" data-path="da.html"><a href="da.html#qda"><i class="fa fa-check"></i><b>7.6</b> 이차판별분석</a><ul>
<li class="chapter" data-level="7.6.1" data-path="da.html"><a href="da.html#qda-basic-script"><i class="fa fa-check"></i><b>7.6.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.6.2" data-path="da.html"><a href="da.html#qda-function"><i class="fa fa-check"></i><b>7.6.2</b> 이차 판별함수</a></li>
<li class="chapter" data-level="7.6.3" data-path="da.html"><a href="da.html#qda-discriminant-rule"><i class="fa fa-check"></i><b>7.6.3</b> 이차판별함수에 의한 분류</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="da.html"><a href="da.html#da-multiclass"><i class="fa fa-check"></i><b>7.7</b> 세 범주 이상의 분류</a><ul>
<li class="chapter" data-level="7.7.1" data-path="da.html"><a href="da.html#mutliclass-da-basic-script"><i class="fa fa-check"></i><b>7.7.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.7.2" data-path="da.html"><a href="da.html#mutliclass-generalized-discriminant-function"><i class="fa fa-check"></i><b>7.7.2</b> 일반화된 판별함수</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="tree-based-method.html"><a href="tree-based-method.html"><i class="fa fa-check"></i><b>8</b> 트리기반 기법</a><ul>
<li class="chapter" data-level="8.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-overview"><i class="fa fa-check"></i><b>8.1</b> CART 개요</a></li>
<li class="chapter" data-level="8.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-packages-install"><i class="fa fa-check"></i><b>8.2</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="8.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-build"><i class="fa fa-check"></i><b>8.3</b> CART 트리 생성</a><ul>
<li class="chapter" data-level="8.3.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-basic-r-script"><i class="fa fa-check"></i><b>8.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="8.3.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-notation"><i class="fa fa-check"></i><b>8.3.2</b> 기호 정의</a></li>
<li class="chapter" data-level="8.3.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-impurity"><i class="fa fa-check"></i><b>8.3.3</b> 노드 및 트리의 불순도</a></li>
<li class="chapter" data-level="8.3.4" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-split"><i class="fa fa-check"></i><b>8.3.4</b> 분지기준</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-pruning-complete"><i class="fa fa-check"></i><b>8.4</b> 가지치기 및 최종 트리 선정</a><ul>
<li class="chapter" data-level="8.4.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-pruning"><i class="fa fa-check"></i><b>8.4.1</b> 가지치기</a></li>
<li class="chapter" data-level="8.4.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-best-tree"><i class="fa fa-check"></i><b>8.4.2</b> 최적 트리의 선정</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg"><i class="fa fa-check"></i><b>8.5</b> R패키지 내 분류 트리 방법</a><ul>
<li class="chapter" data-level="8.5.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-split"><i class="fa fa-check"></i><b>8.5.1</b> 트리 확장</a></li>
<li class="chapter" data-level="8.5.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-pruning"><i class="fa fa-check"></i><b>8.5.2</b> 가지치기</a></li>
<li class="chapter" data-level="8.5.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-param"><i class="fa fa-check"></i><b>8.5.3</b> 파라미터값 결정</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="svm.html"><a href="svm.html"><i class="fa fa-check"></i><b>9</b> 서포트 벡터 머신</a><ul>
<li class="chapter" data-level="9.1" data-path="svm.html"><a href="svm.html#svm-overview"><i class="fa fa-check"></i><b>9.1</b> 개요</a></li>
<li class="chapter" data-level="9.2" data-path="svm.html"><a href="svm.html#svm-packages-install"><i class="fa fa-check"></i><b>9.2</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="9.3" data-path="svm.html"><a href="svm.html#linear-svm-separable"><i class="fa fa-check"></i><b>9.3</b> 선형 SVM - 분리 가능 경우</a><ul>
<li class="chapter" data-level="9.3.1" data-path="svm.html"><a href="svm.html#linear-svm-separable-basic-script"><i class="fa fa-check"></i><b>9.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="9.3.2" data-path="svm.html"><a href="svm.html#linear-svm-notation"><i class="fa fa-check"></i><b>9.3.2</b> 기호 정의</a></li>
<li class="chapter" data-level="9.3.3" data-path="svm.html"><a href="svm.html#linear-svm-separable-hyperplane"><i class="fa fa-check"></i><b>9.3.3</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="svm.html"><a href="svm.html#linear-svm-inseparable"><i class="fa fa-check"></i><b>9.4</b> 선형 SVM - 분리 불가능 경우</a><ul>
<li class="chapter" data-level="9.4.1" data-path="svm.html"><a href="svm.html#linear-svm-inseparable-basic-script"><i class="fa fa-check"></i><b>9.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="9.4.2" data-path="svm.html"><a href="svm.html#linear-svm-inseparable-hyperplane"><i class="fa fa-check"></i><b>9.4.2</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="svm.html"><a href="svm.html#nonlinear-svm"><i class="fa fa-check"></i><b>9.5</b> 비선형 SVM</a><ul>
<li class="chapter" data-level="9.5.1" data-path="svm.html"><a href="svm.html#nonlinear-svm-basic-script"><i class="fa fa-check"></i><b>9.5.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="9.5.2" data-path="svm.html"><a href="svm.html#nonlinear-svm-hyperplane"><i class="fa fa-check"></i><b>9.5.2</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="svm.html"><a href="svm.html#svm-r-pkg"><i class="fa fa-check"></i><b>9.6</b> R패키지 내 SVM</a><ul>
<li class="chapter" data-level="9.6.1" data-path="svm.html"><a href="svm.html#svm-kernel-function"><i class="fa fa-check"></i><b>9.6.1</b> 커널함수</a></li>
<li class="chapter" data-level="9.6.2" data-path="svm.html"><a href="svm.html#svm-nu-classification"><i class="fa fa-check"></i><b>9.6.2</b> <span class="math inline">\(\nu\)</span>-SVC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html"><i class="fa fa-check"></i><b>10</b> 분류규칙의 성능 평가</a><ul>
<li class="chapter" data-level="10.1" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#classifier-evaluation-packages-install"><i class="fa fa-check"></i><b>10.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="10.2" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#classifier-evaluation-misclassification-rate"><i class="fa fa-check"></i><b>10.2</b> 분류오류율</a></li>
<li class="chapter" data-level="10.3" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#precision-sensitivity-specificity"><i class="fa fa-check"></i><b>10.3</b> 정확도, 민감도 및 특이도</a><ul>
<li class="chapter" data-level="10.3.1" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#confusion-matrix-r-package"><i class="fa fa-check"></i><b>10.3.1</b> R 패키지 내 정오분류표</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#roc-curve"><i class="fa fa-check"></i><b>10.4</b> ROC 곡선</a></li>
<li class="chapter" data-level="10.5" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#gain-chart"><i class="fa fa-check"></i><b>10.5</b> 이익도표</a></li>
</ul></li>
<li class="part"><span><b>III 3부 - 군집분석</b></span></li>
<li class="chapter" data-level="11" data-path="clustering-overview.html"><a href="clustering-overview.html"><i class="fa fa-check"></i><b>11</b> 군집분석 개요</a><ul>
<li class="chapter" data-level="11.1" data-path="clustering-overview.html"><a href="clustering-overview.html#clustering-overview-packages-install"><i class="fa fa-check"></i><b>11.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="11.2" data-path="clustering-overview.html"><a href="clustering-overview.html#clustering-method"><i class="fa fa-check"></i><b>11.2</b> 군집분석 기법</a></li>
<li class="chapter" data-level="11.3" data-path="clustering-overview.html"><a href="clustering-overview.html#object-similarity-metric"><i class="fa fa-check"></i><b>11.3</b> 객체 간의 유사성 척도</a><ul>
<li class="chapter" data-level="11.3.1" data-path="clustering-overview.html"><a href="clustering-overview.html#object-distance-metric"><i class="fa fa-check"></i><b>11.3.1</b> 거리 관련 척도</a></li>
<li class="chapter" data-level="11.3.2" data-path="clustering-overview.html"><a href="clustering-overview.html#object-correlation-metric"><i class="fa fa-check"></i><b>11.3.2</b> 상관계수 관련 척도</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="clustering-overview.html"><a href="clustering-overview.html#category-similarity-metric"><i class="fa fa-check"></i><b>11.4</b> 범주형 객체의 유사성 척도</a><ul>
<li class="chapter" data-level="11.4.1" data-path="clustering-overview.html"><a href="clustering-overview.html#binary-similarity-metric"><i class="fa fa-check"></i><b>11.4.1</b> 이분형 변수의 경우</a></li>
<li class="chapter" data-level="11.4.2" data-path="clustering-overview.html"><a href="clustering-overview.html#ordinal-similarity-metric"><i class="fa fa-check"></i><b>11.4.2</b> 서열형 변수의 경우</a></li>
<li class="chapter" data-level="11.4.3" data-path="clustering-overview.html"><a href="clustering-overview.html#nominal-similarity-metric"><i class="fa fa-check"></i><b>11.4.3</b> 명목형 변수의 경우</a></li>
<li class="chapter" data-level="11.4.4" data-path="clustering-overview.html"><a href="clustering-overview.html#mixed-similarity-metric"><i class="fa fa-check"></i><b>11.4.4</b> 혼합형의 경우</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html"><i class="fa fa-check"></i><b>12</b> 계층적 군집방법</a><ul>
<li class="chapter" data-level="12.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hierarchical-clustering-packages-install"><i class="fa fa-check"></i><b>12.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="12.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#distance-between-clusters"><i class="fa fa-check"></i><b>12.2</b> 군집 간 거리척도 및 연결법</a></li>
<li class="chapter" data-level="12.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method"><i class="fa fa-check"></i><b>12.3</b> 연결법의 군집 알고리즘</a><ul>
<li class="chapter" data-level="12.3.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method-basic-script"><i class="fa fa-check"></i><b>12.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="12.3.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method-algorithm"><i class="fa fa-check"></i><b>12.3.2</b> 연결법 군집 알고리즘</a></li>
<li class="chapter" data-level="12.3.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hclust"><i class="fa fa-check"></i><b>12.3.3</b> R 패키지 내 연결법</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method"><i class="fa fa-check"></i><b>12.4</b> 워드 방법</a><ul>
<li class="chapter" data-level="12.4.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method-basic-script"><i class="fa fa-check"></i><b>12.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="12.4.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method-algorithm"><i class="fa fa-check"></i><b>12.4.2</b> 워드 군집 알고리즘</a></li>
<li class="chapter" data-level="12.4.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-rpackages"><i class="fa fa-check"></i><b>12.4.3</b> R 패키지 내 워드 방법</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana"><i class="fa fa-check"></i><b>12.5</b> 분리적 방법 - 다이아나</a><ul>
<li class="chapter" data-level="12.5.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana-basic-script"><i class="fa fa-check"></i><b>12.5.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="12.5.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana-algorithm"><i class="fa fa-check"></i><b>12.5.2</b> 다이아나 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hierarchical-cluster-number"><i class="fa fa-check"></i><b>12.6</b> 군집수의 결정</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html"><i class="fa fa-check"></i><b>13</b> 비계층적 군집방법</a><ul>
<li class="chapter" data-level="13.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#nonhierarchical-clustering-packages-install"><i class="fa fa-check"></i><b>13.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="13.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans"><i class="fa fa-check"></i><b>13.2</b> K-means 알고리즘</a><ul>
<li class="chapter" data-level="13.2.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-basic-script"><i class="fa fa-check"></i><b>13.2.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="13.2.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-algorithm"><i class="fa fa-check"></i><b>13.2.2</b> 알고리즘</a></li>
<li class="chapter" data-level="13.2.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-user-defined-functions"><i class="fa fa-check"></i><b>13.2.3</b> R 스크립트 구현</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmedoids"><i class="fa fa-check"></i><b>13.3</b> K-medoids 군집방법</a><ul>
<li class="chapter" data-level="13.3.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#pam"><i class="fa fa-check"></i><b>13.3.1</b> PAM 알고리즘</a></li>
<li class="chapter" data-level="13.3.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#clara"><i class="fa fa-check"></i><b>13.3.2</b> CLARA 알고리즘</a></li>
<li class="chapter" data-level="13.3.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#clarans"><i class="fa fa-check"></i><b>13.3.3</b> CLARANS 알고리즘</a></li>
<li class="chapter" data-level="13.3.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-like"><i class="fa fa-check"></i><b>13.3.4</b> K-means-like 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans"><i class="fa fa-check"></i><b>13.4</b> 퍼지 K-means 알고리즘</a><ul>
<li class="chapter" data-level="13.4.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-basic-script"><i class="fa fa-check"></i><b>13.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="13.4.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-algorithm"><i class="fa fa-check"></i><b>13.4.2</b> 알고리즘</a></li>
<li class="chapter" data-level="13.4.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-script-implement"><i class="fa fa-check"></i><b>13.4.3</b> R 스크립트 구현</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering"><i class="fa fa-check"></i><b>13.5</b> 모형기반 군집방법</a><ul>
<li class="chapter" data-level="13.5.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-basic-script"><i class="fa fa-check"></i><b>13.5.1</b> 기본 R script</a></li>
<li class="chapter" data-level="13.5.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-em"><i class="fa fa-check"></i><b>13.5.2</b> EM 알고리즘</a></li>
<li class="chapter" data-level="13.5.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-script-implement"><i class="fa fa-check"></i><b>13.5.3</b> R 스크립트 구현</a></li>
<li class="chapter" data-level="13.5.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#r-packages-model-based-clustering"><i class="fa fa-check"></i><b>13.5.4</b> R 패키지 내 모형기반 군집분석</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html"><i class="fa fa-check"></i><b>14</b> 군집해의 평가 및 해석</a><ul>
<li class="chapter" data-level="14.1" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-solution-evaluation-packages-install"><i class="fa fa-check"></i><b>14.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="14.2" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-solution-evaluation-metric"><i class="fa fa-check"></i><b>14.2</b> 군집해의 평가</a><ul>
<li class="chapter" data-level="14.2.1" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-evaluation-external-index"><i class="fa fa-check"></i><b>14.2.1</b> 외부평가지수</a></li>
<li class="chapter" data-level="14.2.2" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-evaluation-internal-index"><i class="fa fa-check"></i><b>14.2.2</b> 내부평가지수</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-solution-interpretation"><i class="fa fa-check"></i><b>14.3</b> 군집해의 해석</a></li>
</ul></li>
<li class="part"><span><b>IV 4부 - 연관규칙</b></span></li>
<li class="chapter" data-level="15" data-path="association-rule.html"><a href="association-rule.html"><i class="fa fa-check"></i><b>15</b> 연관규칙</a><ul>
<li class="chapter" data-level="15.1" data-path="association-rule.html"><a href="association-rule.html#association-packages-install"><i class="fa fa-check"></i><b>15.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="15.2" data-path="association-rule.html"><a href="association-rule.html#association-rule-definition-metric"><i class="fa fa-check"></i><b>15.2</b> 연관규칙의 정의 및 성능척도</a><ul>
<li class="chapter" data-level="15.2.1" data-path="association-rule.html"><a href="association-rule.html#association-rule-support"><i class="fa fa-check"></i><b>15.2.1</b> 지지도</a></li>
<li class="chapter" data-level="15.2.2" data-path="association-rule.html"><a href="association-rule.html#association-rule-confidence"><i class="fa fa-check"></i><b>15.2.2</b> 신뢰도</a></li>
<li class="chapter" data-level="15.2.3" data-path="association-rule.html"><a href="association-rule.html#association-rule-lift"><i class="fa fa-check"></i><b>15.2.3</b> 개선도</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="association-rule.html"><a href="association-rule.html#association-rule-exploration"><i class="fa fa-check"></i><b>15.3</b> 연관규칙의 탐사</a><ul>
<li class="chapter" data-level="15.3.1" data-path="association-rule.html"><a href="association-rule.html#apriori-large-itemsets"><i class="fa fa-check"></i><b>15.3.1</b> 빈발항목집합 생성</a></li>
<li class="chapter" data-level="15.3.2" data-path="association-rule.html"><a href="association-rule.html#apriori-rule-exploration"><i class="fa fa-check"></i><b>15.3.2</b> 규칙의 탐사</a></li>
<li class="chapter" data-level="15.3.3" data-path="association-rule.html"><a href="association-rule.html#apriori-r-package"><i class="fa fa-check"></i><b>15.3.3</b> R 패키지 내 Apriori</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="association-rule.html"><a href="association-rule.html#association-sequential-pattern"><i class="fa fa-check"></i><b>15.4</b> 순차적 패턴의 탐사</a><ul>
<li class="chapter" data-level="15.4.1" data-path="association-rule.html"><a href="association-rule.html#association-aprioriall"><i class="fa fa-check"></i><b>15.4.1</b> AprioriAll 알고리즘</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="recommender-system.html"><a href="recommender-system.html"><i class="fa fa-check"></i><b>16</b> 추천시스템</a><ul>
<li class="chapter" data-level="16.1" data-path="recommender-system.html"><a href="recommender-system.html#recommender-packages-install"><i class="fa fa-check"></i><b>16.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="16.2" data-path="recommender-system.html"><a href="recommender-system.html#content-based-recommender"><i class="fa fa-check"></i><b>16.2</b> 내용기반 추천시스템</a></li>
<li class="chapter" data-level="16.3" data-path="recommender-system.html"><a href="recommender-system.html#collaborative-filtering"><i class="fa fa-check"></i><b>16.3</b> 협업 필터링</a></li>
<li class="chapter" data-level="16.4" data-path="recommender-system.html"><a href="recommender-system.html#market-basket"><i class="fa fa-check"></i><b>16.4</b> 시장바구니 데이터를 이용한 협업 필터링</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">데이터마이닝 with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hierarchical-clustering" class="section level1">
<h1><span class="header-section-number">Chapter 12</span> 계층적 군집방법</h1>
<p>계층적 군집방법에는 집괴법과 분리법이 있으나 주로 집괴법이 사용된다. 본 장에서는 집괴법으로는 연결법을 소개하고, 분리법으로는 다이아나(DIANA)를 소개한다.</p>
<div id="hierarchical-clustering-packages-install" class="section level2">
<h2><span class="header-section-number">12.1</span> 필요 R 패키지 설치</h2>
<p>본 장에서 필요한 R 패키지들은 아래와 같다.</p>
<table>
<thead>
<tr class="header">
<th align="left">package</th>
<th align="left">version</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">tidyverse</td>
<td align="left">1.3.0</td>
</tr>
<tr class="even">
<td align="left">stats</td>
<td align="left">4.0.3</td>
</tr>
<tr class="odd">
<td align="left">cluster</td>
<td align="left">2.1.0</td>
</tr>
</tbody>
</table>
</div>
<div id="distance-between-clusters" class="section level2">
<h2><span class="header-section-number">12.2</span> 군집 간 거리척도 및 연결법</h2>
<p>계층적 군집방법에서는 유사한 객체들을 군집으로 묶고, 다시 유사한 군집을 새로운 군집으로 묶는 등 단계적 절차를 사용한다. 이를 위해서는 군집 간의 유사성 척도 혹은 비유사성 척도가 필요하다.</p>
<ul>
<li><span class="math inline">\(C_i\)</span>: <span class="math inline">\(i\)</span>번째 군집(군집 <span class="math inline">\(i\)</span>)</li>
<li><span class="math inline">\(|C_i|\)</span>: 군집 <span class="math inline">\(i\)</span>의 객체수</li>
<li><span class="math inline">\(\mathbf{c}_i = \left( \bar{x}_1^{(i)}, \bar{x}_2^{(i)}, \cdots, \bar{x}_p^{(i)} \right)\)</span>: 군집 <span class="math inline">\(i\)</span>의 중심좌표(centroid) (<span class="math inline">\(\bar{x}_a^{(i)} = \frac{1}{|C_i|} \sum_{j \in C_i} x_{aj}\)</span>)</li>
<li><span class="math inline">\(d(u, v) = d(\mathbf{x}_u, \mathbf{x}_v)\)</span>: 객체 <span class="math inline">\(u\)</span>와 객체 <span class="math inline">\(v\)</span>의 거리(또는 비유사성 척도)</li>
<li><span class="math inline">\(D(C_i, C_j)\)</span>: 군집 <span class="math inline">\(i\)</span>와 군집 <span class="math inline">\(j\)</span>의 거리(또는 비유사성 척도)</li>
</ul>
<p>군집과 군집 간의 거리척도를 평가하는 방법에 따라 다양한 연결법(linkage method)이 존재한다. 아래에 대표적인 연결법과 군집 간 거리척도를 소개한다.</p>
<table>
<caption><span id="tab:linkage-method">Table 12.1: </span>연결법 종류</caption>
<colgroup>
<col width="30%" />
<col width="69%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">연결법</th>
<th align="center">군집거리 <span class="math inline">\(D(C_i, C_j)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">단일연결법(single linkage method)</td>
<td align="center"><span class="math inline">\(\min_{u \in C_i, \, v \in C_j} d(u, v)\)</span></td>
</tr>
<tr class="even">
<td align="center">완전연결법(complete linkage method)</td>
<td align="center"><span class="math inline">\(\max_{u \in C_i, \, v \in C_j} d(u, v)\)</span></td>
</tr>
<tr class="odd">
<td align="center">평균연결법(average linkage method)</td>
<td align="center"><span class="math inline">\(\frac{1}{&amp;#124;C_i&amp;#124;&amp;#124;C_j&amp;#124;} \sum_{u \in C_i, \, v \in C_j} d(u, v)\)</span></td>
</tr>
<tr class="even">
<td align="center">중심연결법(centroid linkage method)</td>
<td align="center"><span class="math inline">\(d(\mathbf{c}_i, \mathbf{c}_j)\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="linkage-method" class="section level2">
<h2><span class="header-section-number">12.3</span> 연결법의 군집 알고리즘</h2>
<div id="linkage-method-basic-script" class="section level3">
<h3><span class="header-section-number">12.3.1</span> 기본 R 스크립트</h3>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb378-1"><a href="hierarchical-clustering.html#cb378-1"></a>train_df &lt;-<span class="st"> </span><span class="kw">tibble</span>(</span>
<span id="cb378-2"><a href="hierarchical-clustering.html#cb378-2"></a>  <span class="dt">id =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>),</span>
<span id="cb378-3"><a href="hierarchical-clustering.html#cb378-3"></a>  <span class="dt">x1 =</span> <span class="kw">c</span>(<span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">14</span>, <span class="dv">11</span>, <span class="dv">15</span>, <span class="dv">7</span>, <span class="dv">13</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">3</span>),</span>
<span id="cb378-4"><a href="hierarchical-clustering.html#cb378-4"></a>  <span class="dt">x2 =</span> <span class="kw">c</span>(<span class="dv">14</span>,<span class="dv">13</span>, <span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">7</span>, <span class="dv">15</span>, <span class="dv">6</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb378-5"><a href="hierarchical-clustering.html#cb378-5"></a>)</span>
<span id="cb378-6"><a href="hierarchical-clustering.html#cb378-6"></a></span>
<span id="cb378-7"><a href="hierarchical-clustering.html#cb378-7"></a>knitr<span class="op">::</span><span class="kw">kable</span>(train_df, <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,</span>
<span id="cb378-8"><a href="hierarchical-clustering.html#cb378-8"></a>             <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),</span>
<span id="cb378-9"><a href="hierarchical-clustering.html#cb378-9"></a>             <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;객체번호&#39;</span>, <span class="st">&#39;PC 경력(년, $x_1$)&#39;</span>, <span class="st">&#39;사용시간(시간, $x_2$)&#39;</span>),</span>
<span id="cb378-10"><a href="hierarchical-clustering.html#cb378-10"></a>             <span class="dt">caption =</span> <span class="st">&#39;PC 사용자 데이터&#39;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:pc-user-data">Table 12.2: </span>PC 사용자 데이터</caption>
<thead>
<tr class="header">
<th align="right">객체번호</th>
<th align="right">PC 경력(년, <span class="math inline">\(x_1\)</span>)</th>
<th align="right">사용시간(시간, <span class="math inline">\(x_2\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">6</td>
<td align="right">14</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">8</td>
<td align="right">13</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">14</td>
<td align="right">6</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">11</td>
<td align="right">8</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">15</td>
<td align="right">7</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">7</td>
<td align="right">15</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">13</td>
<td align="right">6</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">5</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">3</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">3</td>
<td align="right">2</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb379-1"><a href="hierarchical-clustering.html#cb379-1"></a><span class="kw">theme_set</span>(<span class="kw">theme_gray</span>(<span class="dt">base_family=</span><span class="st">&#39;NanumGothic&#39;</span>))</span>
<span id="cb379-2"><a href="hierarchical-clustering.html#cb379-2"></a><span class="kw">ggplot</span>(train_df, <span class="kw">aes</span>(<span class="dt">x =</span> x1, <span class="dt">y =</span> x2)) <span class="op">+</span></span>
<span id="cb379-3"><a href="hierarchical-clustering.html#cb379-3"></a><span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> id)) <span class="op">+</span></span>
<span id="cb379-4"><a href="hierarchical-clustering.html#cb379-4"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;PC 경력&quot;</span>) <span class="op">+</span></span>
<span id="cb379-5"><a href="hierarchical-clustering.html#cb379-5"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;사용시간&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pc-user-data-plot"></span>
<img src="data-mining-book_files/figure-html/pc-user-data-plot-1.png" alt="PC 사용자 데이터" width="672" />
<p class="caption">
Figure 12.1: PC 사용자 데이터
</p>
</div>
<p>Table <a href="hierarchical-clustering.html#tab:pc-user-data">12.2</a>는 10명의 사람(객체)에 대한 PC 사용경력과 주당 PC 사용시간을 나타낸 것이다. 각 객체가 두 변수로 이루어져 있으며, Figure <a href="hierarchical-clustering.html#fig:pc-user-data-plot">12.1</a>에서 보는 바와 같이 세 개의 군집({1, 2, 6}, {3, 4, 5, 7}, {8, 9, 10})으로 이루어져 있다고 볼 수 있다.</p>
<p>본 장에서 평균연결법에 의한 군집화 과정을 살펴보기로 하자. 우선 R 패키지를 이용해서 간단하게 군집해를 구하는 과정은 아래와 같다.</p>
<ol style="list-style-type: decimal">
<li><code>stats</code> 패키지의 함수 <code>dist</code>를 이용하여 객체간 거리를 계산한다.</li>
<li>1에서 얻은 거리 행렬을 <code>stats</code> 패키지의 <code>hclust</code> 함수에 입력하여 데이터 군집을 분석한다. 이 때, 파라미터 <code>method</code>의 값을 “average”로 설정하면 평균연결법을 이용한다.</li>
</ol>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="hierarchical-clustering.html#cb380-1"></a><span class="kw">dist</span>(train_df[, <span class="dv">-1</span>]) <span class="op">%&gt;%</span></span>
<span id="cb380-2"><a href="hierarchical-clustering.html#cb380-2"></a><span class="st">  </span><span class="kw">hclust</span>(<span class="dt">method =</span> <span class="st">&quot;average&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb380-3"><a href="hierarchical-clustering.html#cb380-3"></a><span class="st">  </span><span class="kw">plot</span>(</span>
<span id="cb380-4"><a href="hierarchical-clustering.html#cb380-4"></a>    <span class="dt">main =</span> <span class="ot">NULL</span>,</span>
<span id="cb380-5"><a href="hierarchical-clustering.html#cb380-5"></a>    <span class="dt">ylab =</span> <span class="st">&quot;distance&quot;</span>,</span>
<span id="cb380-6"><a href="hierarchical-clustering.html#cb380-6"></a>    <span class="dt">xlab =</span> <span class="st">&quot;observation&quot;</span></span>
<span id="cb380-7"><a href="hierarchical-clustering.html#cb380-7"></a>  )</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pc-user-average-linkage"></span>
<img src="data-mining-book_files/figure-html/pc-user-average-linkage-1.png" alt="PC 사용자 데이터에 대한 평균연결법 덴드로그램" width="672" />
<p class="caption">
Figure 12.2: PC 사용자 데이터에 대한 평균연결법 덴드로그램
</p>
</div>
</div>
<div id="linkage-method-algorithm" class="section level3">
<h3><span class="header-section-number">12.3.2</span> 연결법 군집 알고리즘</h3>
<p>각 연결법들은 군집간 유사성 척도 평가 방법이 다를 뿐, 군집화를 위한 알고리즘은 동일하게 아래와 같이 진행된다.</p>
<ol start="0" style="list-style-type: decimal">
<li>단계0: 초기화
<ol style="list-style-type: decimal">
<li>연결법을 선정한다.</li>
<li>각 객체를 하나의 군집으로 간주한다.</li>
<li><span class="math inline">\(k \leftarrow n\)</span></li>
</ol></li>
<li>단계1: 군집
<ol style="list-style-type: decimal">
<li>현재의 군집결과에 있는 모든 군집 간의 쌍에 대하여 <span class="math inline">\(D(C_i, C_j)\)</span>를 산출하여, 이 중 최소가 되는 군집 <span class="math inline">\(i\)</span>와 <span class="math inline">\(j\)</span>를 묶어 하나의 군집으로 만든 후 군집결과를 수정한다.</li>
<li><span class="math inline">\(k \leftarrow k - 1\)</span></li>
</ol></li>
<li>단계2: <span class="math inline">\(k = 1\)</span>이면 Stop, 그렇지 않으면 단계 1을 반복한다.</li>
</ol>
<p>단계1은 객체 수 <span class="math inline">\(n\)</span>만큼 반복된다.</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb381-1"><a href="hierarchical-clustering.html#cb381-1"></a>iteration &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="dt">length =</span> <span class="kw">nrow</span>(train_df))</span></code></pre></div>
<p>임의의 군집해에 대하여, 단계1을 수행하는 함수를 아래와 같이 구현해보자. 아래 함수 <code>merge_cluster</code>는 아래와 같은 두 개의 입력변수를 사용한다.</p>
<ul>
<li><code>df</code>: 객체 데이터 프레임. 열 이름이 <code>id</code>인 열은 객체번호를 나타내어, 객체간 거리 계산에 포함하지 않는다.</li>
<li><code>cluster_label</code>: 두 개의 열로 이루어진 데이터 프레임. 열 <code>id</code>는 객체번호를 나타내며, 열 <code>cluster</code>는 군집 이름을 나타낸다. 하나의 객체는 하나의 군집에만 속할 수 있으나, 하나의 군집은 여러 개의 객체를 포함할 수 있다.</li>
</ul>
<p>함수 수행 결과, 아래와 같은 세 개의 원소를 지닌 리스트를 리턴한다.</p>
<ul>
<li><code>cluster_dist</code>: 군집 간 거리를 나타낸 데이터 프레임. 평균연결법에 기반한 거리.</li>
<li><code>closest_clusters</code>: 입력된 군집해 내에서 가장 가까운 두 군집을 나타낸 데이터 프레임. 두 열 <code>item1</code>과 <code>item2</code>는 각각 군집 이름을 나타내며, <code>distance</code>는 해당 두 군집간의 거리를 나타낸다.</li>
<li><code>new_cluster_label</code>: <code>closest_clusters</code>에 포함된 두 군집을 하나로 묶어 새로운 군집을 만든 후 얻어진 군집해.</li>
</ul>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="hierarchical-clustering.html#cb382-1"></a>merge_cluster &lt;-<span class="st"> </span><span class="cf">function</span>(df, cluster_label) {</span>
<span id="cb382-2"><a href="hierarchical-clustering.html#cb382-2"></a>  <span class="co"># 군집간 거리 계산한다. - 유클리드 거리 및 평균연결법 기반</span></span>
<span id="cb382-3"><a href="hierarchical-clustering.html#cb382-3"></a>  cluster_dist &lt;-<span class="st"> </span><span class="kw">dist</span>(<span class="kw">subset</span>(df, <span class="dt">select =</span> <span class="op">-</span>id), <span class="dt">upper =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb382-4"><a href="hierarchical-clustering.html#cb382-4"></a><span class="st">    </span>broom<span class="op">::</span><span class="kw">tidy</span>() <span class="op">%&gt;%</span></span>
<span id="cb382-5"><a href="hierarchical-clustering.html#cb382-5"></a><span class="st">    </span><span class="kw">mutate_if</span>(is.factor, <span class="op">~</span><span class="st"> </span><span class="kw">as.integer</span>(<span class="kw">as.character</span>(.))) <span class="op">%&gt;%</span></span>
<span id="cb382-6"><a href="hierarchical-clustering.html#cb382-6"></a><span class="st">    </span><span class="kw">inner_join</span>(</span>
<span id="cb382-7"><a href="hierarchical-clustering.html#cb382-7"></a>      cluster_label <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">rename</span>(</span>
<span id="cb382-8"><a href="hierarchical-clustering.html#cb382-8"></a>        <span class="dt">item1 =</span> id, <span class="dt">cluster1 =</span> cluster</span>
<span id="cb382-9"><a href="hierarchical-clustering.html#cb382-9"></a>        ),</span>
<span id="cb382-10"><a href="hierarchical-clustering.html#cb382-10"></a>      <span class="dt">by =</span> <span class="st">&quot;item1&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb382-11"><a href="hierarchical-clustering.html#cb382-11"></a><span class="st">    </span><span class="kw">inner_join</span>(</span>
<span id="cb382-12"><a href="hierarchical-clustering.html#cb382-12"></a>      cluster_label <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">rename</span>(</span>
<span id="cb382-13"><a href="hierarchical-clustering.html#cb382-13"></a>        <span class="dt">item2 =</span> id, <span class="dt">cluster2 =</span> cluster</span>
<span id="cb382-14"><a href="hierarchical-clustering.html#cb382-14"></a>        ),</span>
<span id="cb382-15"><a href="hierarchical-clustering.html#cb382-15"></a>      <span class="dt">by =</span> <span class="st">&quot;item2&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb382-16"><a href="hierarchical-clustering.html#cb382-16"></a><span class="st">    </span><span class="kw">filter</span>(cluster1 <span class="op">!=</span><span class="st"> </span>cluster2) <span class="op">%&gt;%</span></span>
<span id="cb382-17"><a href="hierarchical-clustering.html#cb382-17"></a><span class="st">    </span><span class="kw">group_by</span>(cluster1, cluster2) <span class="op">%&gt;%</span></span>
<span id="cb382-18"><a href="hierarchical-clustering.html#cb382-18"></a><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">distance =</span> <span class="kw">mean</span>(distance)) <span class="op">%&gt;%</span></span>
<span id="cb382-19"><a href="hierarchical-clustering.html#cb382-19"></a><span class="st">    </span><span class="kw">ungroup</span>()</span>
<span id="cb382-20"><a href="hierarchical-clustering.html#cb382-20"></a>  </span>
<span id="cb382-21"><a href="hierarchical-clustering.html#cb382-21"></a>  <span class="co"># 서로 가장 가깝게 위치하는 두 군집을 찾는다.</span></span>
<span id="cb382-22"><a href="hierarchical-clustering.html#cb382-22"></a>  closest_clusters &lt;-<span class="st"> </span>cluster_dist <span class="op">%&gt;%</span></span>
<span id="cb382-23"><a href="hierarchical-clustering.html#cb382-23"></a><span class="st">    </span><span class="kw">arrange</span>(distance) <span class="op">%&gt;%</span></span>
<span id="cb382-24"><a href="hierarchical-clustering.html#cb382-24"></a><span class="st">    </span><span class="kw">slice</span>(<span class="dv">1</span>)</span>
<span id="cb382-25"><a href="hierarchical-clustering.html#cb382-25"></a>  </span>
<span id="cb382-26"><a href="hierarchical-clustering.html#cb382-26"></a>  <span class="co"># 군집해를 업데이트한다.</span></span>
<span id="cb382-27"><a href="hierarchical-clustering.html#cb382-27"></a>  cluster_label[</span>
<span id="cb382-28"><a href="hierarchical-clustering.html#cb382-28"></a>    cluster_label<span class="op">$</span>cluster <span class="op">%in%</span><span class="st"> </span>(</span>
<span id="cb382-29"><a href="hierarchical-clustering.html#cb382-29"></a>      closest_clusters[, <span class="kw">c</span>(<span class="st">&quot;cluster1&quot;</span>, <span class="st">&quot;cluster2&quot;</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()</span>
<span id="cb382-30"><a href="hierarchical-clustering.html#cb382-30"></a>    ),</span>
<span id="cb382-31"><a href="hierarchical-clustering.html#cb382-31"></a>    <span class="st">&quot;cluster&quot;</span></span>
<span id="cb382-32"><a href="hierarchical-clustering.html#cb382-32"></a>  ] &lt;-<span class="st"> </span><span class="kw">paste</span>(</span>
<span id="cb382-33"><a href="hierarchical-clustering.html#cb382-33"></a>    closest_clusters[, <span class="kw">c</span>(<span class="st">&quot;cluster1&quot;</span>, <span class="st">&quot;cluster2&quot;</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>(),</span>
<span id="cb382-34"><a href="hierarchical-clustering.html#cb382-34"></a>    <span class="dt">collapse =</span> <span class="st">&quot;,&quot;</span></span>
<span id="cb382-35"><a href="hierarchical-clustering.html#cb382-35"></a>    )</span>
<span id="cb382-36"><a href="hierarchical-clustering.html#cb382-36"></a>  </span>
<span id="cb382-37"><a href="hierarchical-clustering.html#cb382-37"></a>  <span class="kw">list</span>(<span class="dt">cluster_dist =</span> cluster_dist, </span>
<span id="cb382-38"><a href="hierarchical-clustering.html#cb382-38"></a>       <span class="dt">closest_clusters =</span> closest_clusters, </span>
<span id="cb382-39"><a href="hierarchical-clustering.html#cb382-39"></a>       <span class="dt">new_cluster_label =</span> cluster_label)</span>
<span id="cb382-40"><a href="hierarchical-clustering.html#cb382-40"></a>}</span></code></pre></div>
<p>우선 단계 0에서 얻어지는 군집해에 대한 데이터를 아래와 같이 생성한다.</p>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb383-1"><a href="hierarchical-clustering.html#cb383-1"></a>init_cluster &lt;-<span class="st"> </span><span class="kw">tibble</span>(</span>
<span id="cb383-2"><a href="hierarchical-clustering.html#cb383-2"></a>  <span class="dt">id =</span> train_df<span class="op">$</span>id,</span>
<span id="cb383-3"><a href="hierarchical-clustering.html#cb383-3"></a>  <span class="dt">cluster =</span> <span class="kw">as.character</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(train_df))</span>
<span id="cb383-4"><a href="hierarchical-clustering.html#cb383-4"></a>)</span>
<span id="cb383-5"><a href="hierarchical-clustering.html#cb383-5"></a></span>
<span id="cb383-6"><a href="hierarchical-clustering.html#cb383-6"></a><span class="kw">print</span>(<span class="kw">unique</span>(init_cluster<span class="op">$</span>cluster))</span></code></pre></div>
<pre><code>##  [1] &quot;1&quot;  &quot;2&quot;  &quot;3&quot;  &quot;4&quot;  &quot;5&quot;  &quot;6&quot;  &quot;7&quot;  &quot;8&quot;  &quot;9&quot;  &quot;10&quot;</code></pre>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb385-1"><a href="hierarchical-clustering.html#cb385-1"></a>k &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(init_cluster<span class="op">$</span>cluster))</span>
<span id="cb385-2"><a href="hierarchical-clustering.html#cb385-2"></a></span>
<span id="cb385-3"><a href="hierarchical-clustering.html#cb385-3"></a><span class="kw">print</span>(k)</span></code></pre></div>
<pre><code>## [1] 10</code></pre>
<p>위와 같이, 초기 군집해에서 군집 수는 전체 객체수와 같은 10개이다.</p>
<p>위 초기해로부터 단계1을 아래와 같이 수행해보자.</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb387-1"><a href="hierarchical-clustering.html#cb387-1"></a>iteration[[<span class="dv">1</span>]] &lt;-<span class="st"> </span><span class="kw">merge_cluster</span>(train_df, init_cluster)</span></code></pre></div>
<pre><code>## `summarise()` regrouping output by &#39;cluster1&#39; (override with `.groups` argument)</code></pre>
<p>찾아진 가장 가까운 두 군집은 아래와 같다.</p>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb389-1"><a href="hierarchical-clustering.html#cb389-1"></a>iteration[[<span class="dv">1</span>]]<span class="op">$</span>closest_cluster</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   cluster1 cluster2 distance
##   &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;
## 1 10       9               1</code></pre>
<p>위 두 군집을 하나로 묶은 새로운 군집해는 아래와 같다.</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="hierarchical-clustering.html#cb391-1"></a>iteration[[<span class="dv">1</span>]]<span class="op">$</span>new_cluster_label</span></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##       id cluster
##    &lt;int&gt; &lt;chr&gt;  
##  1     1 1      
##  2     2 2      
##  3     3 3      
##  4     4 4      
##  5     5 5      
##  6     6 6      
##  7     7 7      
##  8     8 8      
##  9     9 10,9   
## 10    10 10,9</code></pre>
<p>위 새로운 군집해의 군집 수는 9이다. 이는 아직 1보다 크므로, 새로 얻어진 군집해로부터 단계 1을 반복한다.</p>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb393-1"><a href="hierarchical-clustering.html#cb393-1"></a>iteration[[<span class="dv">2</span>]] &lt;-<span class="st"> </span><span class="kw">merge_cluster</span>(</span>
<span id="cb393-2"><a href="hierarchical-clustering.html#cb393-2"></a>  train_df,</span>
<span id="cb393-3"><a href="hierarchical-clustering.html#cb393-3"></a>  iteration[[<span class="dv">1</span>]]<span class="op">$</span>new_cluster_label</span>
<span id="cb393-4"><a href="hierarchical-clustering.html#cb393-4"></a>)</span></code></pre></div>
<pre><code>## `summarise()` regrouping output by &#39;cluster1&#39; (override with `.groups` argument)</code></pre>
<p>이번에 찾아진 가장 가까운 두 군집은 아래와 같다.</p>
<div class="sourceCode" id="cb395"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb395-1"><a href="hierarchical-clustering.html#cb395-1"></a>iteration[[<span class="dv">2</span>]]<span class="op">$</span>closest_cluster</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   cluster1 cluster2 distance
##   &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;
## 1 3        7               1</code></pre>
<p>위 두 군집을 하나로 묶은 새로운 군집해는 아래와 같다.</p>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb397-1"><a href="hierarchical-clustering.html#cb397-1"></a>iteration[[<span class="dv">2</span>]]<span class="op">$</span>new_cluster_label</span></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##       id cluster
##    &lt;int&gt; &lt;chr&gt;  
##  1     1 1      
##  2     2 2      
##  3     3 3,7    
##  4     4 4      
##  5     5 5      
##  6     6 6      
##  7     7 3,7    
##  8     8 8      
##  9     9 10,9   
## 10    10 10,9</code></pre>
<p>위 군집해에 기반하여 단계 1을 다시 반복해보자.</p>
<div class="sourceCode" id="cb399"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb399-1"><a href="hierarchical-clustering.html#cb399-1"></a>iteration[[<span class="dv">3</span>]] &lt;-<span class="st"> </span><span class="kw">merge_cluster</span>(</span>
<span id="cb399-2"><a href="hierarchical-clustering.html#cb399-2"></a>  train_df,</span>
<span id="cb399-3"><a href="hierarchical-clustering.html#cb399-3"></a>  iteration[[<span class="dv">2</span>]]<span class="op">$</span>new_cluster_label</span>
<span id="cb399-4"><a href="hierarchical-clustering.html#cb399-4"></a>)</span></code></pre></div>
<pre><code>## `summarise()` regrouping output by &#39;cluster1&#39; (override with `.groups` argument)</code></pre>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="hierarchical-clustering.html#cb401-1"></a><span class="kw">print</span>(iteration[[<span class="dv">3</span>]]<span class="op">$</span>closest_cluster)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   cluster1 cluster2 distance
##   &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;
## 1 1        6            1.41</code></pre>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="hierarchical-clustering.html#cb403-1"></a><span class="kw">print</span>(iteration[[<span class="dv">3</span>]]<span class="op">$</span>new_cluster_label)</span></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##       id cluster
##    &lt;int&gt; &lt;chr&gt;  
##  1     1 1,6    
##  2     2 2      
##  3     3 3,7    
##  4     4 4      
##  5     5 5      
##  6     6 1,6    
##  7     7 3,7    
##  8     8 8      
##  9     9 10,9   
## 10    10 10,9</code></pre>
<p>위와 같은 과정을 전체 객체가 하나의 군집으로 묶일 때까지 아래와 같이 반복하며 군집결과를 출력해보자.</p>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb405-1"><a href="hierarchical-clustering.html#cb405-1"></a><span class="co">#단계0</span></span>
<span id="cb405-2"><a href="hierarchical-clustering.html#cb405-2"></a>init_cluster &lt;-<span class="st"> </span><span class="kw">tibble</span>(</span>
<span id="cb405-3"><a href="hierarchical-clustering.html#cb405-3"></a>  <span class="dt">id =</span> train_df<span class="op">$</span>id,</span>
<span id="cb405-4"><a href="hierarchical-clustering.html#cb405-4"></a>  <span class="dt">cluster =</span> <span class="kw">as.character</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(train_df))</span>
<span id="cb405-5"><a href="hierarchical-clustering.html#cb405-5"></a>)</span>
<span id="cb405-6"><a href="hierarchical-clustering.html#cb405-6"></a></span>
<span id="cb405-7"><a href="hierarchical-clustering.html#cb405-7"></a>i &lt;-<span class="st"> </span>0L</span>
<span id="cb405-8"><a href="hierarchical-clustering.html#cb405-8"></a>current_clusters &lt;-<span class="st"> </span><span class="kw">unique</span>(init_cluster<span class="op">$</span>cluster)</span>
<span id="cb405-9"><a href="hierarchical-clustering.html#cb405-9"></a>k &lt;-<span class="st"> </span><span class="kw">length</span>(current_clusters)</span>
<span id="cb405-10"><a href="hierarchical-clustering.html#cb405-10"></a></span>
<span id="cb405-11"><a href="hierarchical-clustering.html#cb405-11"></a>print_clusters &lt;-<span class="st"> </span><span class="cf">function</span>(i, k, clusters) {</span>
<span id="cb405-12"><a href="hierarchical-clustering.html#cb405-12"></a>  <span class="kw">cat</span>(<span class="st">&quot;Iteration: &quot;</span>, i, <span class="st">&quot;, k = &quot;</span>, k, <span class="st">&quot;, clusters = &quot;</span>, <span class="kw">paste0</span>(<span class="st">&quot;{&quot;</span>, clusters, <span class="st">&quot;}&quot;</span>), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb405-13"><a href="hierarchical-clustering.html#cb405-13"></a>}</span>
<span id="cb405-14"><a href="hierarchical-clustering.html#cb405-14"></a></span>
<span id="cb405-15"><a href="hierarchical-clustering.html#cb405-15"></a><span class="kw">print_clusters</span>(i, k, current_clusters)</span></code></pre></div>
<pre><code>## Iteration:  0 , k =  10 , clusters =  {1} {2} {3} {4} {5} {6} {7} {8} {9} {10}</code></pre>
<div class="sourceCode" id="cb407"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb407-1"><a href="hierarchical-clustering.html#cb407-1"></a><span class="co">#단계1</span></span>
<span id="cb407-2"><a href="hierarchical-clustering.html#cb407-2"></a>iteration &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="dt">length =</span> <span class="kw">nrow</span>(train_df) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</span>
<span id="cb407-3"><a href="hierarchical-clustering.html#cb407-3"></a><span class="cf">while</span>(k <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) {</span>
<span id="cb407-4"><a href="hierarchical-clustering.html#cb407-4"></a>  i &lt;-<span class="st"> </span>i <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb407-5"><a href="hierarchical-clustering.html#cb407-5"></a>  <span class="cf">if</span>(i <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {</span>
<span id="cb407-6"><a href="hierarchical-clustering.html#cb407-6"></a>    iteration[[i]] &lt;-<span class="st"> </span><span class="kw">merge_cluster</span>(</span>
<span id="cb407-7"><a href="hierarchical-clustering.html#cb407-7"></a>      train_df,</span>
<span id="cb407-8"><a href="hierarchical-clustering.html#cb407-8"></a>      init_cluster</span>
<span id="cb407-9"><a href="hierarchical-clustering.html#cb407-9"></a>    )</span>
<span id="cb407-10"><a href="hierarchical-clustering.html#cb407-10"></a>  } <span class="cf">else</span> {</span>
<span id="cb407-11"><a href="hierarchical-clustering.html#cb407-11"></a>    iteration[[i]] &lt;-<span class="st"> </span><span class="kw">merge_cluster</span>(</span>
<span id="cb407-12"><a href="hierarchical-clustering.html#cb407-12"></a>      train_df,</span>
<span id="cb407-13"><a href="hierarchical-clustering.html#cb407-13"></a>      iteration[[i<span class="dv">-1</span>]]<span class="op">$</span>new_cluster_label</span>
<span id="cb407-14"><a href="hierarchical-clustering.html#cb407-14"></a>    )</span>
<span id="cb407-15"><a href="hierarchical-clustering.html#cb407-15"></a>  }</span>
<span id="cb407-16"><a href="hierarchical-clustering.html#cb407-16"></a></span>
<span id="cb407-17"><a href="hierarchical-clustering.html#cb407-17"></a>  current_clusters &lt;-<span class="st"> </span><span class="kw">unique</span>(iteration[[i]]<span class="op">$</span>new_cluster_label<span class="op">$</span>cluster)</span>
<span id="cb407-18"><a href="hierarchical-clustering.html#cb407-18"></a>  k &lt;-<span class="st"> </span><span class="kw">length</span>(current_clusters)</span>
<span id="cb407-19"><a href="hierarchical-clustering.html#cb407-19"></a>  </span>
<span id="cb407-20"><a href="hierarchical-clustering.html#cb407-20"></a>  <span class="kw">print_clusters</span>(i, k, current_clusters)</span>
<span id="cb407-21"><a href="hierarchical-clustering.html#cb407-21"></a>}</span></code></pre></div>
<pre><code>## Iteration:  1 , k =  9 , clusters =  {1} {2} {3} {4} {5} {6} {7} {8} {10,9} 
## Iteration:  2 , k =  8 , clusters =  {1} {2} {3,7} {4} {5} {6} {8} {10,9} 
## Iteration:  3 , k =  7 , clusters =  {1,6} {2} {3,7} {4} {5} {8} {10,9} 
## Iteration:  4 , k =  6 , clusters =  {1,6} {2} {3,7,5} {4} {8} {10,9} 
## Iteration:  5 , k =  5 , clusters =  {1,6,2} {3,7,5} {4} {8} {10,9} 
## Iteration:  6 , k =  4 , clusters =  {1,6,2} {3,7,5} {4} {10,9,8} 
## Iteration:  7 , k =  3 , clusters =  {1,6,2} {3,7,5,4} {10,9,8} 
## Iteration:  8 , k =  2 , clusters =  {1,6,2,3,7,5,4} {10,9,8} 
## Iteration:  9 , k =  1 , clusters =  {1,6,2,3,7,5,4,10,9,8}</code></pre>
</div>
<div id="hclust" class="section level3">
<h3><span class="header-section-number">12.3.3</span> R 패키지 내 연결법</h3>
<p>R에서는 <code>stats</code> 패키지의 <code>hclust</code> 함수를 이용하여 군집해를 구할 수 있다.</p>
<p>우선, 객체간 거리 행렬을 함수 <code>dist</code>를 이용하여 구한다. 아래는 유클리드 거리를 구하는 예이며, 상황에 따라 다른 거리 척도를 이용할 수도 있다.</p>
<div class="sourceCode" id="cb409"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb409-1"><a href="hierarchical-clustering.html#cb409-1"></a>distance_matrix &lt;-<span class="st"> </span><span class="kw">dist</span>(train_df[, <span class="dv">-1</span>])</span></code></pre></div>
<p>객체간 거리를 구한 후, 함수 <code>hclust</code>를 이용하여 군집분석을 수행한다. 기본설정은 완전연결법이며, 파라미터 <code>method</code>의 값을 설정함으로써 단일연결법, 평균연결법, 중심연결법을 수행할 수 있다.</p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="hierarchical-clustering.html#cb410-1"></a>cluster_solution &lt;-<span class="st"> </span><span class="kw">hclust</span>(distance_matrix, <span class="dt">method =</span> <span class="st">&quot;average&quot;</span>)</span></code></pre></div>
<p>결과 객체 <code>cluster_solution</code>는 아래와 같은 컴포넌트(components)를 지닌 리스트(list) 객체이다.</p>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="hierarchical-clustering.html#cb411-1"></a><span class="kw">names</span>(cluster_solution)</span></code></pre></div>
<pre><code>## [1] &quot;merge&quot;       &quot;height&quot;      &quot;order&quot;       &quot;labels&quot;      &quot;method&quot;     
## [6] &quot;call&quot;        &quot;dist.method&quot;</code></pre>
<p>이 중, <code>merge</code>는 2개의 열과 <span class="math inline">\(n - 1\)</span>개의 행으로 이루어진 행렬로, 연결법 알고리즘의 단계1 iteration에서 묶어지는 두 군집을 기록한 것이다.</p>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="hierarchical-clustering.html#cb413-1"></a>cluster_solution<span class="op">$</span>merge</span></code></pre></div>
<pre><code>##       [,1] [,2]
##  [1,]   -3   -7
##  [2,]   -9  -10
##  [3,]   -1   -6
##  [4,]   -5    1
##  [5,]   -2    3
##  [6,]   -8    2
##  [7,]   -4    4
##  [8,]    5    7
##  [9,]    6    8</code></pre>
<p>위에서 각 행은 iteration을 나타내며, 두 열은 묶어지는 두 군집을 나타낸다. 값이 0보다 작은 경우에는 번호가 원 객체 번호를 나타내며, 값이 0보다 큰 경우에는 해당 번호의 iteration에서 묶어진 군집을 나타낸다. 예를 들어, 위 결과의 6번째 행 (-8, 2) 은 객체 8과 두 번째 iteration에서 얻어진 군집 (객체 9와 10이 묶여진 군집)이 묶여 하나의 군집(객체 8, 9, 10)을 이루게 됨을 나타낸다.</p>
<p><code>height</code>는 각 iteration에서 묶이는 두 군집간의 거리를 나타내며, 위 Figure <a href="hierarchical-clustering.html#fig:pc-user-average-linkage">12.2</a>의 덴드로그램에서 세로선의 높이를 나타낸다. Iteration이 증가함에 따라 묶이는 두 군집간의 거리도 증가한다. 일반적으로 이 거리값이 크게 증가하는 iteration에서 두 군집을 묶지 않고 최종 군집해를 도출한다.</p>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb415-1"><a href="hierarchical-clustering.html#cb415-1"></a>cluster_solution<span class="op">$</span>height</span></code></pre></div>
<pre><code>## [1]  1.000000  1.000000  1.414214  1.825141  2.236068  2.532248  3.519028  9.635217
## [9] 10.881878</code></pre>
<p>위 결과의 경우 iteration 8에서 거리값이 크게 증가한다. 이는 위 Figure <a href="hierarchical-clustering.html#fig:pc-user-average-linkage">12.2</a>의 덴드로그램에서 3개의 군집에서 2개의 군집으로 묶이는 과정에서 세로선의 높이가 현격히 증가하는 지점이다. 따라서, iteration 7에서 얻어진 3개의 군집이 적절한 군집해라 판단할 수 있겠다.</p>
</div>
</div>
<div id="ward-method" class="section level2">
<h2><span class="header-section-number">12.4</span> 워드 방법</h2>
<p>워드방법(Ward’s method) 역시 각 객체를 하나의 군집으로 간주함을 시작으로 군집들을 묶어 단계적으로 그 수를 하나가 돌 때까지 줄여나가는 것인데, 군집의 제곱합을 활용한다.</p>
<div id="ward-method-basic-script" class="section level3">
<h3><span class="header-section-number">12.4.1</span> 기본 R 스크립트</h3>
<p>아래 Table <a href="hierarchical-clustering.html#tab:driver-data">12.3</a>는 8명의 운전자에 대한 운전경력과 교통위반 횟수를 나타낸 것이다.</p>
<div class="sourceCode" id="cb417"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb417-1"><a href="hierarchical-clustering.html#cb417-1"></a>train_df &lt;-<span class="st"> </span><span class="kw">tibble</span>(</span>
<span id="cb417-2"><a href="hierarchical-clustering.html#cb417-2"></a>  <span class="dt">id =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">8</span>),</span>
<span id="cb417-3"><a href="hierarchical-clustering.html#cb417-3"></a>  <span class="dt">x1 =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">20</span>, <span class="dv">3</span>, <span class="dv">19</span>, <span class="dv">17</span>, <span class="dv">8</span>, <span class="dv">19</span>, <span class="dv">18</span>),</span>
<span id="cb417-4"><a href="hierarchical-clustering.html#cb417-4"></a>  <span class="dt">x2 =</span> <span class="kw">c</span>(<span class="dv">15</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">4</span>, <span class="dv">17</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">6</span>)</span>
<span id="cb417-5"><a href="hierarchical-clustering.html#cb417-5"></a>)</span>
<span id="cb417-6"><a href="hierarchical-clustering.html#cb417-6"></a></span>
<span id="cb417-7"><a href="hierarchical-clustering.html#cb417-7"></a>knitr<span class="op">::</span><span class="kw">kable</span>(train_df, <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,</span>
<span id="cb417-8"><a href="hierarchical-clustering.html#cb417-8"></a>             <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),</span>
<span id="cb417-9"><a href="hierarchical-clustering.html#cb417-9"></a>             <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;객체번호&#39;</span>, <span class="st">&#39;운전경력($x_1$)&#39;</span>, <span class="st">&#39;위반횟수($x_2$)&#39;</span>),</span>
<span id="cb417-10"><a href="hierarchical-clustering.html#cb417-10"></a>             <span class="dt">caption =</span> <span class="st">&#39;운전경력에 따른 교통위반 횟수&#39;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:driver-data">Table 12.3: </span>운전경력에 따른 교통위반 횟수</caption>
<thead>
<tr class="header">
<th align="right">객체번호</th>
<th align="right">운전경력(<span class="math inline">\(x_1\)</span>)</th>
<th align="right">위반횟수(<span class="math inline">\(x_2\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">4</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">20</td>
<td align="right">13</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">3</td>
<td align="right">13</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">19</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">17</td>
<td align="right">17</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">8</td>
<td align="right">11</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">19</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">18</td>
<td align="right">6</td>
</tr>
</tbody>
</table>
<p>앞 절의 연결법에서 사용했던 <code>hclust</code> 함수를 이용하여 워드 방법에 의한 군집해도 구할 수 있으며, 이 때 파라미터 <code>method</code>의 값으로 “ward.D2”를 사용한다.</p>
<div class="sourceCode" id="cb418"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb418-1"><a href="hierarchical-clustering.html#cb418-1"></a><span class="kw">dist</span>(train_df[, <span class="dv">-1</span>]) <span class="op">%&gt;%</span></span>
<span id="cb418-2"><a href="hierarchical-clustering.html#cb418-2"></a><span class="st">  </span><span class="kw">hclust</span>(<span class="dt">method =</span> <span class="st">&quot;ward.D2&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb418-3"><a href="hierarchical-clustering.html#cb418-3"></a><span class="st">  </span><span class="kw">plot</span>(</span>
<span id="cb418-4"><a href="hierarchical-clustering.html#cb418-4"></a>    <span class="dt">main =</span> <span class="ot">NULL</span>,</span>
<span id="cb418-5"><a href="hierarchical-clustering.html#cb418-5"></a>    <span class="dt">xlab =</span> <span class="st">&quot;observation&quot;</span></span>
<span id="cb418-6"><a href="hierarchical-clustering.html#cb418-6"></a>  )</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ward-dendrogram"></span>
<img src="data-mining-book_files/figure-html/ward-dendrogram-1.png" alt="운전자 데이터에 대한 워드 방법 덴드로그램" width="672" />
<p class="caption">
Figure 12.3: 운전자 데이터에 대한 워드 방법 덴드로그램
</p>
</div>
</div>
<div id="ward-method-algorithm" class="section level3">
<h3><span class="header-section-number">12.4.2</span> 워드 군집 알고리즘</h3>
<p>군집결과가 <span class="math inline">\(\mathbf{C} = \{ C_1, C_2, \cdots, C_k \}\)</span>일 때, 군집 <span class="math inline">\(C_i\)</span> 내의 제곱합(within sum of squares)은 다음과 같이 산출된다.</p>
<p><span class="math display">\[\begin{equation*}
SS(C_i) = \sum_{u \in C_i} \left(\mathbf{x}_u - \mathbf{c}_i\right)^\top\left(\mathbf{x}_u - \mathbf{c}_i\right)
\end{equation*}\]</span></p>
<p>이 때, 전체 군집 내 제곱합을 <span class="math inline">\(SSW\)</span>라 할 때, 이는 다음과 같다.</p>
<p><span class="math display">\[\begin{equation*}
SSW = \sum_{i = 1}^{k} SS(C_i)
\end{equation*}\]</span></p>
<p>다음으로, 현 군집의 각 쌍을 묶는다고 할 때의 새로운 <span class="math inline">\(SSW\)</span>를 산출한 후, 이 값이 가장 작게 되는 군집 쌍을 묶는다.</p>
<ol style="list-style-type: decimal">
<li>단계0
<ol style="list-style-type: decimal">
<li>각 객체를 하나의 군집으로 간주한다.</li>
<li><span class="math inline">\(k \leftarrow n\)</span></li>
</ol></li>
<li>단계1
<ol style="list-style-type: decimal">
<li>현재의 군집 결과에 있는 모든 군집간의 쌍에 대하여 묶을 경우 전체제곱합(SSW)을 산출하고, 이 중 최소가 되는 군집 <span class="math inline">\(i\)</span>와 군집 <span class="math inline">\(j\)</span>를 묶어 하나의 군집으로 만든 후, 군집 결과를 수정한다.</li>
<li><span class="math inline">\(k \leftarrow k - 1\)</span></li>
</ol></li>
<li>단계2: <span class="math inline">\(k = 1\)</span>이면 Stop, 그렇지 않으면 단계1을 반복한다.</li>
</ol>
<p>워드 군집 알고리즘을 R script로 구현해보자. 우선, 객체 데이터 <span class="math inline">\(SSW\)</span>를 계산하는 사용자 정의 함수 <code>calculate_ssw</code>를 아래와 같이 두 입력변수 <code>df</code> 및 <code>cluster_label</code>를 이용하여 구현하자.</p>
<ul>
<li><code>df</code>: 객체 데이터 프레임. 열 이름이 <code>id</code>인 열은 객체번호를 나타내어, 객체간 거리 계산에 포함하지 않는다.</li>
<li><code>cluster_label</code>: 두 개의 열로 이루어진 데이터 프레임. 열 <code>id</code>는 객체번호를 나타내며, 열 <code>cluster</code>는 군집 이름을 나타낸다. 하나의 객체는 하나의 군집에만 속할 수 있으나, 하나의 군집은 여러 개의 객체를 포함할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="hierarchical-clustering.html#cb419-1"></a><span class="co"># SSW 계산</span></span>
<span id="cb419-2"><a href="hierarchical-clustering.html#cb419-2"></a>calculate_ssw &lt;-<span class="st"> </span><span class="cf">function</span>(df, cluster_label) {</span>
<span id="cb419-3"><a href="hierarchical-clustering.html#cb419-3"></a>  df <span class="op">%&gt;%</span></span>
<span id="cb419-4"><a href="hierarchical-clustering.html#cb419-4"></a><span class="st">    </span><span class="kw">inner_join</span>(cluster_label, <span class="dt">by =</span> <span class="st">&quot;id&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb419-5"><a href="hierarchical-clustering.html#cb419-5"></a><span class="st">    </span><span class="kw">group_by</span>(cluster) <span class="op">%&gt;%</span></span>
<span id="cb419-6"><a href="hierarchical-clustering.html#cb419-6"></a><span class="st">    </span><span class="kw">select</span>(<span class="op">-</span>id) <span class="op">%&gt;%</span></span>
<span id="cb419-7"><a href="hierarchical-clustering.html#cb419-7"></a><span class="st">    </span><span class="kw">summarize_all</span>(<span class="cf">function</span>(x) <span class="kw">sum</span>((x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x))<span class="op">^</span><span class="dv">2</span>)) <span class="op">%&gt;%</span></span>
<span id="cb419-8"><a href="hierarchical-clustering.html#cb419-8"></a><span class="st">    </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></span>
<span id="cb419-9"><a href="hierarchical-clustering.html#cb419-9"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">ss =</span> <span class="kw">rowSums</span>(<span class="kw">subset</span>(., <span class="dt">select =</span> <span class="op">-</span>cluster))) <span class="op">%&gt;%</span></span>
<span id="cb419-10"><a href="hierarchical-clustering.html#cb419-10"></a><span class="st">    `</span><span class="dt">[[</span><span class="st">`</span>(<span class="st">&quot;ss&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb419-11"><a href="hierarchical-clustering.html#cb419-11"></a><span class="st">    </span><span class="kw">sum</span>()</span>
<span id="cb419-12"><a href="hierarchical-clustering.html#cb419-12"></a>}</span></code></pre></div>
<p>워드 군집 알고리즘은 현재 군집해 내의 모든 군집쌍에 대하여 두 군집을 하나의 군집으로 묶을 경우의 <span class="math inline">\(SSW\)</span>를 계산해야 한다. 따라서, 우선 고려할 모든 군집해를 생성하는 사용자 정의 함수 <code>generate_clusters</code>를 아래와 같이 구현한다.</p>
<p>아래 사용자 정의 함수 <code>generate_clusters</code>는 임의의 군집해 <code>cluster_label</code>을 입력변수로 사용하며, 해당 입력변수에 대한 설명은 위 함수 <code>calculate_ssw</code>에서와 같다. 함수 수행 결과, 가능한 각각의 군집쌍 결합의 결과물인 군집해 데이터 프레임을 리스트(list) 형태로 출력한다.</p>
<div class="sourceCode" id="cb420"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb420-1"><a href="hierarchical-clustering.html#cb420-1"></a><span class="co"># 임의의 군집해로부터 가능한 다음단계 군집해 생성</span></span>
<span id="cb420-2"><a href="hierarchical-clustering.html#cb420-2"></a>generate_clusters &lt;-<span class="st"> </span><span class="cf">function</span>(cluster_label) {</span>
<span id="cb420-3"><a href="hierarchical-clustering.html#cb420-3"></a>  unique_clusters &lt;-<span class="st"> </span><span class="kw">unique</span>(cluster_label<span class="op">$</span>cluster)</span>
<span id="cb420-4"><a href="hierarchical-clustering.html#cb420-4"></a>  </span>
<span id="cb420-5"><a href="hierarchical-clustering.html#cb420-5"></a>  potential_pairs &lt;-<span class="st"> </span><span class="kw">crossing</span>(<span class="dt">cluster1 =</span> unique_clusters, </span>
<span id="cb420-6"><a href="hierarchical-clustering.html#cb420-6"></a>           <span class="dt">cluster2 =</span> unique_clusters) <span class="op">%&gt;%</span></span>
<span id="cb420-7"><a href="hierarchical-clustering.html#cb420-7"></a><span class="st">    </span><span class="kw">filter</span>(cluster1 <span class="op">&lt;</span><span class="st"> </span>cluster2) <span class="op">%&gt;%</span></span>
<span id="cb420-8"><a href="hierarchical-clustering.html#cb420-8"></a><span class="st">    </span><span class="kw">mutate</span>(<span class="dt">cluster =</span> <span class="kw">paste</span>(cluster1, cluster2, <span class="dt">sep =</span> <span class="st">&quot;,&quot;</span>))</span>
<span id="cb420-9"><a href="hierarchical-clustering.html#cb420-9"></a>  </span>
<span id="cb420-10"><a href="hierarchical-clustering.html#cb420-10"></a>  candidate_solutions &lt;-<span class="st"> </span>potential_pairs <span class="op">%&gt;%</span></span>
<span id="cb420-11"><a href="hierarchical-clustering.html#cb420-11"></a><span class="st">    </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span></span>
<span id="cb420-12"><a href="hierarchical-clustering.html#cb420-12"></a><span class="st">    </span><span class="kw">do</span>(<span class="dt">candidate_solution =</span> <span class="kw">merge_cluster</span>(cluster_label, .)) <span class="op">%&gt;%</span></span>
<span id="cb420-13"><a href="hierarchical-clustering.html#cb420-13"></a><span class="st">    `</span><span class="dt">[[</span><span class="st">`</span>(<span class="st">&quot;candidate_solution&quot;</span>)</span>
<span id="cb420-14"><a href="hierarchical-clustering.html#cb420-14"></a>  </span>
<span id="cb420-15"><a href="hierarchical-clustering.html#cb420-15"></a>  candidate_solutions</span>
<span id="cb420-16"><a href="hierarchical-clustering.html#cb420-16"></a>}</span></code></pre></div>
<p>위에서 보이는 바와 같이, 함수 <code>generate_clusters</code>는 또 다른 사용자 정의함수 <code>merge_cluster</code>를 호출한다. 이 함수는 두 입력변수 <code>cluster_label</code> 및 <code>cluster_merge</code>를 사용하는데, <code>cluster_label</code>에 대한 설명은 위 다른 사용자 정의 함수에서와 동일하며, <code>cluster_merge</code>에 대한 설명은 아래와 같다.</p>
<ul>
<li><code>cluster_merge</code>: 3차원 character 벡터. 첫 두 element는 현재 <code>cluster_label</code>에 존재하는 군집 중 하나의 군집으로 묶일 두 군집의 이름을 나타내며, 세 번째 element는 그 결과 나타나는 군집 이름을 나타낸다.</li>
</ul>
<p>함수 수행 결과, 입력된 <code>cluster_label</code>에서 군집이름이 <code>cluster_merge[1]</code> 혹은 <code>cluster_merge[2]</code>에 해당하는 객체들은, 출력된 군집해에서는 군집이름 <code>cluster_merge[3]</code>을 지닌다.</p>
<div class="sourceCode" id="cb421"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb421-1"><a href="hierarchical-clustering.html#cb421-1"></a><span class="co"># 임의의 군집 결합 규칙 cluster_merge에 따른 군집해</span></span>
<span id="cb421-2"><a href="hierarchical-clustering.html#cb421-2"></a>merge_cluster &lt;-<span class="st"> </span><span class="cf">function</span>(cluster_label, cluster_merge) {</span>
<span id="cb421-3"><a href="hierarchical-clustering.html#cb421-3"></a>  idx &lt;-<span class="st"> </span>cluster_label<span class="op">$</span>cluster <span class="op">%in%</span><span class="st"> </span>cluster_merge[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]</span>
<span id="cb421-4"><a href="hierarchical-clustering.html#cb421-4"></a>  cluster_label[idx, <span class="st">&quot;cluster&quot;</span>] &lt;-<span class="st"> </span>cluster_merge[<span class="dv">3</span>]</span>
<span id="cb421-5"><a href="hierarchical-clustering.html#cb421-5"></a>  cluster_label</span>
<span id="cb421-6"><a href="hierarchical-clustering.html#cb421-6"></a>}</span></code></pre></div>
<p>마지막으로, 현재 군집해로부터 가장 최적의 다음단계 군집해를 얻는 사용자 함수 <code>best_merge_cluster</code>를 아래와 같이 구현해보자.</p>
<ol style="list-style-type: decimal">
<li><code>generate_clusters</code>를 실행하여 다음 단계에 가능한 모든 군집해를 구한다.</li>
<li>1의 각 군집해에 함수 <code>calculate_ssw</code>를 적용하여 <span class="math inline">\(SSW\)</span>값을 구한다.</li>
<li><span class="math inline">\(SSW\)</span>값이 최소인 군집해를 최적 군집해로 선정한다.</li>
</ol>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb422-1"><a href="hierarchical-clustering.html#cb422-1"></a><span class="co"># 최적 군집 결합</span></span>
<span id="cb422-2"><a href="hierarchical-clustering.html#cb422-2"></a>best_merge_cluster &lt;-<span class="st"> </span><span class="cf">function</span>(df, cluster_label) {</span>
<span id="cb422-3"><a href="hierarchical-clustering.html#cb422-3"></a>  candidate_solutions &lt;-<span class="st"> </span><span class="kw">generate_clusters</span>(cluster_label)</span>
<span id="cb422-4"><a href="hierarchical-clustering.html#cb422-4"></a>  ssw &lt;-<span class="st"> </span><span class="kw">sapply</span>(candidate_solutions, <span class="cf">function</span>(x) <span class="kw">calculate_ssw</span>(df, x))</span>
<span id="cb422-5"><a href="hierarchical-clustering.html#cb422-5"></a>  <span class="kw">list</span>(</span>
<span id="cb422-6"><a href="hierarchical-clustering.html#cb422-6"></a>    <span class="dt">new_cluster_label =</span> candidate_solutions[[<span class="kw">which.min</span>(ssw)]],</span>
<span id="cb422-7"><a href="hierarchical-clustering.html#cb422-7"></a>    <span class="dt">new_ssw =</span> <span class="kw">min</span>(ssw)</span>
<span id="cb422-8"><a href="hierarchical-clustering.html#cb422-8"></a>  )</span>
<span id="cb422-9"><a href="hierarchical-clustering.html#cb422-9"></a>}</span></code></pre></div>
<p>위 사용자 함수들을 이용하여 Table <a href="hierarchical-clustering.html#tab:driver-data">12.3</a>에 대한 워드 군집 분석을 수행해보자.</p>
<div class="sourceCode" id="cb423"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb423-1"><a href="hierarchical-clustering.html#cb423-1"></a><span class="co">#단계0</span></span>
<span id="cb423-2"><a href="hierarchical-clustering.html#cb423-2"></a>init_cluster &lt;-<span class="st"> </span><span class="kw">tibble</span>(</span>
<span id="cb423-3"><a href="hierarchical-clustering.html#cb423-3"></a>  <span class="dt">id =</span> train_df<span class="op">$</span>id,</span>
<span id="cb423-4"><a href="hierarchical-clustering.html#cb423-4"></a>  <span class="dt">cluster =</span> <span class="kw">as.character</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(train_df))</span>
<span id="cb423-5"><a href="hierarchical-clustering.html#cb423-5"></a>)</span>
<span id="cb423-6"><a href="hierarchical-clustering.html#cb423-6"></a>i &lt;-<span class="st"> </span>0L</span>
<span id="cb423-7"><a href="hierarchical-clustering.html#cb423-7"></a>current_clusters &lt;-<span class="st"> </span><span class="kw">unique</span>(init_cluster<span class="op">$</span>cluster)</span>
<span id="cb423-8"><a href="hierarchical-clustering.html#cb423-8"></a>k &lt;-<span class="st"> </span><span class="kw">length</span>(current_clusters)</span>
<span id="cb423-9"><a href="hierarchical-clustering.html#cb423-9"></a>ssw &lt;-<span class="st"> </span><span class="kw">calculate_ssw</span>(train_df, init_cluster)</span>
<span id="cb423-10"><a href="hierarchical-clustering.html#cb423-10"></a></span>
<span id="cb423-11"><a href="hierarchical-clustering.html#cb423-11"></a>print_clusters &lt;-<span class="st"> </span><span class="cf">function</span>(i, k, clusters, ssw) {</span>
<span id="cb423-12"><a href="hierarchical-clustering.html#cb423-12"></a>  <span class="kw">cat</span>(<span class="st">&quot;Iteration: &quot;</span>, i, <span class="st">&quot;, k = &quot;</span>, k, <span class="st">&quot;, clusters = &quot;</span>, <span class="kw">paste0</span>(<span class="st">&quot;{&quot;</span>, clusters, <span class="st">&quot;}&quot;</span>), <span class="st">&quot;, SSW =&quot;</span>, ssw, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb423-13"><a href="hierarchical-clustering.html#cb423-13"></a>}</span>
<span id="cb423-14"><a href="hierarchical-clustering.html#cb423-14"></a></span>
<span id="cb423-15"><a href="hierarchical-clustering.html#cb423-15"></a><span class="kw">print_clusters</span>(i, k, current_clusters, ssw)</span></code></pre></div>
<pre><code>## Iteration:  0 , k =  8 , clusters =  {1} {2} {3} {4} {5} {6} {7} {8} , SSW = 0</code></pre>
<div class="sourceCode" id="cb425"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb425-1"><a href="hierarchical-clustering.html#cb425-1"></a><span class="co">#단계1</span></span>
<span id="cb425-2"><a href="hierarchical-clustering.html#cb425-2"></a>iteration &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="dt">length =</span> <span class="kw">nrow</span>(train_df) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</span>
<span id="cb425-3"><a href="hierarchical-clustering.html#cb425-3"></a><span class="cf">while</span>(k <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) {</span>
<span id="cb425-4"><a href="hierarchical-clustering.html#cb425-4"></a>  i &lt;-<span class="st"> </span>i <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb425-5"><a href="hierarchical-clustering.html#cb425-5"></a>  <span class="cf">if</span>(i <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {</span>
<span id="cb425-6"><a href="hierarchical-clustering.html#cb425-6"></a>    iteration[[i]] &lt;-<span class="st"> </span><span class="kw">best_merge_cluster</span>(</span>
<span id="cb425-7"><a href="hierarchical-clustering.html#cb425-7"></a>      train_df,</span>
<span id="cb425-8"><a href="hierarchical-clustering.html#cb425-8"></a>      init_cluster</span>
<span id="cb425-9"><a href="hierarchical-clustering.html#cb425-9"></a>    )</span>
<span id="cb425-10"><a href="hierarchical-clustering.html#cb425-10"></a>  } <span class="cf">else</span> {</span>
<span id="cb425-11"><a href="hierarchical-clustering.html#cb425-11"></a>    iteration[[i]] &lt;-<span class="st"> </span><span class="kw">best_merge_cluster</span>(</span>
<span id="cb425-12"><a href="hierarchical-clustering.html#cb425-12"></a>      train_df,</span>
<span id="cb425-13"><a href="hierarchical-clustering.html#cb425-13"></a>      iteration[[i<span class="dv">-1</span>]]<span class="op">$</span>new_cluster_label</span>
<span id="cb425-14"><a href="hierarchical-clustering.html#cb425-14"></a>    )</span>
<span id="cb425-15"><a href="hierarchical-clustering.html#cb425-15"></a>  }</span>
<span id="cb425-16"><a href="hierarchical-clustering.html#cb425-16"></a></span>
<span id="cb425-17"><a href="hierarchical-clustering.html#cb425-17"></a>  current_clusters &lt;-<span class="st"> </span><span class="kw">unique</span>(iteration[[i]]<span class="op">$</span>new_cluster_label<span class="op">$</span>cluster)</span>
<span id="cb425-18"><a href="hierarchical-clustering.html#cb425-18"></a>  k &lt;-<span class="st"> </span><span class="kw">length</span>(current_clusters)</span>
<span id="cb425-19"><a href="hierarchical-clustering.html#cb425-19"></a>  ssw &lt;-<span class="st"> </span>iteration[[i]]<span class="op">$</span>new_ssw</span>
<span id="cb425-20"><a href="hierarchical-clustering.html#cb425-20"></a>  </span>
<span id="cb425-21"><a href="hierarchical-clustering.html#cb425-21"></a>  <span class="kw">print_clusters</span>(i, k, current_clusters, ssw)</span>
<span id="cb425-22"><a href="hierarchical-clustering.html#cb425-22"></a>}</span></code></pre></div>
<pre><code>## Iteration:  1 , k =  7 , clusters =  {1} {2,7} {3} {4} {5} {6} {8} , SSW = 1 
## Iteration:  2 , k =  6 , clusters =  {1,3} {2,7} {4} {5} {6} {8} , SSW = 3.5 
## Iteration:  3 , k =  5 , clusters =  {1,3} {2,7} {4,8} {5} {6} , SSW = 6 
## Iteration:  4 , k =  4 , clusters =  {1,3} {2,7,5} {4,8} {6} , SSW = 23.66667 
## Iteration:  5 , k =  3 , clusters =  {1,3,6} {2,7,5} {4,8} , SSW = 43.16667 
## Iteration:  6 , k =  2 , clusters =  {1,3,6} {2,7,5,4,8} , SSW = 140.4 
## Iteration:  7 , k =  1 , clusters =  {1,3,6,2,7,5,4,8} , SSW = 499.875</code></pre>
</div>
<div id="ward-rpackages" class="section level3">
<h3><span class="header-section-number">12.4.3</span> R 패키지 내 워드 방법</h3>
<p>R 패키지로 구현된 워드 군집은 위에서 구현한 <span class="math inline">\(SSW\)</span>와는 다소 다른 metric을 이용하여 군집해를 구한다. 따라서, 우선 워드 방법이 제안된 논문들을 살펴볼 필요가 있다.</p>
<p>우선 원 논문 <span class="citation">Ward Jr (<a href="#ref-ward1963hierarchical" role="doc-biblioref">1963</a>)</span> 는 <span class="math inline">\(ESS\)</span>(error sum of squares)를 아래와 같이 정의하였으며, 이는 위에서 사용한 <span class="math inline">\(SSW\)</span>와 일치한다.</p>
<p><span class="math display">\[\begin{equation*}
\begin{split}
ESS(\{C_1, \cdots, C_k \}) &amp;= \sum_{i = 1}^{k} ESS(C_i)\\
&amp;= \sum_{i = 1}^{k} \sum_{u \in C_i} \mathbf{x}_u^\top \mathbf{x}_u - |C_i| \mathbf{c}_i^\top \mathbf{c}_i\\
&amp;= SSW
\end{split}
\end{equation*}\]</span></p>
<p>위 식에서 임의의 두 군집 <span class="math inline">\(C_i\)</span>, <span class="math inline">\(C_j\)</span>를 하나의 군집으로 묶을 때 <span class="math inline">\(SSW\)</span>의 변화는 아래와 같다. <span class="math inline">\(C_i\)</span>와 <span class="math inline">\(C_j\)</span> 외의 군집은 <span class="math inline">\(SSW\)</span>의 변화에 영향을 미치지 않으므로, <span class="math inline">\(SSW\)</span> 변화량은 아래와 같이 군집 <span class="math inline">\(C_i\)</span>와 <span class="math inline">\(C_j\)</span>에 속하는 객체만을 이용하여 구할 수 있으며, 결과적으로 <span class="math inline">\(C_i\)</span>와 <span class="math inline">\(C_j\)</span>의 군집 크기 <span class="math inline">\(|C_i|\)</span>와 <span class="math inline">\(|C_j|\)</span>및 군집 중심벡터 <span class="math inline">\(\mathbf{c}_i\)</span>와 <span class="math inline">\(\mathbf{c}_j\)</span>를 이용하여 구할 수 있다.</p>
<p><span class="math display" id="eq:ward-minimand">\[\begin{equation}
\begin{split}
\Delta SSW =&amp; ESS(C_i \cup C_j) - ESS(C_i) - ESS(C_j)\\
=&amp; \sum_{u \in C_i \cup C_j} \mathbf{x}_u^\top \mathbf{x}_u - (|C_i| + |C_j|)\left[\frac{|C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j}{|C_i| + |C_j|}\right]^\top \left[\frac{|C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j}{|C_i| + |C_j|}\right]\\
&amp; - \left( \sum_{u \in C_i} \mathbf{x}_u^\top \mathbf{x}_u - |C_i| \mathbf{c}_i^\top \mathbf{c}_i \right) - \left( \sum_{u \in C_j} \mathbf{x}_u^\top \mathbf{x}_u - |C_j| \mathbf{c}_j^\top \mathbf{c}_j \right)\\
=&amp; -\frac{1}{|C_i| + |C_j|} \left( |C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j \right)^\top \left( |C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j \right) + |C_i| \mathbf{c}_i^\top \mathbf{c}_i + |C_j| \mathbf{c}_j^\top \mathbf{c}_j\\
=&amp; \frac{|C_i||C_j|}{|C_i| + |C_j|} \left(\mathbf{c}_i - \mathbf{c}_j\right)^\top \left(\mathbf{c}_i - \mathbf{c}_j\right)
\end{split}
\tag{12.1}
\end{equation}\]</span></p>
<p>따라서 워드 방법은 각 iteration에서 식 <a href="hierarchical-clustering.html#eq:ward-minimand">(12.1)</a>를 최소화하는 두 군집 <span class="math inline">\(C_i\)</span>, <span class="math inline">\(C_j\)</span>를 선택하여 두 군집을 하나로 묶는 방법이다.</p>
<p>한편, <span class="math inline">\(SS(C_i)\)</span>는 아래와 같이 군집 <span class="math inline">\(C_i\)</span>내 객체들 간의 제곱 유클리드 거리로 나타낼 수 있다.</p>
<p><span class="math display" id="eq:squared-euclidean-within-cluster">\[\begin{equation}
\begin{split}
D^2(C_i) =&amp; \sum_{u, v \in C_i} (\mathbf{x}_u - \mathbf{x}_v)^\top (\mathbf{x}_u - \mathbf{x}_v)\\
=&amp; \sum_{u, v \in C_i} \left((\mathbf{x}_u - \mathbf{c}_i) - (\mathbf{x}_v - \mathbf{c}_i)\right)^\top \left((\mathbf{x}_u - \mathbf{c}_i) - (\mathbf{x}_v - \mathbf{c}_i)\right)\\
=&amp; 2 \sum_{u \in C_i} (\mathbf{x}_u - \mathbf{c}_i)^\top (\mathbf{x}_u - \mathbf{c}_i) - 2 \sum_{u, v \in C_i} (\mathbf{x}_u - \mathbf{c}_i)^\top (\mathbf{x}_v - \mathbf{c}_i)\\
=&amp; 2 \sum_{u \in C_i} (\mathbf{x}_u - \mathbf{c}_i)^\top (\mathbf{x}_u - \mathbf{c}_i)\\
=&amp; 2 SS(C_i)
\end{split}
\tag{12.2}
\end{equation}\]</span></p>
<p>위 식 <a href="hierarchical-clustering.html#eq:squared-euclidean-within-cluster">(12.2)</a>을 달리 표현하면, 객체간의 제곱 유클리드 거리를 표현한 행렬에서 군집 <span class="math inline">\(i\)</span>에 속한 객체들에 해당하는 부분행렬(submatrix)를 뽑아 행렬의 원소값을 모두 더하면, 그 값이 <span class="math inline">\(2 SS(C_i)\)</span>와 같다. 이를 통해 각 군집의 중심벡터를 계산하지 않고도 각 iteration에서 SSW를 최소화하는 군집 결합을 찾을 수 있다.</p>
<p>R 패키지 <code>stats</code> 내의 <code>hclust</code> 함수는 워드 방법으로 <code>method</code> 파라미터의 값을 “ward.D” 혹은 “ward.D2”로 설정할 수 있다. 이 두 방법의 차이는 입력 거리행렬을 제곱 유클리드 거리로 사용하는지 일반 유클리드 거리로 사용하는지의 차이로, 아래에서 R 스크립트 예제와 함께 설명하기로 한다.</p>
<p>우선 <code>method</code>값을 “ward.D2”로 설정하는 경우, <code>dist</code> 함수의 결과를 입력 거리행렬로 그대로 사용하면 된다.</p>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb427-1"><a href="hierarchical-clustering.html#cb427-1"></a>res_ward.D2 &lt;-<span class="st"> </span><span class="kw">dist</span>(train_df[, <span class="dv">-1</span>]) <span class="op">%&gt;%</span></span>
<span id="cb427-2"><a href="hierarchical-clustering.html#cb427-2"></a><span class="st">  </span><span class="kw">hclust</span>(<span class="dt">method =</span> <span class="st">&quot;ward.D2&quot;</span>)</span></code></pre></div>
<p>이 때, 결과 데이터 <code>res_ward.D2</code>에서 워드 방법의 criterion을 나타내는 <code>height</code> 원소(component)가 표현하는 값은 위에서 계산하였던 <span class="math inline">\(SSW\)</span>와 다르다.</p>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb428-1"><a href="hierarchical-clustering.html#cb428-1"></a>res_ward.D2<span class="op">$</span>height</span></code></pre></div>
<pre><code>## [1]  1.414214  2.236068  2.236068  5.944185  6.244998 13.945131 26.813243</code></pre>
<p>이는 <code>height</code>에서 표현하는 값은 전체 <span class="math inline">\(SSW\)</span>가 아니라, 두 군집 <span class="math inline">\(i\)</span>와 <span class="math inline">\(j\)</span>를 하나로 묶을 때 추가로 증가하는 <span class="math inline">\(SSW\)</span> 수치의 변환으로, 아래와 같이 계산되기 때문이다.</p>
<p><span class="math display" id="eq:hclust-height">\[\begin{equation}
height = \sqrt{D^2(C_i \cup C_j) - \left(D^2(C_i) + D^2(C_j)\right)}
\tag{12.3}
\end{equation}\]</span></p>
<p>따라서, 군집 <span class="math inline">\(i\)</span>와 <span class="math inline">\(j\)</span>를 하나로 묶을 때 증가하는 <span class="math inline">\(SSW\)</span>의 수치 <span class="math inline">\(\Delta SSW\)</span>는 아래와 같이 표현된다.</p>
<p><span class="math display">\[\begin{equation}
\Delta SSW = \frac{1}{2} height^2
\end{equation}\]</span></p>
<p>각 iteration에서 발생하는 <span class="math inline">\(\Delta SSW\)</span>의 누적합이 위 <a href="hierarchical-clustering.html#ward-method-algorithm">12.4.2</a>절에서 보였던 <span class="math inline">\(SSW\)</span> 결과와 동일함을 아래와 같이 확인해보자.</p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb430-1"><a href="hierarchical-clustering.html#cb430-1"></a><span class="kw">tibble</span>(</span>
<span id="cb430-2"><a href="hierarchical-clustering.html#cb430-2"></a>  <span class="dt">iteration =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span>(<span class="kw">nrow</span>(train_df) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)),</span>
<span id="cb430-3"><a href="hierarchical-clustering.html#cb430-3"></a>  <span class="dt">height =</span> res_ward.D2<span class="op">$</span>height</span>
<span id="cb430-4"><a href="hierarchical-clustering.html#cb430-4"></a>) <span class="op">%&gt;%</span></span>
<span id="cb430-5"><a href="hierarchical-clustering.html#cb430-5"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb430-6"><a href="hierarchical-clustering.html#cb430-6"></a>    <span class="dt">delta_ssw =</span> height <span class="op">^</span><span class="st"> </span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb430-7"><a href="hierarchical-clustering.html#cb430-7"></a>  ) <span class="op">%&gt;%</span></span>
<span id="cb430-8"><a href="hierarchical-clustering.html#cb430-8"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb430-9"><a href="hierarchical-clustering.html#cb430-9"></a>    <span class="dt">ssw =</span> <span class="kw">cumsum</span>(delta_ssw)</span>
<span id="cb430-10"><a href="hierarchical-clustering.html#cb430-10"></a>  ) <span class="op">%&gt;%</span></span>
<span id="cb430-11"><a href="hierarchical-clustering.html#cb430-11"></a><span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>(</span>
<span id="cb430-12"><a href="hierarchical-clustering.html#cb430-12"></a>    <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,</span>
<span id="cb430-13"><a href="hierarchical-clustering.html#cb430-13"></a>    <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),</span>
<span id="cb430-14"><a href="hierarchical-clustering.html#cb430-14"></a>    <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;iteration&#39;</span>, <span class="st">&#39;$height$&#39;</span>, <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">Delta SSW = </span><span class="ch">\\</span><span class="st">frac{1}{2} height ^ 2$&#39;</span>, <span class="st">&#39;$SSW = </span><span class="ch">\\</span><span class="st">sum </span><span class="ch">\\</span><span class="st">Delta SSW$&#39;</span>),</span>
<span id="cb430-15"><a href="hierarchical-clustering.html#cb430-15"></a>    <span class="dt">caption =</span> <span class="st">&#39;hclust 함수 ward.D2 방법의 height와 SSW 관계&#39;</span></span>
<span id="cb430-16"><a href="hierarchical-clustering.html#cb430-16"></a>  )</span></code></pre></div>
<table>
<caption><span id="tab:ward-D2-height-ssw">Table 12.4: </span>hclust 함수 ward.D2 방법의 height와 SSW 관계</caption>
<thead>
<tr class="header">
<th align="right">iteration</th>
<th align="right"><span class="math inline">\(height\)</span></th>
<th align="right"><span class="math inline">\(\Delta SSW = \frac{1}{2} height ^ 2\)</span></th>
<th align="right"><span class="math inline">\(SSW = \sum \Delta SSW\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">1.414214</td>
<td align="right">1.00000</td>
<td align="right">1.00000</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">2.236068</td>
<td align="right">2.50000</td>
<td align="right">3.50000</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">2.236068</td>
<td align="right">2.50000</td>
<td align="right">6.00000</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">5.944185</td>
<td align="right">17.66667</td>
<td align="right">23.66667</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">6.244998</td>
<td align="right">19.50000</td>
<td align="right">43.16667</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">13.945131</td>
<td align="right">97.23333</td>
<td align="right">140.40000</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">26.813243</td>
<td align="right">359.47500</td>
<td align="right">499.87500</td>
</tr>
</tbody>
</table>
<p>우선 <code>method</code>값을 “ward.D”로 설정하는 경우, <code>dist</code> 함수의 결과를 입력 거리행렬로 그대로 사용하면 아래와 같이 위 “ward.D2”와는 다른 <code>height</code>값을 출력하며, 이는 워드 방법의 criterion을 정확히 반영하지 못한다.</p>
<div class="sourceCode" id="cb431"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb431-1"><a href="hierarchical-clustering.html#cb431-1"></a>res_ward.D &lt;-<span class="st"> </span><span class="kw">dist</span>(train_df[, <span class="dv">-1</span>]) <span class="op">%&gt;%</span></span>
<span id="cb431-2"><a href="hierarchical-clustering.html#cb431-2"></a><span class="st">  </span><span class="kw">hclust</span>(<span class="dt">method =</span> <span class="st">&quot;ward.D&quot;</span>)</span>
<span id="cb431-3"><a href="hierarchical-clustering.html#cb431-3"></a></span>
<span id="cb431-4"><a href="hierarchical-clustering.html#cb431-4"></a>res_ward.D<span class="op">$</span>height</span></code></pre></div>
<pre><code>## [1]  1.414214  2.236068  2.236068  6.452039  6.615990 17.358484 39.311447</code></pre>
<p>이는 “ward.D2”는 워드 방법 수행 전 입력된 유클리드 거리행렬을 내부적으로 제곱하는 반면, “ward.D” 방법은 제곱 유클리드 거리행렬이 입력되는 것을 가정하기 때문이다.</p>
<p><span class="citation">Lance and Williams (<a href="#ref-lance1967general" role="doc-biblioref">1967</a>)</span> 은 군집 <span class="math inline">\(i\)</span>와 <span class="math inline">\(j\)</span>를 하나로 묶을 때, 새로 생성된 군집과 다른 군집들간의 거리는 원 두 군집들과 다른 군집들간의 거리로 아래와 같이 표현됨을 보였다. 이를 Lance-Williams update 공식이라 한다.</p>
<p><span class="math display" id="eq:lance-williams-update">\[\begin{equation}
D(C_i \cup C_j, C_{h \notin \{i, j\}}) = \alpha_i D(C_i, C_h) + \alpha_j D(C_j, C_h) + \beta D(C_i, C_j) + \gamma |D(C_i, C_h) - D(C_j, C_h)|
\tag{12.4}
\end{equation}\]</span></p>
<p>이후 <span class="citation">Wishart (<a href="#ref-wishart1969256" role="doc-biblioref">1969</a>)</span> 에서 워드 방법을 위 Lance-Williams update 공식으로 표현하였다.</p>
<p><span class="math display" id="eq:wishart">\[\begin{equation}
\begin{split}
\alpha_i =&amp; \frac{|C_i| + |C_h|}{|C_i| + |C_j| + |C_h|}\\
\alpha_j =&amp; \frac{|C_j| + |C_h|}{|C_i| + |C_j| + |C_h|}\\
\beta =&amp; - \frac{|C_h|}{|C_i| + |C_j| + |C_h|}\\
\gamma =&amp; 0
\end{split}
\tag{12.5}
\end{equation}\]</span></p>
<p>이 때, 식 <a href="hierarchical-clustering.html#eq:wishart">(12.5)</a>가 기반한 식 <a href="hierarchical-clustering.html#eq:lance-williams-update">(12.4)</a>에서의 거리함수 <span class="math inline">\(D\)</span>는 제곱 유클리드 거리를 사용한다.</p>
<p>“ward.D” 방법은 제곱 유클리드 거리의 입력을 가정하며, 위의 경우와 같이 제곱 유클리드 거리가 아닌 일반 유클리드 거리행렬을 입력하였을 때, 오류 메시지를 출력하는 대신, 입력된 거리행렬이 제곱 유클리드 거리를 나타낸다 가정하고 Lance-Williams update를 수행한다. 따라서, 이 경우 <code>height</code>는 워드 방법의 criterion을 정확히 표현하지 못한다.</p>
<p>제곱 유클리드 거리를 “ward.D” 방법의 입력 거리행렬로 설정하고, 구해진 <code>height</code>를 출력해보자</p>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="hierarchical-clustering.html#cb433-1"></a>res_ward.D &lt;-<span class="st"> </span><span class="kw">dist</span>(train_df[, <span class="dv">-1</span>])<span class="op">^</span><span class="dv">2</span> <span class="op">%&gt;%</span></span>
<span id="cb433-2"><a href="hierarchical-clustering.html#cb433-2"></a><span class="st">  </span><span class="kw">hclust</span>(<span class="dt">method =</span> <span class="st">&quot;ward.D&quot;</span>)</span>
<span id="cb433-3"><a href="hierarchical-clustering.html#cb433-3"></a></span>
<span id="cb433-4"><a href="hierarchical-clustering.html#cb433-4"></a>res_ward.D<span class="op">$</span>height</span></code></pre></div>
<pre><code>## [1]   2.00000   5.00000   5.00000  35.33333  39.00000 194.46667 718.95000</code></pre>
<p>위 <code>height</code>값은 “ward.D2” 방법에서 출력된 값보다 크다. 위 값의 제곱근(square root)를 구하면 “ward.D2”에서의 <code>height</code>값과 동일한 값을 얻을 수 있다.</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="hierarchical-clustering.html#cb435-1"></a><span class="kw">sqrt</span>(res_ward.D<span class="op">$</span>height)</span></code></pre></div>
<pre><code>## [1]  1.414214  2.236068  2.236068  5.944185  6.244998 13.945131 26.813243</code></pre>
<p>제곱 유클리드 거리행렬을 입력한 “ward.D” 방법의 결과로 출력된 criterion <code>height</code>는 <span class="math inline">\(2 \Delta SSW\)</span>의 값에 해당하는 수치이며, 각 iteration 당 <span class="math inline">\(\sum_i D(C_i)\)</span>의 값의 변화량이라고 볼 수 있다. (식 <a href="hierarchical-clustering.html#eq:squared-euclidean-within-cluster">(12.2)</a> 참조)</p>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="hierarchical-clustering.html#cb437-1"></a><span class="kw">tibble</span>(</span>
<span id="cb437-2"><a href="hierarchical-clustering.html#cb437-2"></a>  <span class="dt">iteration =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span>(<span class="kw">nrow</span>(train_df) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)),</span>
<span id="cb437-3"><a href="hierarchical-clustering.html#cb437-3"></a>  <span class="dt">height =</span> res_ward.D<span class="op">$</span>height</span>
<span id="cb437-4"><a href="hierarchical-clustering.html#cb437-4"></a>) <span class="op">%&gt;%</span></span>
<span id="cb437-5"><a href="hierarchical-clustering.html#cb437-5"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb437-6"><a href="hierarchical-clustering.html#cb437-6"></a>    <span class="dt">delta_ssw =</span> height <span class="op">/</span><span class="st"> </span><span class="dv">2</span></span>
<span id="cb437-7"><a href="hierarchical-clustering.html#cb437-7"></a>  ) <span class="op">%&gt;%</span></span>
<span id="cb437-8"><a href="hierarchical-clustering.html#cb437-8"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb437-9"><a href="hierarchical-clustering.html#cb437-9"></a>    <span class="dt">ssw =</span> <span class="kw">cumsum</span>(delta_ssw)</span>
<span id="cb437-10"><a href="hierarchical-clustering.html#cb437-10"></a>  ) <span class="op">%&gt;%</span></span>
<span id="cb437-11"><a href="hierarchical-clustering.html#cb437-11"></a><span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>(</span>
<span id="cb437-12"><a href="hierarchical-clustering.html#cb437-12"></a>    <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,</span>
<span id="cb437-13"><a href="hierarchical-clustering.html#cb437-13"></a>    <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),</span>
<span id="cb437-14"><a href="hierarchical-clustering.html#cb437-14"></a>    <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;iteration&#39;</span>, <span class="st">&#39;$height$&#39;</span>, <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">Delta SSW = </span><span class="ch">\\</span><span class="st">frac{1}{2} height$&#39;</span>, <span class="st">&#39;$SSW = </span><span class="ch">\\</span><span class="st">sum </span><span class="ch">\\</span><span class="st">Delta SSW$&#39;</span>),</span>
<span id="cb437-15"><a href="hierarchical-clustering.html#cb437-15"></a>    <span class="dt">caption =</span> <span class="st">&#39;hclust 함수 ward.D 방법의 height와 SSW 관계&#39;</span></span>
<span id="cb437-16"><a href="hierarchical-clustering.html#cb437-16"></a>  )</span></code></pre></div>
<table>
<caption><span id="tab:ward-D-height-ssw">Table 12.5: </span>hclust 함수 ward.D 방법의 height와 SSW 관계</caption>
<thead>
<tr class="header">
<th align="right">iteration</th>
<th align="right"><span class="math inline">\(height\)</span></th>
<th align="right"><span class="math inline">\(\Delta SSW = \frac{1}{2} height\)</span></th>
<th align="right"><span class="math inline">\(SSW = \sum \Delta SSW\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">2.00000</td>
<td align="right">1.00000</td>
<td align="right">1.00000</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">5.00000</td>
<td align="right">2.50000</td>
<td align="right">3.50000</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">5.00000</td>
<td align="right">2.50000</td>
<td align="right">6.00000</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">35.33333</td>
<td align="right">17.66667</td>
<td align="right">23.66667</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">39.00000</td>
<td align="right">19.50000</td>
<td align="right">43.16667</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">194.46667</td>
<td align="right">97.23333</td>
<td align="right">140.40000</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">718.95000</td>
<td align="right">359.47500</td>
<td align="right">499.87500</td>
</tr>
</tbody>
</table>
<p>즉, “ward.D2”와 “ward.D”의 가장 큰 차이는 입력될 거리행렬이 유클리드 거리(ward.D2)인지 제곱 유클리드 거리(ward.D)인지의 차이이다.</p>
<p>참고로, <code>cluster</code> 패키지의 <code>agnes</code>함수도 워드 방법을 지원하며, 이 경우 파라미터 <code>method</code>의 값을 “ward”로 설정한 결과가 <code>hclust</code>함수의 “ward.D2”의 경우와 동일하다. 본 절에서는 해당 함수의 자세한 사용법은 생략한다.</p>
<div class="sourceCode" id="cb438"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb438-1"><a href="hierarchical-clustering.html#cb438-1"></a>res_agnes_ward &lt;-<span class="st"> </span>cluster<span class="op">::</span><span class="kw">agnes</span>(train_df[, <span class="dv">-1</span>], <span class="dt">method =</span> <span class="st">&quot;ward&quot;</span>)</span>
<span id="cb438-2"><a href="hierarchical-clustering.html#cb438-2"></a></span>
<span id="cb438-3"><a href="hierarchical-clustering.html#cb438-3"></a><span class="kw">sort</span>(res_agnes_ward<span class="op">$</span>height)</span></code></pre></div>
<pre><code>## [1]  1.414214  2.236068  2.236068  5.944185  6.244998 13.945131 26.813243</code></pre>
</div>
</div>
<div id="diana" class="section level2">
<h2><span class="header-section-number">12.5</span> 분리적 방법 - 다이아나</h2>
<p>다이아나는 분리적 방법의 하나로, <span class="citation">Kaufman and Rousseeuw (<a href="#ref-kaufman1990finding" role="doc-biblioref">1990</a>)</span> 에 의하여 제안된 것이다. 이는 전체의 객체를 하나의 군집으로 시작하여 매번 이분화하는 등 모든 군집이 단독 객체로 구성될 때까지 진행하는 방법이다. 이 때, 비유사성 척도로는 평균거리를 사용한다.</p>
<div id="diana-basic-script" class="section level3">
<h3><span class="header-section-number">12.5.1</span> 기본 R 스크립트</h3>
<div class="sourceCode" id="cb440"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb440-1"><a href="hierarchical-clustering.html#cb440-1"></a>train_df &lt;-<span class="st"> </span><span class="kw">tibble</span>(</span>
<span id="cb440-2"><a href="hierarchical-clustering.html#cb440-2"></a>  <span class="dt">id =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">7</span>),</span>
<span id="cb440-3"><a href="hierarchical-clustering.html#cb440-3"></a>  <span class="dt">x1 =</span> <span class="kw">c</span>(<span class="dv">30</span>, <span class="dv">45</span>, <span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">50</span>, <span class="dv">20</span>, <span class="dv">42</span>),</span>
<span id="cb440-4"><a href="hierarchical-clustering.html#cb440-4"></a>  <span class="dt">x2 =</span> <span class="kw">c</span>(<span class="dv">15</span>, <span class="dv">22</span>, <span class="dv">12</span>, <span class="dv">24</span>, <span class="dv">25</span>, <span class="dv">10</span>, <span class="dv">9</span>)</span>
<span id="cb440-5"><a href="hierarchical-clustering.html#cb440-5"></a>)</span>
<span id="cb440-6"><a href="hierarchical-clustering.html#cb440-6"></a></span>
<span id="cb440-7"><a href="hierarchical-clustering.html#cb440-7"></a>knitr<span class="op">::</span><span class="kw">kable</span>(train_df, <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,</span>
<span id="cb440-8"><a href="hierarchical-clustering.html#cb440-8"></a>             <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),</span>
<span id="cb440-9"><a href="hierarchical-clustering.html#cb440-9"></a>             <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;객체번호&#39;</span>, <span class="st">&#39;$x_1$&#39;</span>, <span class="st">&#39;$x_2$&#39;</span>),</span>
<span id="cb440-10"><a href="hierarchical-clustering.html#cb440-10"></a>             <span class="dt">caption =</span> <span class="st">&#39;DIANA 군집 대상 객체 데이터&#39;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:diana-data">Table 12.6: </span>DIANA 군집 대상 객체 데이터</caption>
<thead>
<tr class="header">
<th align="right">객체번호</th>
<th align="right"><span class="math inline">\(x_1\)</span></th>
<th align="right"><span class="math inline">\(x_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">30</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">45</td>
<td align="right">22</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">25</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">40</td>
<td align="right">24</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">50</td>
<td align="right">25</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">20</td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">42</td>
<td align="right">9</td>
</tr>
</tbody>
</table>
<p>Table <a href="hierarchical-clustering.html#tab:diana-data">12.6</a>와 같이 두 변수 <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>로 이루어진 7개의 객체 데이터에 대해 DIANA 방법에 의해 군집해를 아래와 같이 <code>cluster</code> 패키지의 <code>diana</code> 함수를 이용하여 간단히 구할 수 있다.</p>
<div class="sourceCode" id="cb441"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb441-1"><a href="hierarchical-clustering.html#cb441-1"></a>res_diana &lt;-<span class="st"> </span>cluster<span class="op">::</span><span class="kw">diana</span>(train_df[, <span class="dv">-1</span>])</span>
<span id="cb441-2"><a href="hierarchical-clustering.html#cb441-2"></a>cluster<span class="op">::</span><span class="kw">pltree</span>(res_diana,</span>
<span id="cb441-3"><a href="hierarchical-clustering.html#cb441-3"></a>                <span class="dt">main =</span> <span class="ot">NULL</span>,</span>
<span id="cb441-4"><a href="hierarchical-clustering.html#cb441-4"></a>                <span class="dt">xlab =</span> <span class="st">&quot;observation&quot;</span></span>
<span id="cb441-5"><a href="hierarchical-clustering.html#cb441-5"></a>                )</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:diana-result-plot"></span>
<img src="data-mining-book_files/figure-html/diana-result-plot-1.png" alt="DIANA 방법에 의한 군집 덴드로그램" width="672" />
<p class="caption">
Figure 12.4: DIANA 방법에 의한 군집 덴드로그램
</p>
</div>
</div>
<div id="diana-algorithm" class="section level3">
<h3><span class="header-section-number">12.5.2</span> 다이아나 알고리즘</h3>
<p>가장 처음 이분화가 이루어질 때, 우선 타 객체와의 평균거리가 가장 큰 객체가 분파되어 새로운 군집을 형성한다. 그리고 다른 객체에 대하여, 군집에 남아있을 때의 평균거리와 새로운 군집으로 분리될 때의 평균거리를 산출하여, 현 군집에 잔류 또는 새로운 군집으로의 합류를 결정한다.</p>
<p>여기서 객체 <span class="math inline">\(i\)</span>와 군집 <span class="math inline">\(C\)</span>간의 평균거리는 다음과 같이 산출된다.</p>
<p><span class="math display">\[\begin{equation*}
\bar{d}(i, C) = \begin{cases}
\frac{1}{|C| - 1} \sum_{j \in C} d(i, j) &amp; \text{ if } i \in C\\
\frac{1}{|C|} \sum_{j \in C} d(i, j) &amp; \text{ if } i \notin C
\end{cases}
\end{equation*}\]</span></p>
<p>본 방법의 알고리즘은 다음과 같다.</p>
<ol style="list-style-type: decimal">
<li>단계0: <span class="math inline">\(n\)</span>개의 객체를 하나의 군집으로 간주한다. (<span class="math inline">\(k = 1\)</span>)</li>
<li>단계1: 객체 간 거리가 가장 큰 두 객체를 포함한 군집을 이분화 대상으로 선정한다. (이를 <span class="math inline">\(A\)</span>라 하고, <span class="math inline">\(B \leftarrow \emptyset\)</span>로 둔다.)</li>
<li>단계2: 다음 과정을 통하여 군집 <span class="math inline">\(A\)</span>를 이분화한다.
<ol style="list-style-type: decimal">
<li>단계2-1: <span class="math inline">\(i \leftarrow \arg\,\max_{i&#39;} \bar{d}(i&#39;, A)\)</span></li>
<li>단계2-2: <span class="math inline">\(A \leftarrow A - \{i\}\)</span>, <span class="math inline">\(B \leftarrow B \cup \{i\}\)</span></li>
<li>단계2-3: <span class="math inline">\(i \leftarrow \arg\,\max_{i&#39; \in A} e(i&#39;) = \bar{d}(i&#39;, A) - \bar{d}(i&#39;, B)\)</span></li>
<li>단계2-4: <span class="math inline">\(e(i) &gt; 0\)</span>이면 단계2-2로, <span class="math inline">\(e(i) \le 0\)</span>이면 단계3으로</li>
</ol></li>
<li>단계3
<ol style="list-style-type: decimal">
<li><span class="math inline">\(k \leftarrow k + 1\)</span></li>
<li><span class="math inline">\(k &lt; n\)</span>이면 단계1로, <span class="math inline">\(k = n\)</span>이면 Stop.</li>
</ol></li>
</ol>
<p>DIANA 알고리즘을 R script로 구현해보자.</p>
<p>우선, 단계1의 군집을 찾는 함수 <code>max_distance_cluster</code>를 구현하자. 이 함수는 아래 두 개의 데이터 프레임을 입력받는다.</p>
<ul>
<li>입력
<ul>
<li><code>df</code>: 관측 데이터. 각 열의 설명은 아래와 같다.
<ul>
<li><code>id</code>: 객체번호</li>
<li>나머지 열: 숫자형 변수</li>
</ul></li>
<li><code>cluster_label</code>: 각 객체의 현재 소속 군집을 나타내는 데이터 프레임
<ul>
<li><code>id</code>: 객체번호</li>
<li><code>cluster</code>: 군집명</li>
</ul></li>
</ul></li>
<li>함수값
<ul>
<li><code>cluster</code>: 객체간 거리가 가장 큰 두 객체를 포함한 군집명</li>
<li><code>distance</code>: 군집 내 객체간 최대 거리</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb442-1"><a href="hierarchical-clustering.html#cb442-1"></a>max_distance_cluster &lt;-<span class="st"> </span><span class="cf">function</span>(df, cluster_label) {</span>
<span id="cb442-2"><a href="hierarchical-clustering.html#cb442-2"></a>  unique_cluster &lt;-<span class="st"> </span><span class="kw">unique</span>(cluster_label<span class="op">$</span>cluster)</span>
<span id="cb442-3"><a href="hierarchical-clustering.html#cb442-3"></a>  </span>
<span id="cb442-4"><a href="hierarchical-clustering.html#cb442-4"></a>  cluster_df &lt;-<span class="st"> </span><span class="kw">lapply</span>(unique_cluster, <span class="cf">function</span>(x) {</span>
<span id="cb442-5"><a href="hierarchical-clustering.html#cb442-5"></a>    cluster_label <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb442-6"><a href="hierarchical-clustering.html#cb442-6"></a><span class="st">      </span><span class="kw">filter</span>(cluster <span class="op">==</span><span class="st"> </span>x) <span class="op">%&gt;%</span></span>
<span id="cb442-7"><a href="hierarchical-clustering.html#cb442-7"></a><span class="st">      </span><span class="kw">inner_join</span>(df, <span class="dt">by =</span> <span class="st">&quot;id&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb442-8"><a href="hierarchical-clustering.html#cb442-8"></a><span class="st">      </span><span class="kw">select</span>(<span class="op">-</span>cluster, <span class="op">-</span>id)</span>
<span id="cb442-9"><a href="hierarchical-clustering.html#cb442-9"></a>    })</span>
<span id="cb442-10"><a href="hierarchical-clustering.html#cb442-10"></a>  </span>
<span id="cb442-11"><a href="hierarchical-clustering.html#cb442-11"></a>  max_distance &lt;-<span class="st"> </span><span class="kw">sapply</span>(cluster_df, </span>
<span id="cb442-12"><a href="hierarchical-clustering.html#cb442-12"></a>                         <span class="cf">function</span>(x) {</span>
<span id="cb442-13"><a href="hierarchical-clustering.html#cb442-13"></a>                           <span class="cf">if</span>(<span class="kw">nrow</span>(x) <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="kw">return</span>(<span class="dv">0</span>)</span>
<span id="cb442-14"><a href="hierarchical-clustering.html#cb442-14"></a>                           <span class="kw">max</span>(<span class="kw">dist</span>(x))</span>
<span id="cb442-15"><a href="hierarchical-clustering.html#cb442-15"></a>                         }</span>
<span id="cb442-16"><a href="hierarchical-clustering.html#cb442-16"></a>                         )</span>
<span id="cb442-17"><a href="hierarchical-clustering.html#cb442-17"></a></span>
<span id="cb442-18"><a href="hierarchical-clustering.html#cb442-18"></a>  <span class="kw">list</span>(</span>
<span id="cb442-19"><a href="hierarchical-clustering.html#cb442-19"></a>    <span class="dt">cluster =</span> unique_cluster[<span class="kw">which.max</span>(max_distance)],</span>
<span id="cb442-20"><a href="hierarchical-clustering.html#cb442-20"></a>    <span class="dt">distance =</span> <span class="kw">max</span>(max_distance)</span>
<span id="cb442-21"><a href="hierarchical-clustering.html#cb442-21"></a>  )</span>
<span id="cb442-22"><a href="hierarchical-clustering.html#cb442-22"></a>}</span></code></pre></div>
<p>단계 2-1에서 군집 내 평균거리가 가장 큰 객체를 찾는 함수 <code>max_within_distance</code>를 아래와 같이 구현해보자. 이 때 입력변수인 <code>cluster_df</code>는 해당 군집의 객체 데이터로, 객체 번호를 나타내는 열 <code>id</code>와 객체의 각 숫자형 변수를 표현하는 열들로 구성된다.</p>
<div class="sourceCode" id="cb443"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb443-1"><a href="hierarchical-clustering.html#cb443-1"></a>max_within_distance &lt;-<span class="st"> </span><span class="cf">function</span>(cluster_df) {</span>
<span id="cb443-2"><a href="hierarchical-clustering.html#cb443-2"></a>  idx &lt;-<span class="st"> </span><span class="kw">dist</span>(<span class="kw">subset</span>(cluster_df, <span class="dt">select =</span> <span class="op">-</span>id), <span class="dt">upper =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span></span>
<span id="cb443-3"><a href="hierarchical-clustering.html#cb443-3"></a><span class="st">    </span>broom<span class="op">::</span><span class="kw">tidy</span>() <span class="op">%&gt;%</span></span>
<span id="cb443-4"><a href="hierarchical-clustering.html#cb443-4"></a><span class="st">    </span><span class="kw">group_by</span>(item1) <span class="op">%&gt;%</span></span>
<span id="cb443-5"><a href="hierarchical-clustering.html#cb443-5"></a><span class="st">    </span><span class="kw">summarize</span>(<span class="dt">mean_distance =</span> <span class="kw">mean</span>(distance)) <span class="op">%&gt;%</span></span>
<span id="cb443-6"><a href="hierarchical-clustering.html#cb443-6"></a><span class="st">    </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span></span>
<span id="cb443-7"><a href="hierarchical-clustering.html#cb443-7"></a><span class="st">    </span><span class="kw">arrange</span>(<span class="op">-</span>mean_distance) <span class="op">%&gt;%</span></span>
<span id="cb443-8"><a href="hierarchical-clustering.html#cb443-8"></a><span class="st">    </span>.[[<span class="st">&quot;item1&quot;</span>]] <span class="op">%&gt;%</span></span>
<span id="cb443-9"><a href="hierarchical-clustering.html#cb443-9"></a><span class="st">    </span>.[<span class="dv">1</span>]</span>
<span id="cb443-10"><a href="hierarchical-clustering.html#cb443-10"></a>  </span>
<span id="cb443-11"><a href="hierarchical-clustering.html#cb443-11"></a>  cluster_df<span class="op">$</span>id[idx]</span>
<span id="cb443-12"><a href="hierarchical-clustering.html#cb443-12"></a>}</span></code></pre></div>
<p>이후 단계2-3에서 정의한 <span class="math inline">\(e(i&#39;) = \bar{d}(i&#39;, A) - \bar{d}(i&#39;, B)\)</span>를 계산하는 함수 <code>e_score</code>를 아래와 같이 구현한다.</p>
<ul>
<li><code>object</code>: 객체 번호(<code>id</code>)</li>
<li><code>A</code>(<code>B</code>): 군집 <span class="math inline">\(A\)</span>(<span class="math inline">\(B\)</span>)의 객체 데이터. 행은 객체를 나타내며, <code>id</code> 열은 객체 번호, 이외의 열들은 변수를 나타낸다.</li>
</ul>
<div class="sourceCode" id="cb444"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb444-1"><a href="hierarchical-clustering.html#cb444-1"></a>e_score &lt;-<span class="st"> </span><span class="cf">function</span>(object, A, B) {</span>
<span id="cb444-2"><a href="hierarchical-clustering.html#cb444-2"></a>  d_from_A &lt;-<span class="st"> </span>proxy<span class="op">::</span><span class="kw">dist</span>(<span class="kw">subset</span>(A, id <span class="op">==</span><span class="st"> </span>object, <span class="op">-</span>id), </span>
<span id="cb444-3"><a href="hierarchical-clustering.html#cb444-3"></a>                          <span class="kw">subset</span>(A, id <span class="op">!=</span><span class="st"> </span>object, <span class="op">-</span>id)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb444-4"><a href="hierarchical-clustering.html#cb444-4"></a><span class="st">    </span><span class="kw">mean</span>()</span>
<span id="cb444-5"><a href="hierarchical-clustering.html#cb444-5"></a>  d_from_B &lt;-<span class="st"> </span>proxy<span class="op">::</span><span class="kw">dist</span>(<span class="kw">subset</span>(A, id <span class="op">==</span><span class="st"> </span>object, <span class="op">-</span>id), </span>
<span id="cb444-6"><a href="hierarchical-clustering.html#cb444-6"></a>                          B <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>id)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb444-7"><a href="hierarchical-clustering.html#cb444-7"></a><span class="st">    </span><span class="kw">mean</span>()</span>
<span id="cb444-8"><a href="hierarchical-clustering.html#cb444-8"></a>  <span class="kw">return</span>(d_from_A <span class="op">-</span><span class="st"> </span>d_from_B)</span>
<span id="cb444-9"><a href="hierarchical-clustering.html#cb444-9"></a>}</span></code></pre></div>
<p>위 두 함수 <code>max_within_distance</code>와 <code>e_score</code>를 이용하여, 주어진 데이터 프레임을 두 군집으로 나누는 함수 <code>split_cluster</code>를 구현해보자.</p>
<ul>
<li>입력: 객체 데이터를 나타내는 데이터 프레임 <code>cluster_df</code>. 행은 객체를 나타내며, 객체 번호를 나타내는 열 <code>id</code>와 객체의 각 숫자형 변수를 표현하는 열들로 구성된다.</li>
<li>함수값: 아래 두 개의 component를 지닌 리스트.
<ul>
<li><code>idx_A</code>: 객체 데이터에서 행렬 <span class="math inline">\(A\)</span>에 속하는 객체 번호</li>
<li><code>idx_B</code>: 객체 데이터에서 행렬 <span class="math inline">\(B\)</span>에 속하는 객체 번호</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb445"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb445-1"><a href="hierarchical-clustering.html#cb445-1"></a>split_cluster &lt;-<span class="st"> </span><span class="cf">function</span>(cluster_df) {</span>
<span id="cb445-2"><a href="hierarchical-clustering.html#cb445-2"></a>  n &lt;-<span class="st"> </span><span class="kw">nrow</span>(cluster_df)</span>
<span id="cb445-3"><a href="hierarchical-clustering.html#cb445-3"></a>  </span>
<span id="cb445-4"><a href="hierarchical-clustering.html#cb445-4"></a>  idx_A &lt;-<span class="st"> </span>cluster_df<span class="op">$</span>id</span>
<span id="cb445-5"><a href="hierarchical-clustering.html#cb445-5"></a>  idx_B &lt;-<span class="st"> </span><span class="ot">NULL</span></span>
<span id="cb445-6"><a href="hierarchical-clustering.html#cb445-6"></a>  </span>
<span id="cb445-7"><a href="hierarchical-clustering.html#cb445-7"></a>  <span class="co"># 단계2-1</span></span>
<span id="cb445-8"><a href="hierarchical-clustering.html#cb445-8"></a>  max_object &lt;-<span class="st"> </span><span class="kw">max_within_distance</span>(cluster_df)</span>
<span id="cb445-9"><a href="hierarchical-clustering.html#cb445-9"></a>  e_i &lt;-<span class="st"> </span><span class="ot">Inf</span></span>
<span id="cb445-10"><a href="hierarchical-clustering.html#cb445-10"></a></span>
<span id="cb445-11"><a href="hierarchical-clustering.html#cb445-11"></a>  <span class="cf">while</span>(e_i <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>) {</span>
<span id="cb445-12"><a href="hierarchical-clustering.html#cb445-12"></a>    <span class="co"># 단계2-2</span></span>
<span id="cb445-13"><a href="hierarchical-clustering.html#cb445-13"></a>    idx_B &lt;-<span class="st"> </span><span class="kw">c</span>(idx_B, max_object)</span>
<span id="cb445-14"><a href="hierarchical-clustering.html#cb445-14"></a>    idx_A &lt;-<span class="st"> </span><span class="kw">setdiff</span>(idx_A, max_object)</span>
<span id="cb445-15"><a href="hierarchical-clustering.html#cb445-15"></a>    </span>
<span id="cb445-16"><a href="hierarchical-clustering.html#cb445-16"></a>    A &lt;-<span class="st"> </span>cluster_df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(id <span class="op">%in%</span><span class="st"> </span>idx_A)</span>
<span id="cb445-17"><a href="hierarchical-clustering.html#cb445-17"></a>    B &lt;-<span class="st"> </span>cluster_df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(id <span class="op">%in%</span><span class="st"> </span>idx_B)</span>
<span id="cb445-18"><a href="hierarchical-clustering.html#cb445-18"></a></span>
<span id="cb445-19"><a href="hierarchical-clustering.html#cb445-19"></a>    <span class="co"># 단계2-3</span></span>
<span id="cb445-20"><a href="hierarchical-clustering.html#cb445-20"></a>    <span class="cf">if</span>(<span class="kw">nrow</span>(A) <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) {</span>
<span id="cb445-21"><a href="hierarchical-clustering.html#cb445-21"></a>      e_is &lt;-<span class="st"> </span><span class="kw">sapply</span>(A<span class="op">$</span>id, <span class="cf">function</span>(x) <span class="kw">e_score</span>(x, A, B))</span>
<span id="cb445-22"><a href="hierarchical-clustering.html#cb445-22"></a>      max_object &lt;-<span class="st"> </span>A<span class="op">$</span>id[<span class="kw">which.max</span>(e_is)]</span>
<span id="cb445-23"><a href="hierarchical-clustering.html#cb445-23"></a>      e_i &lt;-<span class="st"> </span><span class="kw">max</span>(e_is)</span>
<span id="cb445-24"><a href="hierarchical-clustering.html#cb445-24"></a>    } <span class="cf">else</span> {</span>
<span id="cb445-25"><a href="hierarchical-clustering.html#cb445-25"></a>      e_i &lt;-<span class="st"> </span><span class="op">-</span><span class="ot">Inf</span></span>
<span id="cb445-26"><a href="hierarchical-clustering.html#cb445-26"></a>    }</span>
<span id="cb445-27"><a href="hierarchical-clustering.html#cb445-27"></a>  }</span>
<span id="cb445-28"><a href="hierarchical-clustering.html#cb445-28"></a>  </span>
<span id="cb445-29"><a href="hierarchical-clustering.html#cb445-29"></a>  <span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">idx_A =</span> idx_A, <span class="dt">idx_B =</span> idx_B))</span>
<span id="cb445-30"><a href="hierarchical-clustering.html#cb445-30"></a>}</span></code></pre></div>
<p>단계1 함수 <code>max_distance_cluster</code>와 단계2 함수 <code>split_cluster</code>를 반복적으로 수행하며 각각의 객체가 군집에 될 때까지 군집을 분리해간다.</p>
<div class="sourceCode" id="cb446"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb446-1"><a href="hierarchical-clustering.html#cb446-1"></a><span class="co"># 단계0</span></span>
<span id="cb446-2"><a href="hierarchical-clustering.html#cb446-2"></a>current_cluster &lt;-<span class="st"> </span><span class="kw">tibble</span>(</span>
<span id="cb446-3"><a href="hierarchical-clustering.html#cb446-3"></a>  <span class="dt">id =</span> train_df<span class="op">$</span>id</span>
<span id="cb446-4"><a href="hierarchical-clustering.html#cb446-4"></a>)</span>
<span id="cb446-5"><a href="hierarchical-clustering.html#cb446-5"></a>current_cluster<span class="op">$</span>cluster &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(current_cluster), <span class="dt">collapse =</span> <span class="st">&quot;,&quot;</span>)</span>
<span id="cb446-6"><a href="hierarchical-clustering.html#cb446-6"></a>i &lt;-<span class="st"> </span>0L</span>
<span id="cb446-7"><a href="hierarchical-clustering.html#cb446-7"></a>k &lt;-<span class="st"> </span>1L</span>
<span id="cb446-8"><a href="hierarchical-clustering.html#cb446-8"></a></span>
<span id="cb446-9"><a href="hierarchical-clustering.html#cb446-9"></a><span class="cf">while</span>(k <span class="op">&lt;</span><span class="st"> </span><span class="kw">nrow</span>(train_df)) {</span>
<span id="cb446-10"><a href="hierarchical-clustering.html#cb446-10"></a>  i &lt;-<span class="st"> </span>i <span class="op">+</span><span class="st"> </span>1L</span>
<span id="cb446-11"><a href="hierarchical-clustering.html#cb446-11"></a>  </span>
<span id="cb446-12"><a href="hierarchical-clustering.html#cb446-12"></a>  <span class="co"># 단계1</span></span>
<span id="cb446-13"><a href="hierarchical-clustering.html#cb446-13"></a>  max_cluster &lt;-<span class="st"> </span><span class="kw">max_distance_cluster</span>(train_df, current_cluster)</span>
<span id="cb446-14"><a href="hierarchical-clustering.html#cb446-14"></a></span>
<span id="cb446-15"><a href="hierarchical-clustering.html#cb446-15"></a>  <span class="co"># 단계2</span></span>
<span id="cb446-16"><a href="hierarchical-clustering.html#cb446-16"></a>  new_split &lt;-<span class="st"> </span>current_cluster <span class="op">%&gt;%</span></span>
<span id="cb446-17"><a href="hierarchical-clustering.html#cb446-17"></a><span class="st">    </span><span class="kw">filter</span>(cluster <span class="op">==</span><span class="st"> </span>max_cluster<span class="op">$</span>cluster) <span class="op">%&gt;%</span></span>
<span id="cb446-18"><a href="hierarchical-clustering.html#cb446-18"></a><span class="st">    </span><span class="kw">inner_join</span>(train_df, <span class="dt">by =</span> <span class="st">&quot;id&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb446-19"><a href="hierarchical-clustering.html#cb446-19"></a><span class="st">    </span><span class="kw">select</span>(<span class="op">-</span>cluster) <span class="op">%&gt;%</span></span>
<span id="cb446-20"><a href="hierarchical-clustering.html#cb446-20"></a><span class="st">    </span><span class="kw">split_cluster</span>()</span>
<span id="cb446-21"><a href="hierarchical-clustering.html#cb446-21"></a></span>
<span id="cb446-22"><a href="hierarchical-clustering.html#cb446-22"></a>  <span class="co"># 군집해 업데이트</span></span>
<span id="cb446-23"><a href="hierarchical-clustering.html#cb446-23"></a>  current_cluster[</span>
<span id="cb446-24"><a href="hierarchical-clustering.html#cb446-24"></a>    current_cluster<span class="op">$</span>id <span class="op">%in%</span><span class="st"> </span>new_split<span class="op">$</span>idx_A, </span>
<span id="cb446-25"><a href="hierarchical-clustering.html#cb446-25"></a>    <span class="st">&quot;cluster&quot;</span>] &lt;-<span class="st"> </span><span class="kw">paste</span>(new_split<span class="op">$</span>idx_A, <span class="dt">collapse =</span> <span class="st">&quot;,&quot;</span>)</span>
<span id="cb446-26"><a href="hierarchical-clustering.html#cb446-26"></a>  current_cluster[</span>
<span id="cb446-27"><a href="hierarchical-clustering.html#cb446-27"></a>    current_cluster<span class="op">$</span>id <span class="op">%in%</span><span class="st"> </span>new_split<span class="op">$</span>idx_B, </span>
<span id="cb446-28"><a href="hierarchical-clustering.html#cb446-28"></a>    <span class="st">&quot;cluster&quot;</span>] &lt;-<span class="st"> </span><span class="kw">paste</span>(new_split<span class="op">$</span>idx_B, <span class="dt">collapse =</span> <span class="st">&quot;,&quot;</span>)</span>
<span id="cb446-29"><a href="hierarchical-clustering.html#cb446-29"></a>  </span>
<span id="cb446-30"><a href="hierarchical-clustering.html#cb446-30"></a>  <span class="co"># 군집해 출력</span></span>
<span id="cb446-31"><a href="hierarchical-clustering.html#cb446-31"></a>  k &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(current_cluster<span class="op">$</span>cluster))</span>
<span id="cb446-32"><a href="hierarchical-clustering.html#cb446-32"></a>  <span class="kw">cat</span>(<span class="st">&quot;Iteration: &quot;</span>, i, <span class="st">&quot;, k = &quot;</span>, k, <span class="st">&quot;, clusters = &quot;</span>, </span>
<span id="cb446-33"><a href="hierarchical-clustering.html#cb446-33"></a>      <span class="kw">paste0</span>(<span class="st">&quot;{&quot;</span>, <span class="kw">unique</span>(current_cluster<span class="op">$</span>cluster), <span class="st">&quot;}&quot;</span>),</span>
<span id="cb446-34"><a href="hierarchical-clustering.html#cb446-34"></a>      <span class="st">&quot;, height = &quot;</span>, max_cluster<span class="op">$</span>distance, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb446-35"><a href="hierarchical-clustering.html#cb446-35"></a>}</span></code></pre></div>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## Iteration:  1 , k =  2 , clusters =  {6,3,1} {2,4,5,7} , height =  33.54102</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## Iteration:  2 , k =  3 , clusters =  {6,3,1} {2,4,5} {7} , height =  17.88854</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## Iteration:  3 , k =  4 , clusters =  {1} {2,4,5} {3,6} {7} , height =  11.18034</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## Iteration:  4 , k =  5 , clusters =  {1} {2,4} {3,6} {5} {7} , height =  10.04988</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## Iteration:  5 , k =  6 , clusters =  {1} {2} {3,6} {4} {5} {7} , height =  5.385165</code></pre>
<pre><code>## `summarise()` ungrouping output (override with `.groups` argument)</code></pre>
<pre><code>## Iteration:  6 , k =  7 , clusters =  {1} {2} {3} {4} {5} {6} {7} , height =  5.385165</code></pre>
<p>위 출력 결과에서 <code>height</code>는 해당 iteration에서 분리된 군집의 분리 전 지름(diameter)으로, 함수 <code>max_distance_cluster</code>에서 계산한 군집 내 객체간 최대 거리를 나타내며, 이는 R 패키지 <code>cluster</code>의 <code>diana</code> 함수 수행 시 함수값으로 출력되는 <code>height</code>값이다. Iteration이 진행됨에 따라 <code>height</code>의 값이 감소하는 것을 확인할 수 있다.</p>
</div>
</div>
<div id="hierarchical-cluster-number" class="section level2">
<h2><span class="header-section-number">12.6</span> 군집수의 결정</h2>
<p>최적의 군집수를 결정하는 객관적인 방법은 존재하지 않는다. 계층적 군집방법에서는 덴드로그램을 참조하여 군집 간의 거리가 급격히 증가하는 계층에서 수평으로 절단하여, 그 이하의 그룹들을 하나의 군집으로 형성하는 방안을 널리 사용하고 있다. 이외에 군집수를 결정하는 데 통계량으로 다음과 같은 통계량들이 부수적으로 사용된다.</p>
<ol style="list-style-type: decimal">
<li>새 군집의 RMS 표준편차(root-mean-square standard deviation of the new cluster; RMSSTD)</li>
</ol>
<p><span class="math display">\[\begin{equation*}
RMSSTD(C_i, C_j) = \sqrt{\frac{SS(C_i \cup C_j)}{p(|C_i| + |C_j| - 1)}}
\end{equation*}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Semipartial R-squared(SPR)</li>
</ol>
<p><span class="math display">\[\begin{equation*}
SPR(C_i, C_j) = \frac{SS(C_i \cup C_j) - (SS(C_i) + SS(C_j))}{SST}
\end{equation*}\]</span></p>
<p>where</p>
<p><span class="math display">\[\begin{equation*}
SST = \sum_{i = 1}^{n} \sum_{j = 1}^{p} \left( x_{ji} - \frac{1}{n} \sum_{a = 1}^{n} x_{ja} \right)^2
\end{equation*}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>R-squared(<span class="math inline">\(R^2\)</span>)</li>
</ol>
<p><span class="math display">\[\begin{equation*}
1 - \frac{\sum_{i = 1}^{k} SS(C_i)}{SST}
\end{equation*}\]</span></p>
<p>위 <a href="hierarchical-clustering.html#ward-method-algorithm">12.4.2</a>절에서 워드 군집 알고리즘으로 구현한 군집 과정에 대해 위 통계량을 계산해보자.</p>
<div class="sourceCode" id="cb459"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb459-1"><a href="hierarchical-clustering.html#cb459-1"></a>train_df &lt;-<span class="st"> </span><span class="kw">tibble</span>(</span>
<span id="cb459-2"><a href="hierarchical-clustering.html#cb459-2"></a>  <span class="dt">id =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">8</span>),</span>
<span id="cb459-3"><a href="hierarchical-clustering.html#cb459-3"></a>  <span class="dt">x1 =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">20</span>, <span class="dv">3</span>, <span class="dv">19</span>, <span class="dv">17</span>, <span class="dv">8</span>, <span class="dv">19</span>, <span class="dv">18</span>),</span>
<span id="cb459-4"><a href="hierarchical-clustering.html#cb459-4"></a>  <span class="dt">x2 =</span> <span class="kw">c</span>(<span class="dv">15</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">4</span>, <span class="dv">17</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">6</span>)</span>
<span id="cb459-5"><a href="hierarchical-clustering.html#cb459-5"></a>)</span>
<span id="cb459-6"><a href="hierarchical-clustering.html#cb459-6"></a></span>
<span id="cb459-7"><a href="hierarchical-clustering.html#cb459-7"></a>sst &lt;-<span class="st"> </span>train_df <span class="op">%&gt;%</span></span>
<span id="cb459-8"><a href="hierarchical-clustering.html#cb459-8"></a><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>id) <span class="op">%&gt;%</span></span>
<span id="cb459-9"><a href="hierarchical-clustering.html#cb459-9"></a><span class="st">  </span><span class="kw">sapply</span>(<span class="cf">function</span>(x) <span class="kw">sum</span>((x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x))<span class="op">^</span><span class="dv">2</span>)) <span class="op">%&gt;%</span></span>
<span id="cb459-10"><a href="hierarchical-clustering.html#cb459-10"></a><span class="st">  </span><span class="kw">sum</span>()</span>
<span id="cb459-11"><a href="hierarchical-clustering.html#cb459-11"></a></span>
<span id="cb459-12"><a href="hierarchical-clustering.html#cb459-12"></a><span class="co">#단계0</span></span>
<span id="cb459-13"><a href="hierarchical-clustering.html#cb459-13"></a>init_cluster &lt;-<span class="st"> </span><span class="kw">tibble</span>(</span>
<span id="cb459-14"><a href="hierarchical-clustering.html#cb459-14"></a>  <span class="dt">id =</span> train_df<span class="op">$</span>id,</span>
<span id="cb459-15"><a href="hierarchical-clustering.html#cb459-15"></a>  <span class="dt">cluster =</span> <span class="kw">as.character</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(train_df))</span>
<span id="cb459-16"><a href="hierarchical-clustering.html#cb459-16"></a>)</span>
<span id="cb459-17"><a href="hierarchical-clustering.html#cb459-17"></a>i &lt;-<span class="st"> </span>0L</span>
<span id="cb459-18"><a href="hierarchical-clustering.html#cb459-18"></a>current_clusters &lt;-<span class="st"> </span><span class="kw">unique</span>(init_cluster<span class="op">$</span>cluster)</span>
<span id="cb459-19"><a href="hierarchical-clustering.html#cb459-19"></a>k &lt;-<span class="st"> </span><span class="kw">length</span>(current_clusters)</span>
<span id="cb459-20"><a href="hierarchical-clustering.html#cb459-20"></a>ssw &lt;-<span class="st"> </span><span class="kw">calculate_ssw</span>(train_df, init_cluster)</span>
<span id="cb459-21"><a href="hierarchical-clustering.html#cb459-21"></a>old_ssw &lt;-<span class="st"> </span><span class="ot">NA_real_</span></span>
<span id="cb459-22"><a href="hierarchical-clustering.html#cb459-22"></a></span>
<span id="cb459-23"><a href="hierarchical-clustering.html#cb459-23"></a><span class="co">#단계1</span></span>
<span id="cb459-24"><a href="hierarchical-clustering.html#cb459-24"></a>iteration &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="dt">length =</span> <span class="kw">nrow</span>(train_df) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)</span>
<span id="cb459-25"><a href="hierarchical-clustering.html#cb459-25"></a><span class="cf">while</span>(k <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) {</span>
<span id="cb459-26"><a href="hierarchical-clustering.html#cb459-26"></a>  i &lt;-<span class="st"> </span>i <span class="op">+</span><span class="st"> </span><span class="dv">1</span></span>
<span id="cb459-27"><a href="hierarchical-clustering.html#cb459-27"></a>  old_ssw &lt;-<span class="st"> </span>ssw</span>
<span id="cb459-28"><a href="hierarchical-clustering.html#cb459-28"></a>  </span>
<span id="cb459-29"><a href="hierarchical-clustering.html#cb459-29"></a>  <span class="cf">if</span>(i <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {</span>
<span id="cb459-30"><a href="hierarchical-clustering.html#cb459-30"></a>    old_cluster &lt;-<span class="st"> </span>init_cluster</span>
<span id="cb459-31"><a href="hierarchical-clustering.html#cb459-31"></a>  } <span class="cf">else</span> {</span>
<span id="cb459-32"><a href="hierarchical-clustering.html#cb459-32"></a>    old_cluster &lt;-<span class="st"> </span>iteration[[i<span class="dv">-1</span>]]<span class="op">$</span>new_cluster_label</span>
<span id="cb459-33"><a href="hierarchical-clustering.html#cb459-33"></a>  }</span>
<span id="cb459-34"><a href="hierarchical-clustering.html#cb459-34"></a>  </span>
<span id="cb459-35"><a href="hierarchical-clustering.html#cb459-35"></a>  iteration[[i]] &lt;-<span class="st"> </span><span class="kw">best_merge_cluster</span>(</span>
<span id="cb459-36"><a href="hierarchical-clustering.html#cb459-36"></a>    train_df,</span>
<span id="cb459-37"><a href="hierarchical-clustering.html#cb459-37"></a>    old_cluster</span>
<span id="cb459-38"><a href="hierarchical-clustering.html#cb459-38"></a>  )</span>
<span id="cb459-39"><a href="hierarchical-clustering.html#cb459-39"></a>  </span>
<span id="cb459-40"><a href="hierarchical-clustering.html#cb459-40"></a>  merged &lt;-<span class="st"> </span>old_cluster <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb459-41"><a href="hierarchical-clustering.html#cb459-41"></a><span class="st">    </span><span class="kw">anti_join</span>(iteration[[i]]<span class="op">$</span>new_cluster_label, <span class="dt">by =</span> <span class="st">&quot;cluster&quot;</span>)</span>
<span id="cb459-42"><a href="hierarchical-clustering.html#cb459-42"></a>  </span>
<span id="cb459-43"><a href="hierarchical-clustering.html#cb459-43"></a>  current_clusters &lt;-<span class="st"> </span><span class="kw">unique</span>(iteration[[i]]<span class="op">$</span>new_cluster_label<span class="op">$</span>cluster)</span>
<span id="cb459-44"><a href="hierarchical-clustering.html#cb459-44"></a>  k &lt;-<span class="st"> </span><span class="kw">length</span>(current_clusters)</span>
<span id="cb459-45"><a href="hierarchical-clustering.html#cb459-45"></a>  ssw &lt;-<span class="st"> </span>iteration[[i]]<span class="op">$</span>new_ssw</span>
<span id="cb459-46"><a href="hierarchical-clustering.html#cb459-46"></a>  </span>
<span id="cb459-47"><a href="hierarchical-clustering.html#cb459-47"></a>  iteration[[i]]<span class="op">$</span>rmsstd &lt;-<span class="st"> </span><span class="kw">sqrt</span>(</span>
<span id="cb459-48"><a href="hierarchical-clustering.html#cb459-48"></a>    merged <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb459-49"><a href="hierarchical-clustering.html#cb459-49"></a><span class="st">      </span><span class="kw">inner_join</span>(train_df, <span class="dt">by =</span> <span class="st">&quot;id&quot;</span>) <span class="op">%&gt;%</span></span>
<span id="cb459-50"><a href="hierarchical-clustering.html#cb459-50"></a><span class="st">      </span><span class="kw">select</span>(<span class="op">-</span>id, <span class="op">-</span>cluster) <span class="op">%&gt;%</span></span>
<span id="cb459-51"><a href="hierarchical-clustering.html#cb459-51"></a><span class="st">      </span><span class="kw">sapply</span>(<span class="cf">function</span>(x) <span class="kw">sum</span>((x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x))<span class="op">^</span><span class="dv">2</span>)) <span class="op">%&gt;%</span></span>
<span id="cb459-52"><a href="hierarchical-clustering.html#cb459-52"></a><span class="st">      </span><span class="kw">sum</span>() <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(<span class="kw">nrow</span>(merged) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))</span>
<span id="cb459-53"><a href="hierarchical-clustering.html#cb459-53"></a>  )</span>
<span id="cb459-54"><a href="hierarchical-clustering.html#cb459-54"></a>  </span>
<span id="cb459-55"><a href="hierarchical-clustering.html#cb459-55"></a>  iteration[[i]]<span class="op">$</span>iter &lt;-<span class="st"> </span>i</span>
<span id="cb459-56"><a href="hierarchical-clustering.html#cb459-56"></a>  iteration[[i]]<span class="op">$</span>merge &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;{&quot;</span>, <span class="kw">unique</span>(merged<span class="op">$</span>cluster), <span class="st">&quot;}&quot;</span>, <span class="dt">collapse =</span> <span class="st">&quot;, &quot;</span>)</span>
<span id="cb459-57"><a href="hierarchical-clustering.html#cb459-57"></a>  iteration[[i]]<span class="op">$</span>sol &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;{&quot;</span>, <span class="kw">unique</span>(current_clusters), <span class="st">&quot;}&quot;</span>, <span class="dt">collapse =</span> <span class="st">&quot;, &quot;</span>)</span>
<span id="cb459-58"><a href="hierarchical-clustering.html#cb459-58"></a>  iteration[[i]]<span class="op">$</span>spr &lt;-<span class="st"> </span>(ssw <span class="op">-</span><span class="st"> </span>old_ssw) <span class="op">/</span><span class="st"> </span>sst</span>
<span id="cb459-59"><a href="hierarchical-clustering.html#cb459-59"></a>  iteration[[i]]<span class="op">$</span>r_sq &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>ssw <span class="op">/</span><span class="st"> </span>sst</span>
<span id="cb459-60"><a href="hierarchical-clustering.html#cb459-60"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb460"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb460-1"><a href="hierarchical-clustering.html#cb460-1"></a>cluster_statistic &lt;-<span class="st"> </span><span class="kw">lapply</span>(iteration, <span class="cf">function</span>(x) x[</span>
<span id="cb460-2"><a href="hierarchical-clustering.html#cb460-2"></a>  <span class="kw">c</span>(<span class="st">&quot;iter&quot;</span>, <span class="st">&quot;merge&quot;</span>, <span class="st">&quot;sol&quot;</span>, <span class="st">&quot;rmsstd&quot;</span>, <span class="st">&quot;spr&quot;</span>, <span class="st">&quot;r_sq&quot;</span>)]) <span class="op">%&gt;%</span></span>
<span id="cb460-3"><a href="hierarchical-clustering.html#cb460-3"></a><span class="st">  </span><span class="kw">bind_rows</span>(</span>
<span id="cb460-4"><a href="hierarchical-clustering.html#cb460-4"></a>    <span class="kw">tibble</span>(</span>
<span id="cb460-5"><a href="hierarchical-clustering.html#cb460-5"></a>      <span class="dt">iter =</span> <span class="dv">0</span>,</span>
<span id="cb460-6"><a href="hierarchical-clustering.html#cb460-6"></a>      <span class="dt">sol =</span> <span class="kw">paste0</span>(<span class="st">&quot;{&quot;</span>, <span class="kw">unique</span>(init_cluster<span class="op">$</span>cluster), <span class="st">&quot;}&quot;</span>, <span class="dt">collapse =</span> <span class="st">&quot;, &quot;</span>),</span>
<span id="cb460-7"><a href="hierarchical-clustering.html#cb460-7"></a>      <span class="dt">r_sq =</span> <span class="dv">1</span></span>
<span id="cb460-8"><a href="hierarchical-clustering.html#cb460-8"></a>    )</span>
<span id="cb460-9"><a href="hierarchical-clustering.html#cb460-9"></a>  ) <span class="op">%&gt;%</span></span>
<span id="cb460-10"><a href="hierarchical-clustering.html#cb460-10"></a><span class="st">  </span><span class="kw">arrange</span>(iter)</span>
<span id="cb460-11"><a href="hierarchical-clustering.html#cb460-11"></a></span>
<span id="cb460-12"><a href="hierarchical-clustering.html#cb460-12"></a>cluster_statistic <span class="op">%&gt;%</span></span>
<span id="cb460-13"><a href="hierarchical-clustering.html#cb460-13"></a><span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>(</span>
<span id="cb460-14"><a href="hierarchical-clustering.html#cb460-14"></a>    <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,</span>
<span id="cb460-15"><a href="hierarchical-clustering.html#cb460-15"></a>    <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;Iteration&#39;</span>, <span class="st">&#39;통합대상군집&#39;</span>, <span class="st">&#39;통합 후 군집&#39;</span>,</span>
<span id="cb460-16"><a href="hierarchical-clustering.html#cb460-16"></a>                  <span class="st">&#39;$RMSSTD$&#39;</span>, <span class="st">&#39;$SPR$&#39;</span>, <span class="st">&#39;$R^2$&#39;</span>),</span>
<span id="cb460-17"><a href="hierarchical-clustering.html#cb460-17"></a>    <span class="dt">caption =</span> <span class="st">&#39;군집 과정에 따른 여러 통계량&#39;</span></span>
<span id="cb460-18"><a href="hierarchical-clustering.html#cb460-18"></a>  )</span></code></pre></div>
<table>
<caption><span id="tab:cluster-statistic">Table 12.7: </span>군집 과정에 따른 여러 통계량</caption>
<thead>
<tr class="header">
<th align="right">Iteration</th>
<th align="left">통합대상군집</th>
<th align="left">통합 후 군집</th>
<th align="right"><span class="math inline">\(RMSSTD\)</span></th>
<th align="right"><span class="math inline">\(SPR\)</span></th>
<th align="right"><span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="left">NA</td>
<td align="left">{1}, {2}, {3}, {4}, {5}, {6}, {7}, {8}</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">1.0000000</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">{2}, {7}</td>
<td align="left">{1}, {2,7}, {3}, {4}, {5}, {6}, {8}</td>
<td align="right">0.7071068</td>
<td align="right">0.0020005</td>
<td align="right">0.9979995</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="left">{1}, {3}</td>
<td align="left">{1,3}, {2,7}, {4}, {5}, {6}, {8}</td>
<td align="right">1.1180340</td>
<td align="right">0.0050013</td>
<td align="right">0.9929982</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="left">{4}, {8}</td>
<td align="left">{1,3}, {2,7}, {4,8}, {5}, {6}</td>
<td align="right">1.1180340</td>
<td align="right">0.0050013</td>
<td align="right">0.9879970</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="left">{2,7}, {5}</td>
<td align="left">{1,3}, {2,7,5}, {4,8}, {6}</td>
<td align="right">2.1602469</td>
<td align="right">0.0353422</td>
<td align="right">0.9526548</td>
</tr>
<tr class="even">
<td align="right">5</td>
<td align="left">{1,3}, {6}</td>
<td align="left">{1,3,6}, {2,7,5}, {4,8}</td>
<td align="right">2.3452079</td>
<td align="right">0.0390098</td>
<td align="right">0.9136451</td>
</tr>
<tr class="odd">
<td align="right">6</td>
<td align="left">{2,7,5}, {4,8}</td>
<td align="left">{1,3,6}, {2,7,5,4,8}</td>
<td align="right">3.8470768</td>
<td align="right">0.1945153</td>
<td align="right">0.7191298</td>
</tr>
<tr class="even">
<td align="right">7</td>
<td align="left">{1,3,6}, {2,7,5,4,8}</td>
<td align="left">{1,3,6,2,7,5,4,8}</td>
<td align="right">5.9753960</td>
<td align="right">0.7191298</td>
<td align="right">0.0000000</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb461"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb461-1"><a href="hierarchical-clustering.html#cb461-1"></a>cluster_statistic <span class="op">%&gt;%</span></span>
<span id="cb461-2"><a href="hierarchical-clustering.html#cb461-2"></a><span class="st">  </span><span class="kw">mutate</span>(</span>
<span id="cb461-3"><a href="hierarchical-clustering.html#cb461-3"></a>    <span class="dt">rmsstd =</span> <span class="kw">if_else</span>(<span class="kw">is.na</span>(rmsstd), <span class="dv">0</span>, rmsstd),</span>
<span id="cb461-4"><a href="hierarchical-clustering.html#cb461-4"></a>    <span class="dt">spr =</span> <span class="kw">if_else</span>(<span class="kw">is.na</span>(spr), <span class="dv">0</span>, spr)</span>
<span id="cb461-5"><a href="hierarchical-clustering.html#cb461-5"></a>    ) <span class="op">%&gt;%</span></span>
<span id="cb461-6"><a href="hierarchical-clustering.html#cb461-6"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> iter)) <span class="op">+</span></span>
<span id="cb461-7"><a href="hierarchical-clustering.html#cb461-7"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> rmsstd, <span class="dt">color =</span> <span class="st">&quot;RMSSTD&quot;</span>)) <span class="op">+</span></span>
<span id="cb461-8"><a href="hierarchical-clustering.html#cb461-8"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> spr <span class="op">*</span><span class="st"> </span><span class="dv">6</span>, <span class="dt">color =</span> <span class="st">&quot;SPR&quot;</span>)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb461-9"><a href="hierarchical-clustering.html#cb461-9"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> r_sq <span class="op">*</span><span class="st"> </span><span class="dv">6</span>, <span class="dt">color =</span> <span class="st">&quot;R2&quot;</span>)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb461-10"><a href="hierarchical-clustering.html#cb461-10"></a><span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">sec.axis =</span> <span class="kw">sec_axis</span>(<span class="op">~</span><span class="st"> </span>. <span class="op">/</span><span class="st"> </span><span class="dv">6</span>, <span class="dt">name =</span> <span class="st">&quot;SPR, R2&quot;</span>)) <span class="op">+</span></span>
<span id="cb461-11"><a href="hierarchical-clustering.html#cb461-11"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;RMSSTD&quot;</span>) <span class="op">+</span></span>
<span id="cb461-12"><a href="hierarchical-clustering.html#cb461-12"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Iteration&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:cluster-statistic"></span>
<img src="data-mining-book_files/figure-html/cluster-statistic-1.png" alt="군집 과정에 따른 통계량 추이" width="672" />
<p class="caption">
Figure 12.5: 군집 과정에 따른 통계량 추이
</p>
</div>
<p>그림 <a href="hierarchical-clustering.html#fig:cluster-statistic">12.5</a>에서 보듯이 Iteration 6부터 3가지 통계량 모두 급격하게 변화하는 것을 알 수 있다. 따라서 군집수는 Iteration 5까지 3개가 가장 적당하다고 하겠다.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-kaufman1990finding">
<p>Kaufman, L, and P. J. Rousseeuw. 1990. “Finding Groups in Data: An Introduction to Cluster Analysis.”</p>
</div>
<div id="ref-lance1967general">
<p>Lance, Godfrey N, and William Thomas Williams. 1967. “A General Theory of Classificatory Sorting Strategies: 1. Hierarchical Systems.” <em>The Computer Journal</em> 9 (4): 373–80.</p>
</div>
<div id="ref-ward1963hierarchical">
<p>Ward Jr, Joe H. 1963. “Hierarchical Grouping to Optimize an Objective Function.” <em>Journal of the American Statistical Association</em> 58 (301): 236–44.</p>
</div>
<div id="ref-wishart1969256">
<p>Wishart, David. 1969. “256. Note: An Algorithm for Hierarchical Classifications.” <em>Biometrics</em>, 165–70.</p>
</div>
</div>
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://r-data-mining-book.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="clustering-overview.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="nonhierarchical-clustering.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["data-mining-book.pdf"],
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
