<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 계층적 군집방법 | 데이터마이닝 with R</title>
  <meta name="description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 계층적 군집방법 | 데이터마이닝 with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://youngroklee-ml.github.io/data-mining-book/" />
  
  <meta property="og:description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  <meta name="github-repo" content="youngroklee-ml/data-mining-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 계층적 군집방법 | 데이터마이닝 with R" />
  
  <meta name="twitter:description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  

<meta name="author" content="전치혁, 이혜선, 이종석, 이영록" />


<meta name="date" content="2021-07-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="clustering-overview.html"/>
<link rel="next" href="nonhierarchical-clustering.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">데이터마이닝 with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>개요</a></li>
<li class="chapter" data-level="1" data-path="datamining-overview.html"><a href="datamining-overview.html"><i class="fa fa-check"></i><b>1</b> 데이터마이닝 개요</a></li>
<li class="part"><span><b>I 1부 - 예측</b></span></li>
<li class="chapter" data-level="2" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>2</b> 회귀분석</a>
<ul>
<li class="chapter" data-level="2.1" data-path="regression.html"><a href="regression.html#regression-packages-install"><i class="fa fa-check"></i><b>2.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="2.2" data-path="regression.html"><a href="regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>2.2</b> 다중회귀모형</a></li>
<li class="chapter" data-level="2.3" data-path="regression.html"><a href="regression.html#regression-response-confidence-prediction"><i class="fa fa-check"></i><b>2.3</b> 반응치에 대한 추정 및 예측</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="regression.html"><a href="regression.html#regression-response-confidence"><i class="fa fa-check"></i><b>2.3.1</b> 평균반응치의 추정</a></li>
<li class="chapter" data-level="2.3.2" data-path="regression.html"><a href="regression.html#regression-response-prediction"><i class="fa fa-check"></i><b>2.3.2</b> 미래반응치의 예측</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="regression.html"><a href="regression.html#regression-indicator-variable"><i class="fa fa-check"></i><b>2.4</b> 지시변수와 회귀모형</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="regression.html"><a href="regression.html#regression-indicator-variable-basic-script"><i class="fa fa-check"></i><b>2.4.1</b> 기본 R 스트립트</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>3</b> 주성분분석</a>
<ul>
<li class="chapter" data-level="3.1" data-path="pca.html"><a href="pca.html#pca-packages-install"><i class="fa fa-check"></i><b>3.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="3.2" data-path="pca.html"><a href="pca.html#pca-matrix-factorization"><i class="fa fa-check"></i><b>3.2</b> 행렬의 분해</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="pca.html"><a href="pca.html#pca-matrix-factorization-basic-script"><i class="fa fa-check"></i><b>3.2.1</b> 기본 R 스트립트</a></li>
<li class="chapter" data-level="3.2.2" data-path="pca.html"><a href="pca.html#pca-ss"><i class="fa fa-check"></i><b>3.2.2</b> 변수의 변동과 제곱합</a></li>
<li class="chapter" data-level="3.2.3" data-path="pca.html"><a href="pca.html#pca-intro"><i class="fa fa-check"></i><b>3.2.3</b> 주성분의 이해 및 행렬의 분해</a></li>
<li class="chapter" data-level="3.2.4" data-path="pca.html"><a href="pca.html#pca-svd"><i class="fa fa-check"></i><b>3.2.4</b> 특이치분해 (Singular Value Decomposition)</a></li>
<li class="chapter" data-level="3.2.5" data-path="pca.html"><a href="pca.html#pca-spectral"><i class="fa fa-check"></i><b>3.2.5</b> 분광분해 (Spectral Decomposition)</a></li>
<li class="chapter" data-level="3.2.6" data-path="pca.html"><a href="pca.html#pca-nipals"><i class="fa fa-check"></i><b>3.2.6</b> NIPALS 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="pca.html"><a href="pca.html#pca-regression"><i class="fa fa-check"></i><b>3.3</b> 주성분 회귀분석</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="pca.html"><a href="pca.html#pcr-basic-script"><i class="fa fa-check"></i><b>3.3.1</b> 기본 R 스트립트</a></li>
<li class="chapter" data-level="3.3.2" data-path="pca.html"><a href="pca.html#pcr-regression-coefficient"><i class="fa fa-check"></i><b>3.3.2</b> 주성분 회귀계수 추정</a></li>
<li class="chapter" data-level="3.3.3" data-path="pca.html"><a href="pca.html#pcr-regression-transform"><i class="fa fa-check"></i><b>3.3.3</b> 회귀계수 선형변환</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="plsr.html"><a href="plsr.html"><i class="fa fa-check"></i><b>4</b> 부분최소자승법</a>
<ul>
<li class="chapter" data-level="4.1" data-path="plsr.html"><a href="plsr.html#plsr-packages-install"><i class="fa fa-check"></i><b>4.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="4.2" data-path="plsr.html"><a href="plsr.html#plsr-single-target"><i class="fa fa-check"></i><b>4.2</b> 하나의 종속변수의 경우</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="plsr.html"><a href="plsr.html#plsr-basic-script"><i class="fa fa-check"></i><b>4.2.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="4.2.2" data-path="plsr.html"><a href="plsr.html#plsr-model"><i class="fa fa-check"></i><b>4.2.2</b> PLS 모형</a></li>
<li class="chapter" data-level="4.2.3" data-path="plsr.html"><a href="plsr.html#plsr-single-nipals"><i class="fa fa-check"></i><b>4.2.3</b> NIPALS 알고리즘</a></li>
<li class="chapter" data-level="4.2.4" data-path="plsr.html"><a href="plsr.html#plsr-single-transform"><i class="fa fa-check"></i><b>4.2.4</b> 회귀식 변환</a></li>
<li class="chapter" data-level="4.2.5" data-path="plsr.html"><a href="plsr.html#plsr-sst"><i class="fa fa-check"></i><b>4.2.5</b> 제곱합 분해</a></li>
<li class="chapter" data-level="4.2.6" data-path="plsr.html"><a href="plsr.html#plsr-variable-importance"><i class="fa fa-check"></i><b>4.2.6</b> 독립변수의 중요도</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-target"><i class="fa fa-check"></i><b>4.3</b> 다수의 종속변수의 경우</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-basic-script"><i class="fa fa-check"></i><b>4.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="4.3.2" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-model"><i class="fa fa-check"></i><b>4.3.2</b> PLS 모형</a></li>
<li class="chapter" data-level="4.3.3" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-nipals"><i class="fa fa-check"></i><b>4.3.3</b> NIPALS 알고리즘</a></li>
<li class="chapter" data-level="4.3.4" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-transform"><i class="fa fa-check"></i><b>4.3.4</b> 회귀식 변환</a></li>
<li class="chapter" data-level="4.3.5" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-sst"><i class="fa fa-check"></i><b>4.3.5</b> 제곱합 분해</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II 2부 - 분류분석</b></span></li>
<li class="chapter" data-level="5" data-path="classification-analysis.html"><a href="classification-analysis.html"><i class="fa fa-check"></i><b>5</b> 분류분석 개요</a>
<ul>
<li class="chapter" data-level="5.1" data-path="classification-analysis.html"><a href="classification-analysis.html#classification-packages-install"><i class="fa fa-check"></i><b>5.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="5.2" data-path="classification-analysis.html"><a href="classification-analysis.html#classification-problem-methods"><i class="fa fa-check"></i><b>5.2</b> 분류문제 및 분류기법</a></li>
<li class="chapter" data-level="5.3" data-path="classification-analysis.html"><a href="classification-analysis.html#simple-classification-methods"><i class="fa fa-check"></i><b>5.3</b> 기본적인 분류기법</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="classification-analysis.html"><a href="classification-analysis.html#nearest-neighbor-classification"><i class="fa fa-check"></i><b>5.3.1</b> 인접객체법</a></li>
<li class="chapter" data-level="5.3.2" data-path="classification-analysis.html"><a href="classification-analysis.html#naive-bayes"><i class="fa fa-check"></i><b>5.3.2</b> 나이브 베이지안 분류법</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>6</b> 로지스틱 회귀분석</a>
<ul>
<li class="chapter" data-level="6.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-packages-install"><i class="fa fa-check"></i><b>6.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="6.2" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-regression"><i class="fa fa-check"></i><b>6.2</b> 이분 로지스틱 회귀모형</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#bianry-logistic-reg-basic-script"><i class="fa fa-check"></i><b>6.2.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="6.2.2" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-reg-model"><i class="fa fa-check"></i><b>6.2.2</b> 회귀모형</a></li>
<li class="chapter" data-level="6.2.3" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-reg-estimation"><i class="fa fa-check"></i><b>6.2.3</b> 회귀계수 추정</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="logistic-regression.html"><a href="logistic-regression.html#nominal-logistic-regression"><i class="fa fa-check"></i><b>6.3</b> 명목 로지스틱 회귀모형</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#nominal-logistic-reg-basic-script"><i class="fa fa-check"></i><b>6.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="6.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#baseline-category-logit-model"><i class="fa fa-check"></i><b>6.3.2</b> 기준범주 로짓모형</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="logistic-regression.html"><a href="logistic-regression.html#ordinal-logistic-regression"><i class="fa fa-check"></i><b>6.4</b> 서열 로지스틱 회귀모형</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#ordinal-logistic-basic-script"><i class="fa fa-check"></i><b>6.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="6.4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#cumulative-logit-model"><i class="fa fa-check"></i><b>6.4.2</b> 누적 로짓모형</a></li>
<li class="chapter" data-level="6.4.3" data-path="logistic-regression.html"><a href="logistic-regression.html#adjacent-categories-logit-model"><i class="fa fa-check"></i><b>6.4.3</b> 인근범주 로짓모형</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="da.html"><a href="da.html"><i class="fa fa-check"></i><b>7</b> 판별분석</a>
<ul>
<li class="chapter" data-level="7.1" data-path="da.html"><a href="da.html#da-overview"><i class="fa fa-check"></i><b>7.1</b> 개요</a></li>
<li class="chapter" data-level="7.2" data-path="da.html"><a href="da.html#da-packages-install"><i class="fa fa-check"></i><b>7.2</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="7.3" data-path="da.html"><a href="da.html#da-fisher"><i class="fa fa-check"></i><b>7.3</b> 피셔 방법</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="da.html"><a href="da.html#da-fisher-basic-script"><i class="fa fa-check"></i><b>7.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.3.2" data-path="da.html"><a href="da.html#피셔-판별함수"><i class="fa fa-check"></i><b>7.3.2</b> 피셔 판별함수</a></li>
<li class="chapter" data-level="7.3.3" data-path="da.html"><a href="da.html#분류-규칙"><i class="fa fa-check"></i><b>7.3.3</b> 분류 규칙</a></li>
<li class="chapter" data-level="7.3.4" data-path="da.html"><a href="da.html#r-패키지를-이용한-분류규칙-도출"><i class="fa fa-check"></i><b>7.3.4</b> R 패키지를 이용한 분류규칙 도출</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="da.html"><a href="da.html#lda"><i class="fa fa-check"></i><b>7.4</b> 의사결정론에 의한 선형분류규칙</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="da.html"><a href="da.html#lda-basic-script"><i class="fa fa-check"></i><b>7.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.4.2" data-path="da.html"><a href="da.html#lda-function"><i class="fa fa-check"></i><b>7.4.2</b> 선형판별함수</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="da.html"><a href="da.html#lda-misclassification-cost"><i class="fa fa-check"></i><b>7.5</b> 오분류비용을 고려한 분류규칙</a></li>
<li class="chapter" data-level="7.6" data-path="da.html"><a href="da.html#qda"><i class="fa fa-check"></i><b>7.6</b> 이차판별분석</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="da.html"><a href="da.html#qda-basic-script"><i class="fa fa-check"></i><b>7.6.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.6.2" data-path="da.html"><a href="da.html#qda-function"><i class="fa fa-check"></i><b>7.6.2</b> 이차 판별함수</a></li>
<li class="chapter" data-level="7.6.3" data-path="da.html"><a href="da.html#qda-discriminant-rule"><i class="fa fa-check"></i><b>7.6.3</b> 이차판별함수에 의한 분류</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="da.html"><a href="da.html#da-multiclass"><i class="fa fa-check"></i><b>7.7</b> 세 범주 이상의 분류</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="da.html"><a href="da.html#mutliclass-da-basic-script"><i class="fa fa-check"></i><b>7.7.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.7.2" data-path="da.html"><a href="da.html#mutliclass-generalized-discriminant-function"><i class="fa fa-check"></i><b>7.7.2</b> 일반화된 판별함수</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="tree-based-method.html"><a href="tree-based-method.html"><i class="fa fa-check"></i><b>8</b> 트리기반 기법</a>
<ul>
<li class="chapter" data-level="8.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-overview"><i class="fa fa-check"></i><b>8.1</b> CART 개요</a></li>
<li class="chapter" data-level="8.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-packages-install"><i class="fa fa-check"></i><b>8.2</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="8.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-build"><i class="fa fa-check"></i><b>8.3</b> CART 트리 생성</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-basic-r-script"><i class="fa fa-check"></i><b>8.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="8.3.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-notation"><i class="fa fa-check"></i><b>8.3.2</b> 기호 정의</a></li>
<li class="chapter" data-level="8.3.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-impurity"><i class="fa fa-check"></i><b>8.3.3</b> 노드 및 트리의 불순도</a></li>
<li class="chapter" data-level="8.3.4" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-split"><i class="fa fa-check"></i><b>8.3.4</b> 분지기준</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-pruning-complete"><i class="fa fa-check"></i><b>8.4</b> 가지치기 및 최종 트리 선정</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-pruning"><i class="fa fa-check"></i><b>8.4.1</b> 가지치기</a></li>
<li class="chapter" data-level="8.4.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-best-tree"><i class="fa fa-check"></i><b>8.4.2</b> 최적 트리의 선정</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg"><i class="fa fa-check"></i><b>8.5</b> R패키지 내 분류 트리 방법</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-split"><i class="fa fa-check"></i><b>8.5.1</b> 트리 확장</a></li>
<li class="chapter" data-level="8.5.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-pruning"><i class="fa fa-check"></i><b>8.5.2</b> 가지치기</a></li>
<li class="chapter" data-level="8.5.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-param"><i class="fa fa-check"></i><b>8.5.3</b> 파라미터값 결정</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="svm.html"><a href="svm.html"><i class="fa fa-check"></i><b>9</b> 서포트 벡터 머신</a>
<ul>
<li class="chapter" data-level="9.1" data-path="svm.html"><a href="svm.html#svm-overview"><i class="fa fa-check"></i><b>9.1</b> 개요</a></li>
<li class="chapter" data-level="9.2" data-path="svm.html"><a href="svm.html#svm-packages-install"><i class="fa fa-check"></i><b>9.2</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="9.3" data-path="svm.html"><a href="svm.html#linear-svm-separable"><i class="fa fa-check"></i><b>9.3</b> 선형 SVM - 분리 가능 경우</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="svm.html"><a href="svm.html#linear-svm-separable-basic-script"><i class="fa fa-check"></i><b>9.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="9.3.2" data-path="svm.html"><a href="svm.html#linear-svm-notation"><i class="fa fa-check"></i><b>9.3.2</b> 기호 정의</a></li>
<li class="chapter" data-level="9.3.3" data-path="svm.html"><a href="svm.html#linear-svm-separable-hyperplane"><i class="fa fa-check"></i><b>9.3.3</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="svm.html"><a href="svm.html#linear-svm-inseparable"><i class="fa fa-check"></i><b>9.4</b> 선형 SVM - 분리 불가능 경우</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="svm.html"><a href="svm.html#linear-svm-inseparable-basic-script"><i class="fa fa-check"></i><b>9.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="9.4.2" data-path="svm.html"><a href="svm.html#linear-svm-inseparable-hyperplane"><i class="fa fa-check"></i><b>9.4.2</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="svm.html"><a href="svm.html#nonlinear-svm"><i class="fa fa-check"></i><b>9.5</b> 비선형 SVM</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="svm.html"><a href="svm.html#nonlinear-svm-basic-script"><i class="fa fa-check"></i><b>9.5.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="9.5.2" data-path="svm.html"><a href="svm.html#nonlinear-svm-hyperplane"><i class="fa fa-check"></i><b>9.5.2</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="svm.html"><a href="svm.html#svm-r-pkg"><i class="fa fa-check"></i><b>9.6</b> R패키지 내 SVM</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="svm.html"><a href="svm.html#svm-kernel-function"><i class="fa fa-check"></i><b>9.6.1</b> 커널함수</a></li>
<li class="chapter" data-level="9.6.2" data-path="svm.html"><a href="svm.html#svm-nu-classification"><i class="fa fa-check"></i><b>9.6.2</b> <span class="math inline">\(\nu\)</span>-SVC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html"><i class="fa fa-check"></i><b>10</b> 분류규칙의 성능 평가</a>
<ul>
<li class="chapter" data-level="10.1" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#classifier-evaluation-packages-install"><i class="fa fa-check"></i><b>10.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="10.2" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#classifier-evaluation-misclassification-rate"><i class="fa fa-check"></i><b>10.2</b> 분류오류율</a></li>
<li class="chapter" data-level="10.3" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#precision-sensitivity-specificity"><i class="fa fa-check"></i><b>10.3</b> 정확도, 민감도 및 특이도</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#confusion-matrix-r-package"><i class="fa fa-check"></i><b>10.3.1</b> R 패키지 내 정오분류표</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#roc-curve"><i class="fa fa-check"></i><b>10.4</b> ROC 곡선</a></li>
<li class="chapter" data-level="10.5" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#gain-chart"><i class="fa fa-check"></i><b>10.5</b> 이익도표</a></li>
</ul></li>
<li class="part"><span><b>III 3부 - 군집분석</b></span></li>
<li class="chapter" data-level="11" data-path="clustering-overview.html"><a href="clustering-overview.html"><i class="fa fa-check"></i><b>11</b> 군집분석 개요</a>
<ul>
<li class="chapter" data-level="11.1" data-path="clustering-overview.html"><a href="clustering-overview.html#clustering-overview-packages-install"><i class="fa fa-check"></i><b>11.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="11.2" data-path="clustering-overview.html"><a href="clustering-overview.html#clustering-method"><i class="fa fa-check"></i><b>11.2</b> 군집분석 기법</a></li>
<li class="chapter" data-level="11.3" data-path="clustering-overview.html"><a href="clustering-overview.html#object-similarity-metric"><i class="fa fa-check"></i><b>11.3</b> 객체 간의 유사성 척도</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="clustering-overview.html"><a href="clustering-overview.html#object-distance-metric"><i class="fa fa-check"></i><b>11.3.1</b> 거리 관련 척도</a></li>
<li class="chapter" data-level="11.3.2" data-path="clustering-overview.html"><a href="clustering-overview.html#object-correlation-metric"><i class="fa fa-check"></i><b>11.3.2</b> 상관계수 관련 척도</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="clustering-overview.html"><a href="clustering-overview.html#category-similarity-metric"><i class="fa fa-check"></i><b>11.4</b> 범주형 객체의 유사성 척도</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="clustering-overview.html"><a href="clustering-overview.html#binary-similarity-metric"><i class="fa fa-check"></i><b>11.4.1</b> 이분형 변수의 경우</a></li>
<li class="chapter" data-level="11.4.2" data-path="clustering-overview.html"><a href="clustering-overview.html#ordinal-similarity-metric"><i class="fa fa-check"></i><b>11.4.2</b> 서열형 변수의 경우</a></li>
<li class="chapter" data-level="11.4.3" data-path="clustering-overview.html"><a href="clustering-overview.html#nominal-similarity-metric"><i class="fa fa-check"></i><b>11.4.3</b> 명목형 변수의 경우</a></li>
<li class="chapter" data-level="11.4.4" data-path="clustering-overview.html"><a href="clustering-overview.html#mixed-similarity-metric"><i class="fa fa-check"></i><b>11.4.4</b> 혼합형의 경우</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html"><i class="fa fa-check"></i><b>12</b> 계층적 군집방법</a>
<ul>
<li class="chapter" data-level="12.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hierarchical-clustering-packages-install"><i class="fa fa-check"></i><b>12.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="12.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#distance-between-clusters"><i class="fa fa-check"></i><b>12.2</b> 군집 간 거리척도 및 연결법</a></li>
<li class="chapter" data-level="12.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method"><i class="fa fa-check"></i><b>12.3</b> 연결법의 군집 알고리즘</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method-basic-script"><i class="fa fa-check"></i><b>12.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="12.3.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method-algorithm"><i class="fa fa-check"></i><b>12.3.2</b> 연결법 군집 알고리즘</a></li>
<li class="chapter" data-level="12.3.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hclust"><i class="fa fa-check"></i><b>12.3.3</b> R 패키지 내 연결법</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method"><i class="fa fa-check"></i><b>12.4</b> 워드 방법</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method-basic-script"><i class="fa fa-check"></i><b>12.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="12.4.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method-algorithm"><i class="fa fa-check"></i><b>12.4.2</b> 워드 군집 알고리즘</a></li>
<li class="chapter" data-level="12.4.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-rpackages"><i class="fa fa-check"></i><b>12.4.3</b> R 패키지 내 워드 방법</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana"><i class="fa fa-check"></i><b>12.5</b> 분리적 방법 - 다이아나</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana-basic-script"><i class="fa fa-check"></i><b>12.5.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="12.5.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana-algorithm"><i class="fa fa-check"></i><b>12.5.2</b> 다이아나 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hierarchical-cluster-number"><i class="fa fa-check"></i><b>12.6</b> 군집수의 결정</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html"><i class="fa fa-check"></i><b>13</b> 비계층적 군집방법</a>
<ul>
<li class="chapter" data-level="13.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#nonhierarchical-clustering-packages-install"><i class="fa fa-check"></i><b>13.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="13.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans"><i class="fa fa-check"></i><b>13.2</b> K-means 알고리즘</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-basic-script"><i class="fa fa-check"></i><b>13.2.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="13.2.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-algorithm"><i class="fa fa-check"></i><b>13.2.2</b> 알고리즘</a></li>
<li class="chapter" data-level="13.2.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-user-defined-functions"><i class="fa fa-check"></i><b>13.2.3</b> R 스크립트 구현</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmedoids"><i class="fa fa-check"></i><b>13.3</b> K-medoids 군집방법</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#pam"><i class="fa fa-check"></i><b>13.3.1</b> PAM 알고리즘</a></li>
<li class="chapter" data-level="13.3.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#clara"><i class="fa fa-check"></i><b>13.3.2</b> CLARA 알고리즘</a></li>
<li class="chapter" data-level="13.3.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#clarans"><i class="fa fa-check"></i><b>13.3.3</b> CLARANS 알고리즘</a></li>
<li class="chapter" data-level="13.3.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-like"><i class="fa fa-check"></i><b>13.3.4</b> K-means-like 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans"><i class="fa fa-check"></i><b>13.4</b> 퍼지 K-means 알고리즘</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-basic-script"><i class="fa fa-check"></i><b>13.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="13.4.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-algorithm"><i class="fa fa-check"></i><b>13.4.2</b> 알고리즘</a></li>
<li class="chapter" data-level="13.4.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-script-implement"><i class="fa fa-check"></i><b>13.4.3</b> R 스크립트 구현</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering"><i class="fa fa-check"></i><b>13.5</b> 모형기반 군집방법</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-basic-script"><i class="fa fa-check"></i><b>13.5.1</b> 기본 R script</a></li>
<li class="chapter" data-level="13.5.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-em"><i class="fa fa-check"></i><b>13.5.2</b> EM 알고리즘</a></li>
<li class="chapter" data-level="13.5.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-script-implement"><i class="fa fa-check"></i><b>13.5.3</b> R 스크립트 구현</a></li>
<li class="chapter" data-level="13.5.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#r-packages-model-based-clustering"><i class="fa fa-check"></i><b>13.5.4</b> R 패키지 내 모형기반 군집분석</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html"><i class="fa fa-check"></i><b>14</b> 군집해의 평가 및 해석</a>
<ul>
<li class="chapter" data-level="14.1" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-solution-evaluation-packages-install"><i class="fa fa-check"></i><b>14.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="14.2" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-solution-evaluation-metric"><i class="fa fa-check"></i><b>14.2</b> 군집해의 평가</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-evaluation-external-index"><i class="fa fa-check"></i><b>14.2.1</b> 외부평가지수</a></li>
<li class="chapter" data-level="14.2.2" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-evaluation-internal-index"><i class="fa fa-check"></i><b>14.2.2</b> 내부평가지수</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-solution-interpretation"><i class="fa fa-check"></i><b>14.3</b> 군집해의 해석</a></li>
</ul></li>
<li class="part"><span><b>IV 4부 - 연관규칙</b></span></li>
<li class="chapter" data-level="15" data-path="association-rule.html"><a href="association-rule.html"><i class="fa fa-check"></i><b>15</b> 연관규칙</a>
<ul>
<li class="chapter" data-level="15.1" data-path="association-rule.html"><a href="association-rule.html#association-packages-install"><i class="fa fa-check"></i><b>15.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="15.2" data-path="association-rule.html"><a href="association-rule.html#association-rule-definition-metric"><i class="fa fa-check"></i><b>15.2</b> 연관규칙의 정의 및 성능척도</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="association-rule.html"><a href="association-rule.html#association-rule-support"><i class="fa fa-check"></i><b>15.2.1</b> 지지도</a></li>
<li class="chapter" data-level="15.2.2" data-path="association-rule.html"><a href="association-rule.html#association-rule-confidence"><i class="fa fa-check"></i><b>15.2.2</b> 신뢰도</a></li>
<li class="chapter" data-level="15.2.3" data-path="association-rule.html"><a href="association-rule.html#association-rule-lift"><i class="fa fa-check"></i><b>15.2.3</b> 개선도</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="association-rule.html"><a href="association-rule.html#association-rule-exploration"><i class="fa fa-check"></i><b>15.3</b> 연관규칙의 탐사</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="association-rule.html"><a href="association-rule.html#apriori-large-itemsets"><i class="fa fa-check"></i><b>15.3.1</b> 빈발항목집합 생성</a></li>
<li class="chapter" data-level="15.3.2" data-path="association-rule.html"><a href="association-rule.html#apriori-rule-exploration"><i class="fa fa-check"></i><b>15.3.2</b> 규칙의 탐사</a></li>
<li class="chapter" data-level="15.3.3" data-path="association-rule.html"><a href="association-rule.html#apriori-r-package"><i class="fa fa-check"></i><b>15.3.3</b> R 패키지 내 Apriori</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="association-rule.html"><a href="association-rule.html#association-sequential-pattern"><i class="fa fa-check"></i><b>15.4</b> 순차적 패턴의 탐사</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="association-rule.html"><a href="association-rule.html#association-aprioriall"><i class="fa fa-check"></i><b>15.4.1</b> AprioriAll 알고리즘</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="recommender-system.html"><a href="recommender-system.html"><i class="fa fa-check"></i><b>16</b> 추천시스템</a>
<ul>
<li class="chapter" data-level="16.1" data-path="recommender-system.html"><a href="recommender-system.html#recommender-packages-install"><i class="fa fa-check"></i><b>16.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="16.2" data-path="recommender-system.html"><a href="recommender-system.html#content-based-recommender"><i class="fa fa-check"></i><b>16.2</b> 내용기반 추천시스템</a></li>
<li class="chapter" data-level="16.3" data-path="recommender-system.html"><a href="recommender-system.html#collaborative-filtering"><i class="fa fa-check"></i><b>16.3</b> 협업 필터링</a></li>
<li class="chapter" data-level="16.4" data-path="recommender-system.html"><a href="recommender-system.html#market-basket"><i class="fa fa-check"></i><b>16.4</b> 시장바구니 데이터를 이용한 협업 필터링</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">데이터마이닝 with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hierarchical-clustering" class="section level1" number="12">
<h1><span class="header-section-number">Chapter 12</span> 계층적 군집방법</h1>
<p>계층적 군집방법에는 집괴법과 분리법이 있으나 주로 집괴법이 사용된다. 본 장에서는 집괴법으로는 연결법을 소개하고, 분리법으로는 다이아나(DIANA)를 소개한다.</p>
<div id="hierarchical-clustering-packages-install" class="section level2" number="12.1">
<h2><span class="header-section-number">12.1</span> 필요 R 패키지 설치</h2>
<p>본 장에서 필요한 R 패키지들은 아래와 같다.</p>
<table>
<thead>
<tr class="header">
<th align="left">package</th>
<th align="left">version</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">tidyverse</td>
<td align="left">1.3.1</td>
</tr>
<tr class="even">
<td align="left">stats</td>
<td align="left">4.1.0</td>
</tr>
<tr class="odd">
<td align="left">cluster</td>
<td align="left">2.1.2</td>
</tr>
</tbody>
</table>
</div>
<div id="distance-between-clusters" class="section level2" number="12.2">
<h2><span class="header-section-number">12.2</span> 군집 간 거리척도 및 연결법</h2>
<p>계층적 군집방법에서는 유사한 객체들을 군집으로 묶고, 다시 유사한 군집을 새로운 군집으로 묶는 등 단계적 절차를 사용한다. 이를 위해서는 군집 간의 유사성 척도 혹은 비유사성 척도가 필요하다.</p>
<ul>
<li><span class="math inline">\(C_i\)</span>: <span class="math inline">\(i\)</span>번째 군집(군집 <span class="math inline">\(i\)</span>)</li>
<li><span class="math inline">\(|C_i|\)</span>: 군집 <span class="math inline">\(i\)</span>의 객체수</li>
<li><span class="math inline">\(\mathbf{c}_i = \left( \bar{x}_1^{(i)}, \bar{x}_2^{(i)}, \cdots, \bar{x}_p^{(i)} \right)\)</span>: 군집 <span class="math inline">\(i\)</span>의 중심좌표(centroid) (<span class="math inline">\(\bar{x}_a^{(i)} = \frac{1}{|C_i|} \sum_{j \in C_i} x_{aj}\)</span>)</li>
<li><span class="math inline">\(d(u, v) = d(\mathbf{x}_u, \mathbf{x}_v)\)</span>: 객체 <span class="math inline">\(u\)</span>와 객체 <span class="math inline">\(v\)</span>의 거리(또는 비유사성 척도)</li>
<li><span class="math inline">\(D(C_i, C_j)\)</span>: 군집 <span class="math inline">\(i\)</span>와 군집 <span class="math inline">\(j\)</span>의 거리(또는 비유사성 척도)</li>
</ul>
<p>군집과 군집 간의 거리척도를 평가하는 방법에 따라 다양한 연결법(linkage method)이 존재한다. 아래에 대표적인 연결법과 군집 간 거리척도를 소개한다.</p>
<table>
<caption><span id="tab:linkage-method">Table 12.1: </span>연결법 종류</caption>
<colgroup>
<col width="29%" />
<col width="70%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">연결법</th>
<th align="center">군집거리 <span class="math inline">\(D(C_i, C_j)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">단일연결법(single linkage method)</td>
<td align="center"><span class="math inline">\(\min_{u \in C_i, \, v \in C_j} d(u, v)\)</span></td>
</tr>
<tr class="even">
<td align="center">완전연결법(complete linkage method)</td>
<td align="center"><span class="math inline">\(\max_{u \in C_i, \, v \in C_j} d(u, v)\)</span></td>
</tr>
<tr class="odd">
<td align="center">평균연결법(average linkage method)</td>
<td align="center"><span class="math inline">\(\frac{1}{\lvert C_i \rvert \lvert C_j \rvert} \sum_{u \in C_i, \, v \in C_j} d(u, v)\)</span></td>
</tr>
<tr class="even">
<td align="center">중심연결법(centroid linkage method)</td>
<td align="center"><span class="math inline">\(d(\mathbf{c}_i, \mathbf{c}_j)\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="linkage-method" class="section level2" number="12.3">
<h2><span class="header-section-number">12.3</span> 연결법의 군집 알고리즘</h2>
<div id="linkage-method-basic-script" class="section level3" number="12.3.1">
<h3><span class="header-section-number">12.3.1</span> 기본 R 스크립트</h3>
<div class="sourceCode" id="cb370"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb370-1"><a href="hierarchical-clustering.html#cb370-1" aria-hidden="true" tabindex="-1"></a>train_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb370-2"><a href="hierarchical-clustering.html#cb370-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">id =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>),</span>
<span id="cb370-3"><a href="hierarchical-clustering.html#cb370-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">c</span>(<span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">14</span>, <span class="dv">11</span>, <span class="dv">15</span>, <span class="dv">7</span>, <span class="dv">13</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">3</span>),</span>
<span id="cb370-4"><a href="hierarchical-clustering.html#cb370-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> <span class="fu">c</span>(<span class="dv">14</span>,<span class="dv">13</span>, <span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">7</span>, <span class="dv">15</span>, <span class="dv">6</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>)</span>
<span id="cb370-5"><a href="hierarchical-clustering.html#cb370-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb370-6"><a href="hierarchical-clustering.html#cb370-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb370-7"><a href="hierarchical-clustering.html#cb370-7" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(train_df, <span class="at">booktabs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb370-8"><a href="hierarchical-clustering.html#cb370-8" aria-hidden="true" tabindex="-1"></a>             <span class="at">align =</span> <span class="fu">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),</span>
<span id="cb370-9"><a href="hierarchical-clustering.html#cb370-9" aria-hidden="true" tabindex="-1"></a>             <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">&#39;객체번호&#39;</span>, <span class="st">&#39;PC 경력(년, $x_1$)&#39;</span>, <span class="st">&#39;사용시간(시간, $x_2$)&#39;</span>),</span>
<span id="cb370-10"><a href="hierarchical-clustering.html#cb370-10" aria-hidden="true" tabindex="-1"></a>             <span class="at">caption =</span> <span class="st">&#39;PC 사용자 데이터&#39;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:pc-user-data">Table 12.2: </span>PC 사용자 데이터</caption>
<thead>
<tr class="header">
<th align="right">객체번호</th>
<th align="right">PC 경력(년, <span class="math inline">\(x_1\)</span>)</th>
<th align="right">사용시간(시간, <span class="math inline">\(x_2\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">6</td>
<td align="right">14</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">8</td>
<td align="right">13</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">14</td>
<td align="right">6</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">11</td>
<td align="right">8</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">15</td>
<td align="right">7</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">7</td>
<td align="right">15</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">13</td>
<td align="right">6</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">5</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">3</td>
<td align="right">3</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">3</td>
<td align="right">2</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="hierarchical-clustering.html#cb371-1" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_gray</span>(<span class="at">base_family=</span><span class="st">&#39;NanumGothic&#39;</span>))</span>
<span id="cb371-2"><a href="hierarchical-clustering.html#cb371-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(train_df, <span class="fu">aes</span>(<span class="at">x =</span> x1, <span class="at">y =</span> x2)) <span class="sc">+</span></span>
<span id="cb371-3"><a href="hierarchical-clustering.html#cb371-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> id)) <span class="sc">+</span></span>
<span id="cb371-4"><a href="hierarchical-clustering.html#cb371-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;PC 경력&quot;</span>) <span class="sc">+</span></span>
<span id="cb371-5"><a href="hierarchical-clustering.html#cb371-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;사용시간&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pc-user-data-plot"></span>
<img src="data-mining-book_files/figure-html/pc-user-data-plot-1.png" alt="PC 사용자 데이터" width="672" />
<p class="caption">
Figure 12.1: PC 사용자 데이터
</p>
</div>
<p>Table <a href="hierarchical-clustering.html#tab:pc-user-data">12.2</a>는 10명의 사람(객체)에 대한 PC 사용경력과 주당 PC 사용시간을 나타낸 것이다. 각 객체가 두 변수로 이루어져 있으며, Figure <a href="hierarchical-clustering.html#fig:pc-user-data-plot">12.1</a>에서 보는 바와 같이 세 개의 군집({1, 2, 6}, {3, 4, 5, 7}, {8, 9, 10})으로 이루어져 있다고 볼 수 있다.</p>
<p>본 장에서 평균연결법에 의한 군집화 과정을 살펴보기로 하자. 우선 R 패키지를 이용해서 간단하게 군집해를 구하는 과정은 아래와 같다.</p>
<ol style="list-style-type: decimal">
<li><code>stats</code> 패키지의 함수 <code>dist</code>를 이용하여 객체간 거리를 계산한다.</li>
<li>1에서 얻은 거리 행렬을 <code>stats</code> 패키지의 <code>hclust</code> 함수에 입력하여 데이터 군집을 분석한다. 이 때, 파라미터 <code>method</code>의 값을 “average”로 설정하면 평균연결법을 이용한다.</li>
</ol>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb372-1"><a href="hierarchical-clustering.html#cb372-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dist</span>(train_df[, <span class="sc">-</span><span class="dv">1</span>]) <span class="sc">%&gt;%</span></span>
<span id="cb372-2"><a href="hierarchical-clustering.html#cb372-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hclust</span>(<span class="at">method =</span> <span class="st">&quot;average&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb372-3"><a href="hierarchical-clustering.html#cb372-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(</span>
<span id="cb372-4"><a href="hierarchical-clustering.html#cb372-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">main =</span> <span class="cn">NULL</span>,</span>
<span id="cb372-5"><a href="hierarchical-clustering.html#cb372-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="st">&quot;distance&quot;</span>,</span>
<span id="cb372-6"><a href="hierarchical-clustering.html#cb372-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;observation&quot;</span></span>
<span id="cb372-7"><a href="hierarchical-clustering.html#cb372-7" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pc-user-average-linkage"></span>
<img src="data-mining-book_files/figure-html/pc-user-average-linkage-1.png" alt="PC 사용자 데이터에 대한 평균연결법 덴드로그램" width="672" />
<p class="caption">
Figure 12.2: PC 사용자 데이터에 대한 평균연결법 덴드로그램
</p>
</div>
</div>
<div id="linkage-method-algorithm" class="section level3" number="12.3.2">
<h3><span class="header-section-number">12.3.2</span> 연결법 군집 알고리즘</h3>
<p>각 연결법들은 군집간 유사성 척도 평가 방법이 다를 뿐, 군집화를 위한 알고리즘은 동일하게 아래와 같이 진행된다.</p>
<ol start="0" style="list-style-type: decimal">
<li>단계0: 초기화
<ol style="list-style-type: decimal">
<li>연결법을 선정한다.</li>
<li>각 객체를 하나의 군집으로 간주한다.</li>
<li><span class="math inline">\(k \leftarrow n\)</span></li>
</ol></li>
<li>단계1: 군집
<ol style="list-style-type: decimal">
<li>현재의 군집결과에 있는 모든 군집 간의 쌍에 대하여 <span class="math inline">\(D(C_i, C_j)\)</span>를 산출하여, 이 중 최소가 되는 군집 <span class="math inline">\(i\)</span>와 <span class="math inline">\(j\)</span>를 묶어 하나의 군집으로 만든 후 군집결과를 수정한다.</li>
<li><span class="math inline">\(k \leftarrow k - 1\)</span></li>
</ol></li>
<li>단계2: <span class="math inline">\(k = 1\)</span>이면 Stop, 그렇지 않으면 단계 1을 반복한다.</li>
</ol>
<p>단계1은 객체 수 <span class="math inline">\(n\)</span>만큼 반복된다.</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="hierarchical-clustering.html#cb373-1" aria-hidden="true" tabindex="-1"></a>iteration <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="at">length =</span> <span class="fu">nrow</span>(train_df))</span></code></pre></div>
<p>임의의 군집해에 대하여, 단계1을 수행하는 함수를 아래와 같이 구현해보자. 아래 함수 <code>merge_cluster</code>는 아래와 같은 두 개의 입력변수를 사용한다.</p>
<ul>
<li><code>df</code>: 객체 데이터 프레임. 열 이름이 <code>id</code>인 열은 객체번호를 나타내어, 객체간 거리 계산에 포함하지 않는다.</li>
<li><code>cluster_label</code>: 두 개의 열로 이루어진 데이터 프레임. 열 <code>id</code>는 객체번호를 나타내며, 열 <code>cluster</code>는 군집 이름을 나타낸다. 하나의 객체는 하나의 군집에만 속할 수 있으나, 하나의 군집은 여러 개의 객체를 포함할 수 있다.</li>
</ul>
<p>함수 수행 결과, 아래와 같은 세 개의 원소를 지닌 리스트를 리턴한다.</p>
<ul>
<li><code>cluster_dist</code>: 군집 간 거리를 나타낸 데이터 프레임. 평균연결법에 기반한 거리.</li>
<li><code>closest_clusters</code>: 입력된 군집해 내에서 가장 가까운 두 군집을 나타낸 데이터 프레임. 두 열 <code>item1</code>과 <code>item2</code>는 각각 군집 이름을 나타내며, <code>distance</code>는 해당 두 군집간의 거리를 나타낸다.</li>
<li><code>new_cluster_label</code>: <code>closest_clusters</code>에 포함된 두 군집을 하나로 묶어 새로운 군집을 만든 후 얻어진 군집해.</li>
</ul>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="hierarchical-clustering.html#cb374-1" aria-hidden="true" tabindex="-1"></a>merge_cluster <span class="ot">&lt;-</span> <span class="cf">function</span>(df, cluster_label) {</span>
<span id="cb374-2"><a href="hierarchical-clustering.html#cb374-2" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 군집간 거리 계산한다. - 유클리드 거리 및 평균연결법 기반</span></span>
<span id="cb374-3"><a href="hierarchical-clustering.html#cb374-3" aria-hidden="true" tabindex="-1"></a>  cluster_dist <span class="ot">&lt;-</span> <span class="fu">dist</span>(<span class="fu">subset</span>(df, <span class="at">select =</span> <span class="sc">-</span>id), <span class="at">upper =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb374-4"><a href="hierarchical-clustering.html#cb374-4" aria-hidden="true" tabindex="-1"></a>    broom<span class="sc">::</span><span class="fu">tidy</span>() <span class="sc">%&gt;%</span></span>
<span id="cb374-5"><a href="hierarchical-clustering.html#cb374-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate_if</span>(is.factor, <span class="sc">~</span> <span class="fu">as.integer</span>(<span class="fu">as.character</span>(.))) <span class="sc">%&gt;%</span></span>
<span id="cb374-6"><a href="hierarchical-clustering.html#cb374-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">inner_join</span>(</span>
<span id="cb374-7"><a href="hierarchical-clustering.html#cb374-7" aria-hidden="true" tabindex="-1"></a>      cluster_label <span class="sc">%&gt;%</span> <span class="fu">rename</span>(</span>
<span id="cb374-8"><a href="hierarchical-clustering.html#cb374-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">item1 =</span> id, <span class="at">cluster1 =</span> cluster</span>
<span id="cb374-9"><a href="hierarchical-clustering.html#cb374-9" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb374-10"><a href="hierarchical-clustering.html#cb374-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">by =</span> <span class="st">&quot;item1&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb374-11"><a href="hierarchical-clustering.html#cb374-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">inner_join</span>(</span>
<span id="cb374-12"><a href="hierarchical-clustering.html#cb374-12" aria-hidden="true" tabindex="-1"></a>      cluster_label <span class="sc">%&gt;%</span> <span class="fu">rename</span>(</span>
<span id="cb374-13"><a href="hierarchical-clustering.html#cb374-13" aria-hidden="true" tabindex="-1"></a>        <span class="at">item2 =</span> id, <span class="at">cluster2 =</span> cluster</span>
<span id="cb374-14"><a href="hierarchical-clustering.html#cb374-14" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb374-15"><a href="hierarchical-clustering.html#cb374-15" aria-hidden="true" tabindex="-1"></a>      <span class="at">by =</span> <span class="st">&quot;item2&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb374-16"><a href="hierarchical-clustering.html#cb374-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(cluster1 <span class="sc">!=</span> cluster2) <span class="sc">%&gt;%</span></span>
<span id="cb374-17"><a href="hierarchical-clustering.html#cb374-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(cluster1, cluster2) <span class="sc">%&gt;%</span></span>
<span id="cb374-18"><a href="hierarchical-clustering.html#cb374-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="at">distance =</span> <span class="fu">mean</span>(distance)) <span class="sc">%&gt;%</span></span>
<span id="cb374-19"><a href="hierarchical-clustering.html#cb374-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ungroup</span>()</span>
<span id="cb374-20"><a href="hierarchical-clustering.html#cb374-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb374-21"><a href="hierarchical-clustering.html#cb374-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 서로 가장 가깝게 위치하는 두 군집을 찾는다.</span></span>
<span id="cb374-22"><a href="hierarchical-clustering.html#cb374-22" aria-hidden="true" tabindex="-1"></a>  closest_clusters <span class="ot">&lt;-</span> cluster_dist <span class="sc">%&gt;%</span></span>
<span id="cb374-23"><a href="hierarchical-clustering.html#cb374-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">arrange</span>(distance) <span class="sc">%&gt;%</span></span>
<span id="cb374-24"><a href="hierarchical-clustering.html#cb374-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">slice</span>(<span class="dv">1</span>)</span>
<span id="cb374-25"><a href="hierarchical-clustering.html#cb374-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb374-26"><a href="hierarchical-clustering.html#cb374-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 군집해를 업데이트한다.</span></span>
<span id="cb374-27"><a href="hierarchical-clustering.html#cb374-27" aria-hidden="true" tabindex="-1"></a>  cluster_label[</span>
<span id="cb374-28"><a href="hierarchical-clustering.html#cb374-28" aria-hidden="true" tabindex="-1"></a>    cluster_label<span class="sc">$</span>cluster <span class="sc">%in%</span> (</span>
<span id="cb374-29"><a href="hierarchical-clustering.html#cb374-29" aria-hidden="true" tabindex="-1"></a>      closest_clusters[, <span class="fu">c</span>(<span class="st">&quot;cluster1&quot;</span>, <span class="st">&quot;cluster2&quot;</span>)] <span class="sc">%&gt;%</span> <span class="fu">unlist</span>()</span>
<span id="cb374-30"><a href="hierarchical-clustering.html#cb374-30" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb374-31"><a href="hierarchical-clustering.html#cb374-31" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;cluster&quot;</span></span>
<span id="cb374-32"><a href="hierarchical-clustering.html#cb374-32" aria-hidden="true" tabindex="-1"></a>  ] <span class="ot">&lt;-</span> <span class="fu">paste</span>(</span>
<span id="cb374-33"><a href="hierarchical-clustering.html#cb374-33" aria-hidden="true" tabindex="-1"></a>    closest_clusters[, <span class="fu">c</span>(<span class="st">&quot;cluster1&quot;</span>, <span class="st">&quot;cluster2&quot;</span>)] <span class="sc">%&gt;%</span> <span class="fu">unlist</span>(),</span>
<span id="cb374-34"><a href="hierarchical-clustering.html#cb374-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">collapse =</span> <span class="st">&quot;,&quot;</span></span>
<span id="cb374-35"><a href="hierarchical-clustering.html#cb374-35" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb374-36"><a href="hierarchical-clustering.html#cb374-36" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb374-37"><a href="hierarchical-clustering.html#cb374-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(<span class="at">cluster_dist =</span> cluster_dist, </span>
<span id="cb374-38"><a href="hierarchical-clustering.html#cb374-38" aria-hidden="true" tabindex="-1"></a>       <span class="at">closest_clusters =</span> closest_clusters, </span>
<span id="cb374-39"><a href="hierarchical-clustering.html#cb374-39" aria-hidden="true" tabindex="-1"></a>       <span class="at">new_cluster_label =</span> cluster_label)</span>
<span id="cb374-40"><a href="hierarchical-clustering.html#cb374-40" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>우선 단계 0에서 얻어지는 군집해에 대한 데이터를 아래와 같이 생성한다.</p>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb375-1"><a href="hierarchical-clustering.html#cb375-1" aria-hidden="true" tabindex="-1"></a>init_cluster <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb375-2"><a href="hierarchical-clustering.html#cb375-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">id =</span> train_df<span class="sc">$</span>id,</span>
<span id="cb375-3"><a href="hierarchical-clustering.html#cb375-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">cluster =</span> <span class="fu">as.character</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(train_df))</span>
<span id="cb375-4"><a href="hierarchical-clustering.html#cb375-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb375-5"><a href="hierarchical-clustering.html#cb375-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb375-6"><a href="hierarchical-clustering.html#cb375-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">unique</span>(init_cluster<span class="sc">$</span>cluster))</span></code></pre></div>
<pre><code>##  [1] &quot;1&quot;  &quot;2&quot;  &quot;3&quot;  &quot;4&quot;  &quot;5&quot;  &quot;6&quot;  &quot;7&quot;  &quot;8&quot;  &quot;9&quot;  &quot;10&quot;</code></pre>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb377-1"><a href="hierarchical-clustering.html#cb377-1" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">unique</span>(init_cluster<span class="sc">$</span>cluster))</span>
<span id="cb377-2"><a href="hierarchical-clustering.html#cb377-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb377-3"><a href="hierarchical-clustering.html#cb377-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(k)</span></code></pre></div>
<pre><code>## [1] 10</code></pre>
<p>위와 같이, 초기 군집해에서 군집 수는 전체 객체수와 같은 10개이다.</p>
<p>위 초기해로부터 단계1을 아래와 같이 수행해보자.</p>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb379-1"><a href="hierarchical-clustering.html#cb379-1" aria-hidden="true" tabindex="-1"></a>iteration[[<span class="dv">1</span>]] <span class="ot">&lt;-</span> <span class="fu">merge_cluster</span>(train_df, init_cluster)</span></code></pre></div>
<pre><code>## `summarise()` has grouped output by &#39;cluster1&#39;. You can override using the `.groups` argument.</code></pre>
<p>찾아진 가장 가까운 두 군집은 아래와 같다.</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb381-1"><a href="hierarchical-clustering.html#cb381-1" aria-hidden="true" tabindex="-1"></a>iteration[[<span class="dv">1</span>]]<span class="sc">$</span>closest_cluster</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   cluster1 cluster2 distance
##   &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;
## 1 10       9               1</code></pre>
<p>위 두 군집을 하나로 묶은 새로운 군집해는 아래와 같다.</p>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb383-1"><a href="hierarchical-clustering.html#cb383-1" aria-hidden="true" tabindex="-1"></a>iteration[[<span class="dv">1</span>]]<span class="sc">$</span>new_cluster_label</span></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##       id cluster
##    &lt;int&gt; &lt;chr&gt;  
##  1     1 1      
##  2     2 2      
##  3     3 3      
##  4     4 4      
##  5     5 5      
##  6     6 6      
##  7     7 7      
##  8     8 8      
##  9     9 10,9   
## 10    10 10,9</code></pre>
<p>위 새로운 군집해의 군집 수는 9이다. 이는 아직 1보다 크므로, 새로 얻어진 군집해로부터 단계 1을 반복한다.</p>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb385-1"><a href="hierarchical-clustering.html#cb385-1" aria-hidden="true" tabindex="-1"></a>iteration[[<span class="dv">2</span>]] <span class="ot">&lt;-</span> <span class="fu">merge_cluster</span>(</span>
<span id="cb385-2"><a href="hierarchical-clustering.html#cb385-2" aria-hidden="true" tabindex="-1"></a>  train_df,</span>
<span id="cb385-3"><a href="hierarchical-clustering.html#cb385-3" aria-hidden="true" tabindex="-1"></a>  iteration[[<span class="dv">1</span>]]<span class="sc">$</span>new_cluster_label</span>
<span id="cb385-4"><a href="hierarchical-clustering.html#cb385-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## `summarise()` has grouped output by &#39;cluster1&#39;. You can override using the `.groups` argument.</code></pre>
<p>이번에 찾아진 가장 가까운 두 군집은 아래와 같다.</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb387-1"><a href="hierarchical-clustering.html#cb387-1" aria-hidden="true" tabindex="-1"></a>iteration[[<span class="dv">2</span>]]<span class="sc">$</span>closest_cluster</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   cluster1 cluster2 distance
##   &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;
## 1 3        7               1</code></pre>
<p>위 두 군집을 하나로 묶은 새로운 군집해는 아래와 같다.</p>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb389-1"><a href="hierarchical-clustering.html#cb389-1" aria-hidden="true" tabindex="-1"></a>iteration[[<span class="dv">2</span>]]<span class="sc">$</span>new_cluster_label</span></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##       id cluster
##    &lt;int&gt; &lt;chr&gt;  
##  1     1 1      
##  2     2 2      
##  3     3 3,7    
##  4     4 4      
##  5     5 5      
##  6     6 6      
##  7     7 3,7    
##  8     8 8      
##  9     9 10,9   
## 10    10 10,9</code></pre>
<p>위 군집해에 기반하여 단계 1을 다시 반복해보자.</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="hierarchical-clustering.html#cb391-1" aria-hidden="true" tabindex="-1"></a>iteration[[<span class="dv">3</span>]] <span class="ot">&lt;-</span> <span class="fu">merge_cluster</span>(</span>
<span id="cb391-2"><a href="hierarchical-clustering.html#cb391-2" aria-hidden="true" tabindex="-1"></a>  train_df,</span>
<span id="cb391-3"><a href="hierarchical-clustering.html#cb391-3" aria-hidden="true" tabindex="-1"></a>  iteration[[<span class="dv">2</span>]]<span class="sc">$</span>new_cluster_label</span>
<span id="cb391-4"><a href="hierarchical-clustering.html#cb391-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## `summarise()` has grouped output by &#39;cluster1&#39;. You can override using the `.groups` argument.</code></pre>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb393-1"><a href="hierarchical-clustering.html#cb393-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(iteration[[<span class="dv">3</span>]]<span class="sc">$</span>closest_cluster)</span></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##   cluster1 cluster2 distance
##   &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;
## 1 1        6            1.41</code></pre>
<div class="sourceCode" id="cb395"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb395-1"><a href="hierarchical-clustering.html#cb395-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(iteration[[<span class="dv">3</span>]]<span class="sc">$</span>new_cluster_label)</span></code></pre></div>
<pre><code>## # A tibble: 10 x 2
##       id cluster
##    &lt;int&gt; &lt;chr&gt;  
##  1     1 1,6    
##  2     2 2      
##  3     3 3,7    
##  4     4 4      
##  5     5 5      
##  6     6 1,6    
##  7     7 3,7    
##  8     8 8      
##  9     9 10,9   
## 10    10 10,9</code></pre>
<p>위와 같은 과정을 전체 객체가 하나의 군집으로 묶일 때까지 아래와 같이 반복하며 군집결과를 출력해보자.</p>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb397-1"><a href="hierarchical-clustering.html#cb397-1" aria-hidden="true" tabindex="-1"></a><span class="co">#단계0</span></span>
<span id="cb397-2"><a href="hierarchical-clustering.html#cb397-2" aria-hidden="true" tabindex="-1"></a>init_cluster <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb397-3"><a href="hierarchical-clustering.html#cb397-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">id =</span> train_df<span class="sc">$</span>id,</span>
<span id="cb397-4"><a href="hierarchical-clustering.html#cb397-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">cluster =</span> <span class="fu">as.character</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(train_df))</span>
<span id="cb397-5"><a href="hierarchical-clustering.html#cb397-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb397-6"><a href="hierarchical-clustering.html#cb397-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb397-7"><a href="hierarchical-clustering.html#cb397-7" aria-hidden="true" tabindex="-1"></a>i <span class="ot">&lt;-</span> 0L</span>
<span id="cb397-8"><a href="hierarchical-clustering.html#cb397-8" aria-hidden="true" tabindex="-1"></a>current_clusters <span class="ot">&lt;-</span> <span class="fu">unique</span>(init_cluster<span class="sc">$</span>cluster)</span>
<span id="cb397-9"><a href="hierarchical-clustering.html#cb397-9" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">length</span>(current_clusters)</span>
<span id="cb397-10"><a href="hierarchical-clustering.html#cb397-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb397-11"><a href="hierarchical-clustering.html#cb397-11" aria-hidden="true" tabindex="-1"></a>print_clusters <span class="ot">&lt;-</span> <span class="cf">function</span>(i, k, clusters) {</span>
<span id="cb397-12"><a href="hierarchical-clustering.html#cb397-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">&quot;Iteration: &quot;</span>, i, <span class="st">&quot;, k = &quot;</span>, k, <span class="st">&quot;, clusters = &quot;</span>, <span class="fu">paste0</span>(<span class="st">&quot;{&quot;</span>, clusters, <span class="st">&quot;}&quot;</span>), <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb397-13"><a href="hierarchical-clustering.html#cb397-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb397-14"><a href="hierarchical-clustering.html#cb397-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb397-15"><a href="hierarchical-clustering.html#cb397-15" aria-hidden="true" tabindex="-1"></a><span class="fu">print_clusters</span>(i, k, current_clusters)</span></code></pre></div>
<pre><code>## Iteration:  0 , k =  10 , clusters =  {1} {2} {3} {4} {5} {6} {7} {8} {9} {10}</code></pre>
<div class="sourceCode" id="cb399"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb399-1"><a href="hierarchical-clustering.html#cb399-1" aria-hidden="true" tabindex="-1"></a><span class="co">#단계1</span></span>
<span id="cb399-2"><a href="hierarchical-clustering.html#cb399-2" aria-hidden="true" tabindex="-1"></a>iteration <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="at">length =</span> <span class="fu">nrow</span>(train_df) <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb399-3"><a href="hierarchical-clustering.html#cb399-3" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span>(k <span class="sc">&gt;</span> <span class="dv">1</span>) {</span>
<span id="cb399-4"><a href="hierarchical-clustering.html#cb399-4" aria-hidden="true" tabindex="-1"></a>  i <span class="ot">&lt;-</span> i <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb399-5"><a href="hierarchical-clustering.html#cb399-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(i <span class="sc">==</span> <span class="dv">1</span>) {</span>
<span id="cb399-6"><a href="hierarchical-clustering.html#cb399-6" aria-hidden="true" tabindex="-1"></a>    iteration[[i]] <span class="ot">&lt;-</span> <span class="fu">merge_cluster</span>(</span>
<span id="cb399-7"><a href="hierarchical-clustering.html#cb399-7" aria-hidden="true" tabindex="-1"></a>      train_df,</span>
<span id="cb399-8"><a href="hierarchical-clustering.html#cb399-8" aria-hidden="true" tabindex="-1"></a>      init_cluster</span>
<span id="cb399-9"><a href="hierarchical-clustering.html#cb399-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb399-10"><a href="hierarchical-clustering.html#cb399-10" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb399-11"><a href="hierarchical-clustering.html#cb399-11" aria-hidden="true" tabindex="-1"></a>    iteration[[i]] <span class="ot">&lt;-</span> <span class="fu">merge_cluster</span>(</span>
<span id="cb399-12"><a href="hierarchical-clustering.html#cb399-12" aria-hidden="true" tabindex="-1"></a>      train_df,</span>
<span id="cb399-13"><a href="hierarchical-clustering.html#cb399-13" aria-hidden="true" tabindex="-1"></a>      iteration[[i<span class="dv">-1</span>]]<span class="sc">$</span>new_cluster_label</span>
<span id="cb399-14"><a href="hierarchical-clustering.html#cb399-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb399-15"><a href="hierarchical-clustering.html#cb399-15" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb399-16"><a href="hierarchical-clustering.html#cb399-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb399-17"><a href="hierarchical-clustering.html#cb399-17" aria-hidden="true" tabindex="-1"></a>  current_clusters <span class="ot">&lt;-</span> <span class="fu">unique</span>(iteration[[i]]<span class="sc">$</span>new_cluster_label<span class="sc">$</span>cluster)</span>
<span id="cb399-18"><a href="hierarchical-clustering.html#cb399-18" aria-hidden="true" tabindex="-1"></a>  k <span class="ot">&lt;-</span> <span class="fu">length</span>(current_clusters)</span>
<span id="cb399-19"><a href="hierarchical-clustering.html#cb399-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb399-20"><a href="hierarchical-clustering.html#cb399-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print_clusters</span>(i, k, current_clusters)</span>
<span id="cb399-21"><a href="hierarchical-clustering.html#cb399-21" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## Iteration:  1 , k =  9 , clusters =  {1} {2} {3} {4} {5} {6} {7} {8} {10,9} 
## Iteration:  2 , k =  8 , clusters =  {1} {2} {3,7} {4} {5} {6} {8} {10,9} 
## Iteration:  3 , k =  7 , clusters =  {1,6} {2} {3,7} {4} {5} {8} {10,9} 
## Iteration:  4 , k =  6 , clusters =  {1,6} {2} {3,7,5} {4} {8} {10,9} 
## Iteration:  5 , k =  5 , clusters =  {1,6,2} {3,7,5} {4} {8} {10,9} 
## Iteration:  6 , k =  4 , clusters =  {1,6,2} {3,7,5} {4} {10,9,8} 
## Iteration:  7 , k =  3 , clusters =  {1,6,2} {3,7,5,4} {10,9,8} 
## Iteration:  8 , k =  2 , clusters =  {1,6,2,3,7,5,4} {10,9,8} 
## Iteration:  9 , k =  1 , clusters =  {1,6,2,3,7,5,4,10,9,8}</code></pre>
</div>
<div id="hclust" class="section level3" number="12.3.3">
<h3><span class="header-section-number">12.3.3</span> R 패키지 내 연결법</h3>
<p>R에서는 <code>stats</code> 패키지의 <code>hclust</code> 함수를 이용하여 군집해를 구할 수 있다.</p>
<p>우선, 객체간 거리 행렬을 함수 <code>dist</code>를 이용하여 구한다. 아래는 유클리드 거리를 구하는 예이며, 상황에 따라 다른 거리 척도를 이용할 수도 있다.</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="hierarchical-clustering.html#cb401-1" aria-hidden="true" tabindex="-1"></a>distance_matrix <span class="ot">&lt;-</span> <span class="fu">dist</span>(train_df[, <span class="sc">-</span><span class="dv">1</span>])</span></code></pre></div>
<p>객체간 거리를 구한 후, 함수 <code>hclust</code>를 이용하여 군집분석을 수행한다. 기본설정은 완전연결법이며, 파라미터 <code>method</code>의 값을 설정함으로써 단일연결법, 평균연결법, 중심연결법을 수행할 수 있다.</p>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="hierarchical-clustering.html#cb402-1" aria-hidden="true" tabindex="-1"></a>cluster_solution <span class="ot">&lt;-</span> <span class="fu">hclust</span>(distance_matrix, <span class="at">method =</span> <span class="st">&quot;average&quot;</span>)</span></code></pre></div>
<p>결과 객체 <code>cluster_solution</code>는 아래와 같은 컴포넌트(components)를 지닌 리스트(list) 객체이다.</p>
<div class="sourceCode" id="cb403"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb403-1"><a href="hierarchical-clustering.html#cb403-1" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(cluster_solution)</span></code></pre></div>
<pre><code>## [1] &quot;merge&quot;       &quot;height&quot;      &quot;order&quot;       &quot;labels&quot;      &quot;method&quot;     
## [6] &quot;call&quot;        &quot;dist.method&quot;</code></pre>
<p>이 중, <code>merge</code>는 2개의 열과 <span class="math inline">\(n - 1\)</span>개의 행으로 이루어진 행렬로, 연결법 알고리즘의 단계1 iteration에서 묶어지는 두 군집을 기록한 것이다.</p>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb405-1"><a href="hierarchical-clustering.html#cb405-1" aria-hidden="true" tabindex="-1"></a>cluster_solution<span class="sc">$</span>merge</span></code></pre></div>
<pre><code>##       [,1] [,2]
##  [1,]   -3   -7
##  [2,]   -9  -10
##  [3,]   -1   -6
##  [4,]   -5    1
##  [5,]   -2    3
##  [6,]   -8    2
##  [7,]   -4    4
##  [8,]    5    7
##  [9,]    6    8</code></pre>
<p>위에서 각 행은 iteration을 나타내며, 두 열은 묶어지는 두 군집을 나타낸다. 값이 0보다 작은 경우에는 번호가 원 객체 번호를 나타내며, 값이 0보다 큰 경우에는 해당 번호의 iteration에서 묶어진 군집을 나타낸다. 예를 들어, 위 결과의 6번째 행 (-8, 2) 은 객체 8과 두 번째 iteration에서 얻어진 군집 (객체 9와 10이 묶여진 군집)이 묶여 하나의 군집(객체 8, 9, 10)을 이루게 됨을 나타낸다.</p>
<p><code>height</code>는 각 iteration에서 묶이는 두 군집간의 거리를 나타내며, 위 Figure <a href="hierarchical-clustering.html#fig:pc-user-average-linkage">12.2</a>의 덴드로그램에서 세로선의 높이를 나타낸다. Iteration이 증가함에 따라 묶이는 두 군집간의 거리도 증가한다. 일반적으로 이 거리값이 크게 증가하는 iteration에서 두 군집을 묶지 않고 최종 군집해를 도출한다.</p>
<div class="sourceCode" id="cb407"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb407-1"><a href="hierarchical-clustering.html#cb407-1" aria-hidden="true" tabindex="-1"></a>cluster_solution<span class="sc">$</span>height</span></code></pre></div>
<pre><code>## [1]  1.000000  1.000000  1.414214  1.825141  2.236068  2.532248  3.519028
## [8]  9.635217 10.881878</code></pre>
<p>위 결과의 경우 iteration 8에서 거리값이 크게 증가한다. 이는 위 Figure <a href="hierarchical-clustering.html#fig:pc-user-average-linkage">12.2</a>의 덴드로그램에서 3개의 군집에서 2개의 군집으로 묶이는 과정에서 세로선의 높이가 현격히 증가하는 지점이다. 따라서, iteration 7에서 얻어진 3개의 군집이 적절한 군집해라 판단할 수 있겠다.</p>
</div>
</div>
<div id="ward-method" class="section level2" number="12.4">
<h2><span class="header-section-number">12.4</span> 워드 방법</h2>
<p>워드방법(Ward’s method) 역시 각 객체를 하나의 군집으로 간주함을 시작으로 군집들을 묶어 단계적으로 그 수를 하나가 돌 때까지 줄여나가는 것인데, 군집의 제곱합을 활용한다.</p>
<div id="ward-method-basic-script" class="section level3" number="12.4.1">
<h3><span class="header-section-number">12.4.1</span> 기본 R 스크립트</h3>
<p>아래 Table <a href="hierarchical-clustering.html#tab:driver-data">12.3</a>는 8명의 운전자에 대한 운전경력과 교통위반 횟수를 나타낸 것이다.</p>
<div class="sourceCode" id="cb409"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb409-1"><a href="hierarchical-clustering.html#cb409-1" aria-hidden="true" tabindex="-1"></a>train_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb409-2"><a href="hierarchical-clustering.html#cb409-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">id =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>),</span>
<span id="cb409-3"><a href="hierarchical-clustering.html#cb409-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">20</span>, <span class="dv">3</span>, <span class="dv">19</span>, <span class="dv">17</span>, <span class="dv">8</span>, <span class="dv">19</span>, <span class="dv">18</span>),</span>
<span id="cb409-4"><a href="hierarchical-clustering.html#cb409-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> <span class="fu">c</span>(<span class="dv">15</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">4</span>, <span class="dv">17</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">6</span>)</span>
<span id="cb409-5"><a href="hierarchical-clustering.html#cb409-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb409-6"><a href="hierarchical-clustering.html#cb409-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb409-7"><a href="hierarchical-clustering.html#cb409-7" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(train_df, <span class="at">booktabs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb409-8"><a href="hierarchical-clustering.html#cb409-8" aria-hidden="true" tabindex="-1"></a>             <span class="at">align =</span> <span class="fu">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),</span>
<span id="cb409-9"><a href="hierarchical-clustering.html#cb409-9" aria-hidden="true" tabindex="-1"></a>             <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">&#39;객체번호&#39;</span>, <span class="st">&#39;운전경력($x_1$)&#39;</span>, <span class="st">&#39;위반횟수($x_2$)&#39;</span>),</span>
<span id="cb409-10"><a href="hierarchical-clustering.html#cb409-10" aria-hidden="true" tabindex="-1"></a>             <span class="at">caption =</span> <span class="st">&#39;운전경력에 따른 교통위반 횟수&#39;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:driver-data">Table 12.3: </span>운전경력에 따른 교통위반 횟수</caption>
<thead>
<tr class="header">
<th align="right">객체번호</th>
<th align="right">운전경력(<span class="math inline">\(x_1\)</span>)</th>
<th align="right">위반횟수(<span class="math inline">\(x_2\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">4</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">20</td>
<td align="right">13</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">3</td>
<td align="right">13</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">19</td>
<td align="right">4</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">17</td>
<td align="right">17</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">8</td>
<td align="right">11</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">19</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">18</td>
<td align="right">6</td>
</tr>
</tbody>
</table>
<p>앞 절의 연결법에서 사용했던 <code>hclust</code> 함수를 이용하여 워드 방법에 의한 군집해도 구할 수 있으며, 이 때 파라미터 <code>method</code>의 값으로 “ward.D2”를 사용한다.</p>
<div class="sourceCode" id="cb410"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb410-1"><a href="hierarchical-clustering.html#cb410-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dist</span>(train_df[, <span class="sc">-</span><span class="dv">1</span>]) <span class="sc">%&gt;%</span></span>
<span id="cb410-2"><a href="hierarchical-clustering.html#cb410-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hclust</span>(<span class="at">method =</span> <span class="st">&quot;ward.D2&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb410-3"><a href="hierarchical-clustering.html#cb410-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot</span>(</span>
<span id="cb410-4"><a href="hierarchical-clustering.html#cb410-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">main =</span> <span class="cn">NULL</span>,</span>
<span id="cb410-5"><a href="hierarchical-clustering.html#cb410-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;observation&quot;</span></span>
<span id="cb410-6"><a href="hierarchical-clustering.html#cb410-6" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:ward-dendrogram"></span>
<img src="data-mining-book_files/figure-html/ward-dendrogram-1.png" alt="운전자 데이터에 대한 워드 방법 덴드로그램" width="672" />
<p class="caption">
Figure 12.3: 운전자 데이터에 대한 워드 방법 덴드로그램
</p>
</div>
</div>
<div id="ward-method-algorithm" class="section level3" number="12.4.2">
<h3><span class="header-section-number">12.4.2</span> 워드 군집 알고리즘</h3>
<p>군집결과가 <span class="math inline">\(\mathbf{C} = \{ C_1, C_2, \cdots, C_k \}\)</span>일 때, 군집 <span class="math inline">\(C_i\)</span> 내의 제곱합(within sum of squares)은 다음과 같이 산출된다.</p>
<p><span class="math display">\[\begin{equation*}
SS(C_i) = \sum_{u \in C_i} \left(\mathbf{x}_u - \mathbf{c}_i\right)^\top\left(\mathbf{x}_u - \mathbf{c}_i\right)
\end{equation*}\]</span></p>
<p>이 때, 전체 군집 내 제곱합을 <span class="math inline">\(SSW\)</span>라 할 때, 이는 다음과 같다.</p>
<p><span class="math display">\[\begin{equation*}
SSW = \sum_{i = 1}^{k} SS(C_i)
\end{equation*}\]</span></p>
<p>다음으로, 현 군집의 각 쌍을 묶는다고 할 때의 새로운 <span class="math inline">\(SSW\)</span>를 산출한 후, 이 값이 가장 작게 되는 군집 쌍을 묶는다.</p>
<ol style="list-style-type: decimal">
<li>단계0
<ol style="list-style-type: decimal">
<li>각 객체를 하나의 군집으로 간주한다.</li>
<li><span class="math inline">\(k \leftarrow n\)</span></li>
</ol></li>
<li>단계1
<ol style="list-style-type: decimal">
<li>현재의 군집 결과에 있는 모든 군집간의 쌍에 대하여 묶을 경우 전체제곱합(SSW)을 산출하고, 이 중 최소가 되는 군집 <span class="math inline">\(i\)</span>와 군집 <span class="math inline">\(j\)</span>를 묶어 하나의 군집으로 만든 후, 군집 결과를 수정한다.</li>
<li><span class="math inline">\(k \leftarrow k - 1\)</span></li>
</ol></li>
<li>단계2: <span class="math inline">\(k = 1\)</span>이면 Stop, 그렇지 않으면 단계1을 반복한다.</li>
</ol>
<p>워드 군집 알고리즘을 R script로 구현해보자. 우선, 객체 데이터 <span class="math inline">\(SSW\)</span>를 계산하는 사용자 정의 함수 <code>calculate_ssw</code>를 아래와 같이 두 입력변수 <code>df</code> 및 <code>cluster_label</code>를 이용하여 구현하자.</p>
<ul>
<li><code>df</code>: 객체 데이터 프레임. 열 이름이 <code>id</code>인 열은 객체번호를 나타내어, 객체간 거리 계산에 포함하지 않는다.</li>
<li><code>cluster_label</code>: 두 개의 열로 이루어진 데이터 프레임. 열 <code>id</code>는 객체번호를 나타내며, 열 <code>cluster</code>는 군집 이름을 나타낸다. 하나의 객체는 하나의 군집에만 속할 수 있으나, 하나의 군집은 여러 개의 객체를 포함할 수 있다.</li>
</ul>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="hierarchical-clustering.html#cb411-1" aria-hidden="true" tabindex="-1"></a><span class="co"># SSW 계산</span></span>
<span id="cb411-2"><a href="hierarchical-clustering.html#cb411-2" aria-hidden="true" tabindex="-1"></a>calculate_ssw <span class="ot">&lt;-</span> <span class="cf">function</span>(df, cluster_label) {</span>
<span id="cb411-3"><a href="hierarchical-clustering.html#cb411-3" aria-hidden="true" tabindex="-1"></a>  df <span class="sc">%&gt;%</span></span>
<span id="cb411-4"><a href="hierarchical-clustering.html#cb411-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">inner_join</span>(cluster_label, <span class="at">by =</span> <span class="st">&quot;id&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb411-5"><a href="hierarchical-clustering.html#cb411-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(cluster) <span class="sc">%&gt;%</span></span>
<span id="cb411-6"><a href="hierarchical-clustering.html#cb411-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(<span class="sc">-</span>id) <span class="sc">%&gt;%</span></span>
<span id="cb411-7"><a href="hierarchical-clustering.html#cb411-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize_all</span>(<span class="cf">function</span>(x) <span class="fu">sum</span>((x <span class="sc">-</span> <span class="fu">mean</span>(x))<span class="sc">^</span><span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb411-8"><a href="hierarchical-clustering.html#cb411-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb411-9"><a href="hierarchical-clustering.html#cb411-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">ss =</span> <span class="fu">rowSums</span>(<span class="fu">subset</span>(., <span class="at">select =</span> <span class="sc">-</span>cluster))) <span class="sc">%&gt;%</span></span>
<span id="cb411-10"><a href="hierarchical-clustering.html#cb411-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at">[[</span><span class="st">`</span>(<span class="st">&quot;ss&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb411-11"><a href="hierarchical-clustering.html#cb411-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">sum</span>()</span>
<span id="cb411-12"><a href="hierarchical-clustering.html#cb411-12" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>워드 군집 알고리즘은 현재 군집해 내의 모든 군집쌍에 대하여 두 군집을 하나의 군집으로 묶을 경우의 <span class="math inline">\(SSW\)</span>를 계산해야 한다. 따라서, 우선 고려할 모든 군집해를 생성하는 사용자 정의 함수 <code>generate_clusters</code>를 아래와 같이 구현한다.</p>
<p>아래 사용자 정의 함수 <code>generate_clusters</code>는 임의의 군집해 <code>cluster_label</code>을 입력변수로 사용하며, 해당 입력변수에 대한 설명은 위 함수 <code>calculate_ssw</code>에서와 같다. 함수 수행 결과, 가능한 각각의 군집쌍 결합의 결과물인 군집해 데이터 프레임을 리스트(list) 형태로 출력한다.</p>
<div class="sourceCode" id="cb412"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb412-1"><a href="hierarchical-clustering.html#cb412-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 임의의 군집해로부터 가능한 다음단계 군집해 생성</span></span>
<span id="cb412-2"><a href="hierarchical-clustering.html#cb412-2" aria-hidden="true" tabindex="-1"></a>generate_clusters <span class="ot">&lt;-</span> <span class="cf">function</span>(cluster_label) {</span>
<span id="cb412-3"><a href="hierarchical-clustering.html#cb412-3" aria-hidden="true" tabindex="-1"></a>  unique_clusters <span class="ot">&lt;-</span> <span class="fu">unique</span>(cluster_label<span class="sc">$</span>cluster)</span>
<span id="cb412-4"><a href="hierarchical-clustering.html#cb412-4" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb412-5"><a href="hierarchical-clustering.html#cb412-5" aria-hidden="true" tabindex="-1"></a>  potential_pairs <span class="ot">&lt;-</span> <span class="fu">crossing</span>(<span class="at">cluster1 =</span> unique_clusters, </span>
<span id="cb412-6"><a href="hierarchical-clustering.html#cb412-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">cluster2 =</span> unique_clusters) <span class="sc">%&gt;%</span></span>
<span id="cb412-7"><a href="hierarchical-clustering.html#cb412-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(cluster1 <span class="sc">&lt;</span> cluster2) <span class="sc">%&gt;%</span></span>
<span id="cb412-8"><a href="hierarchical-clustering.html#cb412-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">cluster =</span> <span class="fu">paste</span>(cluster1, cluster2, <span class="at">sep =</span> <span class="st">&quot;,&quot;</span>))</span>
<span id="cb412-9"><a href="hierarchical-clustering.html#cb412-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb412-10"><a href="hierarchical-clustering.html#cb412-10" aria-hidden="true" tabindex="-1"></a>  candidate_solutions <span class="ot">&lt;-</span> potential_pairs <span class="sc">%&gt;%</span></span>
<span id="cb412-11"><a href="hierarchical-clustering.html#cb412-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rowwise</span>() <span class="sc">%&gt;%</span></span>
<span id="cb412-12"><a href="hierarchical-clustering.html#cb412-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">do</span>(<span class="at">candidate_solution =</span> <span class="fu">merge_cluster</span>(cluster_label, .)) <span class="sc">%&gt;%</span></span>
<span id="cb412-13"><a href="hierarchical-clustering.html#cb412-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">`</span><span class="at">[[</span><span class="st">`</span>(<span class="st">&quot;candidate_solution&quot;</span>)</span>
<span id="cb412-14"><a href="hierarchical-clustering.html#cb412-14" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb412-15"><a href="hierarchical-clustering.html#cb412-15" aria-hidden="true" tabindex="-1"></a>  candidate_solutions</span>
<span id="cb412-16"><a href="hierarchical-clustering.html#cb412-16" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>위에서 보이는 바와 같이, 함수 <code>generate_clusters</code>는 또 다른 사용자 정의함수 <code>merge_cluster</code>를 호출한다. 이 함수는 두 입력변수 <code>cluster_label</code> 및 <code>cluster_merge</code>를 사용하는데, <code>cluster_label</code>에 대한 설명은 위 다른 사용자 정의 함수에서와 동일하며, <code>cluster_merge</code>에 대한 설명은 아래와 같다.</p>
<ul>
<li><code>cluster_merge</code>: 3차원 character 벡터. 첫 두 element는 현재 <code>cluster_label</code>에 존재하는 군집 중 하나의 군집으로 묶일 두 군집의 이름을 나타내며, 세 번째 element는 그 결과 나타나는 군집 이름을 나타낸다.</li>
</ul>
<p>함수 수행 결과, 입력된 <code>cluster_label</code>에서 군집이름이 <code>cluster_merge[1]</code> 혹은 <code>cluster_merge[2]</code>에 해당하는 객체들은, 출력된 군집해에서는 군집이름 <code>cluster_merge[3]</code>을 지닌다.</p>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="hierarchical-clustering.html#cb413-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 임의의 군집 결합 규칙 cluster_merge에 따른 군집해</span></span>
<span id="cb413-2"><a href="hierarchical-clustering.html#cb413-2" aria-hidden="true" tabindex="-1"></a>merge_cluster <span class="ot">&lt;-</span> <span class="cf">function</span>(cluster_label, cluster_merge) {</span>
<span id="cb413-3"><a href="hierarchical-clustering.html#cb413-3" aria-hidden="true" tabindex="-1"></a>  idx <span class="ot">&lt;-</span> cluster_label<span class="sc">$</span>cluster <span class="sc">%in%</span> cluster_merge[<span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>]</span>
<span id="cb413-4"><a href="hierarchical-clustering.html#cb413-4" aria-hidden="true" tabindex="-1"></a>  cluster_label[idx, <span class="st">&quot;cluster&quot;</span>] <span class="ot">&lt;-</span> cluster_merge[<span class="dv">3</span>]</span>
<span id="cb413-5"><a href="hierarchical-clustering.html#cb413-5" aria-hidden="true" tabindex="-1"></a>  cluster_label</span>
<span id="cb413-6"><a href="hierarchical-clustering.html#cb413-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>마지막으로, 현재 군집해로부터 가장 최적의 다음단계 군집해를 얻는 사용자 함수 <code>best_merge_cluster</code>를 아래와 같이 구현해보자.</p>
<ol style="list-style-type: decimal">
<li><code>generate_clusters</code>를 실행하여 다음 단계에 가능한 모든 군집해를 구한다.</li>
<li>1의 각 군집해에 함수 <code>calculate_ssw</code>를 적용하여 <span class="math inline">\(SSW\)</span>값을 구한다.</li>
<li><span class="math inline">\(SSW\)</span>값이 최소인 군집해를 최적 군집해로 선정한다.</li>
</ol>
<div class="sourceCode" id="cb414"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb414-1"><a href="hierarchical-clustering.html#cb414-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 최적 군집 결합</span></span>
<span id="cb414-2"><a href="hierarchical-clustering.html#cb414-2" aria-hidden="true" tabindex="-1"></a>best_merge_cluster <span class="ot">&lt;-</span> <span class="cf">function</span>(df, cluster_label) {</span>
<span id="cb414-3"><a href="hierarchical-clustering.html#cb414-3" aria-hidden="true" tabindex="-1"></a>  candidate_solutions <span class="ot">&lt;-</span> <span class="fu">generate_clusters</span>(cluster_label)</span>
<span id="cb414-4"><a href="hierarchical-clustering.html#cb414-4" aria-hidden="true" tabindex="-1"></a>  ssw <span class="ot">&lt;-</span> <span class="fu">sapply</span>(candidate_solutions, <span class="cf">function</span>(x) <span class="fu">calculate_ssw</span>(df, x))</span>
<span id="cb414-5"><a href="hierarchical-clustering.html#cb414-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(</span>
<span id="cb414-6"><a href="hierarchical-clustering.html#cb414-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">new_cluster_label =</span> candidate_solutions[[<span class="fu">which.min</span>(ssw)]],</span>
<span id="cb414-7"><a href="hierarchical-clustering.html#cb414-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">new_ssw =</span> <span class="fu">min</span>(ssw)</span>
<span id="cb414-8"><a href="hierarchical-clustering.html#cb414-8" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb414-9"><a href="hierarchical-clustering.html#cb414-9" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>위 사용자 함수들을 이용하여 Table <a href="hierarchical-clustering.html#tab:driver-data">12.3</a>에 대한 워드 군집 분석을 수행해보자.</p>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb415-1"><a href="hierarchical-clustering.html#cb415-1" aria-hidden="true" tabindex="-1"></a><span class="co">#단계0</span></span>
<span id="cb415-2"><a href="hierarchical-clustering.html#cb415-2" aria-hidden="true" tabindex="-1"></a>init_cluster <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb415-3"><a href="hierarchical-clustering.html#cb415-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">id =</span> train_df<span class="sc">$</span>id,</span>
<span id="cb415-4"><a href="hierarchical-clustering.html#cb415-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">cluster =</span> <span class="fu">as.character</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(train_df))</span>
<span id="cb415-5"><a href="hierarchical-clustering.html#cb415-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb415-6"><a href="hierarchical-clustering.html#cb415-6" aria-hidden="true" tabindex="-1"></a>i <span class="ot">&lt;-</span> 0L</span>
<span id="cb415-7"><a href="hierarchical-clustering.html#cb415-7" aria-hidden="true" tabindex="-1"></a>current_clusters <span class="ot">&lt;-</span> <span class="fu">unique</span>(init_cluster<span class="sc">$</span>cluster)</span>
<span id="cb415-8"><a href="hierarchical-clustering.html#cb415-8" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">length</span>(current_clusters)</span>
<span id="cb415-9"><a href="hierarchical-clustering.html#cb415-9" aria-hidden="true" tabindex="-1"></a>ssw <span class="ot">&lt;-</span> <span class="fu">calculate_ssw</span>(train_df, init_cluster)</span>
<span id="cb415-10"><a href="hierarchical-clustering.html#cb415-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb415-11"><a href="hierarchical-clustering.html#cb415-11" aria-hidden="true" tabindex="-1"></a>print_clusters <span class="ot">&lt;-</span> <span class="cf">function</span>(i, k, clusters, ssw) {</span>
<span id="cb415-12"><a href="hierarchical-clustering.html#cb415-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">&quot;Iteration: &quot;</span>, i, <span class="st">&quot;, k = &quot;</span>, k, <span class="st">&quot;, clusters = &quot;</span>, <span class="fu">paste0</span>(<span class="st">&quot;{&quot;</span>, clusters, <span class="st">&quot;}&quot;</span>), <span class="st">&quot;, SSW =&quot;</span>, ssw, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb415-13"><a href="hierarchical-clustering.html#cb415-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb415-14"><a href="hierarchical-clustering.html#cb415-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb415-15"><a href="hierarchical-clustering.html#cb415-15" aria-hidden="true" tabindex="-1"></a><span class="fu">print_clusters</span>(i, k, current_clusters, ssw)</span></code></pre></div>
<pre><code>## Iteration:  0 , k =  8 , clusters =  {1} {2} {3} {4} {5} {6} {7} {8} , SSW = 0</code></pre>
<div class="sourceCode" id="cb417"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb417-1"><a href="hierarchical-clustering.html#cb417-1" aria-hidden="true" tabindex="-1"></a><span class="co">#단계1</span></span>
<span id="cb417-2"><a href="hierarchical-clustering.html#cb417-2" aria-hidden="true" tabindex="-1"></a>iteration <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="at">length =</span> <span class="fu">nrow</span>(train_df) <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb417-3"><a href="hierarchical-clustering.html#cb417-3" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span>(k <span class="sc">&gt;</span> <span class="dv">1</span>) {</span>
<span id="cb417-4"><a href="hierarchical-clustering.html#cb417-4" aria-hidden="true" tabindex="-1"></a>  i <span class="ot">&lt;-</span> i <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb417-5"><a href="hierarchical-clustering.html#cb417-5" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(i <span class="sc">==</span> <span class="dv">1</span>) {</span>
<span id="cb417-6"><a href="hierarchical-clustering.html#cb417-6" aria-hidden="true" tabindex="-1"></a>    iteration[[i]] <span class="ot">&lt;-</span> <span class="fu">best_merge_cluster</span>(</span>
<span id="cb417-7"><a href="hierarchical-clustering.html#cb417-7" aria-hidden="true" tabindex="-1"></a>      train_df,</span>
<span id="cb417-8"><a href="hierarchical-clustering.html#cb417-8" aria-hidden="true" tabindex="-1"></a>      init_cluster</span>
<span id="cb417-9"><a href="hierarchical-clustering.html#cb417-9" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb417-10"><a href="hierarchical-clustering.html#cb417-10" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb417-11"><a href="hierarchical-clustering.html#cb417-11" aria-hidden="true" tabindex="-1"></a>    iteration[[i]] <span class="ot">&lt;-</span> <span class="fu">best_merge_cluster</span>(</span>
<span id="cb417-12"><a href="hierarchical-clustering.html#cb417-12" aria-hidden="true" tabindex="-1"></a>      train_df,</span>
<span id="cb417-13"><a href="hierarchical-clustering.html#cb417-13" aria-hidden="true" tabindex="-1"></a>      iteration[[i<span class="dv">-1</span>]]<span class="sc">$</span>new_cluster_label</span>
<span id="cb417-14"><a href="hierarchical-clustering.html#cb417-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb417-15"><a href="hierarchical-clustering.html#cb417-15" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb417-16"><a href="hierarchical-clustering.html#cb417-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb417-17"><a href="hierarchical-clustering.html#cb417-17" aria-hidden="true" tabindex="-1"></a>  current_clusters <span class="ot">&lt;-</span> <span class="fu">unique</span>(iteration[[i]]<span class="sc">$</span>new_cluster_label<span class="sc">$</span>cluster)</span>
<span id="cb417-18"><a href="hierarchical-clustering.html#cb417-18" aria-hidden="true" tabindex="-1"></a>  k <span class="ot">&lt;-</span> <span class="fu">length</span>(current_clusters)</span>
<span id="cb417-19"><a href="hierarchical-clustering.html#cb417-19" aria-hidden="true" tabindex="-1"></a>  ssw <span class="ot">&lt;-</span> iteration[[i]]<span class="sc">$</span>new_ssw</span>
<span id="cb417-20"><a href="hierarchical-clustering.html#cb417-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb417-21"><a href="hierarchical-clustering.html#cb417-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print_clusters</span>(i, k, current_clusters, ssw)</span>
<span id="cb417-22"><a href="hierarchical-clustering.html#cb417-22" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## Iteration:  1 , k =  7 , clusters =  {1} {2,7} {3} {4} {5} {6} {8} , SSW = 1 
## Iteration:  2 , k =  6 , clusters =  {1,3} {2,7} {4} {5} {6} {8} , SSW = 3.5 
## Iteration:  3 , k =  5 , clusters =  {1,3} {2,7} {4,8} {5} {6} , SSW = 6 
## Iteration:  4 , k =  4 , clusters =  {1,3} {2,7,5} {4,8} {6} , SSW = 23.66667 
## Iteration:  5 , k =  3 , clusters =  {1,3,6} {2,7,5} {4,8} , SSW = 43.16667 
## Iteration:  6 , k =  2 , clusters =  {1,3,6} {2,7,5,4,8} , SSW = 140.4 
## Iteration:  7 , k =  1 , clusters =  {1,3,6,2,7,5,4,8} , SSW = 499.875</code></pre>
</div>
<div id="ward-rpackages" class="section level3" number="12.4.3">
<h3><span class="header-section-number">12.4.3</span> R 패키지 내 워드 방법</h3>
<p>R 패키지로 구현된 워드 군집은 위에서 구현한 <span class="math inline">\(SSW\)</span>와는 다소 다른 metric을 이용하여 군집해를 구한다. 따라서, 우선 워드 방법이 제안된 논문들을 살펴볼 필요가 있다.</p>
<p>우선 원 논문 <span class="citation"><a href="#ref-ward1963hierarchical" role="doc-biblioref">Ward Jr</a> (<a href="#ref-ward1963hierarchical" role="doc-biblioref">1963</a>)</span> 는 <span class="math inline">\(ESS\)</span>(error sum of squares)를 아래와 같이 정의하였으며, 이는 위에서 사용한 <span class="math inline">\(SSW\)</span>와 일치한다.</p>
<p><span class="math display">\[\begin{equation*}
\begin{split}
ESS(\{C_1, \cdots, C_k \}) &amp;= \sum_{i = 1}^{k} ESS(C_i)\\
&amp;= \sum_{i = 1}^{k} \sum_{u \in C_i} \mathbf{x}_u^\top \mathbf{x}_u - |C_i| \mathbf{c}_i^\top \mathbf{c}_i\\
&amp;= SSW
\end{split}
\end{equation*}\]</span></p>
<p>위 식에서 임의의 두 군집 <span class="math inline">\(C_i\)</span>, <span class="math inline">\(C_j\)</span>를 하나의 군집으로 묶을 때 <span class="math inline">\(SSW\)</span>의 변화는 아래와 같다. <span class="math inline">\(C_i\)</span>와 <span class="math inline">\(C_j\)</span> 외의 군집은 <span class="math inline">\(SSW\)</span>의 변화에 영향을 미치지 않으므로, <span class="math inline">\(SSW\)</span> 변화량은 아래와 같이 군집 <span class="math inline">\(C_i\)</span>와 <span class="math inline">\(C_j\)</span>에 속하는 객체만을 이용하여 구할 수 있으며, 결과적으로 <span class="math inline">\(C_i\)</span>와 <span class="math inline">\(C_j\)</span>의 군집 크기 <span class="math inline">\(|C_i|\)</span>와 <span class="math inline">\(|C_j|\)</span>및 군집 중심벡터 <span class="math inline">\(\mathbf{c}_i\)</span>와 <span class="math inline">\(\mathbf{c}_j\)</span>를 이용하여 구할 수 있다.</p>
<p><span class="math display" id="eq:ward-minimand">\[\begin{equation}
\begin{split}
\Delta SSW =&amp; ESS(C_i \cup C_j) - ESS(C_i) - ESS(C_j)\\
=&amp; \sum_{u \in C_i \cup C_j} \mathbf{x}_u^\top \mathbf{x}_u - (|C_i| + |C_j|)\left[\frac{|C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j}{|C_i| + |C_j|}\right]^\top \left[\frac{|C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j}{|C_i| + |C_j|}\right]\\
&amp; - \left( \sum_{u \in C_i} \mathbf{x}_u^\top \mathbf{x}_u - |C_i| \mathbf{c}_i^\top \mathbf{c}_i \right) - \left( \sum_{u \in C_j} \mathbf{x}_u^\top \mathbf{x}_u - |C_j| \mathbf{c}_j^\top \mathbf{c}_j \right)\\
=&amp; -\frac{1}{|C_i| + |C_j|} \left( |C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j \right)^\top \left( |C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j \right) + |C_i| \mathbf{c}_i^\top \mathbf{c}_i + |C_j| \mathbf{c}_j^\top \mathbf{c}_j\\
=&amp; \frac{|C_i||C_j|}{|C_i| + |C_j|} \left(\mathbf{c}_i - \mathbf{c}_j\right)^\top \left(\mathbf{c}_i - \mathbf{c}_j\right)
\end{split}
\tag{12.1}
\end{equation}\]</span></p>
<p>따라서 워드 방법은 각 iteration에서 식 <a href="hierarchical-clustering.html#eq:ward-minimand">(12.1)</a>를 최소화하는 두 군집 <span class="math inline">\(C_i\)</span>, <span class="math inline">\(C_j\)</span>를 선택하여 두 군집을 하나로 묶는 방법이다.</p>
<p>한편, <span class="math inline">\(SS(C_i)\)</span>는 아래와 같이 군집 <span class="math inline">\(C_i\)</span>내 객체들 간의 제곱 유클리드 거리로 나타낼 수 있다.</p>
<p><span class="math display" id="eq:squared-euclidean-within-cluster">\[\begin{equation}
\begin{split}
D^2(C_i) =&amp; \sum_{u, v \in C_i} (\mathbf{x}_u - \mathbf{x}_v)^\top (\mathbf{x}_u - \mathbf{x}_v)\\
=&amp; \sum_{u, v \in C_i} \left((\mathbf{x}_u - \mathbf{c}_i) - (\mathbf{x}_v - \mathbf{c}_i)\right)^\top \left((\mathbf{x}_u - \mathbf{c}_i) - (\mathbf{x}_v - \mathbf{c}_i)\right)\\
=&amp; 2 \sum_{u \in C_i} (\mathbf{x}_u - \mathbf{c}_i)^\top (\mathbf{x}_u - \mathbf{c}_i) - 2 \sum_{u, v \in C_i} (\mathbf{x}_u - \mathbf{c}_i)^\top (\mathbf{x}_v - \mathbf{c}_i)\\
=&amp; 2 \sum_{u \in C_i} (\mathbf{x}_u - \mathbf{c}_i)^\top (\mathbf{x}_u - \mathbf{c}_i)\\
=&amp; 2 SS(C_i)
\end{split}
\tag{12.2}
\end{equation}\]</span></p>
<p>위 식 <a href="hierarchical-clustering.html#eq:squared-euclidean-within-cluster">(12.2)</a>을 달리 표현하면, 객체간의 제곱 유클리드 거리를 표현한 행렬에서 군집 <span class="math inline">\(i\)</span>에 속한 객체들에 해당하는 부분행렬(submatrix)를 뽑아 행렬의 원소값을 모두 더하면, 그 값이 <span class="math inline">\(2 SS(C_i)\)</span>와 같다. 이를 통해 각 군집의 중심벡터를 계산하지 않고도 각 iteration에서 SSW를 최소화하는 군집 결합을 찾을 수 있다.</p>
<p>R 패키지 <code>stats</code> 내의 <code>hclust</code> 함수는 워드 방법으로 <code>method</code> 파라미터의 값을 “ward.D” 혹은 “ward.D2”로 설정할 수 있다. 이 두 방법의 차이는 입력 거리행렬을 제곱 유클리드 거리로 사용하는지 일반 유클리드 거리로 사용하는지의 차이로, 아래에서 R 스크립트 예제와 함께 설명하기로 한다.</p>
<p>우선 <code>method</code>값을 “ward.D2”로 설정하는 경우, <code>dist</code> 함수의 결과를 입력 거리행렬로 그대로 사용하면 된다.</p>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="hierarchical-clustering.html#cb419-1" aria-hidden="true" tabindex="-1"></a>res_ward.D2 <span class="ot">&lt;-</span> <span class="fu">dist</span>(train_df[, <span class="sc">-</span><span class="dv">1</span>]) <span class="sc">%&gt;%</span></span>
<span id="cb419-2"><a href="hierarchical-clustering.html#cb419-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hclust</span>(<span class="at">method =</span> <span class="st">&quot;ward.D2&quot;</span>)</span></code></pre></div>
<p>이 때, 결과 데이터 <code>res_ward.D2</code>에서 워드 방법의 criterion을 나타내는 <code>height</code> 원소(component)가 표현하는 값은 위에서 계산하였던 <span class="math inline">\(SSW\)</span>와 다르다.</p>
<div class="sourceCode" id="cb420"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb420-1"><a href="hierarchical-clustering.html#cb420-1" aria-hidden="true" tabindex="-1"></a>res_ward.D2<span class="sc">$</span>height</span></code></pre></div>
<pre><code>## [1]  1.414214  2.236068  2.236068  5.944185  6.244998 13.945131 26.813243</code></pre>
<p>이는 <code>height</code>에서 표현하는 값은 전체 <span class="math inline">\(SSW\)</span>가 아니라, 두 군집 <span class="math inline">\(i\)</span>와 <span class="math inline">\(j\)</span>를 하나로 묶을 때 추가로 증가하는 <span class="math inline">\(SSW\)</span> 수치의 변환으로, 아래와 같이 계산되기 때문이다.</p>
<p><span class="math display" id="eq:hclust-height">\[\begin{equation}
height = \sqrt{D^2(C_i \cup C_j) - \left(D^2(C_i) + D^2(C_j)\right)}
\tag{12.3}
\end{equation}\]</span></p>
<p>따라서, 군집 <span class="math inline">\(i\)</span>와 <span class="math inline">\(j\)</span>를 하나로 묶을 때 증가하는 <span class="math inline">\(SSW\)</span>의 수치 <span class="math inline">\(\Delta SSW\)</span>는 아래와 같이 표현된다.</p>
<p><span class="math display">\[\begin{equation}
\Delta SSW = \frac{1}{2} height^2
\end{equation}\]</span></p>
<p>각 iteration에서 발생하는 <span class="math inline">\(\Delta SSW\)</span>의 누적합이 위 <a href="hierarchical-clustering.html#ward-method-algorithm">12.4.2</a>절에서 보였던 <span class="math inline">\(SSW\)</span> 결과와 동일함을 아래와 같이 확인해보자.</p>
<div class="sourceCode" id="cb422"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb422-1"><a href="hierarchical-clustering.html#cb422-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb422-2"><a href="hierarchical-clustering.html#cb422-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">iteration =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>(<span class="fu">nrow</span>(train_df) <span class="sc">-</span> <span class="dv">1</span>)),</span>
<span id="cb422-3"><a href="hierarchical-clustering.html#cb422-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">height =</span> res_ward.D2<span class="sc">$</span>height</span>
<span id="cb422-4"><a href="hierarchical-clustering.html#cb422-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb422-5"><a href="hierarchical-clustering.html#cb422-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb422-6"><a href="hierarchical-clustering.html#cb422-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">delta_ssw =</span> height <span class="sc">^</span> <span class="dv">2</span> <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb422-7"><a href="hierarchical-clustering.html#cb422-7" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb422-8"><a href="hierarchical-clustering.html#cb422-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb422-9"><a href="hierarchical-clustering.html#cb422-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">ssw =</span> <span class="fu">cumsum</span>(delta_ssw)</span>
<span id="cb422-10"><a href="hierarchical-clustering.html#cb422-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb422-11"><a href="hierarchical-clustering.html#cb422-11" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>(</span>
<span id="cb422-12"><a href="hierarchical-clustering.html#cb422-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">booktabs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb422-13"><a href="hierarchical-clustering.html#cb422-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">align =</span> <span class="fu">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),</span>
<span id="cb422-14"><a href="hierarchical-clustering.html#cb422-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">&#39;iteration&#39;</span>, <span class="st">&#39;$height$&#39;</span>, <span class="st">&#39;$</span><span class="sc">\\</span><span class="st">Delta SSW = </span><span class="sc">\\</span><span class="st">frac{1}{2} height ^ 2$&#39;</span>, <span class="st">&#39;$SSW = </span><span class="sc">\\</span><span class="st">sum </span><span class="sc">\\</span><span class="st">Delta SSW$&#39;</span>),</span>
<span id="cb422-15"><a href="hierarchical-clustering.html#cb422-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">caption =</span> <span class="st">&#39;hclust 함수 ward.D2 방법의 height와 SSW 관계&#39;</span></span>
<span id="cb422-16"><a href="hierarchical-clustering.html#cb422-16" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<table>
<caption><span id="tab:ward-D2-height-ssw">Table 12.4: </span>hclust 함수 ward.D2 방법의 height와 SSW 관계</caption>
<thead>
<tr class="header">
<th align="right">iteration</th>
<th align="right"><span class="math inline">\(height\)</span></th>
<th align="right"><span class="math inline">\(\Delta SSW = \frac{1}{2} height ^ 2\)</span></th>
<th align="right"><span class="math inline">\(SSW = \sum \Delta SSW\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">1.414214</td>
<td align="right">1.00000</td>
<td align="right">1.00000</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">2.236068</td>
<td align="right">2.50000</td>
<td align="right">3.50000</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">2.236068</td>
<td align="right">2.50000</td>
<td align="right">6.00000</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">5.944185</td>
<td align="right">17.66667</td>
<td align="right">23.66667</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">6.244998</td>
<td align="right">19.50000</td>
<td align="right">43.16667</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">13.945131</td>
<td align="right">97.23333</td>
<td align="right">140.40000</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">26.813243</td>
<td align="right">359.47500</td>
<td align="right">499.87500</td>
</tr>
</tbody>
</table>
<p>우선 <code>method</code>값을 “ward.D”로 설정하는 경우, <code>dist</code> 함수의 결과를 입력 거리행렬로 그대로 사용하면 아래와 같이 위 “ward.D2”와는 다른 <code>height</code>값을 출력하며, 이는 워드 방법의 criterion을 정확히 반영하지 못한다.</p>
<div class="sourceCode" id="cb423"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb423-1"><a href="hierarchical-clustering.html#cb423-1" aria-hidden="true" tabindex="-1"></a>res_ward.D <span class="ot">&lt;-</span> <span class="fu">dist</span>(train_df[, <span class="sc">-</span><span class="dv">1</span>]) <span class="sc">%&gt;%</span></span>
<span id="cb423-2"><a href="hierarchical-clustering.html#cb423-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hclust</span>(<span class="at">method =</span> <span class="st">&quot;ward.D&quot;</span>)</span>
<span id="cb423-3"><a href="hierarchical-clustering.html#cb423-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb423-4"><a href="hierarchical-clustering.html#cb423-4" aria-hidden="true" tabindex="-1"></a>res_ward.D<span class="sc">$</span>height</span></code></pre></div>
<pre><code>## [1]  1.414214  2.236068  2.236068  6.452039  6.615990 17.358484 39.311447</code></pre>
<p>이는 “ward.D2”는 워드 방법 수행 전 입력된 유클리드 거리행렬을 내부적으로 제곱하는 반면, “ward.D” 방법은 제곱 유클리드 거리행렬이 입력되는 것을 가정하기 때문이다.</p>
<p><span class="citation"><a href="#ref-lance1967general" role="doc-biblioref">Lance and Williams</a> (<a href="#ref-lance1967general" role="doc-biblioref">1967</a>)</span> 은 군집 <span class="math inline">\(i\)</span>와 <span class="math inline">\(j\)</span>를 하나로 묶을 때, 새로 생성된 군집과 다른 군집들간의 거리는 원 두 군집들과 다른 군집들간의 거리로 아래와 같이 표현됨을 보였다. 이를 Lance-Williams update 공식이라 한다.</p>
<p><span class="math display" id="eq:lance-williams-update">\[\begin{equation}
D(C_i \cup C_j, C_{h \notin \{i, j\}}) = \alpha_i D(C_i, C_h) + \alpha_j D(C_j, C_h) + \beta D(C_i, C_j) + \gamma |D(C_i, C_h) - D(C_j, C_h)|
\tag{12.4}
\end{equation}\]</span></p>
<p>이후 <span class="citation"><a href="#ref-wishart1969256" role="doc-biblioref">Wishart</a> (<a href="#ref-wishart1969256" role="doc-biblioref">1969</a>)</span> 에서 워드 방법을 위 Lance-Williams update 공식으로 표현하였다.</p>
<p><span class="math display" id="eq:wishart">\[\begin{equation}
\begin{split}
\alpha_i =&amp; \frac{|C_i| + |C_h|}{|C_i| + |C_j| + |C_h|}\\
\alpha_j =&amp; \frac{|C_j| + |C_h|}{|C_i| + |C_j| + |C_h|}\\
\beta =&amp; - \frac{|C_h|}{|C_i| + |C_j| + |C_h|}\\
\gamma =&amp; 0
\end{split}
\tag{12.5}
\end{equation}\]</span></p>
<p>이 때, 식 <a href="hierarchical-clustering.html#eq:wishart">(12.5)</a>가 기반한 식 <a href="hierarchical-clustering.html#eq:lance-williams-update">(12.4)</a>에서의 거리함수 <span class="math inline">\(D\)</span>는 제곱 유클리드 거리를 사용한다.</p>
<p>“ward.D” 방법은 제곱 유클리드 거리의 입력을 가정하며, 위의 경우와 같이 제곱 유클리드 거리가 아닌 일반 유클리드 거리행렬을 입력하였을 때, 오류 메시지를 출력하는 대신, 입력된 거리행렬이 제곱 유클리드 거리를 나타낸다 가정하고 Lance-Williams update를 수행한다. 따라서, 이 경우 <code>height</code>는 워드 방법의 criterion을 정확히 표현하지 못한다.</p>
<p>제곱 유클리드 거리를 “ward.D” 방법의 입력 거리행렬로 설정하고, 구해진 <code>height</code>를 출력해보자</p>
<div class="sourceCode" id="cb425"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb425-1"><a href="hierarchical-clustering.html#cb425-1" aria-hidden="true" tabindex="-1"></a>res_ward.D <span class="ot">&lt;-</span> <span class="fu">dist</span>(train_df[, <span class="sc">-</span><span class="dv">1</span>])<span class="sc">^</span><span class="dv">2</span> <span class="sc">%&gt;%</span></span>
<span id="cb425-2"><a href="hierarchical-clustering.html#cb425-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">hclust</span>(<span class="at">method =</span> <span class="st">&quot;ward.D&quot;</span>)</span>
<span id="cb425-3"><a href="hierarchical-clustering.html#cb425-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb425-4"><a href="hierarchical-clustering.html#cb425-4" aria-hidden="true" tabindex="-1"></a>res_ward.D<span class="sc">$</span>height</span></code></pre></div>
<pre><code>## [1]   2.00000   5.00000   5.00000  35.33333  39.00000 194.46667 718.95000</code></pre>
<p>위 <code>height</code>값은 “ward.D2” 방법에서 출력된 값보다 크다. 위 값의 제곱근(square root)를 구하면 “ward.D2”에서의 <code>height</code>값과 동일한 값을 얻을 수 있다.</p>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb427-1"><a href="hierarchical-clustering.html#cb427-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(res_ward.D<span class="sc">$</span>height)</span></code></pre></div>
<pre><code>## [1]  1.414214  2.236068  2.236068  5.944185  6.244998 13.945131 26.813243</code></pre>
<p>제곱 유클리드 거리행렬을 입력한 “ward.D” 방법의 결과로 출력된 criterion <code>height</code>는 <span class="math inline">\(2 \Delta SSW\)</span>의 값에 해당하는 수치이며, 각 iteration 당 <span class="math inline">\(\sum_i D(C_i)\)</span>의 값의 변화량이라고 볼 수 있다. (식 <a href="hierarchical-clustering.html#eq:squared-euclidean-within-cluster">(12.2)</a> 참조)</p>
<div class="sourceCode" id="cb429"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb429-1"><a href="hierarchical-clustering.html#cb429-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tibble</span>(</span>
<span id="cb429-2"><a href="hierarchical-clustering.html#cb429-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">iteration =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span>(<span class="fu">nrow</span>(train_df) <span class="sc">-</span> <span class="dv">1</span>)),</span>
<span id="cb429-3"><a href="hierarchical-clustering.html#cb429-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">height =</span> res_ward.D<span class="sc">$</span>height</span>
<span id="cb429-4"><a href="hierarchical-clustering.html#cb429-4" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb429-5"><a href="hierarchical-clustering.html#cb429-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb429-6"><a href="hierarchical-clustering.html#cb429-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">delta_ssw =</span> height <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb429-7"><a href="hierarchical-clustering.html#cb429-7" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb429-8"><a href="hierarchical-clustering.html#cb429-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb429-9"><a href="hierarchical-clustering.html#cb429-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">ssw =</span> <span class="fu">cumsum</span>(delta_ssw)</span>
<span id="cb429-10"><a href="hierarchical-clustering.html#cb429-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb429-11"><a href="hierarchical-clustering.html#cb429-11" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>(</span>
<span id="cb429-12"><a href="hierarchical-clustering.html#cb429-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">booktabs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb429-13"><a href="hierarchical-clustering.html#cb429-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">align =</span> <span class="fu">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),</span>
<span id="cb429-14"><a href="hierarchical-clustering.html#cb429-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">&#39;iteration&#39;</span>, <span class="st">&#39;$height$&#39;</span>, <span class="st">&#39;$</span><span class="sc">\\</span><span class="st">Delta SSW = </span><span class="sc">\\</span><span class="st">frac{1}{2} height$&#39;</span>, <span class="st">&#39;$SSW = </span><span class="sc">\\</span><span class="st">sum </span><span class="sc">\\</span><span class="st">Delta SSW$&#39;</span>),</span>
<span id="cb429-15"><a href="hierarchical-clustering.html#cb429-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">caption =</span> <span class="st">&#39;hclust 함수 ward.D 방법의 height와 SSW 관계&#39;</span></span>
<span id="cb429-16"><a href="hierarchical-clustering.html#cb429-16" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<table>
<caption><span id="tab:ward-D-height-ssw">Table 12.5: </span>hclust 함수 ward.D 방법의 height와 SSW 관계</caption>
<thead>
<tr class="header">
<th align="right">iteration</th>
<th align="right"><span class="math inline">\(height\)</span></th>
<th align="right"><span class="math inline">\(\Delta SSW = \frac{1}{2} height\)</span></th>
<th align="right"><span class="math inline">\(SSW = \sum \Delta SSW\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">2.00000</td>
<td align="right">1.00000</td>
<td align="right">1.00000</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">5.00000</td>
<td align="right">2.50000</td>
<td align="right">3.50000</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">5.00000</td>
<td align="right">2.50000</td>
<td align="right">6.00000</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">35.33333</td>
<td align="right">17.66667</td>
<td align="right">23.66667</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">39.00000</td>
<td align="right">19.50000</td>
<td align="right">43.16667</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">194.46667</td>
<td align="right">97.23333</td>
<td align="right">140.40000</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">718.95000</td>
<td align="right">359.47500</td>
<td align="right">499.87500</td>
</tr>
</tbody>
</table>
<p>즉, “ward.D2”와 “ward.D”의 가장 큰 차이는 입력될 거리행렬이 유클리드 거리(ward.D2)인지 제곱 유클리드 거리(ward.D)인지의 차이이다.</p>
<p>참고로, <code>cluster</code> 패키지의 <code>agnes</code>함수도 워드 방법을 지원하며, 이 경우 파라미터 <code>method</code>의 값을 “ward”로 설정한 결과가 <code>hclust</code>함수의 “ward.D2”의 경우와 동일하다. 본 절에서는 해당 함수의 자세한 사용법은 생략한다.</p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb430-1"><a href="hierarchical-clustering.html#cb430-1" aria-hidden="true" tabindex="-1"></a>res_agnes_ward <span class="ot">&lt;-</span> cluster<span class="sc">::</span><span class="fu">agnes</span>(train_df[, <span class="sc">-</span><span class="dv">1</span>], <span class="at">method =</span> <span class="st">&quot;ward&quot;</span>)</span>
<span id="cb430-2"><a href="hierarchical-clustering.html#cb430-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb430-3"><a href="hierarchical-clustering.html#cb430-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sort</span>(res_agnes_ward<span class="sc">$</span>height)</span></code></pre></div>
<pre><code>## [1]  1.414214  2.236068  2.236068  5.944185  6.244998 13.945131 26.813243</code></pre>
</div>
</div>
<div id="diana" class="section level2" number="12.5">
<h2><span class="header-section-number">12.5</span> 분리적 방법 - 다이아나</h2>
<p>다이아나는 분리적 방법의 하나로, <span class="citation"><a href="#ref-kaufman1990finding" role="doc-biblioref">Kaufman and Rousseeuw</a> (<a href="#ref-kaufman1990finding" role="doc-biblioref">1990</a>)</span> 에 의하여 제안된 것이다. 이는 전체의 객체를 하나의 군집으로 시작하여 매번 이분화하는 등 모든 군집이 단독 객체로 구성될 때까지 진행하는 방법이다. 이 때, 비유사성 척도로는 평균거리를 사용한다.</p>
<div id="diana-basic-script" class="section level3" number="12.5.1">
<h3><span class="header-section-number">12.5.1</span> 기본 R 스크립트</h3>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb432-1"><a href="hierarchical-clustering.html#cb432-1" aria-hidden="true" tabindex="-1"></a>train_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb432-2"><a href="hierarchical-clustering.html#cb432-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">id =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>),</span>
<span id="cb432-3"><a href="hierarchical-clustering.html#cb432-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">c</span>(<span class="dv">30</span>, <span class="dv">45</span>, <span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">50</span>, <span class="dv">20</span>, <span class="dv">42</span>),</span>
<span id="cb432-4"><a href="hierarchical-clustering.html#cb432-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> <span class="fu">c</span>(<span class="dv">15</span>, <span class="dv">22</span>, <span class="dv">12</span>, <span class="dv">24</span>, <span class="dv">25</span>, <span class="dv">10</span>, <span class="dv">9</span>)</span>
<span id="cb432-5"><a href="hierarchical-clustering.html#cb432-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb432-6"><a href="hierarchical-clustering.html#cb432-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb432-7"><a href="hierarchical-clustering.html#cb432-7" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(train_df, <span class="at">booktabs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb432-8"><a href="hierarchical-clustering.html#cb432-8" aria-hidden="true" tabindex="-1"></a>             <span class="at">align =</span> <span class="fu">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),</span>
<span id="cb432-9"><a href="hierarchical-clustering.html#cb432-9" aria-hidden="true" tabindex="-1"></a>             <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">&#39;객체번호&#39;</span>, <span class="st">&#39;$x_1$&#39;</span>, <span class="st">&#39;$x_2$&#39;</span>),</span>
<span id="cb432-10"><a href="hierarchical-clustering.html#cb432-10" aria-hidden="true" tabindex="-1"></a>             <span class="at">caption =</span> <span class="st">&#39;DIANA 군집 대상 객체 데이터&#39;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:diana-data">Table 12.6: </span>DIANA 군집 대상 객체 데이터</caption>
<thead>
<tr class="header">
<th align="right">객체번호</th>
<th align="right"><span class="math inline">\(x_1\)</span></th>
<th align="right"><span class="math inline">\(x_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">30</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">45</td>
<td align="right">22</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">25</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">40</td>
<td align="right">24</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">50</td>
<td align="right">25</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">20</td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">42</td>
<td align="right">9</td>
</tr>
</tbody>
</table>
<p>Table <a href="hierarchical-clustering.html#tab:diana-data">12.6</a>와 같이 두 변수 <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>로 이루어진 7개의 객체 데이터에 대해 DIANA 방법에 의해 군집해를 아래와 같이 <code>cluster</code> 패키지의 <code>diana</code> 함수를 이용하여 간단히 구할 수 있다.</p>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="hierarchical-clustering.html#cb433-1" aria-hidden="true" tabindex="-1"></a>res_diana <span class="ot">&lt;-</span> cluster<span class="sc">::</span><span class="fu">diana</span>(train_df[, <span class="sc">-</span><span class="dv">1</span>])</span>
<span id="cb433-2"><a href="hierarchical-clustering.html#cb433-2" aria-hidden="true" tabindex="-1"></a>cluster<span class="sc">::</span><span class="fu">pltree</span>(res_diana,</span>
<span id="cb433-3"><a href="hierarchical-clustering.html#cb433-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">main =</span> <span class="cn">NULL</span>,</span>
<span id="cb433-4"><a href="hierarchical-clustering.html#cb433-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">xlab =</span> <span class="st">&quot;observation&quot;</span></span>
<span id="cb433-5"><a href="hierarchical-clustering.html#cb433-5" aria-hidden="true" tabindex="-1"></a>                )</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:diana-result-plot"></span>
<img src="data-mining-book_files/figure-html/diana-result-plot-1.png" alt="DIANA 방법에 의한 군집 덴드로그램" width="672" />
<p class="caption">
Figure 12.4: DIANA 방법에 의한 군집 덴드로그램
</p>
</div>
</div>
<div id="diana-algorithm" class="section level3" number="12.5.2">
<h3><span class="header-section-number">12.5.2</span> 다이아나 알고리즘</h3>
<p>가장 처음 이분화가 이루어질 때, 우선 타 객체와의 평균거리가 가장 큰 객체가 분파되어 새로운 군집을 형성한다. 그리고 다른 객체에 대하여, 군집에 남아있을 때의 평균거리와 새로운 군집으로 분리될 때의 평균거리를 산출하여, 현 군집에 잔류 또는 새로운 군집으로의 합류를 결정한다.</p>
<p>여기서 객체 <span class="math inline">\(i\)</span>와 군집 <span class="math inline">\(C\)</span>간의 평균거리는 다음과 같이 산출된다.</p>
<p><span class="math display">\[\begin{equation*}
\bar{d}(i, C) = \begin{cases}
\frac{1}{|C| - 1} \sum_{j \in C} d(i, j) &amp; \text{ if } i \in C\\
\frac{1}{|C|} \sum_{j \in C} d(i, j) &amp; \text{ if } i \notin C
\end{cases}
\end{equation*}\]</span></p>
<p>본 방법의 알고리즘은 다음과 같다.</p>
<ol style="list-style-type: decimal">
<li>단계0: <span class="math inline">\(n\)</span>개의 객체를 하나의 군집으로 간주한다. (<span class="math inline">\(k = 1\)</span>)</li>
<li>단계1: 객체 간 거리가 가장 큰 두 객체를 포함한 군집을 이분화 대상으로 선정한다. (이를 <span class="math inline">\(A\)</span>라 하고, <span class="math inline">\(B \leftarrow \emptyset\)</span>로 둔다.)</li>
<li>단계2: 다음 과정을 통하여 군집 <span class="math inline">\(A\)</span>를 이분화한다.
<ol style="list-style-type: decimal">
<li>단계2-1: <span class="math inline">\(i \leftarrow \arg\,\max_{i&#39;} \bar{d}(i&#39;, A)\)</span></li>
<li>단계2-2: <span class="math inline">\(A \leftarrow A - \{i\}\)</span>, <span class="math inline">\(B \leftarrow B \cup \{i\}\)</span></li>
<li>단계2-3: <span class="math inline">\(i \leftarrow \arg\,\max_{i&#39; \in A} e(i&#39;) = \bar{d}(i&#39;, A) - \bar{d}(i&#39;, B)\)</span></li>
<li>단계2-4: <span class="math inline">\(e(i) &gt; 0\)</span>이면 단계2-2로, <span class="math inline">\(e(i) \le 0\)</span>이면 단계3으로</li>
</ol></li>
<li>단계3
<ol style="list-style-type: decimal">
<li><span class="math inline">\(k \leftarrow k + 1\)</span></li>
<li><span class="math inline">\(k &lt; n\)</span>이면 단계1로, <span class="math inline">\(k = n\)</span>이면 Stop.</li>
</ol></li>
</ol>
<p>DIANA 알고리즘을 R script로 구현해보자.</p>
<p>우선, 단계1의 군집을 찾는 함수 <code>max_distance_cluster</code>를 구현하자. 이 함수는 아래 두 개의 데이터 프레임을 입력받는다.</p>
<ul>
<li>입력
<ul>
<li><code>df</code>: 관측 데이터. 각 열의 설명은 아래와 같다.
<ul>
<li><code>id</code>: 객체번호</li>
<li>나머지 열: 숫자형 변수</li>
</ul></li>
<li><code>cluster_label</code>: 각 객체의 현재 소속 군집을 나타내는 데이터 프레임
<ul>
<li><code>id</code>: 객체번호</li>
<li><code>cluster</code>: 군집명</li>
</ul></li>
</ul></li>
<li>함수값
<ul>
<li><code>cluster</code>: 객체간 거리가 가장 큰 두 객체를 포함한 군집명</li>
<li><code>distance</code>: 군집 내 객체간 최대 거리</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb434"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb434-1"><a href="hierarchical-clustering.html#cb434-1" aria-hidden="true" tabindex="-1"></a>max_distance_cluster <span class="ot">&lt;-</span> <span class="cf">function</span>(df, cluster_label) {</span>
<span id="cb434-2"><a href="hierarchical-clustering.html#cb434-2" aria-hidden="true" tabindex="-1"></a>  unique_cluster <span class="ot">&lt;-</span> <span class="fu">unique</span>(cluster_label<span class="sc">$</span>cluster)</span>
<span id="cb434-3"><a href="hierarchical-clustering.html#cb434-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb434-4"><a href="hierarchical-clustering.html#cb434-4" aria-hidden="true" tabindex="-1"></a>  cluster_df <span class="ot">&lt;-</span> <span class="fu">lapply</span>(unique_cluster, <span class="cf">function</span>(x) {</span>
<span id="cb434-5"><a href="hierarchical-clustering.html#cb434-5" aria-hidden="true" tabindex="-1"></a>    cluster_label <span class="sc">%&gt;%</span> </span>
<span id="cb434-6"><a href="hierarchical-clustering.html#cb434-6" aria-hidden="true" tabindex="-1"></a>      <span class="fu">filter</span>(cluster <span class="sc">==</span> x) <span class="sc">%&gt;%</span></span>
<span id="cb434-7"><a href="hierarchical-clustering.html#cb434-7" aria-hidden="true" tabindex="-1"></a>      <span class="fu">inner_join</span>(df, <span class="at">by =</span> <span class="st">&quot;id&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb434-8"><a href="hierarchical-clustering.html#cb434-8" aria-hidden="true" tabindex="-1"></a>      <span class="fu">select</span>(<span class="sc">-</span>cluster, <span class="sc">-</span>id)</span>
<span id="cb434-9"><a href="hierarchical-clustering.html#cb434-9" aria-hidden="true" tabindex="-1"></a>    })</span>
<span id="cb434-10"><a href="hierarchical-clustering.html#cb434-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb434-11"><a href="hierarchical-clustering.html#cb434-11" aria-hidden="true" tabindex="-1"></a>  max_distance <span class="ot">&lt;-</span> <span class="fu">sapply</span>(cluster_df, </span>
<span id="cb434-12"><a href="hierarchical-clustering.html#cb434-12" aria-hidden="true" tabindex="-1"></a>                         <span class="cf">function</span>(x) {</span>
<span id="cb434-13"><a href="hierarchical-clustering.html#cb434-13" aria-hidden="true" tabindex="-1"></a>                           <span class="cf">if</span>(<span class="fu">nrow</span>(x) <span class="sc">==</span> <span class="dv">1</span>) <span class="fu">return</span>(<span class="dv">0</span>)</span>
<span id="cb434-14"><a href="hierarchical-clustering.html#cb434-14" aria-hidden="true" tabindex="-1"></a>                           <span class="fu">max</span>(<span class="fu">dist</span>(x))</span>
<span id="cb434-15"><a href="hierarchical-clustering.html#cb434-15" aria-hidden="true" tabindex="-1"></a>                         }</span>
<span id="cb434-16"><a href="hierarchical-clustering.html#cb434-16" aria-hidden="true" tabindex="-1"></a>                         )</span>
<span id="cb434-17"><a href="hierarchical-clustering.html#cb434-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb434-18"><a href="hierarchical-clustering.html#cb434-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">list</span>(</span>
<span id="cb434-19"><a href="hierarchical-clustering.html#cb434-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">cluster =</span> unique_cluster[<span class="fu">which.max</span>(max_distance)],</span>
<span id="cb434-20"><a href="hierarchical-clustering.html#cb434-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">distance =</span> <span class="fu">max</span>(max_distance)</span>
<span id="cb434-21"><a href="hierarchical-clustering.html#cb434-21" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb434-22"><a href="hierarchical-clustering.html#cb434-22" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>단계 2-1에서 군집 내 평균거리가 가장 큰 객체를 찾는 함수 <code>max_within_distance</code>를 아래와 같이 구현해보자. 이 때 입력변수인 <code>cluster_df</code>는 해당 군집의 객체 데이터로, 객체 번호를 나타내는 열 <code>id</code>와 객체의 각 숫자형 변수를 표현하는 열들로 구성된다.</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="hierarchical-clustering.html#cb435-1" aria-hidden="true" tabindex="-1"></a>max_within_distance <span class="ot">&lt;-</span> <span class="cf">function</span>(cluster_df) {</span>
<span id="cb435-2"><a href="hierarchical-clustering.html#cb435-2" aria-hidden="true" tabindex="-1"></a>  idx <span class="ot">&lt;-</span> <span class="fu">dist</span>(<span class="fu">subset</span>(cluster_df, <span class="at">select =</span> <span class="sc">-</span>id), <span class="at">upper =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb435-3"><a href="hierarchical-clustering.html#cb435-3" aria-hidden="true" tabindex="-1"></a>    broom<span class="sc">::</span><span class="fu">tidy</span>() <span class="sc">%&gt;%</span></span>
<span id="cb435-4"><a href="hierarchical-clustering.html#cb435-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(item1) <span class="sc">%&gt;%</span></span>
<span id="cb435-5"><a href="hierarchical-clustering.html#cb435-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarize</span>(<span class="at">mean_distance =</span> <span class="fu">mean</span>(distance)) <span class="sc">%&gt;%</span></span>
<span id="cb435-6"><a href="hierarchical-clustering.html#cb435-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb435-7"><a href="hierarchical-clustering.html#cb435-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">arrange</span>(<span class="sc">-</span>mean_distance) <span class="sc">%&gt;%</span></span>
<span id="cb435-8"><a href="hierarchical-clustering.html#cb435-8" aria-hidden="true" tabindex="-1"></a>    .[[<span class="st">&quot;item1&quot;</span>]] <span class="sc">%&gt;%</span></span>
<span id="cb435-9"><a href="hierarchical-clustering.html#cb435-9" aria-hidden="true" tabindex="-1"></a>    .[<span class="dv">1</span>]</span>
<span id="cb435-10"><a href="hierarchical-clustering.html#cb435-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb435-11"><a href="hierarchical-clustering.html#cb435-11" aria-hidden="true" tabindex="-1"></a>  cluster_df<span class="sc">$</span>id[idx]</span>
<span id="cb435-12"><a href="hierarchical-clustering.html#cb435-12" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>이후 단계2-3에서 정의한 <span class="math inline">\(e(i&#39;) = \bar{d}(i&#39;, A) - \bar{d}(i&#39;, B)\)</span>를 계산하는 함수 <code>e_score</code>를 아래와 같이 구현한다.</p>
<ul>
<li><code>object</code>: 객체 번호(<code>id</code>)</li>
<li><code>A</code>(<code>B</code>): 군집 <span class="math inline">\(A\)</span>(<span class="math inline">\(B\)</span>)의 객체 데이터. 행은 객체를 나타내며, <code>id</code> 열은 객체 번호, 이외의 열들은 변수를 나타낸다.</li>
</ul>
<div class="sourceCode" id="cb436"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb436-1"><a href="hierarchical-clustering.html#cb436-1" aria-hidden="true" tabindex="-1"></a>e_score <span class="ot">&lt;-</span> <span class="cf">function</span>(object, A, B) {</span>
<span id="cb436-2"><a href="hierarchical-clustering.html#cb436-2" aria-hidden="true" tabindex="-1"></a>  d_from_A <span class="ot">&lt;-</span> proxy<span class="sc">::</span><span class="fu">dist</span>(<span class="fu">subset</span>(A, id <span class="sc">==</span> object, <span class="sc">-</span>id), </span>
<span id="cb436-3"><a href="hierarchical-clustering.html#cb436-3" aria-hidden="true" tabindex="-1"></a>                          <span class="fu">subset</span>(A, id <span class="sc">!=</span> object, <span class="sc">-</span>id)) <span class="sc">%&gt;%</span> </span>
<span id="cb436-4"><a href="hierarchical-clustering.html#cb436-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mean</span>()</span>
<span id="cb436-5"><a href="hierarchical-clustering.html#cb436-5" aria-hidden="true" tabindex="-1"></a>  d_from_B <span class="ot">&lt;-</span> proxy<span class="sc">::</span><span class="fu">dist</span>(<span class="fu">subset</span>(A, id <span class="sc">==</span> object, <span class="sc">-</span>id), </span>
<span id="cb436-6"><a href="hierarchical-clustering.html#cb436-6" aria-hidden="true" tabindex="-1"></a>                          B <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span>id)) <span class="sc">%&gt;%</span> </span>
<span id="cb436-7"><a href="hierarchical-clustering.html#cb436-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mean</span>()</span>
<span id="cb436-8"><a href="hierarchical-clustering.html#cb436-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(d_from_A <span class="sc">-</span> d_from_B)</span>
<span id="cb436-9"><a href="hierarchical-clustering.html#cb436-9" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>위 두 함수 <code>max_within_distance</code>와 <code>e_score</code>를 이용하여, 주어진 데이터 프레임을 두 군집으로 나누는 함수 <code>split_cluster</code>를 구현해보자.</p>
<ul>
<li>입력: 객체 데이터를 나타내는 데이터 프레임 <code>cluster_df</code>. 행은 객체를 나타내며, 객체 번호를 나타내는 열 <code>id</code>와 객체의 각 숫자형 변수를 표현하는 열들로 구성된다.</li>
<li>함수값: 아래 두 개의 component를 지닌 리스트.
<ul>
<li><code>idx_A</code>: 객체 데이터에서 행렬 <span class="math inline">\(A\)</span>에 속하는 객체 번호</li>
<li><code>idx_B</code>: 객체 데이터에서 행렬 <span class="math inline">\(B\)</span>에 속하는 객체 번호</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="hierarchical-clustering.html#cb437-1" aria-hidden="true" tabindex="-1"></a>split_cluster <span class="ot">&lt;-</span> <span class="cf">function</span>(cluster_df) {</span>
<span id="cb437-2"><a href="hierarchical-clustering.html#cb437-2" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(cluster_df)</span>
<span id="cb437-3"><a href="hierarchical-clustering.html#cb437-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb437-4"><a href="hierarchical-clustering.html#cb437-4" aria-hidden="true" tabindex="-1"></a>  idx_A <span class="ot">&lt;-</span> cluster_df<span class="sc">$</span>id</span>
<span id="cb437-5"><a href="hierarchical-clustering.html#cb437-5" aria-hidden="true" tabindex="-1"></a>  idx_B <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb437-6"><a href="hierarchical-clustering.html#cb437-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb437-7"><a href="hierarchical-clustering.html#cb437-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 단계2-1</span></span>
<span id="cb437-8"><a href="hierarchical-clustering.html#cb437-8" aria-hidden="true" tabindex="-1"></a>  max_object <span class="ot">&lt;-</span> <span class="fu">max_within_distance</span>(cluster_df)</span>
<span id="cb437-9"><a href="hierarchical-clustering.html#cb437-9" aria-hidden="true" tabindex="-1"></a>  e_i <span class="ot">&lt;-</span> <span class="cn">Inf</span></span>
<span id="cb437-10"><a href="hierarchical-clustering.html#cb437-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb437-11"><a href="hierarchical-clustering.html#cb437-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">while</span>(e_i <span class="sc">&gt;</span> <span class="dv">0</span>) {</span>
<span id="cb437-12"><a href="hierarchical-clustering.html#cb437-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 단계2-2</span></span>
<span id="cb437-13"><a href="hierarchical-clustering.html#cb437-13" aria-hidden="true" tabindex="-1"></a>    idx_B <span class="ot">&lt;-</span> <span class="fu">c</span>(idx_B, max_object)</span>
<span id="cb437-14"><a href="hierarchical-clustering.html#cb437-14" aria-hidden="true" tabindex="-1"></a>    idx_A <span class="ot">&lt;-</span> <span class="fu">setdiff</span>(idx_A, max_object)</span>
<span id="cb437-15"><a href="hierarchical-clustering.html#cb437-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb437-16"><a href="hierarchical-clustering.html#cb437-16" aria-hidden="true" tabindex="-1"></a>    A <span class="ot">&lt;-</span> cluster_df <span class="sc">%&gt;%</span> <span class="fu">filter</span>(id <span class="sc">%in%</span> idx_A)</span>
<span id="cb437-17"><a href="hierarchical-clustering.html#cb437-17" aria-hidden="true" tabindex="-1"></a>    B <span class="ot">&lt;-</span> cluster_df <span class="sc">%&gt;%</span> <span class="fu">filter</span>(id <span class="sc">%in%</span> idx_B)</span>
<span id="cb437-18"><a href="hierarchical-clustering.html#cb437-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb437-19"><a href="hierarchical-clustering.html#cb437-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 단계2-3</span></span>
<span id="cb437-20"><a href="hierarchical-clustering.html#cb437-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(<span class="fu">nrow</span>(A) <span class="sc">&gt;</span> <span class="dv">1</span>) {</span>
<span id="cb437-21"><a href="hierarchical-clustering.html#cb437-21" aria-hidden="true" tabindex="-1"></a>      e_is <span class="ot">&lt;-</span> <span class="fu">sapply</span>(A<span class="sc">$</span>id, <span class="cf">function</span>(x) <span class="fu">e_score</span>(x, A, B))</span>
<span id="cb437-22"><a href="hierarchical-clustering.html#cb437-22" aria-hidden="true" tabindex="-1"></a>      max_object <span class="ot">&lt;-</span> A<span class="sc">$</span>id[<span class="fu">which.max</span>(e_is)]</span>
<span id="cb437-23"><a href="hierarchical-clustering.html#cb437-23" aria-hidden="true" tabindex="-1"></a>      e_i <span class="ot">&lt;-</span> <span class="fu">max</span>(e_is)</span>
<span id="cb437-24"><a href="hierarchical-clustering.html#cb437-24" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb437-25"><a href="hierarchical-clustering.html#cb437-25" aria-hidden="true" tabindex="-1"></a>      e_i <span class="ot">&lt;-</span> <span class="sc">-</span><span class="cn">Inf</span></span>
<span id="cb437-26"><a href="hierarchical-clustering.html#cb437-26" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb437-27"><a href="hierarchical-clustering.html#cb437-27" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb437-28"><a href="hierarchical-clustering.html#cb437-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb437-29"><a href="hierarchical-clustering.html#cb437-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">idx_A =</span> idx_A, <span class="at">idx_B =</span> idx_B))</span>
<span id="cb437-30"><a href="hierarchical-clustering.html#cb437-30" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>단계1 함수 <code>max_distance_cluster</code>와 단계2 함수 <code>split_cluster</code>를 반복적으로 수행하며 각각의 객체가 군집에 될 때까지 군집을 분리해간다.</p>
<div class="sourceCode" id="cb438"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb438-1"><a href="hierarchical-clustering.html#cb438-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 단계0</span></span>
<span id="cb438-2"><a href="hierarchical-clustering.html#cb438-2" aria-hidden="true" tabindex="-1"></a>current_cluster <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb438-3"><a href="hierarchical-clustering.html#cb438-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">id =</span> train_df<span class="sc">$</span>id</span>
<span id="cb438-4"><a href="hierarchical-clustering.html#cb438-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb438-5"><a href="hierarchical-clustering.html#cb438-5" aria-hidden="true" tabindex="-1"></a>current_cluster<span class="sc">$</span>cluster <span class="ot">&lt;-</span> <span class="fu">paste</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(current_cluster), <span class="at">collapse =</span> <span class="st">&quot;,&quot;</span>)</span>
<span id="cb438-6"><a href="hierarchical-clustering.html#cb438-6" aria-hidden="true" tabindex="-1"></a>i <span class="ot">&lt;-</span> 0L</span>
<span id="cb438-7"><a href="hierarchical-clustering.html#cb438-7" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> 1L</span>
<span id="cb438-8"><a href="hierarchical-clustering.html#cb438-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb438-9"><a href="hierarchical-clustering.html#cb438-9" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span>(k <span class="sc">&lt;</span> <span class="fu">nrow</span>(train_df)) {</span>
<span id="cb438-10"><a href="hierarchical-clustering.html#cb438-10" aria-hidden="true" tabindex="-1"></a>  i <span class="ot">&lt;-</span> i <span class="sc">+</span> 1L</span>
<span id="cb438-11"><a href="hierarchical-clustering.html#cb438-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb438-12"><a href="hierarchical-clustering.html#cb438-12" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 단계1</span></span>
<span id="cb438-13"><a href="hierarchical-clustering.html#cb438-13" aria-hidden="true" tabindex="-1"></a>  max_cluster <span class="ot">&lt;-</span> <span class="fu">max_distance_cluster</span>(train_df, current_cluster)</span>
<span id="cb438-14"><a href="hierarchical-clustering.html#cb438-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb438-15"><a href="hierarchical-clustering.html#cb438-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 단계2</span></span>
<span id="cb438-16"><a href="hierarchical-clustering.html#cb438-16" aria-hidden="true" tabindex="-1"></a>  new_split <span class="ot">&lt;-</span> current_cluster <span class="sc">%&gt;%</span></span>
<span id="cb438-17"><a href="hierarchical-clustering.html#cb438-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">filter</span>(cluster <span class="sc">==</span> max_cluster<span class="sc">$</span>cluster) <span class="sc">%&gt;%</span></span>
<span id="cb438-18"><a href="hierarchical-clustering.html#cb438-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">inner_join</span>(train_df, <span class="at">by =</span> <span class="st">&quot;id&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb438-19"><a href="hierarchical-clustering.html#cb438-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">select</span>(<span class="sc">-</span>cluster) <span class="sc">%&gt;%</span></span>
<span id="cb438-20"><a href="hierarchical-clustering.html#cb438-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">split_cluster</span>()</span>
<span id="cb438-21"><a href="hierarchical-clustering.html#cb438-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb438-22"><a href="hierarchical-clustering.html#cb438-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 군집해 업데이트</span></span>
<span id="cb438-23"><a href="hierarchical-clustering.html#cb438-23" aria-hidden="true" tabindex="-1"></a>  current_cluster[</span>
<span id="cb438-24"><a href="hierarchical-clustering.html#cb438-24" aria-hidden="true" tabindex="-1"></a>    current_cluster<span class="sc">$</span>id <span class="sc">%in%</span> new_split<span class="sc">$</span>idx_A, </span>
<span id="cb438-25"><a href="hierarchical-clustering.html#cb438-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;cluster&quot;</span>] <span class="ot">&lt;-</span> <span class="fu">paste</span>(new_split<span class="sc">$</span>idx_A, <span class="at">collapse =</span> <span class="st">&quot;,&quot;</span>)</span>
<span id="cb438-26"><a href="hierarchical-clustering.html#cb438-26" aria-hidden="true" tabindex="-1"></a>  current_cluster[</span>
<span id="cb438-27"><a href="hierarchical-clustering.html#cb438-27" aria-hidden="true" tabindex="-1"></a>    current_cluster<span class="sc">$</span>id <span class="sc">%in%</span> new_split<span class="sc">$</span>idx_B, </span>
<span id="cb438-28"><a href="hierarchical-clustering.html#cb438-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;cluster&quot;</span>] <span class="ot">&lt;-</span> <span class="fu">paste</span>(new_split<span class="sc">$</span>idx_B, <span class="at">collapse =</span> <span class="st">&quot;,&quot;</span>)</span>
<span id="cb438-29"><a href="hierarchical-clustering.html#cb438-29" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb438-30"><a href="hierarchical-clustering.html#cb438-30" aria-hidden="true" tabindex="-1"></a>  <span class="co"># 군집해 출력</span></span>
<span id="cb438-31"><a href="hierarchical-clustering.html#cb438-31" aria-hidden="true" tabindex="-1"></a>  k <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">unique</span>(current_cluster<span class="sc">$</span>cluster))</span>
<span id="cb438-32"><a href="hierarchical-clustering.html#cb438-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">&quot;Iteration: &quot;</span>, i, <span class="st">&quot;, k = &quot;</span>, k, <span class="st">&quot;, clusters = &quot;</span>, </span>
<span id="cb438-33"><a href="hierarchical-clustering.html#cb438-33" aria-hidden="true" tabindex="-1"></a>      <span class="fu">paste0</span>(<span class="st">&quot;{&quot;</span>, <span class="fu">unique</span>(current_cluster<span class="sc">$</span>cluster), <span class="st">&quot;}&quot;</span>),</span>
<span id="cb438-34"><a href="hierarchical-clustering.html#cb438-34" aria-hidden="true" tabindex="-1"></a>      <span class="st">&quot;, height = &quot;</span>, max_cluster<span class="sc">$</span>distance, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb438-35"><a href="hierarchical-clustering.html#cb438-35" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## Iteration:  1 , k =  2 , clusters =  {6,3,1} {2,4,5,7} , height =  33.54102 
## Iteration:  2 , k =  3 , clusters =  {6,3,1} {2,4,5} {7} , height =  17.88854 
## Iteration:  3 , k =  4 , clusters =  {1} {2,4,5} {3,6} {7} , height =  11.18034 
## Iteration:  4 , k =  5 , clusters =  {1} {2,4} {3,6} {5} {7} , height =  10.04988 
## Iteration:  5 , k =  6 , clusters =  {1} {2} {3,6} {4} {5} {7} , height =  5.385165 
## Iteration:  6 , k =  7 , clusters =  {1} {2} {3} {4} {5} {6} {7} , height =  5.385165</code></pre>
<p>위 출력 결과에서 <code>height</code>는 해당 iteration에서 분리된 군집의 분리 전 지름(diameter)으로, 함수 <code>max_distance_cluster</code>에서 계산한 군집 내 객체간 최대 거리를 나타내며, 이는 R 패키지 <code>cluster</code>의 <code>diana</code> 함수 수행 시 함수값으로 출력되는 <code>height</code>값이다. Iteration이 진행됨에 따라 <code>height</code>의 값이 감소하는 것을 확인할 수 있다.</p>
</div>
</div>
<div id="hierarchical-cluster-number" class="section level2" number="12.6">
<h2><span class="header-section-number">12.6</span> 군집수의 결정</h2>
<p>최적의 군집수를 결정하는 객관적인 방법은 존재하지 않는다. 계층적 군집방법에서는 덴드로그램을 참조하여 군집 간의 거리가 급격히 증가하는 계층에서 수평으로 절단하여, 그 이하의 그룹들을 하나의 군집으로 형성하는 방안을 널리 사용하고 있다. 이외에 군집수를 결정하는 데 통계량으로 다음과 같은 통계량들이 부수적으로 사용된다.</p>
<ol style="list-style-type: decimal">
<li>새 군집의 RMS 표준편차(root-mean-square standard deviation of the new cluster; RMSSTD)</li>
</ol>
<p><span class="math display">\[\begin{equation*}
RMSSTD(C_i, C_j) = \sqrt{\frac{SS(C_i \cup C_j)}{p(|C_i| + |C_j| - 1)}}
\end{equation*}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Semipartial R-squared(SPR)</li>
</ol>
<p><span class="math display">\[\begin{equation*}
SPR(C_i, C_j) = \frac{SS(C_i \cup C_j) - (SS(C_i) + SS(C_j))}{SST}
\end{equation*}\]</span></p>
<p>where</p>
<p><span class="math display">\[\begin{equation*}
SST = \sum_{i = 1}^{n} \sum_{j = 1}^{p} \left( x_{ji} - \frac{1}{n} \sum_{a = 1}^{n} x_{ja} \right)^2
\end{equation*}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>R-squared(<span class="math inline">\(R^2\)</span>)</li>
</ol>
<p><span class="math display">\[\begin{equation*}
1 - \frac{\sum_{i = 1}^{k} SS(C_i)}{SST}
\end{equation*}\]</span></p>
<p>위 <a href="hierarchical-clustering.html#ward-method-algorithm">12.4.2</a>절에서 워드 군집 알고리즘으로 구현한 군집 과정에 대해 위 통계량을 계산해보자.</p>
<div class="sourceCode" id="cb440"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb440-1"><a href="hierarchical-clustering.html#cb440-1" aria-hidden="true" tabindex="-1"></a>train_df <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb440-2"><a href="hierarchical-clustering.html#cb440-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">id =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>),</span>
<span id="cb440-3"><a href="hierarchical-clustering.html#cb440-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">x1 =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">20</span>, <span class="dv">3</span>, <span class="dv">19</span>, <span class="dv">17</span>, <span class="dv">8</span>, <span class="dv">19</span>, <span class="dv">18</span>),</span>
<span id="cb440-4"><a href="hierarchical-clustering.html#cb440-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x2 =</span> <span class="fu">c</span>(<span class="dv">15</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">4</span>, <span class="dv">17</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">6</span>)</span>
<span id="cb440-5"><a href="hierarchical-clustering.html#cb440-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb440-6"><a href="hierarchical-clustering.html#cb440-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb440-7"><a href="hierarchical-clustering.html#cb440-7" aria-hidden="true" tabindex="-1"></a>sst <span class="ot">&lt;-</span> train_df <span class="sc">%&gt;%</span></span>
<span id="cb440-8"><a href="hierarchical-clustering.html#cb440-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>id) <span class="sc">%&gt;%</span></span>
<span id="cb440-9"><a href="hierarchical-clustering.html#cb440-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sapply</span>(<span class="cf">function</span>(x) <span class="fu">sum</span>((x <span class="sc">-</span> <span class="fu">mean</span>(x))<span class="sc">^</span><span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb440-10"><a href="hierarchical-clustering.html#cb440-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>()</span>
<span id="cb440-11"><a href="hierarchical-clustering.html#cb440-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb440-12"><a href="hierarchical-clustering.html#cb440-12" aria-hidden="true" tabindex="-1"></a><span class="co">#단계0</span></span>
<span id="cb440-13"><a href="hierarchical-clustering.html#cb440-13" aria-hidden="true" tabindex="-1"></a>init_cluster <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb440-14"><a href="hierarchical-clustering.html#cb440-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">id =</span> train_df<span class="sc">$</span>id,</span>
<span id="cb440-15"><a href="hierarchical-clustering.html#cb440-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">cluster =</span> <span class="fu">as.character</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(train_df))</span>
<span id="cb440-16"><a href="hierarchical-clustering.html#cb440-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb440-17"><a href="hierarchical-clustering.html#cb440-17" aria-hidden="true" tabindex="-1"></a>i <span class="ot">&lt;-</span> 0L</span>
<span id="cb440-18"><a href="hierarchical-clustering.html#cb440-18" aria-hidden="true" tabindex="-1"></a>current_clusters <span class="ot">&lt;-</span> <span class="fu">unique</span>(init_cluster<span class="sc">$</span>cluster)</span>
<span id="cb440-19"><a href="hierarchical-clustering.html#cb440-19" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">length</span>(current_clusters)</span>
<span id="cb440-20"><a href="hierarchical-clustering.html#cb440-20" aria-hidden="true" tabindex="-1"></a>ssw <span class="ot">&lt;-</span> <span class="fu">calculate_ssw</span>(train_df, init_cluster)</span>
<span id="cb440-21"><a href="hierarchical-clustering.html#cb440-21" aria-hidden="true" tabindex="-1"></a>old_ssw <span class="ot">&lt;-</span> <span class="cn">NA_real_</span></span>
<span id="cb440-22"><a href="hierarchical-clustering.html#cb440-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb440-23"><a href="hierarchical-clustering.html#cb440-23" aria-hidden="true" tabindex="-1"></a><span class="co">#단계1</span></span>
<span id="cb440-24"><a href="hierarchical-clustering.html#cb440-24" aria-hidden="true" tabindex="-1"></a>iteration <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="at">length =</span> <span class="fu">nrow</span>(train_df) <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb440-25"><a href="hierarchical-clustering.html#cb440-25" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span>(k <span class="sc">&gt;</span> <span class="dv">1</span>) {</span>
<span id="cb440-26"><a href="hierarchical-clustering.html#cb440-26" aria-hidden="true" tabindex="-1"></a>  i <span class="ot">&lt;-</span> i <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb440-27"><a href="hierarchical-clustering.html#cb440-27" aria-hidden="true" tabindex="-1"></a>  old_ssw <span class="ot">&lt;-</span> ssw</span>
<span id="cb440-28"><a href="hierarchical-clustering.html#cb440-28" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb440-29"><a href="hierarchical-clustering.html#cb440-29" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(i <span class="sc">==</span> <span class="dv">1</span>) {</span>
<span id="cb440-30"><a href="hierarchical-clustering.html#cb440-30" aria-hidden="true" tabindex="-1"></a>    old_cluster <span class="ot">&lt;-</span> init_cluster</span>
<span id="cb440-31"><a href="hierarchical-clustering.html#cb440-31" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb440-32"><a href="hierarchical-clustering.html#cb440-32" aria-hidden="true" tabindex="-1"></a>    old_cluster <span class="ot">&lt;-</span> iteration[[i<span class="dv">-1</span>]]<span class="sc">$</span>new_cluster_label</span>
<span id="cb440-33"><a href="hierarchical-clustering.html#cb440-33" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb440-34"><a href="hierarchical-clustering.html#cb440-34" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb440-35"><a href="hierarchical-clustering.html#cb440-35" aria-hidden="true" tabindex="-1"></a>  iteration[[i]] <span class="ot">&lt;-</span> <span class="fu">best_merge_cluster</span>(</span>
<span id="cb440-36"><a href="hierarchical-clustering.html#cb440-36" aria-hidden="true" tabindex="-1"></a>    train_df,</span>
<span id="cb440-37"><a href="hierarchical-clustering.html#cb440-37" aria-hidden="true" tabindex="-1"></a>    old_cluster</span>
<span id="cb440-38"><a href="hierarchical-clustering.html#cb440-38" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb440-39"><a href="hierarchical-clustering.html#cb440-39" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb440-40"><a href="hierarchical-clustering.html#cb440-40" aria-hidden="true" tabindex="-1"></a>  merged <span class="ot">&lt;-</span> old_cluster <span class="sc">%&gt;%</span> </span>
<span id="cb440-41"><a href="hierarchical-clustering.html#cb440-41" aria-hidden="true" tabindex="-1"></a>    <span class="fu">anti_join</span>(iteration[[i]]<span class="sc">$</span>new_cluster_label, <span class="at">by =</span> <span class="st">&quot;cluster&quot;</span>)</span>
<span id="cb440-42"><a href="hierarchical-clustering.html#cb440-42" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb440-43"><a href="hierarchical-clustering.html#cb440-43" aria-hidden="true" tabindex="-1"></a>  current_clusters <span class="ot">&lt;-</span> <span class="fu">unique</span>(iteration[[i]]<span class="sc">$</span>new_cluster_label<span class="sc">$</span>cluster)</span>
<span id="cb440-44"><a href="hierarchical-clustering.html#cb440-44" aria-hidden="true" tabindex="-1"></a>  k <span class="ot">&lt;-</span> <span class="fu">length</span>(current_clusters)</span>
<span id="cb440-45"><a href="hierarchical-clustering.html#cb440-45" aria-hidden="true" tabindex="-1"></a>  ssw <span class="ot">&lt;-</span> iteration[[i]]<span class="sc">$</span>new_ssw</span>
<span id="cb440-46"><a href="hierarchical-clustering.html#cb440-46" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb440-47"><a href="hierarchical-clustering.html#cb440-47" aria-hidden="true" tabindex="-1"></a>  iteration[[i]]<span class="sc">$</span>rmsstd <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(</span>
<span id="cb440-48"><a href="hierarchical-clustering.html#cb440-48" aria-hidden="true" tabindex="-1"></a>    merged <span class="sc">%&gt;%</span> </span>
<span id="cb440-49"><a href="hierarchical-clustering.html#cb440-49" aria-hidden="true" tabindex="-1"></a>      <span class="fu">inner_join</span>(train_df, <span class="at">by =</span> <span class="st">&quot;id&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb440-50"><a href="hierarchical-clustering.html#cb440-50" aria-hidden="true" tabindex="-1"></a>      <span class="fu">select</span>(<span class="sc">-</span>id, <span class="sc">-</span>cluster) <span class="sc">%&gt;%</span></span>
<span id="cb440-51"><a href="hierarchical-clustering.html#cb440-51" aria-hidden="true" tabindex="-1"></a>      <span class="fu">sapply</span>(<span class="cf">function</span>(x) <span class="fu">sum</span>((x <span class="sc">-</span> <span class="fu">mean</span>(x))<span class="sc">^</span><span class="dv">2</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb440-52"><a href="hierarchical-clustering.html#cb440-52" aria-hidden="true" tabindex="-1"></a>      <span class="fu">sum</span>() <span class="sc">/</span> (<span class="dv">2</span> <span class="sc">*</span> (<span class="fu">nrow</span>(merged) <span class="sc">-</span> <span class="dv">1</span>))</span>
<span id="cb440-53"><a href="hierarchical-clustering.html#cb440-53" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb440-54"><a href="hierarchical-clustering.html#cb440-54" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb440-55"><a href="hierarchical-clustering.html#cb440-55" aria-hidden="true" tabindex="-1"></a>  iteration[[i]]<span class="sc">$</span>iter <span class="ot">&lt;-</span> i</span>
<span id="cb440-56"><a href="hierarchical-clustering.html#cb440-56" aria-hidden="true" tabindex="-1"></a>  iteration[[i]]<span class="sc">$</span>merge <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&quot;{&quot;</span>, <span class="fu">unique</span>(merged<span class="sc">$</span>cluster), <span class="st">&quot;}&quot;</span>, <span class="at">collapse =</span> <span class="st">&quot;, &quot;</span>)</span>
<span id="cb440-57"><a href="hierarchical-clustering.html#cb440-57" aria-hidden="true" tabindex="-1"></a>  iteration[[i]]<span class="sc">$</span>sol <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&quot;{&quot;</span>, <span class="fu">unique</span>(current_clusters), <span class="st">&quot;}&quot;</span>, <span class="at">collapse =</span> <span class="st">&quot;, &quot;</span>)</span>
<span id="cb440-58"><a href="hierarchical-clustering.html#cb440-58" aria-hidden="true" tabindex="-1"></a>  iteration[[i]]<span class="sc">$</span>spr <span class="ot">&lt;-</span> (ssw <span class="sc">-</span> old_ssw) <span class="sc">/</span> sst</span>
<span id="cb440-59"><a href="hierarchical-clustering.html#cb440-59" aria-hidden="true" tabindex="-1"></a>  iteration[[i]]<span class="sc">$</span>r_sq <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> ssw <span class="sc">/</span> sst</span>
<span id="cb440-60"><a href="hierarchical-clustering.html#cb440-60" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb441"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb441-1"><a href="hierarchical-clustering.html#cb441-1" aria-hidden="true" tabindex="-1"></a>cluster_statistic <span class="ot">&lt;-</span> <span class="fu">lapply</span>(iteration, <span class="cf">function</span>(x) x[</span>
<span id="cb441-2"><a href="hierarchical-clustering.html#cb441-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(<span class="st">&quot;iter&quot;</span>, <span class="st">&quot;merge&quot;</span>, <span class="st">&quot;sol&quot;</span>, <span class="st">&quot;rmsstd&quot;</span>, <span class="st">&quot;spr&quot;</span>, <span class="st">&quot;r_sq&quot;</span>)]) <span class="sc">%&gt;%</span></span>
<span id="cb441-3"><a href="hierarchical-clustering.html#cb441-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">bind_rows</span>(</span>
<span id="cb441-4"><a href="hierarchical-clustering.html#cb441-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">tibble</span>(</span>
<span id="cb441-5"><a href="hierarchical-clustering.html#cb441-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">iter =</span> <span class="dv">0</span>,</span>
<span id="cb441-6"><a href="hierarchical-clustering.html#cb441-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">sol =</span> <span class="fu">paste0</span>(<span class="st">&quot;{&quot;</span>, <span class="fu">unique</span>(init_cluster<span class="sc">$</span>cluster), <span class="st">&quot;}&quot;</span>, <span class="at">collapse =</span> <span class="st">&quot;, &quot;</span>),</span>
<span id="cb441-7"><a href="hierarchical-clustering.html#cb441-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">r_sq =</span> <span class="dv">1</span></span>
<span id="cb441-8"><a href="hierarchical-clustering.html#cb441-8" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb441-9"><a href="hierarchical-clustering.html#cb441-9" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb441-10"><a href="hierarchical-clustering.html#cb441-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(iter)</span>
<span id="cb441-11"><a href="hierarchical-clustering.html#cb441-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb441-12"><a href="hierarchical-clustering.html#cb441-12" aria-hidden="true" tabindex="-1"></a>cluster_statistic <span class="sc">%&gt;%</span></span>
<span id="cb441-13"><a href="hierarchical-clustering.html#cb441-13" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>(</span>
<span id="cb441-14"><a href="hierarchical-clustering.html#cb441-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">booktabs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb441-15"><a href="hierarchical-clustering.html#cb441-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">&#39;Iteration&#39;</span>, <span class="st">&#39;통합대상군집&#39;</span>, <span class="st">&#39;통합 후 군집&#39;</span>,</span>
<span id="cb441-16"><a href="hierarchical-clustering.html#cb441-16" aria-hidden="true" tabindex="-1"></a>                  <span class="st">&#39;$RMSSTD$&#39;</span>, <span class="st">&#39;$SPR$&#39;</span>, <span class="st">&#39;$R^2$&#39;</span>),</span>
<span id="cb441-17"><a href="hierarchical-clustering.html#cb441-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">caption =</span> <span class="st">&#39;군집 과정에 따른 여러 통계량&#39;</span></span>
<span id="cb441-18"><a href="hierarchical-clustering.html#cb441-18" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<table>
<caption><span id="tab:cluster-statistic">Table 12.7: </span>군집 과정에 따른 여러 통계량</caption>
<thead>
<tr class="header">
<th align="right">Iteration</th>
<th align="left">통합대상군집</th>
<th align="left">통합 후 군집</th>
<th align="right"><span class="math inline">\(RMSSTD\)</span></th>
<th align="right"><span class="math inline">\(SPR\)</span></th>
<th align="right"><span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="left">NA</td>
<td align="left">{1}, {2}, {3}, {4}, {5}, {6}, {7}, {8}</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">1.0000000</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">{2}, {7}</td>
<td align="left">{1}, {2,7}, {3}, {4}, {5}, {6}, {8}</td>
<td align="right">0.7071068</td>
<td align="right">0.0020005</td>
<td align="right">0.9979995</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="left">{1}, {3}</td>
<td align="left">{1,3}, {2,7}, {4}, {5}, {6}, {8}</td>
<td align="right">1.1180340</td>
<td align="right">0.0050013</td>
<td align="right">0.9929982</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="left">{4}, {8}</td>
<td align="left">{1,3}, {2,7}, {4,8}, {5}, {6}</td>
<td align="right">1.1180340</td>
<td align="right">0.0050013</td>
<td align="right">0.9879970</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="left">{2,7}, {5}</td>
<td align="left">{1,3}, {2,7,5}, {4,8}, {6}</td>
<td align="right">2.1602469</td>
<td align="right">0.0353422</td>
<td align="right">0.9526548</td>
</tr>
<tr class="even">
<td align="right">5</td>
<td align="left">{1,3}, {6}</td>
<td align="left">{1,3,6}, {2,7,5}, {4,8}</td>
<td align="right">2.3452079</td>
<td align="right">0.0390098</td>
<td align="right">0.9136451</td>
</tr>
<tr class="odd">
<td align="right">6</td>
<td align="left">{2,7,5}, {4,8}</td>
<td align="left">{1,3,6}, {2,7,5,4,8}</td>
<td align="right">3.8470768</td>
<td align="right">0.1945153</td>
<td align="right">0.7191298</td>
</tr>
<tr class="even">
<td align="right">7</td>
<td align="left">{1,3,6}, {2,7,5,4,8}</td>
<td align="left">{1,3,6,2,7,5,4,8}</td>
<td align="right">5.9753960</td>
<td align="right">0.7191298</td>
<td align="right">0.0000000</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb442-1"><a href="hierarchical-clustering.html#cb442-1" aria-hidden="true" tabindex="-1"></a>cluster_statistic <span class="sc">%&gt;%</span></span>
<span id="cb442-2"><a href="hierarchical-clustering.html#cb442-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb442-3"><a href="hierarchical-clustering.html#cb442-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">rmsstd =</span> <span class="fu">if_else</span>(<span class="fu">is.na</span>(rmsstd), <span class="dv">0</span>, rmsstd),</span>
<span id="cb442-4"><a href="hierarchical-clustering.html#cb442-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">spr =</span> <span class="fu">if_else</span>(<span class="fu">is.na</span>(spr), <span class="dv">0</span>, spr)</span>
<span id="cb442-5"><a href="hierarchical-clustering.html#cb442-5" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span></span>
<span id="cb442-6"><a href="hierarchical-clustering.html#cb442-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> iter)) <span class="sc">+</span></span>
<span id="cb442-7"><a href="hierarchical-clustering.html#cb442-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> rmsstd, <span class="at">color =</span> <span class="st">&quot;RMSSTD&quot;</span>)) <span class="sc">+</span></span>
<span id="cb442-8"><a href="hierarchical-clustering.html#cb442-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> spr <span class="sc">*</span> <span class="dv">6</span>, <span class="at">color =</span> <span class="st">&quot;SPR&quot;</span>)) <span class="sc">+</span> </span>
<span id="cb442-9"><a href="hierarchical-clustering.html#cb442-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> r_sq <span class="sc">*</span> <span class="dv">6</span>, <span class="at">color =</span> <span class="st">&quot;R2&quot;</span>)) <span class="sc">+</span> </span>
<span id="cb442-10"><a href="hierarchical-clustering.html#cb442-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">sec.axis =</span> <span class="fu">sec_axis</span>(<span class="sc">~</span> . <span class="sc">/</span> <span class="dv">6</span>, <span class="at">name =</span> <span class="st">&quot;SPR, R2&quot;</span>)) <span class="sc">+</span></span>
<span id="cb442-11"><a href="hierarchical-clustering.html#cb442-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&quot;RMSSTD&quot;</span>) <span class="sc">+</span></span>
<span id="cb442-12"><a href="hierarchical-clustering.html#cb442-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&quot;Iteration&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:cluster-statistic"></span>
<img src="data-mining-book_files/figure-html/cluster-statistic-1.png" alt="군집 과정에 따른 통계량 추이" width="672" />
<p class="caption">
Figure 12.5: 군집 과정에 따른 통계량 추이
</p>
</div>
<p>그림 <a href="hierarchical-clustering.html#fig:cluster-statistic">12.5</a>에서 보듯이 Iteration 6부터 3가지 통계량 모두 급격하게 변화하는 것을 알 수 있다. 따라서 군집수는 Iteration 5까지 3개가 가장 적당하다고 하겠다.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-kaufman1990finding" class="csl-entry">
Kaufman, L, and P. J. Rousseeuw. 1990. <span>“Finding Groups in Data: An Introduction to Cluster Analysis.”</span>
</div>
<div id="ref-lance1967general" class="csl-entry">
Lance, Godfrey N, and William Thomas Williams. 1967. <span>“A General Theory of Classificatory Sorting Strategies: 1. Hierarchical Systems.”</span> <em>The Computer Journal</em> 9 (4): 373–80.
</div>
<div id="ref-ward1963hierarchical" class="csl-entry">
Ward Jr, Joe H. 1963. <span>“Hierarchical Grouping to Optimize an Objective Function.”</span> <em>Journal of the American Statistical Association</em> 58 (301): 236–44.
</div>
<div id="ref-wishart1969256" class="csl-entry">
Wishart, David. 1969. <span>“256. Note: An Algorithm for Hierarchical Classifications.”</span> <em>Biometrics</em>, 165–70.
</div>
</div>
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://r-data-mining-book.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                            
            </section>

          </div>
        </div>
      </div>
<a href="clustering-overview.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="nonhierarchical-clustering.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
