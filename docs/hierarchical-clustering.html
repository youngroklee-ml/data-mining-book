<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 계층적 군집방법 | 데이터마이닝 with R</title>
  <meta name="description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 계층적 군집방법 | 데이터마이닝 with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://youngroklee-ml.github.io/data-mining-book/" />
  
  <meta property="og:description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  <meta name="github-repo" content="youngroklee-ml/data-mining-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 계층적 군집방법 | 데이터마이닝 with R" />
  
  <meta name="twitter:description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  

<meta name="author" content="전치혁, 이혜선, 이종석, 이영록" />


<meta name="date" content="2019-06-28" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="clustering-overview.html">
<link rel="next" href="nonhierarchical-clustering.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">데이터마이닝 with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>개요</a></li>
<li class="chapter" data-level="1" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>1</b> 회귀분석</a><ul>
<li class="chapter" data-level="1.1" data-path="regression.html"><a href="regression.html#regression-packages-install"><i class="fa fa-check"></i><b>1.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="1.2" data-path="regression.html"><a href="regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>1.2</b> 다중회귀모형</a></li>
<li class="chapter" data-level="1.3" data-path="regression.html"><a href="regression.html#regression-response-confidence-prediction"><i class="fa fa-check"></i><b>1.3</b> 반응치에 대한 추정 및 예측</a><ul>
<li class="chapter" data-level="1.3.1" data-path="regression.html"><a href="regression.html#regression-response-confidence"><i class="fa fa-check"></i><b>1.3.1</b> 평균반응치의 추정</a></li>
<li class="chapter" data-level="1.3.2" data-path="regression.html"><a href="regression.html#regression-response-prediction"><i class="fa fa-check"></i><b>1.3.2</b> 미래반응치의 예측</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="regression.html"><a href="regression.html#regression-indicator-variable"><i class="fa fa-check"></i><b>1.4</b> 지시변수와 회귀모형</a><ul>
<li class="chapter" data-level="1.4.1" data-path="regression.html"><a href="regression.html#regression-indicator-variable-basic-script"><i class="fa fa-check"></i><b>1.4.1</b> 기본 R 스트립트</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>2</b> 주성분분석</a><ul>
<li class="chapter" data-level="2.1" data-path="pca.html"><a href="pca.html#pca-packages-install"><i class="fa fa-check"></i><b>2.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="2.2" data-path="pca.html"><a href="pca.html#pca-matrix-factorization"><i class="fa fa-check"></i><b>2.2</b> 행렬의 분해</a><ul>
<li class="chapter" data-level="2.2.1" data-path="pca.html"><a href="pca.html#pca-matrix-factorization-basic-script"><i class="fa fa-check"></i><b>2.2.1</b> 기본 R 스트립트</a></li>
<li class="chapter" data-level="2.2.2" data-path="pca.html"><a href="pca.html#pca-ss"><i class="fa fa-check"></i><b>2.2.2</b> 변수의 변동과 제곱합</a></li>
<li class="chapter" data-level="2.2.3" data-path="pca.html"><a href="pca.html#pca-intro"><i class="fa fa-check"></i><b>2.2.3</b> 주성분의 이해 및 행렬의 분해</a></li>
<li class="chapter" data-level="2.2.4" data-path="pca.html"><a href="pca.html#-singular-value-decomposition-pca-svd"><i class="fa fa-check"></i><b>2.2.4</b> 특이치분해 (Singular Value Decomposition) {pca-svd}</a></li>
<li class="chapter" data-level="2.2.5" data-path="pca.html"><a href="pca.html#-spectral-decomposition-pca-spectral"><i class="fa fa-check"></i><b>2.2.5</b> 분광분해 (Spectral Decomposition) {pca-spectral}</a></li>
<li class="chapter" data-level="2.2.6" data-path="pca.html"><a href="pca.html#pca-nipals"><i class="fa fa-check"></i><b>2.2.6</b> NIPALS 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="pca.html"><a href="pca.html#pca-regression"><i class="fa fa-check"></i><b>2.3</b> 주성분 회귀분석</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="classification-analysis.html"><a href="classification-analysis.html"><i class="fa fa-check"></i><b>3</b> 분류분석 개요</a><ul>
<li class="chapter" data-level="3.1" data-path="classification-analysis.html"><a href="classification-analysis.html#classification-packages-install"><i class="fa fa-check"></i><b>3.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="3.2" data-path="classification-analysis.html"><a href="classification-analysis.html#classification-problem-methods"><i class="fa fa-check"></i><b>3.2</b> 분류문제 및 분류기법</a></li>
<li class="chapter" data-level="3.3" data-path="classification-analysis.html"><a href="classification-analysis.html#simple-classification-methods"><i class="fa fa-check"></i><b>3.3</b> 기본적인 분류기법</a><ul>
<li class="chapter" data-level="3.3.1" data-path="classification-analysis.html"><a href="classification-analysis.html#nearest-neighbor-classification"><i class="fa fa-check"></i><b>3.3.1</b> 인접객체법</a></li>
<li class="chapter" data-level="3.3.2" data-path="classification-analysis.html"><a href="classification-analysis.html#naive-bayes"><i class="fa fa-check"></i><b>3.3.2</b> 나이브 베이지안 분류법</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>4</b> 로지스틱 회귀분석</a><ul>
<li class="chapter" data-level="4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-packages-install"><i class="fa fa-check"></i><b>4.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-regression"><i class="fa fa-check"></i><b>4.2</b> 이분 로지스틱 회귀모형</a><ul>
<li class="chapter" data-level="4.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#bianry-logistic-reg-basic-script"><i class="fa fa-check"></i><b>4.2.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="4.2.2" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-reg-model"><i class="fa fa-check"></i><b>4.2.2</b> 회귀모형</a></li>
<li class="chapter" data-level="4.2.3" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-reg-estimation"><i class="fa fa-check"></i><b>4.2.3</b> 회귀계수 추정</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="logistic-regression.html"><a href="logistic-regression.html#nominal-logistic-regression"><i class="fa fa-check"></i><b>4.3</b> 명목 로지스틱 회귀모형</a><ul>
<li class="chapter" data-level="4.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#nominal-logistic-reg-basic-script"><i class="fa fa-check"></i><b>4.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="4.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#baseline-category-logit-model"><i class="fa fa-check"></i><b>4.3.2</b> 기준범주 로짓모형</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="logistic-regression.html"><a href="logistic-regression.html#ordinal-logistic-regression"><i class="fa fa-check"></i><b>4.4</b> 서열 로지스틱 회귀모형</a><ul>
<li class="chapter" data-level="4.4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#ordinal-logistic-basic-script"><i class="fa fa-check"></i><b>4.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="4.4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#cumulative-logit-model"><i class="fa fa-check"></i><b>4.4.2</b> 누적 로짓모형</a></li>
<li class="chapter" data-level="4.4.3" data-path="logistic-regression.html"><a href="logistic-regression.html#adjacent-categories-logit-model"><i class="fa fa-check"></i><b>4.4.3</b> 인근범주 로짓모형</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="da.html"><a href="da.html"><i class="fa fa-check"></i><b>5</b> 판별분석</a><ul>
<li class="chapter" data-level="5.1" data-path="da.html"><a href="da.html#da-overview"><i class="fa fa-check"></i><b>5.1</b> 개요</a></li>
<li class="chapter" data-level="5.2" data-path="da.html"><a href="da.html#da-packages-install"><i class="fa fa-check"></i><b>5.2</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="5.3" data-path="da.html"><a href="da.html#da-fisher"><i class="fa fa-check"></i><b>5.3</b> 피셔 방법</a><ul>
<li class="chapter" data-level="5.3.1" data-path="da.html"><a href="da.html#da-fisher-basic-script"><i class="fa fa-check"></i><b>5.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="5.3.2" data-path="da.html"><a href="da.html#-"><i class="fa fa-check"></i><b>5.3.2</b> 피셔 판별함수</a></li>
<li class="chapter" data-level="5.3.3" data-path="da.html"><a href="da.html#-"><i class="fa fa-check"></i><b>5.3.3</b> 분류 규칙</a></li>
<li class="chapter" data-level="5.3.4" data-path="da.html"><a href="da.html#r----"><i class="fa fa-check"></i><b>5.3.4</b> R 패키지를 이용한 분류규칙 도출</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="da.html"><a href="da.html#lda"><i class="fa fa-check"></i><b>5.4</b> 의사결정론에 의한 선형분류규칙</a><ul>
<li class="chapter" data-level="5.4.1" data-path="da.html"><a href="da.html#lda-basic-script"><i class="fa fa-check"></i><b>5.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="5.4.2" data-path="da.html"><a href="da.html#lda-function"><i class="fa fa-check"></i><b>5.4.2</b> 선형판별함수</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="da.html"><a href="da.html#lda-misclassification-cost"><i class="fa fa-check"></i><b>5.5</b> 오분류비용을 고려한 분류규칙</a></li>
<li class="chapter" data-level="5.6" data-path="da.html"><a href="da.html#qda"><i class="fa fa-check"></i><b>5.6</b> 이차판별분석</a><ul>
<li class="chapter" data-level="5.6.1" data-path="da.html"><a href="da.html#qda-basic-script"><i class="fa fa-check"></i><b>5.6.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="5.6.2" data-path="da.html"><a href="da.html#qda-function"><i class="fa fa-check"></i><b>5.6.2</b> 이차 판별함수</a></li>
<li class="chapter" data-level="5.6.3" data-path="da.html"><a href="da.html#qda-discriminant-rule"><i class="fa fa-check"></i><b>5.6.3</b> 이차판별함수에 의한 분류</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="da.html"><a href="da.html#da-multiclass"><i class="fa fa-check"></i><b>5.7</b> 세 범주 이상의 분류</a><ul>
<li class="chapter" data-level="5.7.1" data-path="da.html"><a href="da.html#mutliclass-da-basic-script"><i class="fa fa-check"></i><b>5.7.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="5.7.2" data-path="da.html"><a href="da.html#mutliclass-generalized-discriminant-function"><i class="fa fa-check"></i><b>5.7.2</b> 일반화된 판별함수</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="tree-based-method.html"><a href="tree-based-method.html"><i class="fa fa-check"></i><b>6</b> 트리기반 기법</a><ul>
<li class="chapter" data-level="6.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-overview"><i class="fa fa-check"></i><b>6.1</b> CART 개요</a></li>
<li class="chapter" data-level="6.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-packages-install"><i class="fa fa-check"></i><b>6.2</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="6.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-build"><i class="fa fa-check"></i><b>6.3</b> CART 트리 생성</a><ul>
<li class="chapter" data-level="6.3.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-basic-r-script"><i class="fa fa-check"></i><b>6.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="6.3.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-notation"><i class="fa fa-check"></i><b>6.3.2</b> 기호 정의</a></li>
<li class="chapter" data-level="6.3.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-impurity"><i class="fa fa-check"></i><b>6.3.3</b> 노드 및 트리의 불순도</a></li>
<li class="chapter" data-level="6.3.4" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-split"><i class="fa fa-check"></i><b>6.3.4</b> 분지기준</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-pruning-complete"><i class="fa fa-check"></i><b>6.4</b> 가지치기 및 최종 트리 선정</a><ul>
<li class="chapter" data-level="6.4.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-pruning"><i class="fa fa-check"></i><b>6.4.1</b> 가지치기</a></li>
<li class="chapter" data-level="6.4.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-best-tree"><i class="fa fa-check"></i><b>6.4.2</b> 최적 트리의 선정</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg"><i class="fa fa-check"></i><b>6.5</b> R패키지 내 분류 트리 방법</a><ul>
<li class="chapter" data-level="6.5.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-split"><i class="fa fa-check"></i><b>6.5.1</b> 트리 확장</a></li>
<li class="chapter" data-level="6.5.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-pruning"><i class="fa fa-check"></i><b>6.5.2</b> 가지치기</a></li>
<li class="chapter" data-level="6.5.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-param"><i class="fa fa-check"></i><b>6.5.3</b> 파라미터값 결정</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="svm.html"><a href="svm.html"><i class="fa fa-check"></i><b>7</b> 서포트 벡터 머신</a><ul>
<li class="chapter" data-level="7.1" data-path="svm.html"><a href="svm.html#svm-overview"><i class="fa fa-check"></i><b>7.1</b> 개요</a></li>
<li class="chapter" data-level="7.2" data-path="svm.html"><a href="svm.html#svm-packages-install"><i class="fa fa-check"></i><b>7.2</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="7.3" data-path="svm.html"><a href="svm.html#linear-svm-separable"><i class="fa fa-check"></i><b>7.3</b> 선형 SVM - 분리 가능 경우</a><ul>
<li class="chapter" data-level="7.3.1" data-path="svm.html"><a href="svm.html#linear-svm-separable-basic-script"><i class="fa fa-check"></i><b>7.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.3.2" data-path="svm.html"><a href="svm.html#linear-svm-notation"><i class="fa fa-check"></i><b>7.3.2</b> 기호 정의</a></li>
<li class="chapter" data-level="7.3.3" data-path="svm.html"><a href="svm.html#linear-svm-separable-hyperplane"><i class="fa fa-check"></i><b>7.3.3</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="svm.html"><a href="svm.html#linear-svm-inseparable"><i class="fa fa-check"></i><b>7.4</b> 선형 SVM - 분리 불가능 경우</a><ul>
<li class="chapter" data-level="7.4.1" data-path="svm.html"><a href="svm.html#linear-svm-inseparable-basic-script"><i class="fa fa-check"></i><b>7.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.4.2" data-path="svm.html"><a href="svm.html#linear-svm-inseparable-hyperplane"><i class="fa fa-check"></i><b>7.4.2</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="svm.html"><a href="svm.html#nonlinear-svm"><i class="fa fa-check"></i><b>7.5</b> 비선형 SVM</a><ul>
<li class="chapter" data-level="7.5.1" data-path="svm.html"><a href="svm.html#nonlinear-svm-basic-script"><i class="fa fa-check"></i><b>7.5.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.5.2" data-path="svm.html"><a href="svm.html#nonlinear-svm-hyperplane"><i class="fa fa-check"></i><b>7.5.2</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="svm.html"><a href="svm.html#svm-r-pkg"><i class="fa fa-check"></i><b>7.6</b> R패키지 내 SVM</a><ul>
<li class="chapter" data-level="7.6.1" data-path="svm.html"><a href="svm.html#svm-kernel-function"><i class="fa fa-check"></i><b>7.6.1</b> 커널함수</a></li>
<li class="chapter" data-level="7.6.2" data-path="svm.html"><a href="svm.html#svm-nu-classification"><i class="fa fa-check"></i><b>7.6.2</b> <span class="math inline">\(\nu\)</span>-SVC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html"><i class="fa fa-check"></i><b>8</b> 분류규칙의 성능 평가</a><ul>
<li class="chapter" data-level="8.1" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#classifier-evaluation-packages-install"><i class="fa fa-check"></i><b>8.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="8.2" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#classifier-evaluation-misclassification-rate"><i class="fa fa-check"></i><b>8.2</b> 분류오류율</a></li>
<li class="chapter" data-level="8.3" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#precision-sensitivity-specificity"><i class="fa fa-check"></i><b>8.3</b> 정확도, 민감도 및 특이도</a><ul>
<li class="chapter" data-level="8.3.1" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#confusion-matrix-r-package"><i class="fa fa-check"></i><b>8.3.1</b> R 패키지 내 정오분류표</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#roc-curve"><i class="fa fa-check"></i><b>8.4</b> ROC 곡선</a></li>
<li class="chapter" data-level="8.5" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#gain-chart"><i class="fa fa-check"></i><b>8.5</b> 이익도표</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="clustering-overview.html"><a href="clustering-overview.html"><i class="fa fa-check"></i><b>9</b> 군집분석 개요</a><ul>
<li class="chapter" data-level="9.1" data-path="clustering-overview.html"><a href="clustering-overview.html#clustering-overview-packages-install"><i class="fa fa-check"></i><b>9.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="9.2" data-path="clustering-overview.html"><a href="clustering-overview.html#clustering-method"><i class="fa fa-check"></i><b>9.2</b> 군집분석 기법</a></li>
<li class="chapter" data-level="9.3" data-path="clustering-overview.html"><a href="clustering-overview.html#object-similarity-metric"><i class="fa fa-check"></i><b>9.3</b> 객체 간의 유사성 척도</a><ul>
<li class="chapter" data-level="9.3.1" data-path="clustering-overview.html"><a href="clustering-overview.html#object-distance-metric"><i class="fa fa-check"></i><b>9.3.1</b> 거리 관련 척도</a></li>
<li class="chapter" data-level="9.3.2" data-path="clustering-overview.html"><a href="clustering-overview.html#object-correlation-metric"><i class="fa fa-check"></i><b>9.3.2</b> 상관계수 관련 척도</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="clustering-overview.html"><a href="clustering-overview.html#category-similarity-metric"><i class="fa fa-check"></i><b>9.4</b> 범주형 객체의 유사성 척도</a><ul>
<li class="chapter" data-level="9.4.1" data-path="clustering-overview.html"><a href="clustering-overview.html#binary-similarity-metric"><i class="fa fa-check"></i><b>9.4.1</b> 이분형 변수의 경우</a></li>
<li class="chapter" data-level="9.4.2" data-path="clustering-overview.html"><a href="clustering-overview.html#ordinal-similarity-metric"><i class="fa fa-check"></i><b>9.4.2</b> 서열형 변수의 경우</a></li>
<li class="chapter" data-level="9.4.3" data-path="clustering-overview.html"><a href="clustering-overview.html#nominal-similarity-metric"><i class="fa fa-check"></i><b>9.4.3</b> 명목형 변수의 경우</a></li>
<li class="chapter" data-level="9.4.4" data-path="clustering-overview.html"><a href="clustering-overview.html#mixed-similarity-metric"><i class="fa fa-check"></i><b>9.4.4</b> 혼합형의 경우</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html"><i class="fa fa-check"></i><b>10</b> 계층적 군집방법</a><ul>
<li class="chapter" data-level="10.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hierarchical-clustering-packages-install"><i class="fa fa-check"></i><b>10.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="10.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#distance-between-clusters"><i class="fa fa-check"></i><b>10.2</b> 군집 간 거리척도 및 연결법</a></li>
<li class="chapter" data-level="10.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method"><i class="fa fa-check"></i><b>10.3</b> 연결법의 군집 알고리즘</a><ul>
<li class="chapter" data-level="10.3.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method-basic-script"><i class="fa fa-check"></i><b>10.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="10.3.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method-algorithm"><i class="fa fa-check"></i><b>10.3.2</b> 연결법 군집 알고리즘</a></li>
<li class="chapter" data-level="10.3.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hclust"><i class="fa fa-check"></i><b>10.3.3</b> R 패키지 내 연결법</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method"><i class="fa fa-check"></i><b>10.4</b> 워드 방법</a><ul>
<li class="chapter" data-level="10.4.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method-basic-script"><i class="fa fa-check"></i><b>10.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="10.4.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method-algorithm"><i class="fa fa-check"></i><b>10.4.2</b> 워드 군집 알고리즘</a></li>
<li class="chapter" data-level="10.4.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-rpackages"><i class="fa fa-check"></i><b>10.4.3</b> R 패키지 내 워드 방법</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana"><i class="fa fa-check"></i><b>10.5</b> 분리적 방법 - 다이아나</a><ul>
<li class="chapter" data-level="10.5.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana-basic-script"><i class="fa fa-check"></i><b>10.5.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="10.5.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana-algorithm"><i class="fa fa-check"></i><b>10.5.2</b> 다이아나 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hierarchical-cluster-number"><i class="fa fa-check"></i><b>10.6</b> 군집수의 결정</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html"><i class="fa fa-check"></i><b>11</b> 비계층적 군집방법</a><ul>
<li class="chapter" data-level="11.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#nonhierarchical-clustering-packages-install"><i class="fa fa-check"></i><b>11.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="11.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans"><i class="fa fa-check"></i><b>11.2</b> K-means 알고리즘</a><ul>
<li class="chapter" data-level="11.2.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-basic-script"><i class="fa fa-check"></i><b>11.2.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="11.2.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-algorithm"><i class="fa fa-check"></i><b>11.2.2</b> 알고리즘</a></li>
<li class="chapter" data-level="11.2.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-user-defined-functions"><i class="fa fa-check"></i><b>11.2.3</b> R 스크립트 구현</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmedoids"><i class="fa fa-check"></i><b>11.3</b> K-medoids 군집방법</a><ul>
<li class="chapter" data-level="11.3.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#pam"><i class="fa fa-check"></i><b>11.3.1</b> PAM 알고리즘</a></li>
<li class="chapter" data-level="11.3.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#clara"><i class="fa fa-check"></i><b>11.3.2</b> CLARA 알고리즘</a></li>
<li class="chapter" data-level="11.3.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#clarans"><i class="fa fa-check"></i><b>11.3.3</b> CLARANS 알고리즘</a></li>
<li class="chapter" data-level="11.3.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-like"><i class="fa fa-check"></i><b>11.3.4</b> K-means-like 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans"><i class="fa fa-check"></i><b>11.4</b> 퍼지 K-means 알고리즘</a><ul>
<li class="chapter" data-level="11.4.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-basic-script"><i class="fa fa-check"></i><b>11.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="11.4.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-algorithm"><i class="fa fa-check"></i><b>11.4.2</b> 알고리즘</a></li>
<li class="chapter" data-level="11.4.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-script-implement"><i class="fa fa-check"></i><b>11.4.3</b> R 스크립트 구현</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering"><i class="fa fa-check"></i><b>11.5</b> 모형기반 군집방법</a><ul>
<li class="chapter" data-level="11.5.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-basic-script"><i class="fa fa-check"></i><b>11.5.1</b> 기본 R script</a></li>
<li class="chapter" data-level="11.5.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-em"><i class="fa fa-check"></i><b>11.5.2</b> EM 알고리즘</a></li>
<li class="chapter" data-level="11.5.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-script-implement"><i class="fa fa-check"></i><b>11.5.3</b> R 스크립트 구현</a></li>
<li class="chapter" data-level="11.5.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#r-packages-model-based-clustering"><i class="fa fa-check"></i><b>11.5.4</b> R 패키지 내 모형기반 군집분석</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html"><i class="fa fa-check"></i><b>12</b> 군집해의 평가 및 해석</a><ul>
<li class="chapter" data-level="12.1" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-solution-evaluation-packages-install"><i class="fa fa-check"></i><b>12.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="12.2" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-solution-evaluation-metric"><i class="fa fa-check"></i><b>12.2</b> 군집해의 평가</a><ul>
<li class="chapter" data-level="12.2.1" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-evaluation-external-index"><i class="fa fa-check"></i><b>12.2.1</b> 외부평가지수</a></li>
<li class="chapter" data-level="12.2.2" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-evaluation-internal-index"><i class="fa fa-check"></i><b>12.2.2</b> 내부평가지수</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-solution-interpretation"><i class="fa fa-check"></i><b>12.3</b> 군집해의 해석</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="association-rule.html"><a href="association-rule.html"><i class="fa fa-check"></i><b>13</b> 연관규칙</a><ul>
<li class="chapter" data-level="13.1" data-path="association-rule.html"><a href="association-rule.html#association-packages-install"><i class="fa fa-check"></i><b>13.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="13.2" data-path="association-rule.html"><a href="association-rule.html#association-rule-definition-metric"><i class="fa fa-check"></i><b>13.2</b> 연관규칙의 정의 및 성능척도</a><ul>
<li class="chapter" data-level="13.2.1" data-path="association-rule.html"><a href="association-rule.html#association-rule-support"><i class="fa fa-check"></i><b>13.2.1</b> 지지도</a></li>
<li class="chapter" data-level="13.2.2" data-path="association-rule.html"><a href="association-rule.html#association-rule-confidence"><i class="fa fa-check"></i><b>13.2.2</b> 신뢰도</a></li>
<li class="chapter" data-level="13.2.3" data-path="association-rule.html"><a href="association-rule.html#association-rule-lift"><i class="fa fa-check"></i><b>13.2.3</b> 개선도</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="association-rule.html"><a href="association-rule.html#association-rule-exploration"><i class="fa fa-check"></i><b>13.3</b> 연관규칙의 탐사</a><ul>
<li class="chapter" data-level="13.3.1" data-path="association-rule.html"><a href="association-rule.html#apriori-large-itemsets"><i class="fa fa-check"></i><b>13.3.1</b> 빈발항목집합 생성</a></li>
<li class="chapter" data-level="13.3.2" data-path="association-rule.html"><a href="association-rule.html#apriori-rule-exploration"><i class="fa fa-check"></i><b>13.3.2</b> 규칙의 탐사</a></li>
<li class="chapter" data-level="13.3.3" data-path="association-rule.html"><a href="association-rule.html#apriori-r-package"><i class="fa fa-check"></i><b>13.3.3</b> R 패키지 내 Apriori</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="association-rule.html"><a href="association-rule.html#association-sequential-pattern"><i class="fa fa-check"></i><b>13.4</b> 순차적 패턴의 탐사</a><ul>
<li class="chapter" data-level="13.4.1" data-path="association-rule.html"><a href="association-rule.html#association-aprioriall"><i class="fa fa-check"></i><b>13.4.1</b> AprioriAll 알고리즘</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="recommender-system.html"><a href="recommender-system.html"><i class="fa fa-check"></i><b>14</b> 추천시스템</a><ul>
<li class="chapter" data-level="14.1" data-path="recommender-system.html"><a href="recommender-system.html#recommender-packages-install"><i class="fa fa-check"></i><b>14.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="14.2" data-path="recommender-system.html"><a href="recommender-system.html#content-based-recommender"><i class="fa fa-check"></i><b>14.2</b> 내용기반 추천시스템</a></li>
<li class="chapter" data-level="14.3" data-path="recommender-system.html"><a href="recommender-system.html#collaborative-filtering"><i class="fa fa-check"></i><b>14.3</b> 협업 필터링</a></li>
<li class="chapter" data-level="14.4" data-path="recommender-system.html"><a href="recommender-system.html#market-basket"><i class="fa fa-check"></i><b>14.4</b> 시장바구니 데이터를 이용한 협업 필터링</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">데이터마이닝 with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hierarchical-clustering" class="section level1">
<h1><span class="header-section-number">Chapter 10</span> 계층적 군집방법</h1>
<p>계층적 군집방법에는 집괴법과 분리법이 있으나 주로 집괴법이 사용된다. 본 장에서는 집괴법으로는 연결법을 소개하고, 분리법으로는 다이아나(DIANA)를 소개한다.</p>
<div id="hierarchical-clustering-packages-install" class="section level2">
<h2><span class="header-section-number">10.1</span> 필요 R 패키지 설치</h2>
<p>본 장에서 필요한 R 패키지들은 아래와 같다.</p>
<table>
<thead>
<tr class="header">
<th align="left">package</th>
<th align="left">version</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">tidyverse</td>
<td align="left">1.2.1</td>
</tr>
<tr class="even">
<td align="left">stats</td>
<td align="left">3.6.0</td>
</tr>
<tr class="odd">
<td align="left">cluster</td>
<td align="left">2.0.8</td>
</tr>
</tbody>
</table>
</div>
<div id="distance-between-clusters" class="section level2">
<h2><span class="header-section-number">10.2</span> 군집 간 거리척도 및 연결법</h2>
<p>계층적 군집방법에서는 유사한 객체들을 군집으로 묶고, 다시 유사한 군집을 새로운 군집으로 묶는 등 단계적 절차를 사용한다. 이를 위해서는 군집 간의 유사성 척도 혹은 비유사성 척도가 필요하다.</p>
<ul>
<li><span class="math inline">\(C_i\)</span>: <span class="math inline">\(i\)</span>번째 군집(군집 <span class="math inline">\(i\)</span>)</li>
<li><span class="math inline">\(|C_i|\)</span>: 군집 <span class="math inline">\(i\)</span>의 객체수</li>
<li><span class="math inline">\(\mathbf{c}_i = \left( \bar{x}_1^{(i)}, \bar{x}_2^{(i)}, \cdots, \bar{x}_p^{(i)} \right)\)</span>: 군집 <span class="math inline">\(i\)</span>의 중심좌표(centroid) (<span class="math inline">\(\bar{x}_a^{(i)} = \frac{1}{|C_i|} \sum_{j \in C_i} x_{aj}\)</span>)</li>
<li><span class="math inline">\(d(u, v) = d(\mathbf{x}_u, \mathbf{x}_v)\)</span>: 객체 <span class="math inline">\(u\)</span>와 객체 <span class="math inline">\(v\)</span>의 거리(또는 비유사성 척도)</li>
<li><span class="math inline">\(D(C_i, C_j)\)</span>: 군집 <span class="math inline">\(i\)</span>와 군집 <span class="math inline">\(j\)</span>의 거리(또는 비유사성 척도)</li>
</ul>
<p>군집과 군집 간의 거리척도를 평가하는 방법에 따라 다양한 연결법(linkage method)이 존재한다. 아래에 대표적인 연결법과 군집 간 거리척도를 소개한다.</p>
<table>
<caption><span id="tab:linkage-method">Table 10.1: </span>연결법 종류</caption>
<thead>
<tr class="header">
<th align="center">연결법</th>
<th align="center">군집거리 <span class="math inline">\(D(C_i, C_j)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">단일연결법(single linkage method)</td>
<td align="center"><span class="math inline">\(\min_{u \in C_i, \, v \in C_j} d(u, v)\)</span></td>
</tr>
<tr class="even">
<td align="center">완전연결법(complete linkage method)</td>
<td align="center"><span class="math inline">\(\max_{u \in C_i, \, v \in C_j} d(u, v)\)</span></td>
</tr>
<tr class="odd">
<td align="center">평균연결법(average linkage method)</td>
<td align="center"><span class="math inline">\(\frac{1}{|C_i||C_j|} \sum_{u \in C_i, \, v \in C_j} d(u, v)\)</span></td>
</tr>
<tr class="even">
<td align="center">중심연결법(centroid linkage method)</td>
<td align="center"><span class="math inline">\(d(\mathbf{c}_i, \mathbf{c}_j)\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="linkage-method" class="section level2">
<h2><span class="header-section-number">10.3</span> 연결법의 군집 알고리즘</h2>
<div id="linkage-method-basic-script" class="section level3">
<h3><span class="header-section-number">10.3.1</span> 기본 R 스크립트</h3>
<pre class="sourceCode r"><code class="sourceCode r">train_df &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">id =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>),
  <span class="dt">x1 =</span> <span class="kw">c</span>(<span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">14</span>, <span class="dv">11</span>, <span class="dv">15</span>, <span class="dv">7</span>, <span class="dv">13</span>, <span class="dv">5</span>, <span class="dv">3</span>, <span class="dv">3</span>),
  <span class="dt">x2 =</span> <span class="kw">c</span>(<span class="dv">14</span>,<span class="dv">13</span>, <span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">7</span>, <span class="dv">15</span>, <span class="dv">6</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>)
)

knitr<span class="op">::</span><span class="kw">kable</span>(train_df, <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
             <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),
             <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;객체번호&#39;</span>, <span class="st">&#39;PC 경력(년, $x_1$)&#39;</span>, <span class="st">&#39;사용시간(시간, $x_2$)&#39;</span>),
             <span class="dt">caption =</span> <span class="st">&#39;PC 사용자 데이터&#39;</span>)</code></pre>
<table>
<caption><span id="tab:pc-user-data">Table 10.2: </span>PC 사용자 데이터</caption>
<thead>
<tr class="header">
<th align="center">객체번호</th>
<th align="center">PC 경력(년, <span class="math inline">\(x_1\)</span>)</th>
<th align="center">사용시간(시간, <span class="math inline">\(x_2\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">6</td>
<td align="center">14</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">8</td>
<td align="center">13</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">14</td>
<td align="center">6</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">11</td>
<td align="center">8</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">15</td>
<td align="center">7</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">7</td>
<td align="center">15</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">13</td>
<td align="center">6</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">5</td>
<td align="center">4</td>
</tr>
<tr class="odd">
<td align="center">9</td>
<td align="center">3</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">10</td>
<td align="center">3</td>
<td align="center">2</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">theme_set</span>(<span class="kw">theme_gray</span>(<span class="dt">base_family=</span><span class="st">&#39;NanumGothic&#39;</span>))
<span class="kw">ggplot</span>(train_df, <span class="kw">aes</span>(<span class="dt">x =</span> x1, <span class="dt">y =</span> x2)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> id)) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;PC 경력&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;사용시간&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:pc-user-data-plot"></span>
<img src="data-mining-book_files/figure-html/pc-user-data-plot-1.png" alt="PC 사용자 데이터" width="672" />
<p class="caption">
Figure 10.1: PC 사용자 데이터
</p>
</div>
<p>Table <a href="hierarchical-clustering.html#tab:pc-user-data">10.2</a>는 10명의 사람(객체)에 대한 PC 사용경력과 주당 PC 사용시간을 나타낸 것이다. 각 객체가 두 변수로 이루어져 있으며, Figure <a href="hierarchical-clustering.html#fig:pc-user-data-plot">10.1</a>에서 보는 바와 같이 세 개의 군집({1, 2, 6}, {3, 4, 5, 7}, {8, 9, 10})으로 이루어져 있다고 볼 수 있다.</p>
<p>본 장에서 평균연결법에 의한 군집화 과정을 살펴보기로 하자. 우선 R 패키지를 이용해서 간단하게 군집해를 구하는 과정은 아래와 같다.</p>
<ol style="list-style-type: decimal">
<li><code>stats</code> 패키지의 함수 <code>dist</code>를 이용하여 객체간 거리를 계산한다.</li>
<li>1에서 얻은 거리 행렬을 <code>stats</code> 패키지의 <code>hclust</code> 함수에 입력하여 데이터 군집을 분석한다. 이 때, 파라미터 <code>method</code>의 값을 “average”로 설정하면 평균연결법을 이용한다.</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dist</span>(train_df[, <span class="dv">-1</span>]) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">hclust</span>(<span class="dt">method =</span> <span class="st">&quot;average&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">plot</span>(
    <span class="dt">main =</span> <span class="ot">NULL</span>,
    <span class="dt">ylab =</span> <span class="st">&quot;distance&quot;</span>,
    <span class="dt">xlab =</span> <span class="st">&quot;observation&quot;</span>
  )</code></pre>
<div class="figure" style="text-align: center"><span id="fig:pc-user-average-linkage"></span>
<img src="data-mining-book_files/figure-html/pc-user-average-linkage-1.png" alt="PC 사용자 데이터에 대한 평균연결법 덴드로그램" width="672" />
<p class="caption">
Figure 10.2: PC 사용자 데이터에 대한 평균연결법 덴드로그램
</p>
</div>
</div>
<div id="linkage-method-algorithm" class="section level3">
<h3><span class="header-section-number">10.3.2</span> 연결법 군집 알고리즘</h3>
<p>각 연결법들은 군집간 유사성 척도 평가 방법이 다를 뿐, 군집화를 위한 알고리즘은 동일하게 아래와 같이 진행된다.</p>
<ol start="0" style="list-style-type: decimal">
<li>단계0: 초기화
<ol style="list-style-type: decimal">
<li>연결법을 선정한다.</li>
<li>각 객체를 하나의 군집으로 간주한다.</li>
<li><span class="math inline">\(k \leftarrow n\)</span></li>
</ol></li>
<li>단계1: 군집
<ol style="list-style-type: decimal">
<li>현재의 군집결과에 있는 모든 군집 간의 쌍에 대하여 <span class="math inline">\(D(C_i, C_j)\)</span>를 산출하여, 이 중 최소가 되는 군집 <span class="math inline">\(i\)</span>와 <span class="math inline">\(j\)</span>를 묶어 하나의 군집으로 만든 후 군집결과를 수정한다.</li>
<li><span class="math inline">\(k \leftarrow k - 1\)</span></li>
</ol></li>
<li>단계2: <span class="math inline">\(k = 1\)</span>이면 Stop, 그렇지 않으면 단계 1을 반복한다.</li>
</ol>
<p>단계1은 객체 수 <span class="math inline">\(n\)</span>만큼 반복된다.</p>
<pre class="sourceCode r"><code class="sourceCode r">iteration &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="dt">length =</span> <span class="kw">nrow</span>(train_df))</code></pre>
<p>임의의 군집해에 대하여, 단계1을 수행하는 함수를 아래와 같이 구현해보자. 아래 함수 <code>merge_cluster</code>는 아래와 같은 두 개의 입력변수를 사용한다.</p>
<ul>
<li><code>df</code>: 객체 데이터 프레임. 열 이름이 <code>id</code>인 열은 객체번호를 나타내어, 객체간 거리 계산에 포함하지 않는다.</li>
<li><code>cluster_label</code>: 두 개의 열로 이루어진 데이터 프레임. 열 <code>id</code>는 객체번호를 나타내며, 열 <code>cluster</code>는 군집 이름을 나타낸다. 하나의 객체는 하나의 군집에만 속할 수 있으나, 하나의 군집은 여러 개의 객체를 포함할 수 있다.</li>
</ul>
<p>함수 수행 결과, 아래와 같은 세 개의 원소를 지닌 리스트를 리턴한다.</p>
<ul>
<li><code>cluster_dist</code>: 군집 간 거리를 나타낸 데이터 프레임. 평균연결법에 기반한 거리.</li>
<li><code>closest_clusters</code>: 입력된 군집해 내에서 가장 가까운 두 군집을 나타낸 데이터 프레임. 두 열 <code>item1</code>과 <code>item2</code>는 각각 군집 이름을 나타내며, <code>distance</code>는 해당 두 군집간의 거리를 나타낸다.</li>
<li><code>new_cluster_label</code>: <code>closest_clusters</code>에 포함된 두 군집을 하나로 묶어 새로운 군집을 만든 후 얻어진 군집해.</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">merge_cluster &lt;-<span class="st"> </span><span class="cf">function</span>(df, cluster_label) {
  <span class="co"># 군집간 거리 계산한다. - 유클리드 거리 및 평균연결법 기반</span>
  cluster_dist &lt;-<span class="st"> </span><span class="kw">dist</span>(<span class="kw">subset</span>(df, <span class="dt">select =</span> <span class="op">-</span>id), <span class="dt">upper =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span>broom<span class="op">::</span><span class="kw">tidy</span>() <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">inner_join</span>(
      cluster_label <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">rename</span>(
        <span class="dt">item1 =</span> id, <span class="dt">cluster1 =</span> cluster
        ),
      <span class="dt">by =</span> <span class="st">&quot;item1&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">inner_join</span>(
      cluster_label <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">rename</span>(
        <span class="dt">item2 =</span> id, <span class="dt">cluster2 =</span> cluster
        ),
      <span class="dt">by =</span> <span class="st">&quot;item2&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">filter</span>(cluster1 <span class="op">!=</span><span class="st"> </span>cluster2) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(cluster1, cluster2) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">distance =</span> <span class="kw">mean</span>(distance)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">ungroup</span>()
  
  <span class="co"># 서로 가장 가깝게 위치하는 두 군집을 찾는다.</span>
  closest_clusters &lt;-<span class="st"> </span>cluster_dist <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">arrange</span>(distance) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">slice</span>(<span class="dv">1</span>)
  
  <span class="co"># 군집해를 업데이트한다.</span>
  cluster_label[
    cluster_label<span class="op">$</span>cluster <span class="op">%in%</span><span class="st"> </span>(
      closest_clusters[, <span class="kw">c</span>(<span class="st">&quot;cluster1&quot;</span>, <span class="st">&quot;cluster2&quot;</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>()
    ),
    <span class="st">&quot;cluster&quot;</span>
  ] &lt;-<span class="st"> </span><span class="kw">paste</span>(
    closest_clusters[, <span class="kw">c</span>(<span class="st">&quot;cluster1&quot;</span>, <span class="st">&quot;cluster2&quot;</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unlist</span>(),
    <span class="dt">collapse =</span> <span class="st">&quot;,&quot;</span>
    )
  
  <span class="kw">list</span>(<span class="dt">cluster_dist =</span> cluster_dist, 
       <span class="dt">closest_clusters =</span> closest_clusters, 
       <span class="dt">new_cluster_label =</span> cluster_label)
}</code></pre>
<p>우선 단계 0에서 얻어지는 군집해에 대한 데이터를 아래와 같이 생성한다.</p>
<pre class="sourceCode r"><code class="sourceCode r">init_cluster &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">id =</span> train_df<span class="op">$</span>id,
  <span class="dt">cluster =</span> <span class="kw">as.character</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(train_df))
)

<span class="kw">print</span>(<span class="kw">unique</span>(init_cluster<span class="op">$</span>cluster))</code></pre>
<pre><code>##  [1] &quot;1&quot;  &quot;2&quot;  &quot;3&quot;  &quot;4&quot;  &quot;5&quot;  &quot;6&quot;  &quot;7&quot;  &quot;8&quot;  &quot;9&quot;  &quot;10&quot;</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">k &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(init_cluster<span class="op">$</span>cluster))

<span class="kw">print</span>(k)</code></pre>
<pre><code>## [1] 10</code></pre>
<p>위와 같이, 초기 군집해에서 군집 수는 전체 객체수와 같은 10개이다.</p>
<p>위 초기해로부터 단계1을 아래와 같이 수행해보자.</p>
<pre class="sourceCode r"><code class="sourceCode r">iteration[[<span class="dv">1</span>]] &lt;-<span class="st"> </span><span class="kw">merge_cluster</span>(train_df, init_cluster)</code></pre>
<p>찾아진 가장 가까운 두 군집은 아래와 같다.</p>
<pre class="sourceCode r"><code class="sourceCode r">iteration[[<span class="dv">1</span>]]<span class="op">$</span>closest_cluster</code></pre>
<pre><code>## # A tibble: 1 x 3
##   cluster1 cluster2 distance
##   &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;
## 1 10       9               1</code></pre>
<p>위 두 군집을 하나로 묶은 새로운 군집해는 아래와 같다.</p>
<pre class="sourceCode r"><code class="sourceCode r">iteration[[<span class="dv">1</span>]]<span class="op">$</span>new_cluster_label</code></pre>
<pre><code>## # A tibble: 10 x 2
##       id cluster
##    &lt;int&gt; &lt;chr&gt;  
##  1     1 1      
##  2     2 2      
##  3     3 3      
##  4     4 4      
##  5     5 5      
##  6     6 6      
##  7     7 7      
##  8     8 8      
##  9     9 10,9   
## 10    10 10,9</code></pre>
<p>위 새로운 군집해의 군집 수는 9이다. 이는 아직 1보다 크므로, 새로 얻어진 군집해로부터 단계 1을 반복한다.</p>
<pre class="sourceCode r"><code class="sourceCode r">iteration[[<span class="dv">2</span>]] &lt;-<span class="st"> </span><span class="kw">merge_cluster</span>(
  train_df,
  iteration[[<span class="dv">1</span>]]<span class="op">$</span>new_cluster_label
)</code></pre>
<p>이번에 찾아진 가장 가까운 두 군집은 아래와 같다.</p>
<pre class="sourceCode r"><code class="sourceCode r">iteration[[<span class="dv">2</span>]]<span class="op">$</span>closest_cluster</code></pre>
<pre><code>## # A tibble: 1 x 3
##   cluster1 cluster2 distance
##   &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;
## 1 3        7               1</code></pre>
<p>위 두 군집을 하나로 묶은 새로운 군집해는 아래와 같다.</p>
<pre class="sourceCode r"><code class="sourceCode r">iteration[[<span class="dv">2</span>]]<span class="op">$</span>new_cluster_label</code></pre>
<pre><code>## # A tibble: 10 x 2
##       id cluster
##    &lt;int&gt; &lt;chr&gt;  
##  1     1 1      
##  2     2 2      
##  3     3 3,7    
##  4     4 4      
##  5     5 5      
##  6     6 6      
##  7     7 3,7    
##  8     8 8      
##  9     9 10,9   
## 10    10 10,9</code></pre>
<p>위 군집해에 기반하여 단계 1을 다시 반복해보자.</p>
<pre class="sourceCode r"><code class="sourceCode r">iteration[[<span class="dv">3</span>]] &lt;-<span class="st"> </span><span class="kw">merge_cluster</span>(
  train_df,
  iteration[[<span class="dv">2</span>]]<span class="op">$</span>new_cluster_label
)

<span class="kw">print</span>(iteration[[<span class="dv">3</span>]]<span class="op">$</span>closest_cluster)</code></pre>
<pre><code>## # A tibble: 1 x 3
##   cluster1 cluster2 distance
##   &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;
## 1 1        6            1.41</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(iteration[[<span class="dv">3</span>]]<span class="op">$</span>new_cluster_label)</code></pre>
<pre><code>## # A tibble: 10 x 2
##       id cluster
##    &lt;int&gt; &lt;chr&gt;  
##  1     1 1,6    
##  2     2 2      
##  3     3 3,7    
##  4     4 4      
##  5     5 5      
##  6     6 1,6    
##  7     7 3,7    
##  8     8 8      
##  9     9 10,9   
## 10    10 10,9</code></pre>
<p>위와 같은 과정을 전체 객체가 하나의 군집으로 묶일 때까지 아래와 같이 반복하며 군집결과를 출력해보자.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#단계0</span>
init_cluster &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">id =</span> train_df<span class="op">$</span>id,
  <span class="dt">cluster =</span> <span class="kw">as.character</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(train_df))
)

i &lt;-<span class="st"> </span>0L
current_clusters &lt;-<span class="st"> </span><span class="kw">unique</span>(init_cluster<span class="op">$</span>cluster)
k &lt;-<span class="st"> </span><span class="kw">length</span>(current_clusters)

print_clusters &lt;-<span class="st"> </span><span class="cf">function</span>(i, k, clusters) {
  <span class="kw">cat</span>(<span class="st">&quot;Iteration: &quot;</span>, i, <span class="st">&quot;, k = &quot;</span>, k, <span class="st">&quot;, clusters = &quot;</span>, <span class="kw">paste0</span>(<span class="st">&quot;{&quot;</span>, clusters, <span class="st">&quot;}&quot;</span>), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
}

<span class="kw">print_clusters</span>(i, k, current_clusters)</code></pre>
<pre><code>## Iteration:  0 , k =  10 , clusters =  {1} {2} {3} {4} {5} {6} {7} {8} {9} {10}</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#단계1</span>
iteration &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="dt">length =</span> <span class="kw">nrow</span>(train_df) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)
<span class="cf">while</span>(k <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) {
  i &lt;-<span class="st"> </span>i <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
  <span class="cf">if</span>(i <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
    iteration[[i]] &lt;-<span class="st"> </span><span class="kw">merge_cluster</span>(
      train_df,
      init_cluster
    )
  } <span class="cf">else</span> {
    iteration[[i]] &lt;-<span class="st"> </span><span class="kw">merge_cluster</span>(
      train_df,
      iteration[[i<span class="dv">-1</span>]]<span class="op">$</span>new_cluster_label
    )
  }

  current_clusters &lt;-<span class="st"> </span><span class="kw">unique</span>(iteration[[i]]<span class="op">$</span>new_cluster_label<span class="op">$</span>cluster)
  k &lt;-<span class="st"> </span><span class="kw">length</span>(current_clusters)
  
  <span class="kw">print_clusters</span>(i, k, current_clusters)
}</code></pre>
<pre><code>## Iteration:  1 , k =  9 , clusters =  {1} {2} {3} {4} {5} {6} {7} {8} {10,9} 
## Iteration:  2 , k =  8 , clusters =  {1} {2} {3,7} {4} {5} {6} {8} {10,9} 
## Iteration:  3 , k =  7 , clusters =  {1,6} {2} {3,7} {4} {5} {8} {10,9} 
## Iteration:  4 , k =  6 , clusters =  {1,6} {2} {3,7,5} {4} {8} {10,9} 
## Iteration:  5 , k =  5 , clusters =  {1,6,2} {3,7,5} {4} {8} {10,9} 
## Iteration:  6 , k =  4 , clusters =  {1,6,2} {3,7,5} {4} {10,9,8} 
## Iteration:  7 , k =  3 , clusters =  {1,6,2} {3,7,5,4} {10,9,8} 
## Iteration:  8 , k =  2 , clusters =  {1,6,2,3,7,5,4} {10,9,8} 
## Iteration:  9 , k =  1 , clusters =  {1,6,2,3,7,5,4,10,9,8}</code></pre>
</div>
<div id="hclust" class="section level3">
<h3><span class="header-section-number">10.3.3</span> R 패키지 내 연결법</h3>
<p>R에서는 <code>stats</code> 패키지의 <code>hclust</code> 함수를 이용하여 군집해를 구할 수 있다.</p>
<p>우선, 객체간 거리 행렬을 함수 <code>dist</code>를 이용하여 구한다. 아래는 유클리드 거리를 구하는 예이며, 상황에 따라 다른 거리 척도를 이용할 수도 있다.</p>
<pre class="sourceCode r"><code class="sourceCode r">distance_matrix &lt;-<span class="st"> </span><span class="kw">dist</span>(train_df[, <span class="dv">-1</span>])</code></pre>
<p>객체간 거리를 구한 후, 함수 <code>hclust</code>를 이용하여 군집분석을 수행한다. 기본설정은 완전연결법이며, 파라미터 <code>method</code>의 값을 설정함으로써 단일연결법, 평균연결법, 중심연결법을 수행할 수 있다.</p>
<pre class="sourceCode r"><code class="sourceCode r">cluster_solution &lt;-<span class="st"> </span><span class="kw">hclust</span>(distance_matrix, <span class="dt">method =</span> <span class="st">&quot;average&quot;</span>)</code></pre>
<p>결과 객체 <code>cluster_solution</code>는 아래와 같은 컴포넌트(components)를 지닌 리스트(list) 객체이다.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">names</span>(cluster_solution)</code></pre>
<pre><code>## [1] &quot;merge&quot;       &quot;height&quot;      &quot;order&quot;       &quot;labels&quot;      &quot;method&quot;     
## [6] &quot;call&quot;        &quot;dist.method&quot;</code></pre>
<p>이 중, <code>merge</code>는 2개의 열과 <span class="math inline">\(n - 1\)</span>개의 행으로 이루어진 행렬로, 연결법 알고리즘의 단계1 iteration에서 묶어지는 두 군집을 기록한 것이다.</p>
<pre class="sourceCode r"><code class="sourceCode r">cluster_solution<span class="op">$</span>merge</code></pre>
<pre><code>##       [,1] [,2]
##  [1,]   -3   -7
##  [2,]   -9  -10
##  [3,]   -1   -6
##  [4,]   -5    1
##  [5,]   -2    3
##  [6,]   -8    2
##  [7,]   -4    4
##  [8,]    5    7
##  [9,]    6    8</code></pre>
<p>위에서 각 행은 iteration을 나타내며, 두 열은 묶어지는 두 군집을 나타낸다. 값이 0보다 작은 경우에는 번호가 원 객체 번호를 나타내며, 값이 0보다 큰 경우에는 해당 번호의 iteration에서 묶어진 군집을 나타낸다. 예를 들어, 위 결과의 6번째 행 (-8, 2) 은 객체 8과 두 번째 iteration에서 얻어진 군집 (객체 9와 10이 묶여진 군집)이 묶여 하나의 군집(객체 8, 9, 10)을 이루게 됨을 나타낸다.</p>
<p><code>height</code>는 각 iteration에서 묶이는 두 군집간의 거리를 나타내며, 위 Figure <a href="hierarchical-clustering.html#fig:pc-user-average-linkage">10.2</a>의 덴드로그램에서 세로선의 높이를 나타낸다. Iteration이 증가함에 따라 묶이는 두 군집간의 거리도 증가한다. 일반적으로 이 거리값이 크게 증가하는 iteration에서 두 군집을 묶지 않고 최종 군집해를 도출한다.</p>
<pre class="sourceCode r"><code class="sourceCode r">cluster_solution<span class="op">$</span>height</code></pre>
<pre><code>## [1]  1.000000  1.000000  1.414214  1.825141  2.236068  2.532248  3.519028
## [8]  9.635217 10.881878</code></pre>
<p>위 결과의 경우 iteration 8에서 거리값이 크게 증가한다. 이는 위 Figure <a href="hierarchical-clustering.html#fig:pc-user-average-linkage">10.2</a>의 덴드로그램에서 3개의 군집에서 2개의 군집으로 묶이는 과정에서 세로선의 높이가 현격히 증가하는 지점이다. 따라서, iteration 7에서 얻어진 3개의 군집이 적절한 군집해라 판단할 수 있겠다.</p>
</div>
</div>
<div id="ward-method" class="section level2">
<h2><span class="header-section-number">10.4</span> 워드 방법</h2>
<p>워드방법(Ward’s method) 역시 각 객체를 하나의 군집으로 간주함을 시작으로 군집들을 묶어 단계적으로 그 수를 하나가 돌 때까지 줄여나가는 것인데, 군집의 제곱합을 활용한다.</p>
<div id="ward-method-basic-script" class="section level3">
<h3><span class="header-section-number">10.4.1</span> 기본 R 스크립트</h3>
<p>아래 Table <a href="hierarchical-clustering.html#tab:driver-data">10.3</a>는 8명의 운전자에 대한 운전경력과 교통위반 횟수를 나타낸 것이다.</p>
<pre class="sourceCode r"><code class="sourceCode r">train_df &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">id =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">8</span>),
  <span class="dt">x1 =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">20</span>, <span class="dv">3</span>, <span class="dv">19</span>, <span class="dv">17</span>, <span class="dv">8</span>, <span class="dv">19</span>, <span class="dv">18</span>),
  <span class="dt">x2 =</span> <span class="kw">c</span>(<span class="dv">15</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">4</span>, <span class="dv">17</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">6</span>)
)

knitr<span class="op">::</span><span class="kw">kable</span>(train_df, <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
             <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),
             <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;객체번호&#39;</span>, <span class="st">&#39;운전경력($x_1$)&#39;</span>, <span class="st">&#39;위반횟수($x_2$)&#39;</span>),
             <span class="dt">caption =</span> <span class="st">&#39;운전경력에 따른 교통위반 횟수&#39;</span>)</code></pre>
<table>
<caption><span id="tab:driver-data">Table 10.3: </span>운전경력에 따른 교통위반 횟수</caption>
<thead>
<tr class="header">
<th align="center">객체번호</th>
<th align="center">운전경력(<span class="math inline">\(x_1\)</span>)</th>
<th align="center">위반횟수(<span class="math inline">\(x_2\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">4</td>
<td align="center">15</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">20</td>
<td align="center">13</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">3</td>
<td align="center">13</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">19</td>
<td align="center">4</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">17</td>
<td align="center">17</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">8</td>
<td align="center">11</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">19</td>
<td align="center">12</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">18</td>
<td align="center">6</td>
</tr>
</tbody>
</table>
<p>앞 절의 연결법에서 사용했던 <code>hclust</code> 함수를 이용하여 워드 방법에 의한 군집해도 구할 수 있으며, 이 때 파라미터 <code>method</code>의 값으로 “ward.D2”를 사용한다.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dist</span>(train_df[, <span class="dv">-1</span>]) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">hclust</span>(<span class="dt">method =</span> <span class="st">&quot;ward.D2&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">plot</span>(
    <span class="dt">main =</span> <span class="ot">NULL</span>,
    <span class="dt">xlab =</span> <span class="st">&quot;observation&quot;</span>
  )</code></pre>
<div class="figure" style="text-align: center"><span id="fig:ward-dendrogram"></span>
<img src="data-mining-book_files/figure-html/ward-dendrogram-1.png" alt="운전자 데이터에 대한 워드 방법 덴드로그램" width="672" />
<p class="caption">
Figure 10.3: 운전자 데이터에 대한 워드 방법 덴드로그램
</p>
</div>
</div>
<div id="ward-method-algorithm" class="section level3">
<h3><span class="header-section-number">10.4.2</span> 워드 군집 알고리즘</h3>
<p>군집결과가 <span class="math inline">\(\mathbf{C} = \{ C_1, C_2, \cdots, C_k \}\)</span>일 때, 군집 <span class="math inline">\(C_i\)</span> 내의 제곱합(within sum of squares)은 다음과 같이 산출된다.</p>
<p><span class="math display">\[\begin{equation*}
SS(C_i) = \sum_{u \in C_i} \left(\mathbf{x}_u - \mathbf{c}_i\right)^\top\left(\mathbf{x}_u - \mathbf{c}_i\right)
\end{equation*}\]</span></p>
<p>이 때, 전체 군집 내 제곱합을 <span class="math inline">\(SSW\)</span>라 할 때, 이는 다음과 같다.</p>
<p><span class="math display">\[\begin{equation*}
SSW = \sum_{i = 1}^{k} SS(C_i)
\end{equation*}\]</span></p>
<p>다음으로, 현 군집의 각 쌍을 묶는다고 할 때의 새로운 <span class="math inline">\(SSW\)</span>를 산출한 후, 이 값이 가장 작게 되는 군집 쌍을 묶는다.</p>
<ol style="list-style-type: decimal">
<li>단계0
<ol style="list-style-type: decimal">
<li>각 객체를 하나의 군집으로 간주한다.</li>
<li><span class="math inline">\(k \leftarrow n\)</span></li>
</ol></li>
<li>단계1
<ol style="list-style-type: decimal">
<li>현재의 군집 결과에 있는 모든 군집간의 쌍에 대하여 묶을 경우 전체제곱합(SSW)을 산출하고, 이 중 최소가 되는 군집 <span class="math inline">\(i\)</span>와 군집 <span class="math inline">\(j\)</span>를 묶어 하나의 군집으로 만든 후, 군집 결과를 수정한다.</li>
<li><span class="math inline">\(k \leftarrow k - 1\)</span></li>
</ol></li>
<li>단계2: <span class="math inline">\(k = 1\)</span>이면 Stop, 그렇지 않으면 단계1을 반복한다.</li>
</ol>
<p>워드 군집 알고리즘을 R script로 구현해보자. 우선, 객체 데이터 <span class="math inline">\(SSW\)</span>를 계산하는 사용자 정의 함수 <code>calculate_ssw</code>를 아래와 같이 두 입력변수 <code>df</code> 및 <code>cluster_label</code>를 이용하여 구현하자.</p>
<ul>
<li><code>df</code>: 객체 데이터 프레임. 열 이름이 <code>id</code>인 열은 객체번호를 나타내어, 객체간 거리 계산에 포함하지 않는다.</li>
<li><code>cluster_label</code>: 두 개의 열로 이루어진 데이터 프레임. 열 <code>id</code>는 객체번호를 나타내며, 열 <code>cluster</code>는 군집 이름을 나타낸다. 하나의 객체는 하나의 군집에만 속할 수 있으나, 하나의 군집은 여러 개의 객체를 포함할 수 있다.</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># SSW 계산</span>
calculate_ssw &lt;-<span class="st"> </span><span class="cf">function</span>(df, cluster_label) {
  df <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">inner_join</span>(cluster_label, <span class="dt">by =</span> <span class="st">&quot;id&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(cluster) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">select</span>(<span class="op">-</span>id) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">summarize_all</span>(<span class="cf">function</span>(x) <span class="kw">sum</span>((x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x))<span class="op">^</span><span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">ss =</span> <span class="kw">rowSums</span>(<span class="kw">subset</span>(., <span class="dt">select =</span> <span class="op">-</span>cluster))) <span class="op">%&gt;%</span>
<span class="st">    `</span><span class="dt">[[</span><span class="st">`</span>(<span class="st">&quot;ss&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">sum</span>()
}</code></pre>
<p>워드 군집 알고리즘은 현재 군집해 내의 모든 군집쌍에 대하여 두 군집을 하나의 군집으로 묶을 경우의 <span class="math inline">\(SSW\)</span>를 계산해야 한다. 따라서, 우선 고려할 모든 군집해를 생성하는 사용자 정의 함수 <code>generate_clusters</code>를 아래와 같이 구현한다.</p>
<p>아래 사용자 정의 함수 <code>generate_clusters</code>는 임의의 군집해 <code>cluster_label</code>을 입력변수로 사용하며, 해당 입력변수에 대한 설명은 위 함수 <code>calculate_ssw</code>에서와 같다. 함수 수행 결과, 가능한 각각의 군집쌍 결합의 결과물인 군집해 데이터 프레임을 리스트(list) 형태로 출력한다.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 임의의 군집해로부터 가능한 다음단계 군집해 생성</span>
generate_clusters &lt;-<span class="st"> </span><span class="cf">function</span>(cluster_label) {
  unique_clusters &lt;-<span class="st"> </span><span class="kw">unique</span>(cluster_label<span class="op">$</span>cluster)
  
  potential_pairs &lt;-<span class="st"> </span><span class="kw">crossing</span>(<span class="dt">cluster1 =</span> unique_clusters, 
           <span class="dt">cluster2 =</span> unique_clusters) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">filter</span>(cluster1 <span class="op">&lt;</span><span class="st"> </span>cluster2) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">mutate</span>(<span class="dt">cluster =</span> <span class="kw">paste</span>(cluster1, cluster2, <span class="dt">sep =</span> <span class="st">&quot;,&quot;</span>))
  
  candidate_solutions &lt;-<span class="st"> </span>potential_pairs <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">rowwise</span>() <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">do</span>(<span class="dt">candidate_solution =</span> <span class="kw">merge_cluster</span>(cluster_label, .)) <span class="op">%&gt;%</span>
<span class="st">    `</span><span class="dt">[[</span><span class="st">`</span>(<span class="st">&quot;candidate_solution&quot;</span>)
  
  candidate_solutions
}</code></pre>
<p>위에서 보이는 바와 같이, 함수 <code>generate_clusters</code>는 또 다른 사용자 정의함수 <code>merge_cluster</code>를 호출한다. 이 함수는 두 입력변수 <code>cluster_label</code> 및 <code>cluster_merge</code>를 사용하는데, <code>cluster_label</code>에 대한 설명은 위 다른 사용자 정의 함수에서와 동일하며, <code>cluster_merge</code>에 대한 설명은 아래와 같다.</p>
<ul>
<li><code>cluster_merge</code>: 3차원 character 벡터. 첫 두 element는 현재 <code>cluster_label</code>에 존재하는 군집 중 하나의 군집으로 묶일 두 군집의 이름을 나타내며, 세 번째 element는 그 결과 나타나는 군집 이름을 나타낸다.</li>
</ul>
<p>함수 수행 결과, 입력된 <code>cluster_label</code>에서 군집이름이 <code>cluster_merge[1]</code> 혹은 <code>cluster_merge[2]</code>에 해당하는 객체들은, 출력된 군집해에서는 군집이름 <code>cluster_merge[3]</code>을 지닌다.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 임의의 군집 결합 규칙 cluster_merge에 따른 군집해</span>
merge_cluster &lt;-<span class="st"> </span><span class="cf">function</span>(cluster_label, cluster_merge) {
  idx &lt;-<span class="st"> </span>cluster_label<span class="op">$</span>cluster <span class="op">%in%</span><span class="st"> </span>cluster_merge[<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>]
  cluster_label[idx, <span class="st">&quot;cluster&quot;</span>] &lt;-<span class="st"> </span>cluster_merge[<span class="dv">3</span>]
  cluster_label
}</code></pre>
<p>마지막으로, 현재 군집해로부터 가장 최적의 다음단계 군집해를 얻는 사용자 함수 <code>best_merge_cluster</code>를 아래와 같이 구현해보자.</p>
<ol style="list-style-type: decimal">
<li><code>generate_clusters</code>를 실행하여 다음 단계에 가능한 모든 군집해를 구한다.</li>
<li>1의 각 군집해에 함수 <code>calculate_ssw</code>를 적용하여 <span class="math inline">\(SSW\)</span>값을 구한다.</li>
<li><span class="math inline">\(SSW\)</span>값이 최소인 군집해를 최적 군집해로 선정한다.</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 최적 군집 결합</span>
best_merge_cluster &lt;-<span class="st"> </span><span class="cf">function</span>(df, cluster_label) {
  candidate_solutions &lt;-<span class="st"> </span><span class="kw">generate_clusters</span>(cluster_label)
  ssw &lt;-<span class="st"> </span><span class="kw">sapply</span>(candidate_solutions, <span class="cf">function</span>(x) <span class="kw">calculate_ssw</span>(df, x))
  <span class="kw">list</span>(
    <span class="dt">new_cluster_label =</span> candidate_solutions[[<span class="kw">which.min</span>(ssw)]],
    <span class="dt">new_ssw =</span> <span class="kw">min</span>(ssw)
  )
}</code></pre>
<p>위 사용자 함수들을 이용하여 Table <a href="hierarchical-clustering.html#tab:driver-data">10.3</a>에 대한 워드 군집 분석을 수행해보자.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#단계0</span>
init_cluster &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">id =</span> train_df<span class="op">$</span>id,
  <span class="dt">cluster =</span> <span class="kw">as.character</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(train_df))
)
i &lt;-<span class="st"> </span>0L
current_clusters &lt;-<span class="st"> </span><span class="kw">unique</span>(init_cluster<span class="op">$</span>cluster)
k &lt;-<span class="st"> </span><span class="kw">length</span>(current_clusters)
ssw &lt;-<span class="st"> </span><span class="kw">calculate_ssw</span>(train_df, init_cluster)

print_clusters &lt;-<span class="st"> </span><span class="cf">function</span>(i, k, clusters, ssw) {
  <span class="kw">cat</span>(<span class="st">&quot;Iteration: &quot;</span>, i, <span class="st">&quot;, k = &quot;</span>, k, <span class="st">&quot;, clusters = &quot;</span>, <span class="kw">paste0</span>(<span class="st">&quot;{&quot;</span>, clusters, <span class="st">&quot;}&quot;</span>), <span class="st">&quot;, SSW =&quot;</span>, ssw, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
}

<span class="kw">print_clusters</span>(i, k, current_clusters, ssw)</code></pre>
<pre><code>## Iteration:  0 , k =  8 , clusters =  {1} {2} {3} {4} {5} {6} {7} {8} , SSW = 0</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co">#단계1</span>
iteration &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="dt">length =</span> <span class="kw">nrow</span>(train_df) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)
<span class="cf">while</span>(k <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) {
  i &lt;-<span class="st"> </span>i <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
  <span class="cf">if</span>(i <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
    iteration[[i]] &lt;-<span class="st"> </span><span class="kw">best_merge_cluster</span>(
      train_df,
      init_cluster
    )
  } <span class="cf">else</span> {
    iteration[[i]] &lt;-<span class="st"> </span><span class="kw">best_merge_cluster</span>(
      train_df,
      iteration[[i<span class="dv">-1</span>]]<span class="op">$</span>new_cluster_label
    )
  }

  current_clusters &lt;-<span class="st"> </span><span class="kw">unique</span>(iteration[[i]]<span class="op">$</span>new_cluster_label<span class="op">$</span>cluster)
  k &lt;-<span class="st"> </span><span class="kw">length</span>(current_clusters)
  ssw &lt;-<span class="st"> </span>iteration[[i]]<span class="op">$</span>new_ssw
  
  <span class="kw">print_clusters</span>(i, k, current_clusters, ssw)
}</code></pre>
<pre><code>## Iteration:  1 , k =  7 , clusters =  {1} {2,7} {3} {4} {5} {6} {8} , SSW = 1 
## Iteration:  2 , k =  6 , clusters =  {1,3} {2,7} {4} {5} {6} {8} , SSW = 3.5 
## Iteration:  3 , k =  5 , clusters =  {1,3} {2,7} {4,8} {5} {6} , SSW = 6 
## Iteration:  4 , k =  4 , clusters =  {1,3} {2,7,5} {4,8} {6} , SSW = 23.66667 
## Iteration:  5 , k =  3 , clusters =  {1,3,6} {2,7,5} {4,8} , SSW = 43.16667 
## Iteration:  6 , k =  2 , clusters =  {1,3,6} {2,7,5,4,8} , SSW = 140.4 
## Iteration:  7 , k =  1 , clusters =  {1,3,6,2,7,5,4,8} , SSW = 499.875</code></pre>
</div>
<div id="ward-rpackages" class="section level3">
<h3><span class="header-section-number">10.4.3</span> R 패키지 내 워드 방법</h3>
<p>R 패키지로 구현된 워드 군집은 위에서 구현한 <span class="math inline">\(SSW\)</span>와는 다소 다른 metric을 이용하여 군집해를 구한다. 따라서, 우선 워드 방법이 제안된 논문들을 살펴볼 필요가 있다.</p>
<p>우선 원 논문 <span class="citation">Ward Jr (<a href="#ref-ward1963hierarchical">1963</a>)</span> 는 <span class="math inline">\(ESS\)</span>(error sum of squares)를 아래와 같이 정의하였으며, 이는 위에서 사용한 <span class="math inline">\(SSW\)</span>와 일치한다.</p>
<p><span class="math display">\[\begin{equation*}
\begin{split}
ESS(\{C_1, \cdots, C_k \}) &amp;= \sum_{i = 1}^{k} ESS(C_i)\\
&amp;= \sum_{i = 1}^{k} \sum_{u \in C_i} \mathbf{x}_u^\top \mathbf{x}_u - |C_i| \mathbf{c}_i^\top \mathbf{c}_i\\
&amp;= SSW
\end{split}
\end{equation*}\]</span></p>
<p>위 식에서 임의의 두 군집 <span class="math inline">\(C_i\)</span>, <span class="math inline">\(C_j\)</span>를 하나의 군집으로 묶을 때 <span class="math inline">\(SSW\)</span>의 변화는 아래와 같다. <span class="math inline">\(C_i\)</span>와 <span class="math inline">\(C_j\)</span> 외의 군집은 <span class="math inline">\(SSW\)</span>의 변화에 영향을 미치지 않으므로, <span class="math inline">\(SSW\)</span> 변화량은 아래와 같이 군집 <span class="math inline">\(C_i\)</span>와 <span class="math inline">\(C_j\)</span>에 속하는 객체만을 이용하여 구할 수 있으며, 결과적으로 <span class="math inline">\(C_i\)</span>와 <span class="math inline">\(C_j\)</span>의 군집 크기 <span class="math inline">\(|C_i|\)</span>와 <span class="math inline">\(|C_j|\)</span>및 군집 중심벡터 <span class="math inline">\(\mathbf{c}_i\)</span>와 <span class="math inline">\(\mathbf{c}_j\)</span>를 이용하여 구할 수 있다.</p>
<p><span class="math display" id="eq:ward-minimand">\[\begin{equation}
\begin{split}
\Delta SSW =&amp; ESS(C_i \cup C_j) - ESS(C_i) - ESS(C_j)\\
=&amp; \sum_{u \in C_i \cup C_j} \mathbf{x}_u^\top \mathbf{x}_u - (|C_i| + |C_j|)\left[\frac{|C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j}{|C_i| + |C_j|}\right]^\top \left[\frac{|C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j}{|C_i| + |C_j|}\right]\\
&amp; - \left( \sum_{u \in C_i} \mathbf{x}_u^\top \mathbf{x}_u - |C_i| \mathbf{c}_i^\top \mathbf{c}_i \right) - \left( \sum_{u \in C_j} \mathbf{x}_u^\top \mathbf{x}_u - |C_j| \mathbf{c}_j^\top \mathbf{c}_j \right)\\
=&amp; -\frac{1}{|C_i| + |C_j|} \left( |C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j \right)^\top \left( |C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j \right) + |C_i| \mathbf{c}_i^\top \mathbf{c}_i + |C_j| \mathbf{c}_j^\top \mathbf{c}_j\\
=&amp; \frac{|C_i||C_j|}{|C_i| + |C_j|} \left(\mathbf{c}_i - \mathbf{c}_j\right)^\top \left(\mathbf{c}_i - \mathbf{c}_j\right)
\end{split}
\tag{10.1}
\end{equation}\]</span></p>
<p>따라서 워드 방법은 각 iteration에서 식 <a href="hierarchical-clustering.html#eq:ward-minimand">(10.1)</a>를 최소화하는 두 군집 <span class="math inline">\(C_i\)</span>, <span class="math inline">\(C_j\)</span>를 선택하여 두 군집을 하나로 묶는 방법이다.</p>
<p>한편, <span class="math inline">\(SS(C_i)\)</span>는 아래와 같이 군집 <span class="math inline">\(C_i\)</span>내 객체들 간의 제곱 유클리드 거리로 나타낼 수 있다.</p>
<p><span class="math display" id="eq:squared-euclidean-within-cluster">\[\begin{equation}
\begin{split}
D^2(C_i) =&amp; \sum_{u, v \in C_i} (\mathbf{x}_u - \mathbf{x}_v)^\top (\mathbf{x}_u - \mathbf{x}_v)\\
=&amp; \sum_{u, v \in C_i} \left((\mathbf{x}_u - \mathbf{c}_i) - (\mathbf{x}_v - \mathbf{c}_i)\right)^\top \left((\mathbf{x}_u - \mathbf{c}_i) - (\mathbf{x}_v - \mathbf{c}_i)\right)\\
=&amp; 2 \sum_{u \in C_i} (\mathbf{x}_u - \mathbf{c}_i)^\top (\mathbf{x}_u - \mathbf{c}_i) - 2 \sum_{u, v \in C_i} (\mathbf{x}_u - \mathbf{c}_i)^\top (\mathbf{x}_v - \mathbf{c}_i)\\
=&amp; 2 \sum_{u \in C_i} (\mathbf{x}_u - \mathbf{c}_i)^\top (\mathbf{x}_u - \mathbf{c}_i)\\
=&amp; 2 SS(C_i)
\end{split}
\tag{10.2}
\end{equation}\]</span></p>
<p>위 식 <a href="hierarchical-clustering.html#eq:squared-euclidean-within-cluster">(10.2)</a>을 달리 표현하면, 객체간의 제곱 유클리드 거리를 표현한 행렬에서 군집 <span class="math inline">\(i\)</span>에 속한 객체들에 해당하는 부분행렬(submatrix)를 뽑아 행렬의 원소값을 모두 더하면, 그 값이 <span class="math inline">\(2 SS(C_i)\)</span>와 같다. 이를 통해 각 군집의 중심벡터를 계산하지 않고도 각 iteration에서 SSW를 최소화하는 군집 결합을 찾을 수 있다.</p>
<p>R 패키지 <code>stats</code> 내의 <code>hclust</code> 함수는 워드 방법으로 <code>method</code> 파라미터의 값을 “ward.D” 혹은 “ward.D2”로 설정할 수 있다. 이 두 방법의 차이는 입력 거리행렬을 제곱 유클리드 거리로 사용하는지 일반 유클리드 거리로 사용하는지의 차이로, 아래에서 R 스크립트 예제와 함께 설명하기로 한다.</p>
<p>우선 <code>method</code>값을 “ward.D2”로 설정하는 경우, <code>dist</code> 함수의 결과를 입력 거리행렬로 그대로 사용하면 된다.</p>
<pre class="sourceCode r"><code class="sourceCode r">res_ward.D2 &lt;-<span class="st"> </span><span class="kw">dist</span>(train_df[, <span class="dv">-1</span>]) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">hclust</span>(<span class="dt">method =</span> <span class="st">&quot;ward.D2&quot;</span>)</code></pre>
<p>이 때, 결과 데이터 <code>res_ward.D2</code>에서 워드 방법의 criterion을 나타내는 <code>height</code> 원소(component)가 표현하는 값은 위에서 계산하였던 <span class="math inline">\(SSW\)</span>와 다르다.</p>
<pre class="sourceCode r"><code class="sourceCode r">res_ward.D2<span class="op">$</span>height</code></pre>
<pre><code>## [1]  1.414214  2.236068  2.236068  5.944185  6.244998 13.945131 26.813243</code></pre>
<p>이는 <code>height</code>에서 표현하는 값은 전체 <span class="math inline">\(SSW\)</span>가 아니라, 두 군집 <span class="math inline">\(i\)</span>와 <span class="math inline">\(j\)</span>를 하나로 묶을 때 추가로 증가하는 <span class="math inline">\(SSW\)</span> 수치의 변환으로, 아래와 같이 계산되기 때문이다.</p>
<p><span class="math display" id="eq:hclust-height">\[\begin{equation}
height = \sqrt{D^2(C_i \cup C_j) - \left(D^2(C_i) + D^2(C_j)\right)}
\tag{10.3}
\end{equation}\]</span></p>
<p>따라서, 군집 <span class="math inline">\(i\)</span>와 <span class="math inline">\(j\)</span>를 하나로 묶을 때 증가하는 <span class="math inline">\(SSW\)</span>의 수치 <span class="math inline">\(\Delta SSW\)</span>는 아래와 같이 표현된다.</p>
<p><span class="math display">\[\begin{equation}
\Delta SSW = \frac{1}{2} height^2
\end{equation}\]</span></p>
<p>각 iteration에서 발생하는 <span class="math inline">\(\Delta SSW\)</span>의 누적합이 위 <a href="hierarchical-clustering.html#ward-method-algorithm">10.4.2</a>절에서 보였던 <span class="math inline">\(SSW\)</span> 결과와 동일함을 아래와 같이 확인해보자.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tibble</span>(
  <span class="dt">iteration =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span>(<span class="kw">nrow</span>(train_df) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)),
  <span class="dt">height =</span> res_ward.D2<span class="op">$</span>height
) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">delta_ssw =</span> height <span class="op">^</span><span class="st"> </span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span>
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">ssw =</span> <span class="kw">cumsum</span>(delta_ssw)
  ) <span class="op">%&gt;%</span>
<span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>(
    <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
    <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),
    <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;iteration&#39;</span>, <span class="st">&#39;$height$&#39;</span>, <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">Delta SSW = </span><span class="ch">\\</span><span class="st">frac{1}{2} height ^ 2$&#39;</span>, <span class="st">&#39;$SSW = </span><span class="ch">\\</span><span class="st">sum </span><span class="ch">\\</span><span class="st">Delta SSW$&#39;</span>),
    <span class="dt">caption =</span> <span class="st">&#39;hclust 함수 ward.D2 방법의 height와 SSW 관계&#39;</span>
  )</code></pre>
<table>
<caption><span id="tab:ward-D2-height-ssw">Table 10.4: </span>hclust 함수 ward.D2 방법의 height와 SSW 관계</caption>
<thead>
<tr class="header">
<th align="right">iteration</th>
<th align="right"><span class="math inline">\(height\)</span></th>
<th align="right"><span class="math inline">\(\Delta SSW = \frac{1}{2} height ^ 2\)</span></th>
<th align="right"><span class="math inline">\(SSW = \sum \Delta SSW\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">1.414214</td>
<td align="right">1.00000</td>
<td align="right">1.00000</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">2.236068</td>
<td align="right">2.50000</td>
<td align="right">3.50000</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">2.236068</td>
<td align="right">2.50000</td>
<td align="right">6.00000</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">5.944185</td>
<td align="right">17.66667</td>
<td align="right">23.66667</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">6.244998</td>
<td align="right">19.50000</td>
<td align="right">43.16667</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">13.945131</td>
<td align="right">97.23333</td>
<td align="right">140.40000</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">26.813243</td>
<td align="right">359.47500</td>
<td align="right">499.87500</td>
</tr>
</tbody>
</table>
<p>우선 <code>method</code>값을 “ward.D”로 설정하는 경우, <code>dist</code> 함수의 결과를 입력 거리행렬로 그대로 사용하면 아래와 같이 위 “ward.D2”와는 다른 <code>height</code>값을 출력하며, 이는 워드 방법의 criterion을 정확히 반영하지 못한다.</p>
<pre class="sourceCode r"><code class="sourceCode r">res_ward.D &lt;-<span class="st"> </span><span class="kw">dist</span>(train_df[, <span class="dv">-1</span>]) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">hclust</span>(<span class="dt">method =</span> <span class="st">&quot;ward.D&quot;</span>)

res_ward.D<span class="op">$</span>height</code></pre>
<pre><code>## [1]  1.414214  2.236068  2.236068  6.452039  6.615990 17.358484 39.311447</code></pre>
<p>이는 “ward.D2”는 워드 방법 수행 전 입력된 유클리드 거리행렬을 내부적으로 제곱하는 반면, “ward.D” 방법은 제곱 유클리드 거리행렬이 입력되는 것을 가정하기 때문이다.</p>
<p><span class="citation">Lance and Williams (<a href="#ref-lance1967general">1967</a>)</span> 은 군집 <span class="math inline">\(i\)</span>와 <span class="math inline">\(j\)</span>를 하나로 묶을 때, 새로 생성된 군집과 다른 군집들간의 거리는 원 두 군집들과 다른 군집들간의 거리로 아래와 같이 표현됨을 보였다. 이를 Lance-Williams update 공식이라 한다.</p>
<p><span class="math display" id="eq:lance-williams-update">\[\begin{equation}
D(C_i \cup C_j, C_{h \notin \{i, j\}}) = \alpha_i D(C_i, C_h) + \alpha_j D(C_j, C_h) + \beta D(C_i, C_j) + \gamma |D(C_i, C_h) - D(C_j, C_h)|
\tag{10.4}
\end{equation}\]</span></p>
<p>이후 <span class="citation">Wishart (<a href="#ref-wishart1969256">1969</a>)</span> 에서 워드 방법을 위 Lance-Williams update 공식으로 표현하였다.</p>
<p><span class="math display" id="eq:wishart">\[\begin{equation}
\begin{split}
\alpha_i =&amp; \frac{|C_i| + |C_h|}{|C_i| + |C_j| + |C_h|}\\
\alpha_j =&amp; \frac{|C_j| + |C_h|}{|C_i| + |C_j| + |C_h|}\\
\beta =&amp; - \frac{|C_h|}{|C_i| + |C_j| + |C_h|}\\
\gamma =&amp; 0
\end{split}
\tag{10.5}
\end{equation}\]</span></p>
<p>이 때, 식 <a href="hierarchical-clustering.html#eq:wishart">(10.5)</a>가 기반한 식 <a href="hierarchical-clustering.html#eq:lance-williams-update">(10.4)</a>에서의 거리함수 <span class="math inline">\(D\)</span>는 제곱 유클리드 거리를 사용한다.</p>
<p>“ward.D” 방법은 제곱 유클리드 거리의 입력을 가정하며, 위의 경우와 같이 제곱 유클리드 거리가 아닌 일반 유클리드 거리행렬을 입력하였을 때, 오류 메시지를 출력하는 대신, 입력된 거리행렬이 제곱 유클리드 거리를 나타낸다 가정하고 Lance-Williams update를 수행한다. 따라서, 이 경우 <code>height</code>는 워드 방법의 criterion을 정확히 표현하지 못한다.</p>
<p>제곱 유클리드 거리를 “ward.D” 방법의 입력 거리행렬로 설정하고, 구해진 <code>height</code>를 출력해보자</p>
<pre class="sourceCode r"><code class="sourceCode r">res_ward.D &lt;-<span class="st"> </span><span class="kw">dist</span>(train_df[, <span class="dv">-1</span>])<span class="op">^</span><span class="dv">2</span> <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">hclust</span>(<span class="dt">method =</span> <span class="st">&quot;ward.D&quot;</span>)

res_ward.D<span class="op">$</span>height</code></pre>
<pre><code>## [1]   2.00000   5.00000   5.00000  35.33333  39.00000 194.46667 718.95000</code></pre>
<p>위 <code>height</code>값은 “ward.D2” 방법에서 출력된 값보다 크다. 위 값의 제곱근(square root)를 구하면 “ward.D2”에서의 <code>height</code>값과 동일한 값을 얻을 수 있다.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sqrt</span>(res_ward.D<span class="op">$</span>height)</code></pre>
<pre><code>## [1]  1.414214  2.236068  2.236068  5.944185  6.244998 13.945131 26.813243</code></pre>
<p>제곱 유클리드 거리행렬을 입력한 “ward.D” 방법의 결과로 출력된 criterion <code>height</code>는 <span class="math inline">\(2 \Delta SSW\)</span>의 값에 해당하는 수치이며, 각 iteration 당 <span class="math inline">\(\sum_i D(C_i)\)</span>의 값의 변화량이라고 볼 수 있다. (식 <a href="hierarchical-clustering.html#eq:squared-euclidean-within-cluster">(10.2)</a> 참조)</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">tibble</span>(
  <span class="dt">iteration =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span>(<span class="kw">nrow</span>(train_df) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)),
  <span class="dt">height =</span> res_ward.D<span class="op">$</span>height
) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">delta_ssw =</span> height <span class="op">/</span><span class="st"> </span><span class="dv">2</span>
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">ssw =</span> <span class="kw">cumsum</span>(delta_ssw)
  ) <span class="op">%&gt;%</span>
<span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>(
    <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
    <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),
    <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;iteration&#39;</span>, <span class="st">&#39;$height$&#39;</span>, <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">Delta SSW = </span><span class="ch">\\</span><span class="st">frac{1}{2} height$&#39;</span>, <span class="st">&#39;$SSW = </span><span class="ch">\\</span><span class="st">sum </span><span class="ch">\\</span><span class="st">Delta SSW$&#39;</span>),
    <span class="dt">caption =</span> <span class="st">&#39;hclust 함수 ward.D 방법의 height와 SSW 관계&#39;</span>
  )</code></pre>
<table>
<caption><span id="tab:ward-D-height-ssw">Table 10.5: </span>hclust 함수 ward.D 방법의 height와 SSW 관계</caption>
<thead>
<tr class="header">
<th align="right">iteration</th>
<th align="right"><span class="math inline">\(height\)</span></th>
<th align="right"><span class="math inline">\(\Delta SSW = \frac{1}{2} height\)</span></th>
<th align="right"><span class="math inline">\(SSW = \sum \Delta SSW\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">2.00000</td>
<td align="right">1.00000</td>
<td align="right">1.00000</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">5.00000</td>
<td align="right">2.50000</td>
<td align="right">3.50000</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">5.00000</td>
<td align="right">2.50000</td>
<td align="right">6.00000</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">35.33333</td>
<td align="right">17.66667</td>
<td align="right">23.66667</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">39.00000</td>
<td align="right">19.50000</td>
<td align="right">43.16667</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">194.46667</td>
<td align="right">97.23333</td>
<td align="right">140.40000</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">718.95000</td>
<td align="right">359.47500</td>
<td align="right">499.87500</td>
</tr>
</tbody>
</table>
<p>즉, “ward.D2”와 “ward.D”의 가장 큰 차이는 입력될 거리행렬이 유클리드 거리(ward.D2)인지 제곱 유클리드 거리(ward.D)인지의 차이이다.</p>
<p>참고로, <code>cluster</code> 패키지의 <code>agnes</code>함수도 워드 방법을 지원하며, 이 경우 파라미터 <code>method</code>의 값을 “ward”로 설정한 결과가 <code>hclust</code>함수의 “ward.D2”의 경우와 동일하다. 본 절에서는 해당 함수의 자세한 사용법은 생략한다.</p>
<pre class="sourceCode r"><code class="sourceCode r">res_agnes_ward &lt;-<span class="st"> </span>cluster<span class="op">::</span><span class="kw">agnes</span>(train_df[, <span class="dv">-1</span>], <span class="dt">method =</span> <span class="st">&quot;ward&quot;</span>)

<span class="kw">sort</span>(res_agnes_ward<span class="op">$</span>height)</code></pre>
<pre><code>## [1]  1.414214  2.236068  2.236068  5.944185  6.244998 13.945131 26.813243</code></pre>
</div>
</div>
<div id="diana" class="section level2">
<h2><span class="header-section-number">10.5</span> 분리적 방법 - 다이아나</h2>
<p>다이아나는 분리적 방법의 하나로, <span class="citation">Kaufman and Rousseeuw (<a href="#ref-kaufman1990finding">1990</a>)</span> 에 의하여 제안된 것이다. 이는 전체의 객체를 하나의 군집으로 시작하여 매번 이분화하는 등 모든 군집이 단독 객체로 구성될 때까지 진행하는 방법이다. 이 때, 비유사성 척도로는 평균거리를 사용한다.</p>
<div id="diana-basic-script" class="section level3">
<h3><span class="header-section-number">10.5.1</span> 기본 R 스크립트</h3>
<pre class="sourceCode r"><code class="sourceCode r">train_df &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">id =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">7</span>),
  <span class="dt">x1 =</span> <span class="kw">c</span>(<span class="dv">30</span>, <span class="dv">45</span>, <span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">50</span>, <span class="dv">20</span>, <span class="dv">42</span>),
  <span class="dt">x2 =</span> <span class="kw">c</span>(<span class="dv">15</span>, <span class="dv">22</span>, <span class="dv">12</span>, <span class="dv">24</span>, <span class="dv">25</span>, <span class="dv">10</span>, <span class="dv">9</span>)
)

knitr<span class="op">::</span><span class="kw">kable</span>(train_df, <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
             <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),
             <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;객체번호&#39;</span>, <span class="st">&#39;$x_1$&#39;</span>, <span class="st">&#39;$x_2$&#39;</span>),
             <span class="dt">caption =</span> <span class="st">&#39;DIANA 군집 대상 객체 데이터&#39;</span>)</code></pre>
<table>
<caption><span id="tab:diana-data">Table 10.6: </span>DIANA 군집 대상 객체 데이터</caption>
<thead>
<tr class="header">
<th align="center">객체번호</th>
<th align="right"><span class="math inline">\(x_1\)</span></th>
<th align="right"><span class="math inline">\(x_2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="right">30</td>
<td align="right">15</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="right">45</td>
<td align="right">22</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="right">25</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="right">40</td>
<td align="right">24</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="right">50</td>
<td align="right">25</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="right">20</td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="right">42</td>
<td align="right">9</td>
</tr>
</tbody>
</table>
<p>Table <a href="hierarchical-clustering.html#tab:diana-data">10.6</a>와 같이 두 변수 <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>로 이루어진 7개의 객체 데이터에 대해 DIANA 방법에 의해 군집해를 아래와 같이 <code>cluster</code> 패키지의 <code>diana</code> 함수를 이용하여 간단히 구할 수 있다.</p>
<pre class="sourceCode r"><code class="sourceCode r">res_diana &lt;-<span class="st"> </span>cluster<span class="op">::</span><span class="kw">diana</span>(train_df[, <span class="dv">-1</span>])
cluster<span class="op">::</span><span class="kw">pltree</span>(res_diana,
                <span class="dt">main =</span> <span class="ot">NULL</span>,
                <span class="dt">xlab =</span> <span class="st">&quot;observation&quot;</span>
                )</code></pre>
<div class="figure" style="text-align: center"><span id="fig:diana-result-plot"></span>
<img src="data-mining-book_files/figure-html/diana-result-plot-1.png" alt="DIANA 방법에 의한 군집 덴드로그램" width="672" />
<p class="caption">
Figure 10.4: DIANA 방법에 의한 군집 덴드로그램
</p>
</div>
</div>
<div id="diana-algorithm" class="section level3">
<h3><span class="header-section-number">10.5.2</span> 다이아나 알고리즘</h3>
<p>가장 처음 이분화가 이루어질 때, 우선 타 객체와의 평균거리가 가장 큰 객체가 분파되어 새로운 군집을 형성한다. 그리고 다른 객체에 대하여, 군집에 남아있을 때의 평균거리와 새로운 군집으로 분리될 때의 평균거리를 산출하여, 현 군집에 잔류 또는 새로운 군집으로의 합류를 결정한다.</p>
<p>여기서 객체 <span class="math inline">\(i\)</span>와 군집 <span class="math inline">\(C\)</span>간의 평균거리는 다음과 같이 산출된다.</p>
<p><span class="math display">\[\begin{equation*}
\bar{d}(i, C) = \begin{cases}
\frac{1}{|C| - 1} \sum_{j \in C} d(i, j) &amp; \text{ if } i \in C\\
\frac{1}{|C|} \sum_{j \in C} d(i, j) &amp; \text{ if } i \notin C
\end{cases}
\end{equation*}\]</span></p>
<p>본 방법의 알고리즘은 다음과 같다.</p>
<ol style="list-style-type: decimal">
<li>단계0: <span class="math inline">\(n\)</span>개의 객체를 하나의 군집으로 간주한다. (<span class="math inline">\(k = 1\)</span>)</li>
<li>단계1: 객체 간 거리가 가장 큰 두 객체를 포함한 군집을 이분화 대상으로 선정한다. (이를 <span class="math inline">\(A\)</span>라 하고, <span class="math inline">\(B \leftarrow \emptyset\)</span>로 둔다.)</li>
<li>단계2: 다음 과정을 통하여 군집 <span class="math inline">\(A\)</span>를 이분화한다.
<ol style="list-style-type: decimal">
<li>단계2-1: <span class="math inline">\(i \leftarrow \arg\,\max_{i&#39;} \bar{d}(i&#39;, A)\)</span></li>
<li>단계2-2: <span class="math inline">\(A \leftarrow A - \{i\}\)</span>, <span class="math inline">\(B \leftarrow B \cup \{i\}\)</span></li>
<li>단계2-3: <span class="math inline">\(i \leftarrow \arg\,\max_{i&#39; \in A} e(i&#39;) = \bar{d}(i&#39;, A) - \bar{d}(i&#39;, B)\)</span></li>
<li>단계2-4: <span class="math inline">\(e(i) &gt; 0\)</span>이면 단계2-2로, <span class="math inline">\(e(i) \le 0\)</span>이면 단계3으로</li>
</ol></li>
<li>단계3
<ol style="list-style-type: decimal">
<li><span class="math inline">\(k \leftarrow k + 1\)</span></li>
<li><span class="math inline">\(k &lt; n\)</span>이면 단계1로, <span class="math inline">\(k = n\)</span>이면 Stop.</li>
</ol></li>
</ol>
<p>DIANA 알고리즘을 R script로 구현해보자.</p>
<p>우선, 단계1의 군집을 찾는 함수 <code>max_distance_cluster</code>를 구현하자. 이 함수는 아래 두 개의 데이터 프레임을 입력받는다.</p>
<ul>
<li>입력
<ul>
<li><code>df</code>: 관측 데이터. 각 열의 설명은 아래와 같다.
<ul>
<li><code>id</code>: 객체번호</li>
<li>나머지 열: 숫자형 변수</li>
</ul></li>
<li><code>cluster_label</code>: 각 객체의 현재 소속 군집을 나타내는 데이터 프레임
<ul>
<li><code>id</code>: 객체번호</li>
<li><code>cluster</code>: 군집명</li>
</ul></li>
</ul></li>
<li>함수값
<ul>
<li><code>cluster</code>: 객체간 거리가 가장 큰 두 객체를 포함한 군집명</li>
<li><code>distance</code>: 군집 내 객체간 최대 거리</li>
</ul></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">max_distance_cluster &lt;-<span class="st"> </span><span class="cf">function</span>(df, cluster_label) {
  unique_cluster &lt;-<span class="st"> </span><span class="kw">unique</span>(cluster_label<span class="op">$</span>cluster)
  
  cluster_df &lt;-<span class="st"> </span><span class="kw">lapply</span>(unique_cluster, <span class="cf">function</span>(x) {
    cluster_label <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">      </span><span class="kw">filter</span>(cluster <span class="op">==</span><span class="st"> </span>x) <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">inner_join</span>(df, <span class="dt">by =</span> <span class="st">&quot;id&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">select</span>(<span class="op">-</span>cluster, <span class="op">-</span>id)
    })
  
  max_distance &lt;-<span class="st"> </span><span class="kw">sapply</span>(cluster_df, 
                         <span class="cf">function</span>(x) {
                           <span class="cf">if</span>(<span class="kw">nrow</span>(x) <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="kw">return</span>(<span class="dv">0</span>)
                           <span class="kw">max</span>(<span class="kw">dist</span>(x))
                         }
                         )

  <span class="kw">list</span>(
    <span class="dt">cluster =</span> unique_cluster[<span class="kw">which.max</span>(max_distance)],
    <span class="dt">distance =</span> <span class="kw">max</span>(max_distance)
  )
}</code></pre>
<p>단계 2-1에서 군집 내 평균거리가 가장 큰 객체를 찾는 함수 <code>max_within_distance</code>를 아래와 같이 구현해보자. 이 때 입력변수인 <code>cluster_df</code>는 해당 군집의 객체 데이터로, 객체 번호를 나타내는 열 <code>id</code>와 객체의 각 숫자형 변수를 표현하는 열들로 구성된다.</p>
<pre class="sourceCode r"><code class="sourceCode r">max_within_distance &lt;-<span class="st"> </span><span class="cf">function</span>(cluster_df) {
  idx &lt;-<span class="st"> </span><span class="kw">dist</span>(<span class="kw">subset</span>(cluster_df, <span class="dt">select =</span> <span class="op">-</span>id), <span class="dt">upper =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span>
<span class="st">    </span>broom<span class="op">::</span><span class="kw">tidy</span>() <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">group_by</span>(item1) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">summarize</span>(<span class="dt">mean_distance =</span> <span class="kw">mean</span>(distance)) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">ungroup</span>() <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">arrange</span>(<span class="op">-</span>mean_distance) <span class="op">%&gt;%</span>
<span class="st">    </span>.[[<span class="st">&quot;item1&quot;</span>]] <span class="op">%&gt;%</span>
<span class="st">    </span>.[<span class="dv">1</span>]
  
  cluster_df<span class="op">$</span>id[idx]
}</code></pre>
<p>이후 단계2-3에서 정의한 <span class="math inline">\(e(i&#39;) = \bar{d}(i&#39;, A) - \bar{d}(i&#39;, B)\)</span>를 계산하는 함수 <code>e_score</code>를 아래와 같이 구현한다.</p>
<ul>
<li><code>object</code>: 객체 번호(<code>id</code>)</li>
<li><code>A</code>(<code>B</code>): 군집 <span class="math inline">\(A\)</span>(<span class="math inline">\(B\)</span>)의 객체 데이터. 행은 객체를 나타내며, <code>id</code> 열은 객체 번호, 이외의 열들은 변수를 나타낸다.</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">e_score &lt;-<span class="st"> </span><span class="cf">function</span>(object, A, B) {
  d_from_A &lt;-<span class="st"> </span>proxy<span class="op">::</span><span class="kw">dist</span>(<span class="kw">subset</span>(A, id <span class="op">==</span><span class="st"> </span>object, <span class="op">-</span>id), 
                          <span class="kw">subset</span>(A, id <span class="op">!=</span><span class="st"> </span>object, <span class="op">-</span>id)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mean</span>()
  d_from_B &lt;-<span class="st"> </span>proxy<span class="op">::</span><span class="kw">dist</span>(<span class="kw">subset</span>(A, id <span class="op">==</span><span class="st"> </span>object, <span class="op">-</span>id), 
                          B <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>id)) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">mean</span>()
  <span class="kw">return</span>(d_from_A <span class="op">-</span><span class="st"> </span>d_from_B)
}</code></pre>
<p>위 두 함수 <code>max_within_distance</code>와 <code>e_score</code>를 이용하여, 주어진 데이터 프레임을 두 군집으로 나누는 함수 <code>split_cluster</code>를 구현해보자.</p>
<ul>
<li>입력: 객체 데이터를 나타내는 데이터 프레임 <code>cluster_df</code>. 행은 객체를 나타내며, 객체 번호를 나타내는 열 <code>id</code>와 객체의 각 숫자형 변수를 표현하는 열들로 구성된다.</li>
<li>함수값: 아래 두 개의 component를 지닌 리스트.
<ul>
<li><code>idx_A</code>: 객체 데이터에서 행렬 <span class="math inline">\(A\)</span>에 속하는 객체 번호</li>
<li><code>idx_B</code>: 객체 데이터에서 행렬 <span class="math inline">\(B\)</span>에 속하는 객체 번호</li>
</ul></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">split_cluster &lt;-<span class="st"> </span><span class="cf">function</span>(cluster_df) {
  n &lt;-<span class="st"> </span><span class="kw">nrow</span>(cluster_df)
  
  idx_A &lt;-<span class="st"> </span>cluster_df<span class="op">$</span>id
  idx_B &lt;-<span class="st"> </span><span class="ot">NULL</span>
  
  <span class="co"># 단계2-1</span>
  max_object &lt;-<span class="st"> </span><span class="kw">max_within_distance</span>(cluster_df)
  e_i &lt;-<span class="st"> </span><span class="ot">Inf</span>

  <span class="cf">while</span>(e_i <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span>) {
    <span class="co"># 단계2-2</span>
    idx_B &lt;-<span class="st"> </span><span class="kw">c</span>(idx_B, max_object)
    idx_A &lt;-<span class="st"> </span><span class="kw">setdiff</span>(idx_A, max_object)
    
    A &lt;-<span class="st"> </span>cluster_df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(id <span class="op">%in%</span><span class="st"> </span>idx_A)
    B &lt;-<span class="st"> </span>cluster_df <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(id <span class="op">%in%</span><span class="st"> </span>idx_B)

    <span class="co"># 단계2-3</span>
    <span class="cf">if</span>(<span class="kw">nrow</span>(A) <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) {
      e_is &lt;-<span class="st"> </span><span class="kw">sapply</span>(A<span class="op">$</span>id, <span class="cf">function</span>(x) <span class="kw">e_score</span>(x, A, B))
      max_object &lt;-<span class="st"> </span>A<span class="op">$</span>id[<span class="kw">which.max</span>(e_is)]
      e_i &lt;-<span class="st"> </span><span class="kw">max</span>(e_is)
    } <span class="cf">else</span> {
      e_i &lt;-<span class="st"> </span><span class="op">-</span><span class="ot">Inf</span>
    }
  }
  
  <span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">idx_A =</span> idx_A, <span class="dt">idx_B =</span> idx_B))
}</code></pre>
<p>단계1 함수 <code>max_distance_cluster</code>와 단계2 함수 <code>split_cluster</code>를 반복적으로 수행하며 각각의 객체가 군집에 될 때까지 군집을 분리해간다.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># 단계0</span>
current_cluster &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">id =</span> train_df<span class="op">$</span>id
)
current_cluster<span class="op">$</span>cluster &lt;-<span class="st"> </span><span class="kw">paste</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(current_cluster), <span class="dt">collapse =</span> <span class="st">&quot;,&quot;</span>)
i &lt;-<span class="st"> </span>0L
k &lt;-<span class="st"> </span>1L

<span class="cf">while</span>(k <span class="op">&lt;</span><span class="st"> </span><span class="kw">nrow</span>(train_df)) {
  i &lt;-<span class="st"> </span>i <span class="op">+</span><span class="st"> </span>1L
  
  <span class="co"># 단계1</span>
  max_cluster &lt;-<span class="st"> </span><span class="kw">max_distance_cluster</span>(train_df, current_cluster)

  <span class="co"># 단계2</span>
  new_split &lt;-<span class="st"> </span>current_cluster <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">filter</span>(cluster <span class="op">==</span><span class="st"> </span>max_cluster<span class="op">$</span>cluster) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">inner_join</span>(train_df, <span class="dt">by =</span> <span class="st">&quot;id&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">select</span>(<span class="op">-</span>cluster) <span class="op">%&gt;%</span>
<span class="st">    </span><span class="kw">split_cluster</span>()

  <span class="co"># 군집해 업데이트</span>
  current_cluster[
    current_cluster<span class="op">$</span>id <span class="op">%in%</span><span class="st"> </span>new_split<span class="op">$</span>idx_A, 
    <span class="st">&quot;cluster&quot;</span>] &lt;-<span class="st"> </span><span class="kw">paste</span>(new_split<span class="op">$</span>idx_A, <span class="dt">collapse =</span> <span class="st">&quot;,&quot;</span>)
  current_cluster[
    current_cluster<span class="op">$</span>id <span class="op">%in%</span><span class="st"> </span>new_split<span class="op">$</span>idx_B, 
    <span class="st">&quot;cluster&quot;</span>] &lt;-<span class="st"> </span><span class="kw">paste</span>(new_split<span class="op">$</span>idx_B, <span class="dt">collapse =</span> <span class="st">&quot;,&quot;</span>)
  
  <span class="co"># 군집해 출력</span>
  k &lt;-<span class="st"> </span><span class="kw">length</span>(<span class="kw">unique</span>(current_cluster<span class="op">$</span>cluster))
  <span class="kw">cat</span>(<span class="st">&quot;Iteration: &quot;</span>, i, <span class="st">&quot;, k = &quot;</span>, k, <span class="st">&quot;, clusters = &quot;</span>, 
      <span class="kw">paste0</span>(<span class="st">&quot;{&quot;</span>, <span class="kw">unique</span>(current_cluster<span class="op">$</span>cluster), <span class="st">&quot;}&quot;</span>),
      <span class="st">&quot;, height = &quot;</span>, max_cluster<span class="op">$</span>distance, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)
}</code></pre>
<pre><code>## Iteration:  1 , k =  2 , clusters =  {6,3,1} {2,4,5,7} , height =  33.54102 
## Iteration:  2 , k =  3 , clusters =  {6,3,1} {2,4,5} {7} , height =  17.88854 
## Iteration:  3 , k =  4 , clusters =  {1} {2,4,5} {3,6} {7} , height =  11.18034 
## Iteration:  4 , k =  5 , clusters =  {1} {2,4} {3,6} {5} {7} , height =  10.04988 
## Iteration:  5 , k =  6 , clusters =  {1} {2} {3,6} {4} {5} {7} , height =  5.385165 
## Iteration:  6 , k =  7 , clusters =  {1} {2} {3} {4} {5} {6} {7} , height =  5.385165</code></pre>
<p>위 출력 결과에서 <code>height</code>는 해당 iteration에서 분리된 군집의 분리 전 지름(diameter)으로, 함수 <code>max_distance_cluster</code>에서 계산한 군집 내 객체간 최대 거리를 나타내며, 이는 R 패키지 <code>cluster</code>의 <code>diana</code> 함수 수행 시 함수값으로 출력되는 <code>height</code>값이다. Iteration이 진행됨에 따라 <code>height</code>의 값이 감소하는 것을 확인할 수 있다.</p>
</div>
</div>
<div id="hierarchical-cluster-number" class="section level2">
<h2><span class="header-section-number">10.6</span> 군집수의 결정</h2>
<p>최적의 군집수를 결정하는 객관적인 방법은 존재하지 않는다. 계층적 군집방법에서는 덴드로그램을 참조하여 군집 간의 거리가 급격히 증가하는 계층에서 수평으로 절단하여, 그 이하의 그룹들을 하나의 군집으로 형성하는 방안을 널리 사용하고 있다. 이외에 군집수를 결정하는 데 통계량으로 다음과 같은 통계량들이 부수적으로 사용된다.</p>
<ol style="list-style-type: decimal">
<li>새 군집의 RMS 표준편차(root-mean-square standard deviation of the new cluster; RMSSTD)</li>
</ol>
<p><span class="math display">\[\begin{equation*}
RMSSTD(C_i, C_j) = \sqrt{\frac{SS(C_i \cup C_j)}{p(|C_i| + |C_j| - 1)}}
\end{equation*}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Semipartial R-squared(SPR)</li>
</ol>
<p><span class="math display">\[\begin{equation*}
SPR(C_i, C_j) = \frac{SS(C_i \cup C_j) - (SS(C_i) + SS(C_j))}{SST}
\end{equation*}\]</span></p>
<p>where</p>
<p><span class="math display">\[\begin{equation*}
SST = \sum_{i = 1}^{n} \sum_{j = 1}^{p} \left( x_{ji} - \frac{1}{n} \sum_{a = 1}^{n} x_{ja} \right)^2
\end{equation*}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>R-squared(<span class="math inline">\(R^2\)</span>)</li>
</ol>
<p><span class="math display">\[\begin{equation*}
1 - \frac{\sum_{i = 1}^{k} SS(C_i)}{SST}
\end{equation*}\]</span></p>
<p>위 <a href="hierarchical-clustering.html#ward-method-algorithm">10.4.2</a>절에서 워드 군집 알고리즘으로 구현한 군집 과정에 대해 위 통계량을 계산해보자.</p>
<pre class="sourceCode r"><code class="sourceCode r">train_df &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">id =</span> <span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">8</span>),
  <span class="dt">x1 =</span> <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">20</span>, <span class="dv">3</span>, <span class="dv">19</span>, <span class="dv">17</span>, <span class="dv">8</span>, <span class="dv">19</span>, <span class="dv">18</span>),
  <span class="dt">x2 =</span> <span class="kw">c</span>(<span class="dv">15</span>, <span class="dv">13</span>, <span class="dv">13</span>, <span class="dv">4</span>, <span class="dv">17</span>, <span class="dv">11</span>, <span class="dv">12</span>, <span class="dv">6</span>)
)

sst &lt;-<span class="st"> </span>train_df <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>id) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sapply</span>(<span class="cf">function</span>(x) <span class="kw">sum</span>((x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x))<span class="op">^</span><span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">sum</span>()

<span class="co">#단계0</span>
init_cluster &lt;-<span class="st"> </span><span class="kw">tibble</span>(
  <span class="dt">id =</span> train_df<span class="op">$</span>id,
  <span class="dt">cluster =</span> <span class="kw">as.character</span>(<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(train_df))
)
i &lt;-<span class="st"> </span>0L
current_clusters &lt;-<span class="st"> </span><span class="kw">unique</span>(init_cluster<span class="op">$</span>cluster)
k &lt;-<span class="st"> </span><span class="kw">length</span>(current_clusters)
ssw &lt;-<span class="st"> </span><span class="kw">calculate_ssw</span>(train_df, init_cluster)
old_ssw &lt;-<span class="st"> </span><span class="ot">NA_real_</span>

<span class="co">#단계1</span>
iteration &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">&quot;list&quot;</span>, <span class="dt">length =</span> <span class="kw">nrow</span>(train_df) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)
<span class="cf">while</span>(k <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>) {
  i &lt;-<span class="st"> </span>i <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
  old_ssw &lt;-<span class="st"> </span>ssw
  
  <span class="cf">if</span>(i <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) {
    old_cluster &lt;-<span class="st"> </span>init_cluster
  } <span class="cf">else</span> {
    old_cluster &lt;-<span class="st"> </span>iteration[[i<span class="dv">-1</span>]]<span class="op">$</span>new_cluster_label
  }
  
  iteration[[i]] &lt;-<span class="st"> </span><span class="kw">best_merge_cluster</span>(
    train_df,
    old_cluster
  )
  
  merged &lt;-<span class="st"> </span>old_cluster <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">anti_join</span>(iteration[[i]]<span class="op">$</span>new_cluster_label, <span class="dt">by =</span> <span class="st">&quot;cluster&quot;</span>)
  
  current_clusters &lt;-<span class="st"> </span><span class="kw">unique</span>(iteration[[i]]<span class="op">$</span>new_cluster_label<span class="op">$</span>cluster)
  k &lt;-<span class="st"> </span><span class="kw">length</span>(current_clusters)
  ssw &lt;-<span class="st"> </span>iteration[[i]]<span class="op">$</span>new_ssw
  
  iteration[[i]]<span class="op">$</span>rmsstd &lt;-<span class="st"> </span><span class="kw">sqrt</span>(
    merged <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">      </span><span class="kw">inner_join</span>(train_df, <span class="dt">by =</span> <span class="st">&quot;id&quot;</span>) <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">select</span>(<span class="op">-</span>id, <span class="op">-</span>cluster) <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">sapply</span>(<span class="cf">function</span>(x) <span class="kw">sum</span>((x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x))<span class="op">^</span><span class="dv">2</span>)) <span class="op">%&gt;%</span>
<span class="st">      </span><span class="kw">sum</span>() <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(<span class="kw">nrow</span>(merged) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))
  )
  
  iteration[[i]]<span class="op">$</span>iter &lt;-<span class="st"> </span>i
  iteration[[i]]<span class="op">$</span>merge &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;{&quot;</span>, <span class="kw">unique</span>(merged<span class="op">$</span>cluster), <span class="st">&quot;}&quot;</span>, <span class="dt">collapse =</span> <span class="st">&quot;, &quot;</span>)
  iteration[[i]]<span class="op">$</span>sol &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&quot;{&quot;</span>, <span class="kw">unique</span>(current_clusters), <span class="st">&quot;}&quot;</span>, <span class="dt">collapse =</span> <span class="st">&quot;, &quot;</span>)
  iteration[[i]]<span class="op">$</span>spr &lt;-<span class="st"> </span>(ssw <span class="op">-</span><span class="st"> </span>old_ssw) <span class="op">/</span><span class="st"> </span>sst
  iteration[[i]]<span class="op">$</span>r_sq &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>ssw <span class="op">/</span><span class="st"> </span>sst
}</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">cluster_statistic &lt;-<span class="st"> </span><span class="kw">lapply</span>(iteration, <span class="cf">function</span>(x) x[
  <span class="kw">c</span>(<span class="st">&quot;iter&quot;</span>, <span class="st">&quot;merge&quot;</span>, <span class="st">&quot;sol&quot;</span>, <span class="st">&quot;rmsstd&quot;</span>, <span class="st">&quot;spr&quot;</span>, <span class="st">&quot;r_sq&quot;</span>)]) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">bind_rows</span>(
    <span class="kw">tibble</span>(
      <span class="dt">iter =</span> <span class="dv">0</span>,
      <span class="dt">sol =</span> <span class="kw">paste0</span>(<span class="st">&quot;{&quot;</span>, <span class="kw">unique</span>(init_cluster<span class="op">$</span>cluster), <span class="st">&quot;}&quot;</span>, <span class="dt">collapse =</span> <span class="st">&quot;, &quot;</span>),
      <span class="dt">r_sq =</span> <span class="dv">1</span>
    )
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">arrange</span>(iter)

cluster_statistic <span class="op">%&gt;%</span>
<span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>(
    <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
    <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;Iteration&#39;</span>, <span class="st">&#39;통합대상군집&#39;</span>, <span class="st">&#39;통합 후 군집&#39;</span>,
                  <span class="st">&#39;$RMSSTD$&#39;</span>, <span class="st">&#39;$SPR$&#39;</span>, <span class="st">&#39;$R^2$&#39;</span>),
    <span class="dt">caption =</span> <span class="st">&#39;군집 과정에 따른 여러 통계량&#39;</span>
  )</code></pre>
<table>
<caption><span id="tab:cluster-statistic">Table 10.7: </span>군집 과정에 따른 여러 통계량</caption>
<thead>
<tr class="header">
<th align="right">Iteration</th>
<th align="left">통합대상군집</th>
<th align="left">통합 후 군집</th>
<th align="right"><span class="math inline">\(RMSSTD\)</span></th>
<th align="right"><span class="math inline">\(SPR\)</span></th>
<th align="right"><span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="left">NA</td>
<td align="left">{1}, {2}, {3}, {4}, {5}, {6}, {7}, {8}</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">1.0000000</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="left">{2}, {7}</td>
<td align="left">{1}, {2,7}, {3}, {4}, {5}, {6}, {8}</td>
<td align="right">0.7071068</td>
<td align="right">0.0020005</td>
<td align="right">0.9979995</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="left">{1}, {3}</td>
<td align="left">{1,3}, {2,7}, {4}, {5}, {6}, {8}</td>
<td align="right">1.1180340</td>
<td align="right">0.0050013</td>
<td align="right">0.9929982</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="left">{4}, {8}</td>
<td align="left">{1,3}, {2,7}, {4,8}, {5}, {6}</td>
<td align="right">1.1180340</td>
<td align="right">0.0050013</td>
<td align="right">0.9879970</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="left">{2,7}, {5}</td>
<td align="left">{1,3}, {2,7,5}, {4,8}, {6}</td>
<td align="right">2.1602469</td>
<td align="right">0.0353422</td>
<td align="right">0.9526548</td>
</tr>
<tr class="even">
<td align="right">5</td>
<td align="left">{1,3}, {6}</td>
<td align="left">{1,3,6}, {2,7,5}, {4,8}</td>
<td align="right">2.3452079</td>
<td align="right">0.0390098</td>
<td align="right">0.9136451</td>
</tr>
<tr class="odd">
<td align="right">6</td>
<td align="left">{2,7,5}, {4,8}</td>
<td align="left">{1,3,6}, {2,7,5,4,8}</td>
<td align="right">3.8470768</td>
<td align="right">0.1945153</td>
<td align="right">0.7191298</td>
</tr>
<tr class="even">
<td align="right">7</td>
<td align="left">{1,3,6}, {2,7,5,4,8}</td>
<td align="left">{1,3,6,2,7,5,4,8}</td>
<td align="right">5.9753960</td>
<td align="right">0.7191298</td>
<td align="right">0.0000000</td>
</tr>
</tbody>
</table>
<pre class="sourceCode r"><code class="sourceCode r">cluster_statistic <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">rmsstd =</span> <span class="kw">if_else</span>(<span class="kw">is.na</span>(rmsstd), <span class="dv">0</span>, rmsstd),
    <span class="dt">spr =</span> <span class="kw">if_else</span>(<span class="kw">is.na</span>(spr), <span class="dv">0</span>, spr)
    ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> iter)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> rmsstd, <span class="dt">color =</span> <span class="st">&quot;RMSSTD&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> spr <span class="op">*</span><span class="st"> </span><span class="dv">6</span>, <span class="dt">color =</span> <span class="st">&quot;SPR&quot;</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> r_sq <span class="op">*</span><span class="st"> </span><span class="dv">6</span>, <span class="dt">color =</span> <span class="st">&quot;R2&quot;</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">scale_y_continuous</span>(<span class="dt">sec.axis =</span> <span class="kw">sec_axis</span>(<span class="op">~</span><span class="st"> </span>. <span class="op">/</span><span class="st"> </span><span class="dv">6</span>, <span class="dt">name =</span> <span class="st">&quot;SPR, R2&quot;</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;RMSSTD&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Iteration&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:cluster-statistic"></span>
<img src="data-mining-book_files/figure-html/cluster-statistic-1.png" alt="군집 과정에 따른 통계량 추이" width="672" />
<p class="caption">
Figure 10.5: 군집 과정에 따른 통계량 추이
</p>
</div>
<p>그림 <a href="hierarchical-clustering.html#fig:cluster-statistic">10.5</a>에서 보듯이 Iteration 6부터 3가지 통계량 모두 급격하게 변화하는 것을 알 수 있다. 따라서 군집수는 Iteration 5까지 3개가 가장 적당하다고 하겠다.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-kaufman1990finding">
<p>Kaufman, L, and P. J. Rousseeuw. 1990. “Finding Groups in Data: An Introduction to Cluster Analysis.” Wiley.</p>
</div>
<div id="ref-lance1967general">
<p>Lance, Godfrey N, and William Thomas Williams. 1967. “A General Theory of Classificatory Sorting Strategies: 1. Hierarchical Systems.” <em>The Computer Journal</em> 9 (4). The British Computer Society: 373–80.</p>
</div>
<div id="ref-ward1963hierarchical">
<p>Ward Jr, Joe H. 1963. “Hierarchical Grouping to Optimize an Objective Function.” <em>Journal of the American Statistical Association</em> 58 (301). Taylor &amp; Francis Group: 236–44.</p>
</div>
<div id="ref-wishart1969256">
<p>Wishart, David. 1969. “256. Note: An Algorithm for Hierarchical Classifications.” <em>Biometrics</em>. JSTOR, 165–70.</p>
</div>
</div>
<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://r-data-mining-book.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="clustering-overview.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="nonhierarchical-clustering.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["data-mining-book.pdf"],
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
