<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 부분최소자승법 | 데이터마이닝 with R</title>
  <meta name="description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 부분최소자승법 | 데이터마이닝 with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://youngroklee-ml.github.io/data-mining-book/" />
  
  <meta property="og:description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  <meta name="github-repo" content="youngroklee-ml/data-mining-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 부분최소자승법 | 데이터마이닝 with R" />
  
  <meta name="twitter:description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  

<meta name="author" content="전치혁, 이혜선, 이종석, 이영록" />


<meta name="date" content="2021-07-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="pca.html"/>
<link rel="next" href="classification-analysis.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">데이터마이닝 with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>개요</a></li>
<li class="chapter" data-level="1" data-path="datamining-overview.html"><a href="datamining-overview.html"><i class="fa fa-check"></i><b>1</b> 데이터마이닝 개요</a></li>
<li class="part"><span><b>I 1부 - 예측</b></span></li>
<li class="chapter" data-level="2" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>2</b> 회귀분석</a>
<ul>
<li class="chapter" data-level="2.1" data-path="regression.html"><a href="regression.html#regression-packages-install"><i class="fa fa-check"></i><b>2.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="2.2" data-path="regression.html"><a href="regression.html#multiple-linear-regression"><i class="fa fa-check"></i><b>2.2</b> 다중회귀모형</a></li>
<li class="chapter" data-level="2.3" data-path="regression.html"><a href="regression.html#regression-response-confidence-prediction"><i class="fa fa-check"></i><b>2.3</b> 반응치에 대한 추정 및 예측</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="regression.html"><a href="regression.html#regression-response-confidence"><i class="fa fa-check"></i><b>2.3.1</b> 평균반응치의 추정</a></li>
<li class="chapter" data-level="2.3.2" data-path="regression.html"><a href="regression.html#regression-response-prediction"><i class="fa fa-check"></i><b>2.3.2</b> 미래반응치의 예측</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="regression.html"><a href="regression.html#regression-indicator-variable"><i class="fa fa-check"></i><b>2.4</b> 지시변수와 회귀모형</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="regression.html"><a href="regression.html#regression-indicator-variable-basic-script"><i class="fa fa-check"></i><b>2.4.1</b> 기본 R 스트립트</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>3</b> 주성분분석</a>
<ul>
<li class="chapter" data-level="3.1" data-path="pca.html"><a href="pca.html#pca-packages-install"><i class="fa fa-check"></i><b>3.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="3.2" data-path="pca.html"><a href="pca.html#pca-matrix-factorization"><i class="fa fa-check"></i><b>3.2</b> 행렬의 분해</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="pca.html"><a href="pca.html#pca-matrix-factorization-basic-script"><i class="fa fa-check"></i><b>3.2.1</b> 기본 R 스트립트</a></li>
<li class="chapter" data-level="3.2.2" data-path="pca.html"><a href="pca.html#pca-ss"><i class="fa fa-check"></i><b>3.2.2</b> 변수의 변동과 제곱합</a></li>
<li class="chapter" data-level="3.2.3" data-path="pca.html"><a href="pca.html#pca-intro"><i class="fa fa-check"></i><b>3.2.3</b> 주성분의 이해 및 행렬의 분해</a></li>
<li class="chapter" data-level="3.2.4" data-path="pca.html"><a href="pca.html#pca-svd"><i class="fa fa-check"></i><b>3.2.4</b> 특이치분해 (Singular Value Decomposition)</a></li>
<li class="chapter" data-level="3.2.5" data-path="pca.html"><a href="pca.html#pca-spectral"><i class="fa fa-check"></i><b>3.2.5</b> 분광분해 (Spectral Decomposition)</a></li>
<li class="chapter" data-level="3.2.6" data-path="pca.html"><a href="pca.html#pca-nipals"><i class="fa fa-check"></i><b>3.2.6</b> NIPALS 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="pca.html"><a href="pca.html#pca-regression"><i class="fa fa-check"></i><b>3.3</b> 주성분 회귀분석</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="pca.html"><a href="pca.html#pcr-basic-script"><i class="fa fa-check"></i><b>3.3.1</b> 기본 R 스트립트</a></li>
<li class="chapter" data-level="3.3.2" data-path="pca.html"><a href="pca.html#pcr-regression-coefficient"><i class="fa fa-check"></i><b>3.3.2</b> 주성분 회귀계수 추정</a></li>
<li class="chapter" data-level="3.3.3" data-path="pca.html"><a href="pca.html#pcr-regression-transform"><i class="fa fa-check"></i><b>3.3.3</b> 회귀계수 선형변환</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="plsr.html"><a href="plsr.html"><i class="fa fa-check"></i><b>4</b> 부분최소자승법</a>
<ul>
<li class="chapter" data-level="4.1" data-path="plsr.html"><a href="plsr.html#plsr-packages-install"><i class="fa fa-check"></i><b>4.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="4.2" data-path="plsr.html"><a href="plsr.html#plsr-single-target"><i class="fa fa-check"></i><b>4.2</b> 하나의 종속변수의 경우</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="plsr.html"><a href="plsr.html#plsr-basic-script"><i class="fa fa-check"></i><b>4.2.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="4.2.2" data-path="plsr.html"><a href="plsr.html#plsr-model"><i class="fa fa-check"></i><b>4.2.2</b> PLS 모형</a></li>
<li class="chapter" data-level="4.2.3" data-path="plsr.html"><a href="plsr.html#plsr-single-nipals"><i class="fa fa-check"></i><b>4.2.3</b> NIPALS 알고리즘</a></li>
<li class="chapter" data-level="4.2.4" data-path="plsr.html"><a href="plsr.html#plsr-single-transform"><i class="fa fa-check"></i><b>4.2.4</b> 회귀식 변환</a></li>
<li class="chapter" data-level="4.2.5" data-path="plsr.html"><a href="plsr.html#plsr-sst"><i class="fa fa-check"></i><b>4.2.5</b> 제곱합 분해</a></li>
<li class="chapter" data-level="4.2.6" data-path="plsr.html"><a href="plsr.html#plsr-variable-importance"><i class="fa fa-check"></i><b>4.2.6</b> 독립변수의 중요도</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-target"><i class="fa fa-check"></i><b>4.3</b> 다수의 종속변수의 경우</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-basic-script"><i class="fa fa-check"></i><b>4.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="4.3.2" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-model"><i class="fa fa-check"></i><b>4.3.2</b> PLS 모형</a></li>
<li class="chapter" data-level="4.3.3" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-nipals"><i class="fa fa-check"></i><b>4.3.3</b> NIPALS 알고리즘</a></li>
<li class="chapter" data-level="4.3.4" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-transform"><i class="fa fa-check"></i><b>4.3.4</b> 회귀식 변환</a></li>
<li class="chapter" data-level="4.3.5" data-path="plsr.html"><a href="plsr.html#plsr-multivariate-sst"><i class="fa fa-check"></i><b>4.3.5</b> 제곱합 분해</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II 2부 - 분류분석</b></span></li>
<li class="chapter" data-level="5" data-path="classification-analysis.html"><a href="classification-analysis.html"><i class="fa fa-check"></i><b>5</b> 분류분석 개요</a>
<ul>
<li class="chapter" data-level="5.1" data-path="classification-analysis.html"><a href="classification-analysis.html#classification-packages-install"><i class="fa fa-check"></i><b>5.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="5.2" data-path="classification-analysis.html"><a href="classification-analysis.html#classification-problem-methods"><i class="fa fa-check"></i><b>5.2</b> 분류문제 및 분류기법</a></li>
<li class="chapter" data-level="5.3" data-path="classification-analysis.html"><a href="classification-analysis.html#simple-classification-methods"><i class="fa fa-check"></i><b>5.3</b> 기본적인 분류기법</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="classification-analysis.html"><a href="classification-analysis.html#nearest-neighbor-classification"><i class="fa fa-check"></i><b>5.3.1</b> 인접객체법</a></li>
<li class="chapter" data-level="5.3.2" data-path="classification-analysis.html"><a href="classification-analysis.html#naive-bayes"><i class="fa fa-check"></i><b>5.3.2</b> 나이브 베이지안 분류법</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>6</b> 로지스틱 회귀분석</a>
<ul>
<li class="chapter" data-level="6.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-packages-install"><i class="fa fa-check"></i><b>6.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="6.2" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-regression"><i class="fa fa-check"></i><b>6.2</b> 이분 로지스틱 회귀모형</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#bianry-logistic-reg-basic-script"><i class="fa fa-check"></i><b>6.2.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="6.2.2" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-reg-model"><i class="fa fa-check"></i><b>6.2.2</b> 회귀모형</a></li>
<li class="chapter" data-level="6.2.3" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-reg-estimation"><i class="fa fa-check"></i><b>6.2.3</b> 회귀계수 추정</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="logistic-regression.html"><a href="logistic-regression.html#nominal-logistic-regression"><i class="fa fa-check"></i><b>6.3</b> 명목 로지스틱 회귀모형</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#nominal-logistic-reg-basic-script"><i class="fa fa-check"></i><b>6.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="6.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#baseline-category-logit-model"><i class="fa fa-check"></i><b>6.3.2</b> 기준범주 로짓모형</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="logistic-regression.html"><a href="logistic-regression.html#ordinal-logistic-regression"><i class="fa fa-check"></i><b>6.4</b> 서열 로지스틱 회귀모형</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#ordinal-logistic-basic-script"><i class="fa fa-check"></i><b>6.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="6.4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#cumulative-logit-model"><i class="fa fa-check"></i><b>6.4.2</b> 누적 로짓모형</a></li>
<li class="chapter" data-level="6.4.3" data-path="logistic-regression.html"><a href="logistic-regression.html#adjacent-categories-logit-model"><i class="fa fa-check"></i><b>6.4.3</b> 인근범주 로짓모형</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="da.html"><a href="da.html"><i class="fa fa-check"></i><b>7</b> 판별분석</a>
<ul>
<li class="chapter" data-level="7.1" data-path="da.html"><a href="da.html#da-overview"><i class="fa fa-check"></i><b>7.1</b> 개요</a></li>
<li class="chapter" data-level="7.2" data-path="da.html"><a href="da.html#da-packages-install"><i class="fa fa-check"></i><b>7.2</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="7.3" data-path="da.html"><a href="da.html#da-fisher"><i class="fa fa-check"></i><b>7.3</b> 피셔 방법</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="da.html"><a href="da.html#da-fisher-basic-script"><i class="fa fa-check"></i><b>7.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.3.2" data-path="da.html"><a href="da.html#피셔-판별함수"><i class="fa fa-check"></i><b>7.3.2</b> 피셔 판별함수</a></li>
<li class="chapter" data-level="7.3.3" data-path="da.html"><a href="da.html#분류-규칙"><i class="fa fa-check"></i><b>7.3.3</b> 분류 규칙</a></li>
<li class="chapter" data-level="7.3.4" data-path="da.html"><a href="da.html#r-패키지를-이용한-분류규칙-도출"><i class="fa fa-check"></i><b>7.3.4</b> R 패키지를 이용한 분류규칙 도출</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="da.html"><a href="da.html#lda"><i class="fa fa-check"></i><b>7.4</b> 의사결정론에 의한 선형분류규칙</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="da.html"><a href="da.html#lda-basic-script"><i class="fa fa-check"></i><b>7.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.4.2" data-path="da.html"><a href="da.html#lda-function"><i class="fa fa-check"></i><b>7.4.2</b> 선형판별함수</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="da.html"><a href="da.html#lda-misclassification-cost"><i class="fa fa-check"></i><b>7.5</b> 오분류비용을 고려한 분류규칙</a></li>
<li class="chapter" data-level="7.6" data-path="da.html"><a href="da.html#qda"><i class="fa fa-check"></i><b>7.6</b> 이차판별분석</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="da.html"><a href="da.html#qda-basic-script"><i class="fa fa-check"></i><b>7.6.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.6.2" data-path="da.html"><a href="da.html#qda-function"><i class="fa fa-check"></i><b>7.6.2</b> 이차 판별함수</a></li>
<li class="chapter" data-level="7.6.3" data-path="da.html"><a href="da.html#qda-discriminant-rule"><i class="fa fa-check"></i><b>7.6.3</b> 이차판별함수에 의한 분류</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="da.html"><a href="da.html#da-multiclass"><i class="fa fa-check"></i><b>7.7</b> 세 범주 이상의 분류</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="da.html"><a href="da.html#mutliclass-da-basic-script"><i class="fa fa-check"></i><b>7.7.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.7.2" data-path="da.html"><a href="da.html#mutliclass-generalized-discriminant-function"><i class="fa fa-check"></i><b>7.7.2</b> 일반화된 판별함수</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="tree-based-method.html"><a href="tree-based-method.html"><i class="fa fa-check"></i><b>8</b> 트리기반 기법</a>
<ul>
<li class="chapter" data-level="8.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-overview"><i class="fa fa-check"></i><b>8.1</b> CART 개요</a></li>
<li class="chapter" data-level="8.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-packages-install"><i class="fa fa-check"></i><b>8.2</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="8.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-build"><i class="fa fa-check"></i><b>8.3</b> CART 트리 생성</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-basic-r-script"><i class="fa fa-check"></i><b>8.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="8.3.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-notation"><i class="fa fa-check"></i><b>8.3.2</b> 기호 정의</a></li>
<li class="chapter" data-level="8.3.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-impurity"><i class="fa fa-check"></i><b>8.3.3</b> 노드 및 트리의 불순도</a></li>
<li class="chapter" data-level="8.3.4" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-split"><i class="fa fa-check"></i><b>8.3.4</b> 분지기준</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-pruning-complete"><i class="fa fa-check"></i><b>8.4</b> 가지치기 및 최종 트리 선정</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-pruning"><i class="fa fa-check"></i><b>8.4.1</b> 가지치기</a></li>
<li class="chapter" data-level="8.4.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-best-tree"><i class="fa fa-check"></i><b>8.4.2</b> 최적 트리의 선정</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg"><i class="fa fa-check"></i><b>8.5</b> R패키지 내 분류 트리 방법</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-split"><i class="fa fa-check"></i><b>8.5.1</b> 트리 확장</a></li>
<li class="chapter" data-level="8.5.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-pruning"><i class="fa fa-check"></i><b>8.5.2</b> 가지치기</a></li>
<li class="chapter" data-level="8.5.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-param"><i class="fa fa-check"></i><b>8.5.3</b> 파라미터값 결정</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="svm.html"><a href="svm.html"><i class="fa fa-check"></i><b>9</b> 서포트 벡터 머신</a>
<ul>
<li class="chapter" data-level="9.1" data-path="svm.html"><a href="svm.html#svm-overview"><i class="fa fa-check"></i><b>9.1</b> 개요</a></li>
<li class="chapter" data-level="9.2" data-path="svm.html"><a href="svm.html#svm-packages-install"><i class="fa fa-check"></i><b>9.2</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="9.3" data-path="svm.html"><a href="svm.html#linear-svm-separable"><i class="fa fa-check"></i><b>9.3</b> 선형 SVM - 분리 가능 경우</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="svm.html"><a href="svm.html#linear-svm-separable-basic-script"><i class="fa fa-check"></i><b>9.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="9.3.2" data-path="svm.html"><a href="svm.html#linear-svm-notation"><i class="fa fa-check"></i><b>9.3.2</b> 기호 정의</a></li>
<li class="chapter" data-level="9.3.3" data-path="svm.html"><a href="svm.html#linear-svm-separable-hyperplane"><i class="fa fa-check"></i><b>9.3.3</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="svm.html"><a href="svm.html#linear-svm-inseparable"><i class="fa fa-check"></i><b>9.4</b> 선형 SVM - 분리 불가능 경우</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="svm.html"><a href="svm.html#linear-svm-inseparable-basic-script"><i class="fa fa-check"></i><b>9.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="9.4.2" data-path="svm.html"><a href="svm.html#linear-svm-inseparable-hyperplane"><i class="fa fa-check"></i><b>9.4.2</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="svm.html"><a href="svm.html#nonlinear-svm"><i class="fa fa-check"></i><b>9.5</b> 비선형 SVM</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="svm.html"><a href="svm.html#nonlinear-svm-basic-script"><i class="fa fa-check"></i><b>9.5.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="9.5.2" data-path="svm.html"><a href="svm.html#nonlinear-svm-hyperplane"><i class="fa fa-check"></i><b>9.5.2</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="svm.html"><a href="svm.html#svm-r-pkg"><i class="fa fa-check"></i><b>9.6</b> R패키지 내 SVM</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="svm.html"><a href="svm.html#svm-kernel-function"><i class="fa fa-check"></i><b>9.6.1</b> 커널함수</a></li>
<li class="chapter" data-level="9.6.2" data-path="svm.html"><a href="svm.html#svm-nu-classification"><i class="fa fa-check"></i><b>9.6.2</b> <span class="math inline">\(\nu\)</span>-SVC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html"><i class="fa fa-check"></i><b>10</b> 분류규칙의 성능 평가</a>
<ul>
<li class="chapter" data-level="10.1" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#classifier-evaluation-packages-install"><i class="fa fa-check"></i><b>10.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="10.2" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#classifier-evaluation-misclassification-rate"><i class="fa fa-check"></i><b>10.2</b> 분류오류율</a></li>
<li class="chapter" data-level="10.3" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#precision-sensitivity-specificity"><i class="fa fa-check"></i><b>10.3</b> 정확도, 민감도 및 특이도</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#confusion-matrix-r-package"><i class="fa fa-check"></i><b>10.3.1</b> R 패키지 내 정오분류표</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#roc-curve"><i class="fa fa-check"></i><b>10.4</b> ROC 곡선</a></li>
<li class="chapter" data-level="10.5" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#gain-chart"><i class="fa fa-check"></i><b>10.5</b> 이익도표</a></li>
</ul></li>
<li class="part"><span><b>III 3부 - 군집분석</b></span></li>
<li class="chapter" data-level="11" data-path="clustering-overview.html"><a href="clustering-overview.html"><i class="fa fa-check"></i><b>11</b> 군집분석 개요</a>
<ul>
<li class="chapter" data-level="11.1" data-path="clustering-overview.html"><a href="clustering-overview.html#clustering-overview-packages-install"><i class="fa fa-check"></i><b>11.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="11.2" data-path="clustering-overview.html"><a href="clustering-overview.html#clustering-method"><i class="fa fa-check"></i><b>11.2</b> 군집분석 기법</a></li>
<li class="chapter" data-level="11.3" data-path="clustering-overview.html"><a href="clustering-overview.html#object-similarity-metric"><i class="fa fa-check"></i><b>11.3</b> 객체 간의 유사성 척도</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="clustering-overview.html"><a href="clustering-overview.html#object-distance-metric"><i class="fa fa-check"></i><b>11.3.1</b> 거리 관련 척도</a></li>
<li class="chapter" data-level="11.3.2" data-path="clustering-overview.html"><a href="clustering-overview.html#object-correlation-metric"><i class="fa fa-check"></i><b>11.3.2</b> 상관계수 관련 척도</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="clustering-overview.html"><a href="clustering-overview.html#category-similarity-metric"><i class="fa fa-check"></i><b>11.4</b> 범주형 객체의 유사성 척도</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="clustering-overview.html"><a href="clustering-overview.html#binary-similarity-metric"><i class="fa fa-check"></i><b>11.4.1</b> 이분형 변수의 경우</a></li>
<li class="chapter" data-level="11.4.2" data-path="clustering-overview.html"><a href="clustering-overview.html#ordinal-similarity-metric"><i class="fa fa-check"></i><b>11.4.2</b> 서열형 변수의 경우</a></li>
<li class="chapter" data-level="11.4.3" data-path="clustering-overview.html"><a href="clustering-overview.html#nominal-similarity-metric"><i class="fa fa-check"></i><b>11.4.3</b> 명목형 변수의 경우</a></li>
<li class="chapter" data-level="11.4.4" data-path="clustering-overview.html"><a href="clustering-overview.html#mixed-similarity-metric"><i class="fa fa-check"></i><b>11.4.4</b> 혼합형의 경우</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html"><i class="fa fa-check"></i><b>12</b> 계층적 군집방법</a>
<ul>
<li class="chapter" data-level="12.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hierarchical-clustering-packages-install"><i class="fa fa-check"></i><b>12.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="12.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#distance-between-clusters"><i class="fa fa-check"></i><b>12.2</b> 군집 간 거리척도 및 연결법</a></li>
<li class="chapter" data-level="12.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method"><i class="fa fa-check"></i><b>12.3</b> 연결법의 군집 알고리즘</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method-basic-script"><i class="fa fa-check"></i><b>12.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="12.3.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method-algorithm"><i class="fa fa-check"></i><b>12.3.2</b> 연결법 군집 알고리즘</a></li>
<li class="chapter" data-level="12.3.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hclust"><i class="fa fa-check"></i><b>12.3.3</b> R 패키지 내 연결법</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method"><i class="fa fa-check"></i><b>12.4</b> 워드 방법</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method-basic-script"><i class="fa fa-check"></i><b>12.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="12.4.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method-algorithm"><i class="fa fa-check"></i><b>12.4.2</b> 워드 군집 알고리즘</a></li>
<li class="chapter" data-level="12.4.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-rpackages"><i class="fa fa-check"></i><b>12.4.3</b> R 패키지 내 워드 방법</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana"><i class="fa fa-check"></i><b>12.5</b> 분리적 방법 - 다이아나</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana-basic-script"><i class="fa fa-check"></i><b>12.5.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="12.5.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana-algorithm"><i class="fa fa-check"></i><b>12.5.2</b> 다이아나 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hierarchical-cluster-number"><i class="fa fa-check"></i><b>12.6</b> 군집수의 결정</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html"><i class="fa fa-check"></i><b>13</b> 비계층적 군집방법</a>
<ul>
<li class="chapter" data-level="13.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#nonhierarchical-clustering-packages-install"><i class="fa fa-check"></i><b>13.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="13.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans"><i class="fa fa-check"></i><b>13.2</b> K-means 알고리즘</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-basic-script"><i class="fa fa-check"></i><b>13.2.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="13.2.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-algorithm"><i class="fa fa-check"></i><b>13.2.2</b> 알고리즘</a></li>
<li class="chapter" data-level="13.2.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-user-defined-functions"><i class="fa fa-check"></i><b>13.2.3</b> R 스크립트 구현</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmedoids"><i class="fa fa-check"></i><b>13.3</b> K-medoids 군집방법</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#pam"><i class="fa fa-check"></i><b>13.3.1</b> PAM 알고리즘</a></li>
<li class="chapter" data-level="13.3.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#clara"><i class="fa fa-check"></i><b>13.3.2</b> CLARA 알고리즘</a></li>
<li class="chapter" data-level="13.3.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#clarans"><i class="fa fa-check"></i><b>13.3.3</b> CLARANS 알고리즘</a></li>
<li class="chapter" data-level="13.3.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-like"><i class="fa fa-check"></i><b>13.3.4</b> K-means-like 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans"><i class="fa fa-check"></i><b>13.4</b> 퍼지 K-means 알고리즘</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-basic-script"><i class="fa fa-check"></i><b>13.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="13.4.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-algorithm"><i class="fa fa-check"></i><b>13.4.2</b> 알고리즘</a></li>
<li class="chapter" data-level="13.4.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-script-implement"><i class="fa fa-check"></i><b>13.4.3</b> R 스크립트 구현</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering"><i class="fa fa-check"></i><b>13.5</b> 모형기반 군집방법</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-basic-script"><i class="fa fa-check"></i><b>13.5.1</b> 기본 R script</a></li>
<li class="chapter" data-level="13.5.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-em"><i class="fa fa-check"></i><b>13.5.2</b> EM 알고리즘</a></li>
<li class="chapter" data-level="13.5.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-script-implement"><i class="fa fa-check"></i><b>13.5.3</b> R 스크립트 구현</a></li>
<li class="chapter" data-level="13.5.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#r-packages-model-based-clustering"><i class="fa fa-check"></i><b>13.5.4</b> R 패키지 내 모형기반 군집분석</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html"><i class="fa fa-check"></i><b>14</b> 군집해의 평가 및 해석</a>
<ul>
<li class="chapter" data-level="14.1" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-solution-evaluation-packages-install"><i class="fa fa-check"></i><b>14.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="14.2" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-solution-evaluation-metric"><i class="fa fa-check"></i><b>14.2</b> 군집해의 평가</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-evaluation-external-index"><i class="fa fa-check"></i><b>14.2.1</b> 외부평가지수</a></li>
<li class="chapter" data-level="14.2.2" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-evaluation-internal-index"><i class="fa fa-check"></i><b>14.2.2</b> 내부평가지수</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-solution-interpretation"><i class="fa fa-check"></i><b>14.3</b> 군집해의 해석</a></li>
</ul></li>
<li class="part"><span><b>IV 4부 - 연관규칙</b></span></li>
<li class="chapter" data-level="15" data-path="association-rule.html"><a href="association-rule.html"><i class="fa fa-check"></i><b>15</b> 연관규칙</a>
<ul>
<li class="chapter" data-level="15.1" data-path="association-rule.html"><a href="association-rule.html#association-packages-install"><i class="fa fa-check"></i><b>15.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="15.2" data-path="association-rule.html"><a href="association-rule.html#association-rule-definition-metric"><i class="fa fa-check"></i><b>15.2</b> 연관규칙의 정의 및 성능척도</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="association-rule.html"><a href="association-rule.html#association-rule-support"><i class="fa fa-check"></i><b>15.2.1</b> 지지도</a></li>
<li class="chapter" data-level="15.2.2" data-path="association-rule.html"><a href="association-rule.html#association-rule-confidence"><i class="fa fa-check"></i><b>15.2.2</b> 신뢰도</a></li>
<li class="chapter" data-level="15.2.3" data-path="association-rule.html"><a href="association-rule.html#association-rule-lift"><i class="fa fa-check"></i><b>15.2.3</b> 개선도</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="association-rule.html"><a href="association-rule.html#association-rule-exploration"><i class="fa fa-check"></i><b>15.3</b> 연관규칙의 탐사</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="association-rule.html"><a href="association-rule.html#apriori-large-itemsets"><i class="fa fa-check"></i><b>15.3.1</b> 빈발항목집합 생성</a></li>
<li class="chapter" data-level="15.3.2" data-path="association-rule.html"><a href="association-rule.html#apriori-rule-exploration"><i class="fa fa-check"></i><b>15.3.2</b> 규칙의 탐사</a></li>
<li class="chapter" data-level="15.3.3" data-path="association-rule.html"><a href="association-rule.html#apriori-r-package"><i class="fa fa-check"></i><b>15.3.3</b> R 패키지 내 Apriori</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="association-rule.html"><a href="association-rule.html#association-sequential-pattern"><i class="fa fa-check"></i><b>15.4</b> 순차적 패턴의 탐사</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="association-rule.html"><a href="association-rule.html#association-aprioriall"><i class="fa fa-check"></i><b>15.4.1</b> AprioriAll 알고리즘</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="recommender-system.html"><a href="recommender-system.html"><i class="fa fa-check"></i><b>16</b> 추천시스템</a>
<ul>
<li class="chapter" data-level="16.1" data-path="recommender-system.html"><a href="recommender-system.html#recommender-packages-install"><i class="fa fa-check"></i><b>16.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="16.2" data-path="recommender-system.html"><a href="recommender-system.html#content-based-recommender"><i class="fa fa-check"></i><b>16.2</b> 내용기반 추천시스템</a></li>
<li class="chapter" data-level="16.3" data-path="recommender-system.html"><a href="recommender-system.html#collaborative-filtering"><i class="fa fa-check"></i><b>16.3</b> 협업 필터링</a></li>
<li class="chapter" data-level="16.4" data-path="recommender-system.html"><a href="recommender-system.html#market-basket"><i class="fa fa-check"></i><b>16.4</b> 시장바구니 데이터를 이용한 협업 필터링</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">데이터마이닝 with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="plsr" class="section level1" number="4">
<h1><span class="header-section-number">Chapter 4</span> 부분최소자승법</h1>
<p>회귀분석에서와 같이 하나의 종속변수에 영향을 주는 <span class="math inline">\(k\)</span>개의 독립변수가 있다고 하자. 모든 변수는 평균조정되었다고 간주한다. 본 장에서 다루고자 하는 부분최소자승법(partial least squares: PLS)는 앞에서 다룬 주성분 회귀분석(PCR)과 유사하나, 도출되는 새로운 잠재변수들이 다르다.</p>
<p>독립변수와 종속변수간의 관계를 설명하기 위해, 우선 독립변수 행렬과 종속변수 행렬(또는 벡터)가 각각 서로 다른 잠재변수들에 의해 설명된다고 가정한 뒤, 두 잠재변수들간의 관계에 대한 모형을 세운다. 이 때, 본 장에서는 두 잠재변수들간의 관계가 선형인 모형(선형 PLS)만을 살펴본다.</p>
<div id="plsr-packages-install" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> 필요 R 패키지 설치</h2>
<p>본 장에서 필요한 R 패키지들은 아래와 같다.</p>
<table>
<thead>
<tr class="header">
<th align="left">package</th>
<th align="left">version</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">tidyverse</td>
<td align="left">1.3.1</td>
</tr>
<tr class="even">
<td align="left">pls</td>
<td align="left">2.7-3</td>
</tr>
</tbody>
</table>
</div>
<div id="plsr-single-target" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> 하나의 종속변수의 경우</h2>
<div id="plsr-basic-script" class="section level3" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> 기본 R 스크립트</h3>
<p>앞 장의 주성분 회귀분석에서 사용했던 데이터에 대해 부분최소자승 회귀분석을 수행해보도록 하자.</p>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="plsr.html#cb103-1" aria-hidden="true" tabindex="-1"></a>train_df <span class="ot">&lt;-</span> <span class="fu">tribble</span>(</span>
<span id="cb103-2"><a href="plsr.html#cb103-2" aria-hidden="true" tabindex="-1"></a>  <span class="sc">~</span>x1, <span class="sc">~</span>x2, <span class="sc">~</span>x3, <span class="sc">~</span>y,</span>
<span id="cb103-3"><a href="plsr.html#cb103-3" aria-hidden="true" tabindex="-1"></a>  <span class="sc">-</span><span class="dv">3</span>, <span class="sc">-</span><span class="dv">3</span>, <span class="dv">5</span>, <span class="sc">-</span><span class="dv">30</span>,</span>
<span id="cb103-4"><a href="plsr.html#cb103-4" aria-hidden="true" tabindex="-1"></a>  <span class="sc">-</span><span class="dv">2</span>, <span class="sc">-</span><span class="dv">3</span>, <span class="dv">7</span>, <span class="sc">-</span><span class="dv">20</span>,</span>
<span id="cb103-5"><a href="plsr.html#cb103-5" aria-hidden="true" tabindex="-1"></a>  <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">4</span>, <span class="dv">0</span>,</span>
<span id="cb103-6"><a href="plsr.html#cb103-6" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">5</span>,</span>
<span id="cb103-7"><a href="plsr.html#cb103-7" aria-hidden="true" tabindex="-1"></a>  <span class="dv">2</span>, <span class="dv">2</span>, <span class="sc">-</span><span class="dv">5</span>, <span class="dv">10</span>,</span>
<span id="cb103-8"><a href="plsr.html#cb103-8" aria-hidden="true" tabindex="-1"></a>  <span class="dv">2</span>, <span class="dv">2</span>, <span class="sc">-</span><span class="dv">11</span>, <span class="dv">35</span></span>
<span id="cb103-9"><a href="plsr.html#cb103-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb103-10"><a href="plsr.html#cb103-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-11"><a href="plsr.html#cb103-11" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(</span>
<span id="cb103-12"><a href="plsr.html#cb103-12" aria-hidden="true" tabindex="-1"></a>  train_df, <span class="at">booktabs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb103-13"><a href="plsr.html#cb103-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">align =</span> <span class="fu">rep</span>(<span class="st">&quot;r&quot;</span>, <span class="fu">ncol</span>(train_df)),</span>
<span id="cb103-14"><a href="plsr.html#cb103-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">caption =</span> <span class="st">&quot;부분최소자승 회귀분석 예제 데이터&quot;</span></span>
<span id="cb103-15"><a href="plsr.html#cb103-15" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<table>
<caption><span id="tab:plsr-example-data">Table 4.1: </span>부분최소자승 회귀분석 예제 데이터</caption>
<thead>
<tr class="header">
<th align="right">x1</th>
<th align="right">x2</th>
<th align="right">x3</th>
<th align="right">y</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">-3</td>
<td align="right">-3</td>
<td align="right">5</td>
<td align="right">-30</td>
</tr>
<tr class="even">
<td align="right">-2</td>
<td align="right">-3</td>
<td align="right">7</td>
<td align="right">-20</td>
</tr>
<tr class="odd">
<td align="right">0</td>
<td align="right">0</td>
<td align="right">4</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">5</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="right">2</td>
<td align="right">-5</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">2</td>
<td align="right">-11</td>
<td align="right">35</td>
</tr>
</tbody>
</table>
<p>R 패키지 <code>pls</code> 내의 함수 <code>plsr()</code>을 이용하여 PLS 모형을 아래와 같이 추정할 수 있다.</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="plsr.html#cb104-1" aria-hidden="true" tabindex="-1"></a>plsr_fit <span class="ot">&lt;-</span> pls<span class="sc">::</span><span class="fu">plsr</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3, <span class="at">data =</span> train_df, <span class="at">ncomp =</span> <span class="dv">2</span>)</span>
<span id="cb104-2"><a href="plsr.html#cb104-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(plsr_fit)</span></code></pre></div>
<pre><code>## , , 2 comps
## 
##            y
## x1  2.475395
## x2  2.523238
## x3 -1.704636</code></pre>
<p>수행결과 object에 <code>summary()</code> 함수를 사용하여 학습된 모형의 독립변수 <span class="math inline">\(\mathbf{X}\)</span> 및 종속변수 <span class="math inline">\(\mathbf{y}\)</span>의 총변동에 대한 기여율을 확인할 수 있다.</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="plsr.html#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(plsr_fit)</span></code></pre></div>
<pre><code>## Data:    X dimension: 6 3 
##  Y dimension: 6 1
## Fit method: kernelpls
## Number of components considered: 2
## TRAINING: % variance explained
##    1 comps  2 comps
## X    94.97    99.78
## y    88.28    91.46</code></pre>
<p>위 요약표는 하나의 잠재변수와 두 개의 잠재변수를 이용하였을 때 추정된 회귀모형들이 종속변수의 총 변량을 각각 88.2814529%와 91.4578959% 만큼을 설명함을 알려준다. 이는 앞 장에서 살펴보았던 주성분 회귀모형보다 더 높은 수치이다.</p>
</div>
<div id="plsr-model" class="section level3" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> PLS 모형</h3>
<p>종속변수가 하나만 존재하는 경우에는 데이터 행렬 <span class="math inline">\(\mathbf{X}\)</span>와 종속변수벡터 <span class="math inline">\(\mathbf{y}\)</span>가 동일한 잠재변수로 설명된다고 가정할 수 있다. (<span class="math inline">\(n \times k\)</span>) 데이터 행렬 <span class="math inline">\(\mathbf{X}\)</span>와 종속변수벡터 <span class="math inline">\(\mathbf{y}\)</span>에 대하여 동시에 <span class="math inline">\(A\)</span>개의 잠재변수벡터 <span class="math inline">\(\mathbf{t}_1, \cdots, \mathbf{t}_A\)</span>로 설명하는 모형을 아래와 같이 기술해보자.</p>
<p><span class="math display" id="eq:plsr-y-single" id="eq:plsr-x-single">\[\begin{eqnarray}
\mathbf{X} &amp;=&amp; \mathbf{t}_1 \mathbf{p}_1^\top + \mathbf{t}_2 \mathbf{p}_2^\top + \cdots + \mathbf{t}_A \mathbf{p}_A^\top + \mathbf{E} \tag{4.1}\\
\mathbf{y} &amp;=&amp; \mathbf{t}_1 b_1 + \mathbf{t}_2 b_2 + \cdots + \mathbf{t}_A b_A + \mathbf{f} \tag{4.2}
\end{eqnarray}\]</span></p>
<p>여기서 계수벡터 <span class="math inline">\(\mathbf{p}_a\)</span>는 <span class="math inline">\(\mathbf{X}\)</span>에 해당하는 로딩(loading)을, 그리고 계수 <span class="math inline">\(b_a\)</span>는 <span class="math inline">\(\mathbf{y}\)</span>에 해당하는 로딩을 나타내며, <span class="math inline">\(\mathbf{E}\)</span>와 <span class="math inline">\(\mathbf{f}\)</span>는 각 모형에 해당하는 오차항(행렬 또는 벡터)이다.</p>
<p>위 모형을 (<span class="math inline">\(n \times A\)</span>) 잠재변수 행렬 <span class="math inline">\(\mathbf{T} = \left[\mathbf{t}_1 \, \cdots \mathbf{t}_A \right]\)</span>와 (<span class="math inline">\(k \times A\)</span>) 로딩행렬 <span class="math inline">\(\mathbf{P} = \left[\mathbf{p}_1 \, \cdots \mathbf{p}_A \right]\)</span>, 그리고 로딩벡터 <span class="math inline">\(\mathbf{b} = \left[b_1 \, \cdots b_A \right]^\top\)</span> 을 이용하여 아래와 같이 행렬식으로 나타낼 수 있다.</p>
<p><span class="math display" id="eq:plsr-y-single-matrix" id="eq:plsr-x-single-matrix">\[\begin{eqnarray}
\mathbf{X} &amp;=&amp; \mathbf{T}\mathbf{P}^\top + \mathbf{E} \tag{4.3}\\
\mathbf{y} &amp;=&amp; \mathbf{T}\mathbf{b} + \mathbf{f} \tag{4.4}
\end{eqnarray}\]</span></p>
</div>
<div id="plsr-single-nipals" class="section level3" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> NIPALS 알고리즘</h3>
<ul>
<li><strong>[단계 0]</strong> 반복알고리즘 수행을 위한 초기화를 한다. <span class="math inline">\(a \leftarrow 1\)</span>, <span class="math inline">\(\mathbf{X}_a \leftarrow \mathbf{X}\)</span>, <span class="math inline">\(\mathbf{y}_a \leftarrow \mathbf{y}\)</span>.</li>
<li><strong>[단계 1]</strong> <span class="math inline">\(\mathbf{X}_a\)</span>을 다중종속변수 행렬으로, <span class="math inline">\(\mathbf{y}_a\)</span>를 독립변수 벡터로 하는 회귀모형으로부터 기울기 <span class="math inline">\(\mathbf{w}_a = [w_{a1} \, \cdots \, w_{ak}]^\top\)</span>를 산출한다.
<span class="math display">\[\mathbf{w}_a \leftarrow \left. \mathbf{X}_a^\top \mathbf{y}_a \middle/ \mathbf{y}_a^\top \mathbf{y}_a \right.  \]</span></li>
<li><strong>[단계 2]</strong> 기울기 벡터 <span class="math inline">\(\mathbf{w}_a\)</span>의 크기가 1이 되도록 한다.
<span class="math display">\[\left. \mathbf{w}_a \leftarrow \mathbf{w}_a \middle/ \sqrt{\mathbf{w}_a^\top \mathbf{w}_a} \right.\]</span></li>
<li><strong>[단계 3]</strong> 잠재변수 <span class="math inline">\(\mathbf{t}_a\)</span>를 행렬 <span class="math inline">\(\mathbf{X}_a\)</span>의 각 열의 가중평균으로 구한다. 이 때, 가중치는 기울기 벡터 <span class="math inline">\(\mathbf{w}_a\)</span>를 이용한다.
<span class="math display">\[\mathbf{t}_a \leftarrow \mathbf{X}_a \mathbf{w}_a\]</span></li>
<li><strong>[단계 4]</strong> 식 <a href="plsr.html#eq:plsr-x-single">(4.1)</a>와 같이 <span class="math inline">\(\mathbf{X}_a\)</span>을 다중종속변수 행렬으로, <span class="math inline">\(\mathbf{t}_a\)</span>를 독립변수 벡터로 하는 회귀모형으로부터 로딩벡터 <span class="math inline">\(\mathbf{p}_a\)</span>를 구한다.
<span class="math display">\[\mathbf{p}_a \leftarrow \left. \mathbf{X}_a^\top \mathbf{t}_a \middle/ \mathbf{t}_a^\top \mathbf{t}_a \right.\]</span></li>
<li><strong>[단계 5]</strong> 로딩벡터 <span class="math inline">\(\mathbf{p}_a\)</span>의 크기를 1로 조정하고, 잠재변수 벡터 <span class="math inline">\(\mathbf{t}_a\)</span>와 기울기 벡터 <span class="math inline">\(\mathbf{w}_a\)</span>의 크기를 그에 따라 보정한다.
<span class="math display">\[d \leftarrow \sqrt{\mathbf{p}_a^\top \mathbf{p}_a}, \, \mathbf{t}_a \leftarrow \mathbf{t}_a d, \, \mathbf{w}_a \leftarrow \mathbf{w}_a d, \, \mathbf{p}_a \leftarrow \frac{1}{d} \mathbf{p}_a \]</span></li>
<li><strong>[단계 6]</strong> 식 <a href="plsr.html#eq:plsr-y-single">(4.2)</a>와 같이 잠재변수 <span class="math inline">\(\mathbf{t}_a\)</span>를 종속변수 <span class="math inline">\(\mathbf{y}_a\)</span>에 회귀시킬 때 계수 <span class="math inline">\(b_a\)</span>를 산출한다.
<span class="math display">\[b_a \leftarrow \left. \mathbf{y}_a^\top \mathbf{t}_a \middle/ \mathbf{t}_a^\top \mathbf{t}_a \right. \]</span></li>
<li><strong>[단계 7]</strong> 독립변수 행렬 <span class="math inline">\(\mathbf{X}_a\)</span>와 종속변수벡터 <span class="math inline">\(\mathbf{y}_a\)</span>로부터 새로 얻어진 잠재변수 벡터 <span class="math inline">\(\mathbf{t}_a\)</span>가 설명하는 부분을 제거하고 나머지 변동만을 담은 독립변수 행렬 <span class="math inline">\(\mathbf{X}_{a + 1}\)</span>과 종속변수벡터 <span class="math inline">\(\mathbf{y}_{a + 1}\)</span>을 구한다.
<span class="math display">\[\mathbf{X}_{a + 1} \leftarrow \mathbf{X}_a - \mathbf{t}_a \mathbf{p}_a^\top, \, \mathbf{y}_{a + 1} \leftarrow \mathbf{y}_a - \mathbf{t}_a b_a\]</span></li>
<li><strong>[단계 8]</strong> <span class="math inline">\(a \leftarrow a + 1\)</span>로 업데이트하고, [단계 1]로 돌아간다. [단계 1] - [단계 8]의 과정을 <span class="math inline">\(A\)</span>개의 잠재변수를 얻을 때까지 반복한다.</li>
</ul>
<p>위 NIPALS 알고리즘을 아래 <code>nipals_plsr</code>이라는 함수로 구현해보자. 이 때, 함수의 입력변수는 아래와 같다.</p>
<ul>
<li><code>X</code>: 평균조정된 (<span class="math inline">\(n \times k\)</span>) 행렬</li>
<li><code>y</code>: 평균조정된 종속변수 벡터</li>
<li><code>A</code>: 잠재변수 개수</li>
</ul>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="plsr.html#cb108-1" aria-hidden="true" tabindex="-1"></a>nipals_plsr <span class="ot">&lt;-</span> <span class="cf">function</span>(X, y, <span class="at">A =</span> <span class="cn">NULL</span>) {</span>
<span id="cb108-2"><a href="plsr.html#cb108-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is_empty</span>(A) <span class="sc">||</span> (A <span class="sc">&gt;</span> <span class="fu">min</span>(<span class="fu">dim</span>(X)))) {</span>
<span id="cb108-3"><a href="plsr.html#cb108-3" aria-hidden="true" tabindex="-1"></a>    A <span class="ot">&lt;-</span> <span class="fu">min</span>(<span class="fu">dim</span>(X))</span>
<span id="cb108-4"><a href="plsr.html#cb108-4" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb108-5"><a href="plsr.html#cb108-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb108-6"><a href="plsr.html#cb108-6" aria-hidden="true" tabindex="-1"></a>  Tmat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> <span class="fu">nrow</span>(X), <span class="at">ncol =</span> A)</span>
<span id="cb108-7"><a href="plsr.html#cb108-7" aria-hidden="true" tabindex="-1"></a>  Wmat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> <span class="fu">ncol</span>(X), <span class="at">ncol =</span> A)</span>
<span id="cb108-8"><a href="plsr.html#cb108-8" aria-hidden="true" tabindex="-1"></a>  Pmat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> <span class="fu">ncol</span>(X), <span class="at">ncol =</span> A)</span>
<span id="cb108-9"><a href="plsr.html#cb108-9" aria-hidden="true" tabindex="-1"></a>  b <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="st">&quot;numeric&quot;</span>, <span class="at">length =</span> A)</span>
<span id="cb108-10"><a href="plsr.html#cb108-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb108-11"><a href="plsr.html#cb108-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (a <span class="cf">in</span> <span class="fu">seq_len</span>(A)) {</span>
<span id="cb108-12"><a href="plsr.html#cb108-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 단계 1</span></span>
<span id="cb108-13"><a href="plsr.html#cb108-13" aria-hidden="true" tabindex="-1"></a>    Wmat[, a] <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(X <span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span> y))</span>
<span id="cb108-14"><a href="plsr.html#cb108-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb108-15"><a href="plsr.html#cb108-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 단계 2</span></span>
<span id="cb108-16"><a href="plsr.html#cb108-16" aria-hidden="true" tabindex="-1"></a>    Wmat[, a] <span class="ot">&lt;-</span> Wmat[, a] <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>(Wmat[, a] <span class="sc">^</span> <span class="dv">2</span>))</span>
<span id="cb108-17"><a href="plsr.html#cb108-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-18"><a href="plsr.html#cb108-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 단계 3</span></span>
<span id="cb108-19"><a href="plsr.html#cb108-19" aria-hidden="true" tabindex="-1"></a>    Tmat[, a] <span class="ot">&lt;-</span> X <span class="sc">%*%</span> Wmat[, a]</span>
<span id="cb108-20"><a href="plsr.html#cb108-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb108-21"><a href="plsr.html#cb108-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 단계 4</span></span>
<span id="cb108-22"><a href="plsr.html#cb108-22" aria-hidden="true" tabindex="-1"></a>    Pmat[, a] <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(X <span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span> Tmat[, a]))</span>
<span id="cb108-23"><a href="plsr.html#cb108-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb108-24"><a href="plsr.html#cb108-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 단계 5</span></span>
<span id="cb108-25"><a href="plsr.html#cb108-25" aria-hidden="true" tabindex="-1"></a>    p_size <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>(Pmat[, a] <span class="sc">^</span> <span class="dv">2</span>))</span>
<span id="cb108-26"><a href="plsr.html#cb108-26" aria-hidden="true" tabindex="-1"></a>    Tmat[, a] <span class="ot">&lt;-</span> Tmat[, a] <span class="sc">*</span> p_size</span>
<span id="cb108-27"><a href="plsr.html#cb108-27" aria-hidden="true" tabindex="-1"></a>    Wmat[, a] <span class="ot">&lt;-</span> Wmat[, a] <span class="sc">*</span> p_size</span>
<span id="cb108-28"><a href="plsr.html#cb108-28" aria-hidden="true" tabindex="-1"></a>    Pmat[, a] <span class="ot">&lt;-</span> Pmat[, a] <span class="sc">/</span> p_size</span>
<span id="cb108-29"><a href="plsr.html#cb108-29" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb108-30"><a href="plsr.html#cb108-30" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 단계 6</span></span>
<span id="cb108-31"><a href="plsr.html#cb108-31" aria-hidden="true" tabindex="-1"></a>    b[a] <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(y <span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span> Tmat[, a]))</span>
<span id="cb108-32"><a href="plsr.html#cb108-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-33"><a href="plsr.html#cb108-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 단계 7</span></span>
<span id="cb108-34"><a href="plsr.html#cb108-34" aria-hidden="true" tabindex="-1"></a>    X <span class="ot">&lt;-</span> X <span class="sc">-</span> Tmat[, a] <span class="sc">%*%</span> <span class="fu">t</span>(Pmat[, a])</span>
<span id="cb108-35"><a href="plsr.html#cb108-35" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> y <span class="sc">-</span> Tmat[, a] <span class="sc">%*%</span> <span class="fu">t</span>(b[a])</span>
<span id="cb108-36"><a href="plsr.html#cb108-36" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb108-37"><a href="plsr.html#cb108-37" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb108-38"><a href="plsr.html#cb108-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">T =</span> Tmat, <span class="at">W =</span> Wmat, <span class="at">P =</span> Pmat, <span class="at">b =</span> b))</span>
<span id="cb108-39"><a href="plsr.html#cb108-39" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb108-40"><a href="plsr.html#cb108-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-41"><a href="plsr.html#cb108-41" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(train_df[, <span class="fu">c</span>(<span class="st">&quot;x1&quot;</span>, <span class="st">&quot;x2&quot;</span>, <span class="st">&quot;x3&quot;</span>)])</span>
<span id="cb108-42"><a href="plsr.html#cb108-42" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> train_df<span class="sc">$</span>y</span>
<span id="cb108-43"><a href="plsr.html#cb108-43" aria-hidden="true" tabindex="-1"></a>nipals_fit <span class="ot">&lt;-</span> <span class="fu">nipals_plsr</span>(X, y, <span class="at">A =</span> <span class="dv">2</span>)</span>
<span id="cb108-44"><a href="plsr.html#cb108-44" aria-hidden="true" tabindex="-1"></a>nipals_fit</span></code></pre></div>
<pre><code>## $T
##            [,1]       [,2]
## [1,] -6.3243200 -2.0380766
## [2,] -7.8584372 -0.5965965
## [3,] -3.6317877  1.5429616
## [4,]  0.9079469  1.9745198
## [5,]  5.7294582  0.7158171
## [6,] 11.1771398 -1.5986253
## 
## $W
##            [,1]      [,2]
## [1,]  0.2817766 0.6579688
## [2,]  0.3130851 0.6388931
## [3,] -0.9079469 0.4245052
## 
## $P
##            [,1]      [,2]
## [1,]  0.2537679 0.5424154
## [2,]  0.2858180 0.7279599
## [3,] -0.9240724 0.4193565
## 
## $b
## [1] 2.924570 2.464658</code></pre>
<p>식 <a href="plsr.html#eq:plsr-x-single-matrix">(4.3)</a>과 <a href="plsr.html#eq:plsr-y-single-matrix">(4.4)</a>에서, 잠재변수 행렬 <span class="math inline">\(\mathbf{T}\)</span>가 주어졌다 가정할 때 로딩행렬 및 벡터 <span class="math inline">\(\mathbf{P}\)</span>와 <span class="math inline">\(\mathbf{b}\)</span>는 아래와 같이 추정된다.</p>
<p><span class="math display" id="eq:plsr-y-single-loading-est" id="eq:plsr-x-single-loading-est">\[\begin{eqnarray}
\hat{\mathbf{P}}^\top = \left(\mathbf{T}^\top \mathbf{T}\right)^{-1} \mathbf{T}^\top \mathbf{X} \tag{4.5}\\
\hat{\mathbf{b}} = \left(\mathbf{T}^\top \mathbf{T}\right)^{-1} \mathbf{T}^\top \mathbf{y} \tag{4.6}
\end{eqnarray}\]</span></p>
<p>위 NIPALS 알고리즘 수행 결과에서 이를 확인해보자.</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="plsr.html#cb110-1" aria-hidden="true" tabindex="-1"></a>P_hat <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">solve</span>(<span class="fu">t</span>(nipals_fit<span class="sc">$</span>T) <span class="sc">%*%</span> nipals_fit<span class="sc">$</span>T) <span class="sc">%*%</span> <span class="fu">t</span>(nipals_fit<span class="sc">$</span>T) <span class="sc">%*%</span> X)</span>
<span id="cb110-2"><a href="plsr.html#cb110-2" aria-hidden="true" tabindex="-1"></a><span class="fu">all</span>(<span class="fu">near</span>(nipals_fit<span class="sc">$</span>P, P_hat))</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="plsr.html#cb112-1" aria-hidden="true" tabindex="-1"></a>b_hat <span class="ot">&lt;-</span> <span class="fu">as.vector</span>(<span class="fu">t</span>(<span class="fu">solve</span>(<span class="fu">t</span>(nipals_fit<span class="sc">$</span>T) <span class="sc">%*%</span> nipals_fit<span class="sc">$</span>T) <span class="sc">%*%</span> </span>
<span id="cb112-2"><a href="plsr.html#cb112-2" aria-hidden="true" tabindex="-1"></a>                       <span class="fu">t</span>(nipals_fit<span class="sc">$</span>T) <span class="sc">%*%</span> <span class="fu">as.matrix</span>(y, <span class="at">ncol =</span> <span class="dv">1</span>)))</span>
<span id="cb112-3"><a href="plsr.html#cb112-3" aria-hidden="true" tabindex="-1"></a><span class="fu">all</span>(<span class="fu">near</span>(nipals_fit<span class="sc">$</span>b, b_hat))</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
</div>
<div id="plsr-single-transform" class="section level3" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> 회귀식 변환</h3>
<p>위 NIPALS 알고리즘 수행 결과를 원래 독립변수 <span class="math inline">\(\mathbf{X}\)</span>와 종속변수 <span class="math inline">\(\mathbf{y}\)</span>에 대한 식으로 변환하는 방법은 아래와 같다.</p>
<p>잠재변수행렬 <span class="math inline">\(\mathbf{T}\)</span>는 아래와 같이 독립변수 행렬 <span class="math inline">\(\mathbf{X}\)</span>와 가중치행렬 <span class="math inline">\(\mathbf{W}\)</span>, 그리고 로딩행렬 <span class="math inline">\(\mathbf{P}\)</span>의 연산으로 표현된다.</p>
<p><span class="math display" id="eq:plsr-x-t-relation">\[\begin{equation}
\mathbf{T} = \mathbf{X} \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1} \tag{4.7}
\end{equation}\]</span></p>
<p>이를 식 <a href="plsr.html#eq:plsr-y-single-matrix">(4.4)</a>에 대입하면,</p>
<p><span class="math display" id="eq:plsr-single-beta">\[\begin{equation}
\begin{split}
\mathbf{y} &amp;= \mathbf{X} \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1} \mathbf{b} + \mathbf{f}\\
&amp;= \mathbf{X} \boldsymbol{\beta}_{PLS} + \mathbf{f}
\end{split} \tag{4.8}
\end{equation}\]</span></p>
<p>따라서, 원 독립변수 행렬 <span class="math inline">\(\mathbf{X}\)</span>에 대한 회귀계수는 아래와 같이 정리된다.</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{\beta}_{PLS} = \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1} \mathbf{b}
\end{equation}\]</span></p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="plsr.html#cb114-1" aria-hidden="true" tabindex="-1"></a>beta_pls <span class="ot">&lt;-</span> nipals_fit<span class="sc">$</span>W <span class="sc">%*%</span> </span>
<span id="cb114-2"><a href="plsr.html#cb114-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">solve</span>(<span class="fu">t</span>(nipals_fit<span class="sc">$</span>P) <span class="sc">%*%</span> nipals_fit<span class="sc">$</span>W) <span class="sc">%*%</span></span>
<span id="cb114-3"><a href="plsr.html#cb114-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>(nipals_fit<span class="sc">$</span>b, <span class="at">ncol =</span> 1L)</span>
<span id="cb114-4"><a href="plsr.html#cb114-4" aria-hidden="true" tabindex="-1"></a>beta_pls</span></code></pre></div>
<pre><code>##           [,1]
## [1,]  2.475395
## [2,]  2.523238
## [3,] -1.704636</code></pre>
</div>
<div id="plsr-sst" class="section level3" number="4.2.5">
<h3><span class="header-section-number">4.2.5</span> 제곱합 분해</h3>
<p><span class="math inline">\(A\)</span>개의 잠재변수를 사용하는 모형에 대하여 모형이 설명하는 <span class="math inline">\(\mathbf{y}\)</span>의 변동(제곱합)을 <span class="math inline">\({SSR}\)</span>, 설명하지 못하는 변동을 <span class="math inline">\({SSE}\)</span>라 할 때, <span class="math inline">\(\mathbf{y}\)</span>의 전체제곱합(<span class="math inline">\({SST}\)</span>)은 다음과 같이 분해된다.</p>
<p><span class="math display">\[{SST} = {SS}(\mathbf{y}) = {SSR} + {SSE}\]</span></p>
<p>여기서 <span class="math inline">\({SS}()\)</span>는 제곱합 함수로, 임의의 벡터 <span class="math inline">\(\mathbf{x}\)</span>에 대해 아래와 같이 정의된다.</p>
<p><span class="math display">\[
{SS}(\mathbf{x}) = \mathbf{x}^\top \mathbf{x}
\]</span></p>
<p>이 때, <span class="math inline">\({SSR}\)</span>은 다음과 같이 산출할 수 있다.</p>
<p><span class="math display" id="eq:plsr-ssr">\[\begin{equation}
\begin{split}
SSR &amp;= \sum_{a = 1}^{A} SS(b_a \mathbf{t}_a)\\
&amp;= \sum_{a = 1}^{A} b_a^2 SS(\mathbf{t}_a)
\end{split} \tag{4.9}
\end{equation}\]</span></p>
<p><span class="math inline">\(a\)</span>번째 잠재변수 <span class="math inline">\(\mathbf{t}_a\)</span>가 <span class="math inline">\(\mathbf{y}\)</span>를 설명하는 회귀제곱합을 <span class="math inline">\(SSR_a = b_a^2 SS(\mathbf{t}_a)\)</span>라 할 때, <span class="math inline">\(SSR\)</span>은 아래와 같이 분해된다.</p>
<p><span class="math display">\[
SSR = \sum_{a = 1}^{A} SSR_a
\]</span></p>
<p>위 예제에서 2개의 잠재변수가 설명하는 <span class="math inline">\(\mathbf{y}\)</span>의 총변동을 PLS 결과를 이용하여 계산하면 아래와 같다.</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="plsr.html#cb116-1" aria-hidden="true" tabindex="-1"></a>SSR_a <span class="ot">&lt;-</span> nipals_fit<span class="sc">$</span>b <span class="sc">^</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">diag</span>(<span class="fu">t</span>(nipals_fit<span class="sc">$</span>T) <span class="sc">%*%</span> nipals_fit<span class="sc">$</span>T)</span>
<span id="cb116-2"><a href="plsr.html#cb116-2" aria-hidden="true" tabindex="-1"></a>SSR_a</span></code></pre></div>
<pre><code>## [1] 2339.45850   84.17574</code></pre>
<p>이 때, 각 주성분이 설명하는 <span class="math inline">\(\mathbf{y}\)</span> 변동의 기여율을 아래와 같이 정의한다.</p>
<p><span class="math display" id="eq:plsr-rsq">\[\begin{equation}
\Delta R_a^2 = \frac{SSR_a}{SST} \tag{4.10}
\end{equation}\]</span></p>
<p>앞 예제에서 각 잠재변수의 <span class="math inline">\(\mathbf{y}\)</span> 변동에 대한 기여율을 계산해보자.</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="plsr.html#cb118-1" aria-hidden="true" tabindex="-1"></a>SST <span class="ot">&lt;-</span> <span class="fu">sum</span>(y <span class="sc">^</span> <span class="dv">2</span>)</span>
<span id="cb118-2"><a href="plsr.html#cb118-2" aria-hidden="true" tabindex="-1"></a>delta_Rsq <span class="ot">&lt;-</span> SSR_a <span class="sc">/</span> SST</span>
<span id="cb118-3"><a href="plsr.html#cb118-3" aria-hidden="true" tabindex="-1"></a>delta_Rsq</span></code></pre></div>
<pre><code>## [1] 0.88281453 0.03176443</code></pre>
<p>잠재변수 <span class="math inline">\(A\)</span>개를 이용한 PLS 모형이 설명하는 <span class="math inline">\(\mathbf{y}\)</span>의 총 변동에 대한 기여도(<span class="math inline">\(SSR / SST\)</span>)은 아래와 같이 각 잠재변수의 기여도의 합으로 산출된다.</p>
<p><span class="math display">\[
R^2 = \frac{SSR}{SST} = \frac{\sum_{a = 1}^{A} SSR_a}{SST} = \sum_{a = 1}^{A} \Delta R_a^2
\]</span></p>
<p>따라서, 잠재변수 <span class="math inline">\(A\)</span>개를 이용한 PLS 모형이 설명하는 <span class="math inline">\(\mathbf{y}\)</span>의 총 변동에 대한 기여도(<span class="math inline">\(SSR / SST\)</span>)은 아래와 같이 각 잠재변수의 기여도의 합으로 산출된다.</p>
<p>앞 예제에서 잠재변수 2개를 이용한 최종모형이 설명하는 <span class="math inline">\(\mathbf{y}\)</span>의 변동은 아래와 같다.</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="plsr.html#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(delta_Rsq)</span></code></pre></div>
<pre><code>## [1] 0.914579</code></pre>
<p>이는 앞 <a href="plsr.html#plsr-basic-script">4.2.1</a>절에서 R 패키지 <code>pls</code>를 이용하여 얻어진 결과와 동일함을 확인할 수 있다.</p>
<p>한편, 잠재변수들이 독립변수행렬 <span class="math inline">\(\mathbf{X}\)</span>의 변동을 얼마나 설명하는지 동시에 검토할 필요가 있다. 각 잠재변수들의 제곱합 <span class="math inline">\(SS(\mathbf{t}_a)\)</span>의 <span class="math inline">\(\mathbf{X}\)</span>의 총변동 (<span class="math inline">\(SS(\mathbf{X})\)</span>)에 대한 비율이 그 기여율을 설명한다.</p>
<p>앞 예제에서 각각의 잠재변수의 <span class="math inline">\(\mathbf{X}\)</span>에 대한 기여율은 아래와 같다.</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="plsr.html#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="fu">diag</span>(<span class="fu">t</span>(nipals_fit<span class="sc">$</span>T) <span class="sc">%*%</span> nipals_fit<span class="sc">$</span>T) <span class="sc">/</span> <span class="fu">sum</span>(<span class="fu">diag</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X))</span></code></pre></div>
<pre><code>## [1] 0.94972728 0.04811507</code></pre>
<p>잠재변수 2개를 이용한 PLS 모형의 <span class="math inline">\(\mathbf{X}\)</span>에 대한 기여율은 아래와 같다.</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="plsr.html#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">diag</span>(<span class="fu">t</span>(nipals_fit<span class="sc">$</span>T) <span class="sc">%*%</span> nipals_fit<span class="sc">$</span>T)) <span class="sc">/</span> <span class="fu">sum</span>(<span class="fu">diag</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X))</span></code></pre></div>
<pre><code>## [1] 0.9978423</code></pre>
<p>잠재변수 2개가 독립변수행렬의 대부분의 변동을 설명함을 알 수 있으며, 위 결과는 역시 앞 <a href="plsr.html#plsr-basic-script">4.2.1</a>절에서 R 패키지 <code>pls</code>를 이용하여 얻어진 결과와 동일함을 확인할 수 있다.</p>
</div>
<div id="plsr-variable-importance" class="section level3" number="4.2.6">
<h3><span class="header-section-number">4.2.6</span> 독립변수의 중요도</h3>
<p>원래의 각 독립변수가 종속변수를 설명하는 데 얼마나 영향을 미치는지는 공정분석 등에서 매우 중요하다. 식 <a href="plsr.html#eq:plsr-x-t-relation">(4.7)</a>의 <span class="math inline">\(\mathbf{T}\)</span>와 <span class="math inline">\(\mathbf{X}\)</span>간의 관계식을 아래와 같이 다시 표현해보자.</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
\mathbf{T} &amp;= \mathbf{X} \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1}\\
&amp;= \mathbf{X} \mathbf{W}^{*}
\end{split}
\end{equation}\]</span></p>
<p>이 때, <span class="math inline">\(\mathbf{W}^{*} = \left[\mathbf{w}^{*}_1 \, \cdots \, \mathbf{w}^{*}_A \right]\)</span>를 변환가중치행렬이라 한다.</p>
<p><span class="math display">\[\begin{equation}
\mathbf{W}^{*} = \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1}
\end{equation}\]</span></p>
<p>이 때, 각 잠재변수가 설명하는 <span class="math inline">\(\mathbf{y}\)</span>의 변동과 각 독립변수가 각 잠재변수에 기여하는 가중치를 고려하여, <span class="math inline">\(j\)</span>번째 독립변수의 종속변수에 대한 중요도 척도로 <span class="math inline">\(VIP\)</span>(variable importance in projection)를 다음과 같이 정의한다.</p>
<p><span class="math display" id="eq:plsr-single-vip">\[\begin{equation}
VIP_j = \sqrt{\frac{k}{SSR} \sum_{a = 1}^{A} SSR_a \left( w^{*}_{aj} \middle/ \| \mathbf{w}^{*}_a \|  \right)^2} \tag{4.11}
\end{equation}\]</span></p>
<p>위 정의에 의하면 다음이 성립한다.</p>
<p><span class="math display">\[
\sum_{j = 1}^{k} VIP_j^2 = k
\]</span></p>
<p>즉, 독립변수당 중요도 제곱의 평균은 1이 된다. 이에 따라, 통상 <span class="math inline">\(VIP\)</span>가 1보다 큰 독립변수를 의미있는 변수로 간주한다.</p>
<p>앞 예제에 대해 각 변수의 중요도를 계산해보자.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="plsr.html#cb126-1" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="fu">ncol</span>(X)</span>
<span id="cb126-2"><a href="plsr.html#cb126-2" aria-hidden="true" tabindex="-1"></a>Wx <span class="ot">&lt;-</span> nipals_fit<span class="sc">$</span>W <span class="sc">%*%</span> <span class="fu">solve</span>(<span class="fu">t</span>(nipals_fit<span class="sc">$</span>P) <span class="sc">%*%</span> nipals_fit<span class="sc">$</span>W)</span>
<span id="cb126-3"><a href="plsr.html#cb126-3" aria-hidden="true" tabindex="-1"></a>VIP <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(</span>
<span id="cb126-4"><a href="plsr.html#cb126-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">colSums</span>(</span>
<span id="cb126-5"><a href="plsr.html#cb126-5" aria-hidden="true" tabindex="-1"></a>    k <span class="sc">/</span> <span class="fu">sum</span>(SSR_a) <span class="sc">*</span> SSR_a <span class="sc">*</span> </span>
<span id="cb126-6"><a href="plsr.html#cb126-6" aria-hidden="true" tabindex="-1"></a>      (<span class="fu">t</span>(Wx <span class="sc">^</span> <span class="dv">2</span>) <span class="sc">/</span><span class="fu">diag</span>(<span class="fu">t</span>(Wx) <span class="sc">%*%</span> Wx))</span>
<span id="cb126-7"><a href="plsr.html#cb126-7" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb126-8"><a href="plsr.html#cb126-8" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb126-9"><a href="plsr.html#cb126-9" aria-hidden="true" tabindex="-1"></a>VIP</span></code></pre></div>
<pre><code>## [1] 0.5246196 0.5715532 1.5485804</code></pre>
<p>즉, <span class="math inline">\(x_3\)</span>가 가장 영향력있는 변수라 할 수 있겠다.</p>
</div>
</div>
<div id="plsr-multivariate-target" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> 다수의 종속변수의 경우</h2>
<p><span class="math inline">\(m\)</span>개의 종속변수가 존재하여, 종속변수 데이터가 벡터가 아닌 (<span class="math inline">\(n \times m\)</span>) 행렬</p>
<p><span class="math display">\[\mathbf{Y} = \left[ \mathbf{y}_1 \, \cdots \, \mathbf{y}_m \right]\]</span></p>
<p>으로 표현될 때, 각각의 종속변수에 대해 따로 잠재변수를 산출하기보다는, 여러 종속변수를 설명하는 공통의 잠재변수행렬 <span class="math inline">\(\mathbf{T}\)</span>를 산출하는 것이 합리적이라 할 수 있다.</p>
<div id="plsr-multivariate-basic-script" class="section level3" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> 기본 R 스크립트</h3>
<p>4개의 독립변수 및 2개의 종속변수에 대한 평균조정된 데이터가 다음과 같다.</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="plsr.html#cb128-1" aria-hidden="true" tabindex="-1"></a>train_df <span class="ot">&lt;-</span> <span class="fu">tribble</span>(</span>
<span id="cb128-2"><a href="plsr.html#cb128-2" aria-hidden="true" tabindex="-1"></a>  <span class="sc">~</span>x1, <span class="sc">~</span>x2, <span class="sc">~</span>x3, <span class="sc">~</span>x4, <span class="sc">~</span>y1, <span class="sc">~</span>y2,</span>
<span id="cb128-3"><a href="plsr.html#cb128-3" aria-hidden="true" tabindex="-1"></a>  <span class="sc">-</span><span class="dv">1</span>, <span class="sc">-</span><span class="fl">0.5</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">5.9</span>, <span class="sc">-</span><span class="dv">10</span>,</span>
<span id="cb128-4"><a href="plsr.html#cb128-4" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span>, <span class="fl">1.1</span>, <span class="sc">-</span><span class="dv">6</span>, <span class="sc">-</span><span class="dv">6</span>, <span class="sc">-</span><span class="fl">3.7</span>, <span class="sc">-</span><span class="dv">2</span>,</span>
<span id="cb128-5"><a href="plsr.html#cb128-5" aria-hidden="true" tabindex="-1"></a>  <span class="dv">0</span>, <span class="fl">0.3</span>, <span class="sc">-</span><span class="dv">5</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">11</span>,</span>
<span id="cb128-6"><a href="plsr.html#cb128-6" aria-hidden="true" tabindex="-1"></a>  <span class="sc">-</span><span class="dv">3</span>, <span class="sc">-</span><span class="fl">3.2</span>, <span class="sc">-</span><span class="dv">9</span>, <span class="dv">19</span>, <span class="fl">7.7</span>, <span class="sc">-</span><span class="dv">22</span>,</span>
<span id="cb128-7"><a href="plsr.html#cb128-7" aria-hidden="true" tabindex="-1"></a>  <span class="dv">4</span>, <span class="fl">1.2</span>, <span class="dv">14</span>, <span class="sc">-</span><span class="dv">12</span>, <span class="sc">-</span><span class="fl">7.5</span>, <span class="dv">4</span>,</span>
<span id="cb128-8"><a href="plsr.html#cb128-8" aria-hidden="true" tabindex="-1"></a>  <span class="sc">-</span><span class="dv">2</span>, <span class="sc">-</span><span class="fl">2.6</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">9</span>, <span class="fl">2.8</span>, <span class="dv">1</span>,</span>
<span id="cb128-9"><a href="plsr.html#cb128-9" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span>, <span class="fl">3.7</span>, <span class="dv">9</span>, <span class="sc">-</span><span class="dv">9</span>, <span class="sc">-</span><span class="fl">6.2</span>, <span class="dv">18</span></span>
<span id="cb128-10"><a href="plsr.html#cb128-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb128-11"><a href="plsr.html#cb128-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-12"><a href="plsr.html#cb128-12" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(</span>
<span id="cb128-13"><a href="plsr.html#cb128-13" aria-hidden="true" tabindex="-1"></a>  train_df, <span class="at">booktabs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb128-14"><a href="plsr.html#cb128-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">align =</span> <span class="fu">rep</span>(<span class="st">&quot;r&quot;</span>, <span class="fu">ncol</span>(train_df)),</span>
<span id="cb128-15"><a href="plsr.html#cb128-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">caption =</span> <span class="st">&quot;다수의 종속변수에 대한 부분최소자승 회귀분석 예제 데이터&quot;</span></span>
<span id="cb128-16"><a href="plsr.html#cb128-16" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<table>
<caption><span id="tab:plsr-multivariate-example-data">Table 4.2: </span>다수의 종속변수에 대한 부분최소자승 회귀분석 예제 데이터</caption>
<thead>
<tr class="header">
<th align="right">x1</th>
<th align="right">x2</th>
<th align="right">x3</th>
<th align="right">x4</th>
<th align="right">y1</th>
<th align="right">y2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">-1</td>
<td align="right">-0.5</td>
<td align="right">-1</td>
<td align="right">1</td>
<td align="right">5.9</td>
<td align="right">-10</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">1.1</td>
<td align="right">-6</td>
<td align="right">-6</td>
<td align="right">-3.7</td>
<td align="right">-2</td>
</tr>
<tr class="odd">
<td align="right">0</td>
<td align="right">0.3</td>
<td align="right">-5</td>
<td align="right">-2</td>
<td align="right">1.0</td>
<td align="right">11</td>
</tr>
<tr class="even">
<td align="right">-3</td>
<td align="right">-3.2</td>
<td align="right">-9</td>
<td align="right">19</td>
<td align="right">7.7</td>
<td align="right">-22</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="right">1.2</td>
<td align="right">14</td>
<td align="right">-12</td>
<td align="right">-7.5</td>
<td align="right">4</td>
</tr>
<tr class="even">
<td align="right">-2</td>
<td align="right">-2.6</td>
<td align="right">-2</td>
<td align="right">9</td>
<td align="right">2.8</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">3.7</td>
<td align="right">9</td>
<td align="right">-9</td>
<td align="right">-6.2</td>
<td align="right">18</td>
</tr>
</tbody>
</table>
<p>앞서 하나의 종속변수를 다루는 경우와 마찬가지로, R 패키지 <code>pls</code> 내의 함수 <code>plsr()</code>을 이용하여 PLS 모형을 추정할 수 있다. 이 때, <code>formula</code> 입력 시 종속변수의 행렬을 이용한다.</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="plsr.html#cb129-1" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(train_df[, <span class="fu">c</span>(<span class="st">&quot;x1&quot;</span>, <span class="st">&quot;x2&quot;</span>, <span class="st">&quot;x3&quot;</span>, <span class="st">&quot;x4&quot;</span>)])</span>
<span id="cb129-2"><a href="plsr.html#cb129-2" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(train_df[, <span class="fu">c</span>(<span class="st">&quot;y1&quot;</span>, <span class="st">&quot;y2&quot;</span>)])</span>
<span id="cb129-3"><a href="plsr.html#cb129-3" aria-hidden="true" tabindex="-1"></a>plsr_multi_fit <span class="ot">&lt;-</span> pls<span class="sc">::</span><span class="fu">plsr</span>(Y <span class="sc">~</span> X, <span class="at">ncomp =</span> <span class="dv">3</span>)</span></code></pre></div>
<p>함수 수행 결과 추정된 PLS 모형으로부터 원 독립변수 <span class="math inline">\(x_1, \cdots, x_4\)</span>와 종속변수 <span class="math inline">\(y_1, y_2\)</span>간의 선형관계를 함수 <code>coef()</code>를 적용하여 아래와 같이 얻을 수 있다.</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="plsr.html#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(plsr_multi_fit)</span></code></pre></div>
<pre><code>## , , 3 comps
## 
##             y1         y2
## x1 -0.26509645 -2.8773570
## x2  0.08864959  2.7249194
## x3 -0.14258488  0.3377420
## x4  0.37330470 -0.7406377</code></pre>
<p>또한 <code>summary()</code> 함수를 적용하여 잠재변수들이 독립변수행렬 및 각 종속변수의 총변동에 기여하는 비율을 확인할 수 있다.</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="plsr.html#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(plsr_multi_fit)</span></code></pre></div>
<pre><code>## Data:    X dimension: 7 4 
##  Y dimension: 7 2
## Fit method: kernelpls
## Number of components considered: 3
## TRAINING: % variance explained
##     1 comps  2 comps  3 comps
## X     86.59    99.00    99.81
## y1    81.71    81.89    82.19
## y2    53.98    56.50    65.99</code></pre>
</div>
<div id="plsr-multivariate-model" class="section level3" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> PLS 모형</h3>
<p>앞 <a href="plsr.html#plsr-model">4.2.2</a>절의 모형을 일반화하여 아래와 같은 모형을 가정한다.</p>
<p><span class="math display" id="eq:plsr-inner-multivariate-matrix" id="eq:plsr-y-multivariate-matrix" id="eq:plsr-x-multivariate-matrix">\[\begin{eqnarray}
\mathbf{X} &amp;=&amp; \mathbf{T} \mathbf{P}^\top + \mathbf{E} \tag{4.12}\\
\mathbf{Y} &amp;=&amp; \mathbf{U} \mathbf{Q}^\top + \mathbf{F} \tag{4.13}\\
\mathbf{U} &amp;=&amp; \mathbf{T} \mathbf{B} + \mathbf{H}  \tag{4.14}
\end{eqnarray}\]</span></p>
<p>식 <a href="plsr.html#eq:plsr-x-multivariate-matrix">(4.12)</a>의 모형은 앞서 하나의 종속변수의 경우에서 살펴본 모형식 <a href="plsr.html#eq:plsr-x-single-matrix">(4.3)</a>와 동일하다. 식 <a href="plsr.html#eq:plsr-y-multivariate-matrix">(4.13)</a>에서 (<span class="math inline">\(n \times A\)</span>) 행렬 <span class="math inline">\(\mathbf{U}\)</span>는 <span class="math inline">\(\mathbf{Y}\)</span>를 설명하는 <span class="math inline">\(A\)</span>개의 잠재변수를 나타내는 행렬이며, (<span class="math inline">\(m \times A\)</span>) 행렬 <span class="math inline">\(\mathbf{Q}\)</span>는 종속변수행렬 <span class="math inline">\(\mathbf{Y}\)</span>와 잠재변수행렬 <span class="math inline">\(\mathbf{U}\)</span>간의 선형관계를 나타내는 로딩행렬이다. 또한 식 <a href="plsr.html#eq:plsr-inner-multivariate-matrix">(4.14)</a>는 잠재변수행렬 <span class="math inline">\(\mathbf{T}\)</span>와 <span class="math inline">\(\mathbf{U}\)</span>간의 선형관계를 나타내는데, 특히 <span class="math inline">\(\mathbf{B}\)</span>는 (<span class="math inline">\(A \times A\)</span>) 대각행렬(diagonal matrix)로써, <span class="math inline">\(\mathbf{U}\)</span>와 <span class="math inline">\(\mathbf{T}\)</span>간에는 서로 대응하는 열 간에만 관계가 성립하며, 그 관계는 아래와 같다.</p>
<p><span class="math display">\[\begin{equation*}
\mathbf{u}_a = b_a \mathbf{t}_a + \mathbf{h}_a, \, a = 1, \cdots, A
\end{equation*}\]</span></p>
<p>이 때, <span class="math inline">\(b_a\)</span>는 행렬 <span class="math inline">\(\mathbf{B}\)</span>의 <span class="math inline">\(a\)</span>번째 대각 원소를 나타낸다.</p>
<p><span class="math display">\[\mathbf{B} = \left[ \begin{array}{c c c c}
b_{1} &amp; 0 &amp; \cdots &amp; 0\\
0 &amp; b_{2} &amp;  &amp; 0\\
\vdots &amp;  &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; b_{A}
\end{array} \right]
\]</span></p>
<p>행렬 <span class="math inline">\(\mathbf{E}\)</span>, <span class="math inline">\(\mathbf{F}\)</span>, <span class="math inline">\(\mathbf{H}\)</span>는 오차항에 해당하는 행렬이다.</p>
</div>
<div id="plsr-multivariate-nipals" class="section level3" number="4.3.3">
<h3><span class="header-section-number">4.3.3</span> NIPALS 알고리즘</h3>
<p>다수의 종속변수가 존재하는 경우에도 NIPALS 알고리즘을 이용하여 모형을 추정한다. 이때는 각 잠재변수 <span class="math inline">\(\mathbf{t}_a\)</span>를 추출할 때 추출한 잠재변수의 수렴 여부를 확인할 필요가 없었던 위 <a href="plsr.html#plsr-single-nipals">4.2.3</a>절의 경우와는 달리, 각 잠재변수 <span class="math inline">\(\mathbf{t}_a\)</span>와 <span class="math inline">\(\mathbf{u}_a\)</span>를 추출하는 과정에서 반복적인(iterative) 기법으로 두 잠재변수 벡터들을 업데이트하며 수렴 여부를 확인하여야 한다.</p>
<ul>
<li><strong>[단계 0]</strong> 반복알고리즘 수행을 위한 초기화를 한다. <span class="math inline">\(a \leftarrow 1\)</span>, <span class="math inline">\(\mathbf{X}_a \leftarrow \mathbf{X}\)</span>, <span class="math inline">\(\mathbf{Y}_a \leftarrow \mathbf{Y}\)</span>.</li>
<li><strong>[단계 1]</strong> 종속변수 행렬 <span class="math inline">\(\mathbf{Y}_a\)</span>의 임의의 열 하나를 잠재변수 벡터 <span class="math inline">\(\mathbf{u}_a\)</span>로 선정한다.</li>
<li><strong>[단계 2]</strong> <span class="math inline">\(\mathbf{X}_a\)</span>을 다중종속변수 행렬으로, 잠재변수 <span class="math inline">\(\mathbf{u}_a\)</span>를 독립변수 벡터로 하는 회귀모형으로부터 기울기 <span class="math inline">\(\mathbf{w}_a = [w_{a1} \, \cdots \, w_{ak}]^\top\)</span>를 산출한다.
<span class="math display">\[\mathbf{w}_a \leftarrow \left. \mathbf{X}_a^\top \mathbf{u}_a \middle/ \mathbf{u}_a^\top \mathbf{u}_a \right.  \]</span></li>
<li><strong>[단계 3]</strong> 기울기 벡터 <span class="math inline">\(\mathbf{w}_a\)</span>의 크기가 1이 되도록 한다.
<span class="math display">\[\left. \mathbf{w}_a \leftarrow \mathbf{w}_a \middle/ \sqrt{\mathbf{w}_a^\top \mathbf{w}_a} \right.\]</span></li>
<li><strong>[단계 4]</strong> 잠재변수 <span class="math inline">\(\mathbf{t}_a\)</span>를 행렬 <span class="math inline">\(\mathbf{X}_a\)</span>의 각 열의 가중평균으로 구한다. 이 때, 가중치는 기울기 벡터 <span class="math inline">\(\mathbf{w}_a\)</span>를 이용한다.
<span class="math display">\[\mathbf{t}_a \leftarrow \mathbf{X}_a \mathbf{w}_a\]</span></li>
<li><strong>[단계 5]</strong> <span class="math inline">\(\mathbf{Y}_a\)</span>을 다중종속변수 행렬으로, 잠재변수 <span class="math inline">\(\mathbf{t}_a\)</span>를 독립변수 벡터로 하는 회귀모형으로부터 기울기 (로딩벡터) <span class="math inline">\(\mathbf{q}_a = [q_{a1} \, \cdots \, q_{am}]^\top\)</span>를 산출한다.
<span class="math display">\[\mathbf{q}_a \leftarrow \left. \mathbf{Y}_a^\top \mathbf{t}_a \middle/ \mathbf{t}_a^\top \mathbf{t}_a \right.  \]</span></li>
<li><strong>[단계 6]</strong> 기울기 벡터 <span class="math inline">\(\mathbf{q}_a\)</span>의 크기가 1이 되도록 한다.
<span class="math display">\[\left. \mathbf{q}_a \leftarrow \mathbf{q}_a \middle/ \sqrt{\mathbf{q}_a^\top \mathbf{q}_a} \right.\]</span></li>
<li><strong>[단계 7]</strong> 잠재변수 <span class="math inline">\(\mathbf{u}_a\)</span>를 행렬 <span class="math inline">\(\mathbf{Y}_a\)</span>의 각 열의 가중평균으로 구한다. 이 때, 가중치는 기울기 벡터 <span class="math inline">\(\mathbf{q}_a\)</span>를 이용한다.
<span class="math display">\[\mathbf{u}_a \leftarrow \mathbf{Y}_a \mathbf{q}_a\]</span></li>
<li><strong>[단계 8]</strong> (수렴 확인) [단계 2]에서 [단계 7]까지의 과정을 잠재변수 벡터 <span class="math inline">\(\mathbf{u}_a\)</span>의 모든 원소값이 수렴할 때까지 반복한다. 수렴이 확인되면 [단계 9]로 진행한다.</li>
<li><strong>[단계 9]</strong> <span class="math inline">\(\mathbf{t}_a\)</span>를 <span class="math inline">\(\mathbf{X}_a\)</span>에 회귀시켜, <span class="math inline">\(\mathbf{X}_a\)</span>을 다중종속변수 행렬으로, <span class="math inline">\(\mathbf{t}_a\)</span>를 독립변수 벡터로 하는 회귀모형으로부터 로딩벡터 <span class="math inline">\(\mathbf{p}_a\)</span>를 구한다.
<span class="math display">\[\mathbf{p}_a \leftarrow \left. \mathbf{X}_a^\top \mathbf{t}_a \middle/ \mathbf{t}_a^\top \mathbf{t}_a \right.\]</span></li>
<li><strong>[단계 10]</strong> 로딩벡터 <span class="math inline">\(\mathbf{p}_a\)</span>의 크기를 1로 조정하고, 잠재변수 벡터 <span class="math inline">\(\mathbf{t}_a\)</span>와 기울기 벡터 <span class="math inline">\(\mathbf{w}_a\)</span>의 크기를 그에 따라 보정한다.
<span class="math display">\[d \leftarrow \sqrt{\mathbf{p}_a^\top \mathbf{p}_a}, \, \mathbf{t}_a \leftarrow \mathbf{t}_a d, \, \mathbf{w}_a \leftarrow \mathbf{w}_a d, \, \mathbf{p}_a \leftarrow \frac{1}{d} \mathbf{p}_a \]</span></li>
<li><strong>[단계 11]</strong> 잠재변수벡터 <span class="math inline">\(\mathbf{u}_a\)</span>와 <span class="math inline">\(\mathbf{t}_a\)</span>간의 내부관계 계수 <span class="math inline">\(b_a\)</span>를 산출한다.
<span class="math display">\[b_a \leftarrow \left. \mathbf{u}_a^\top \mathbf{t}_a \middle/ \mathbf{t}_a^\top \mathbf{t}_a \right. \]</span></li>
<li><strong>[단계 12]</strong> 독립변수행렬 <span class="math inline">\(\mathbf{X}_a\)</span>와 종속변수행렬 <span class="math inline">\(\mathbf{Y}_a\)</span>로부터 새로 얻어진 잠재변수 벡터 <span class="math inline">\(\mathbf{t}_a\)</span>가 설명하는 부분을 제거하고 나머지 변동만을 담은 독립변수행렬 <span class="math inline">\(\mathbf{X}_{a + 1}\)</span>과 종속변수행렬 <span class="math inline">\(\mathbf{Y}_{a + 1}\)</span>을 구한다.
<span class="math display">\[\mathbf{X}_{a + 1} \leftarrow \mathbf{X}_a - \mathbf{t}_a \mathbf{p}_a^\top, \, \mathbf{Y}_{a + 1} \leftarrow \mathbf{Y}_a - b_a \mathbf{t}_a \mathbf{q}_a^\top \]</span></li>
<li><strong>[단계 13]</strong> <span class="math inline">\(a \leftarrow a + 1\)</span>로 업데이트하고, [단계 1]로 돌아간다. [단계 1] - [단계 13]의 과정을 <span class="math inline">\(A\)</span>개의 잠재변수를 얻을 때까지 반복한다.</li>
</ul>
<p>위 알고리즘을 아래 <code>nipals_plsr2</code>이라는 함수로 구현해보자. 이 때, 함수의 입력변수는 아래와 같다.</p>
<ul>
<li><code>X</code>: 평균조정된 (<span class="math inline">\(n \times k\)</span>) 독립변수행렬</li>
<li><code>Y</code>: 평균조정된 (<span class="math inline">\(n \times m\)</span>) 종속변수행렬</li>
<li><code>A</code>: 잠재변수 개수</li>
</ul>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="plsr.html#cb134-1" aria-hidden="true" tabindex="-1"></a>nipals_plsr2 <span class="ot">&lt;-</span> <span class="cf">function</span>(X, Y, <span class="at">A =</span> <span class="cn">NULL</span>) {</span>
<span id="cb134-2"><a href="plsr.html#cb134-2" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is.vector</span>(Y)) {</span>
<span id="cb134-3"><a href="plsr.html#cb134-3" aria-hidden="true" tabindex="-1"></a>    Y <span class="ot">&lt;-</span> <span class="fu">as.matrix</span>(Y, <span class="at">ncol =</span> 1L)</span>
<span id="cb134-4"><a href="plsr.html#cb134-4" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb134-5"><a href="plsr.html#cb134-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb134-6"><a href="plsr.html#cb134-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">nrow</span>(X) <span class="sc">!=</span> <span class="fu">nrow</span>(Y)) <span class="fu">stop</span>(<span class="st">&quot;X and Y must have the same numbers of observations.&quot;</span>)</span>
<span id="cb134-7"><a href="plsr.html#cb134-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb134-8"><a href="plsr.html#cb134-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is_empty</span>(A) <span class="sc">||</span> (A <span class="sc">&gt;</span> <span class="fu">min</span>(<span class="fu">dim</span>(X)))) {</span>
<span id="cb134-9"><a href="plsr.html#cb134-9" aria-hidden="true" tabindex="-1"></a>    A <span class="ot">&lt;-</span> <span class="fu">min</span>(<span class="fu">dim</span>(X))</span>
<span id="cb134-10"><a href="plsr.html#cb134-10" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb134-11"><a href="plsr.html#cb134-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb134-12"><a href="plsr.html#cb134-12" aria-hidden="true" tabindex="-1"></a>  Tmat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> <span class="fu">nrow</span>(X), <span class="at">ncol =</span> A)</span>
<span id="cb134-13"><a href="plsr.html#cb134-13" aria-hidden="true" tabindex="-1"></a>  Umat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> <span class="fu">nrow</span>(X), <span class="at">ncol =</span> A)</span>
<span id="cb134-14"><a href="plsr.html#cb134-14" aria-hidden="true" tabindex="-1"></a>  Wmat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> <span class="fu">ncol</span>(X), <span class="at">ncol =</span> A)</span>
<span id="cb134-15"><a href="plsr.html#cb134-15" aria-hidden="true" tabindex="-1"></a>  Pmat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> <span class="fu">ncol</span>(X), <span class="at">ncol =</span> A)</span>
<span id="cb134-16"><a href="plsr.html#cb134-16" aria-hidden="true" tabindex="-1"></a>  Qmat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> <span class="fu">ncol</span>(Y), <span class="at">ncol =</span> A)</span>
<span id="cb134-17"><a href="plsr.html#cb134-17" aria-hidden="true" tabindex="-1"></a>  Bmat <span class="ot">&lt;-</span> <span class="fu">diag</span>(<span class="at">nrow =</span> A)</span>
<span id="cb134-18"><a href="plsr.html#cb134-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb134-19"><a href="plsr.html#cb134-19" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (a <span class="cf">in</span> <span class="fu">seq_len</span>(A)) {</span>
<span id="cb134-20"><a href="plsr.html#cb134-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 단계 1</span></span>
<span id="cb134-21"><a href="plsr.html#cb134-21" aria-hidden="true" tabindex="-1"></a>    j <span class="ot">&lt;-</span> <span class="fu">sample.int</span>(<span class="fu">ncol</span>(Y), <span class="at">size =</span> 1L)</span>
<span id="cb134-22"><a href="plsr.html#cb134-22" aria-hidden="true" tabindex="-1"></a>    Umat[, a] <span class="ot">&lt;-</span> Y[, j]</span>
<span id="cb134-23"><a href="plsr.html#cb134-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb134-24"><a href="plsr.html#cb134-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> (<span class="cn">TRUE</span>) {</span>
<span id="cb134-25"><a href="plsr.html#cb134-25" aria-hidden="true" tabindex="-1"></a>      <span class="co"># 단계 2</span></span>
<span id="cb134-26"><a href="plsr.html#cb134-26" aria-hidden="true" tabindex="-1"></a>      Wmat[, a] <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(X <span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span> Umat[, a]))</span>
<span id="cb134-27"><a href="plsr.html#cb134-27" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb134-28"><a href="plsr.html#cb134-28" aria-hidden="true" tabindex="-1"></a>      <span class="co"># 단계 3</span></span>
<span id="cb134-29"><a href="plsr.html#cb134-29" aria-hidden="true" tabindex="-1"></a>      Wmat[, a] <span class="ot">&lt;-</span> Wmat[, a] <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>(Wmat[, a] <span class="sc">^</span> <span class="dv">2</span>))</span>
<span id="cb134-30"><a href="plsr.html#cb134-30" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb134-31"><a href="plsr.html#cb134-31" aria-hidden="true" tabindex="-1"></a>      <span class="co"># 단계 4</span></span>
<span id="cb134-32"><a href="plsr.html#cb134-32" aria-hidden="true" tabindex="-1"></a>      Tmat[, a] <span class="ot">&lt;-</span> X <span class="sc">%*%</span> Wmat[, a]</span>
<span id="cb134-33"><a href="plsr.html#cb134-33" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb134-34"><a href="plsr.html#cb134-34" aria-hidden="true" tabindex="-1"></a>      <span class="co"># 단계 5</span></span>
<span id="cb134-35"><a href="plsr.html#cb134-35" aria-hidden="true" tabindex="-1"></a>      Qmat[, a] <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(Y <span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span> Tmat[, a]))</span>
<span id="cb134-36"><a href="plsr.html#cb134-36" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb134-37"><a href="plsr.html#cb134-37" aria-hidden="true" tabindex="-1"></a>      <span class="co"># 단계 6</span></span>
<span id="cb134-38"><a href="plsr.html#cb134-38" aria-hidden="true" tabindex="-1"></a>      Qmat[, a] <span class="ot">&lt;-</span> Qmat[, a] <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>(Qmat[, a] <span class="sc">^</span> <span class="dv">2</span>))</span>
<span id="cb134-39"><a href="plsr.html#cb134-39" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb134-40"><a href="plsr.html#cb134-40" aria-hidden="true" tabindex="-1"></a>      <span class="co"># 단계 7</span></span>
<span id="cb134-41"><a href="plsr.html#cb134-41" aria-hidden="true" tabindex="-1"></a>      u_new <span class="ot">&lt;-</span> Y <span class="sc">%*%</span> Qmat[, a]</span>
<span id="cb134-42"><a href="plsr.html#cb134-42" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb134-43"><a href="plsr.html#cb134-43" aria-hidden="true" tabindex="-1"></a>      <span class="co"># 단계 8</span></span>
<span id="cb134-44"><a href="plsr.html#cb134-44" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span> (<span class="fu">all</span>(<span class="fu">near</span>(u_new, Umat[, a]))) <span class="cf">break</span></span>
<span id="cb134-45"><a href="plsr.html#cb134-45" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb134-46"><a href="plsr.html#cb134-46" aria-hidden="true" tabindex="-1"></a>      Umat[, a] <span class="ot">&lt;-</span> u_new</span>
<span id="cb134-47"><a href="plsr.html#cb134-47" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb134-48"><a href="plsr.html#cb134-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-49"><a href="plsr.html#cb134-49" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 단계 9</span></span>
<span id="cb134-50"><a href="plsr.html#cb134-50" aria-hidden="true" tabindex="-1"></a>    Pmat[, a] <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(X <span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span> Tmat[, a]))</span>
<span id="cb134-51"><a href="plsr.html#cb134-51" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb134-52"><a href="plsr.html#cb134-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 단계 10</span></span>
<span id="cb134-53"><a href="plsr.html#cb134-53" aria-hidden="true" tabindex="-1"></a>    p_size <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>(Pmat[, a] <span class="sc">^</span> <span class="dv">2</span>))</span>
<span id="cb134-54"><a href="plsr.html#cb134-54" aria-hidden="true" tabindex="-1"></a>    Tmat[, a] <span class="ot">&lt;-</span> Tmat[, a] <span class="sc">*</span> p_size</span>
<span id="cb134-55"><a href="plsr.html#cb134-55" aria-hidden="true" tabindex="-1"></a>    Wmat[, a] <span class="ot">&lt;-</span> Wmat[, a] <span class="sc">*</span> p_size</span>
<span id="cb134-56"><a href="plsr.html#cb134-56" aria-hidden="true" tabindex="-1"></a>    Pmat[, a] <span class="ot">&lt;-</span> Pmat[, a] <span class="sc">/</span> p_size</span>
<span id="cb134-57"><a href="plsr.html#cb134-57" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb134-58"><a href="plsr.html#cb134-58" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 단계 11</span></span>
<span id="cb134-59"><a href="plsr.html#cb134-59" aria-hidden="true" tabindex="-1"></a>    Bmat[a, a] <span class="ot">&lt;-</span> <span class="fu">coef</span>(<span class="fu">lm</span>(Umat[, a] <span class="sc">~</span> <span class="sc">-</span><span class="dv">1</span> <span class="sc">+</span> Tmat[, a]))</span>
<span id="cb134-60"><a href="plsr.html#cb134-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-61"><a href="plsr.html#cb134-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 단계 12</span></span>
<span id="cb134-62"><a href="plsr.html#cb134-62" aria-hidden="true" tabindex="-1"></a>    X <span class="ot">&lt;-</span> X <span class="sc">-</span> Tmat[, a] <span class="sc">%*%</span> <span class="fu">t</span>(Pmat[, a])</span>
<span id="cb134-63"><a href="plsr.html#cb134-63" aria-hidden="true" tabindex="-1"></a>    Y <span class="ot">&lt;-</span> Y <span class="sc">-</span> Bmat[a, a] <span class="sc">*</span> Tmat[, a] <span class="sc">%*%</span> <span class="fu">t</span>(Qmat[, a])</span>
<span id="cb134-64"><a href="plsr.html#cb134-64" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb134-65"><a href="plsr.html#cb134-65" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb134-66"><a href="plsr.html#cb134-66" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">T =</span> Tmat, <span class="at">W =</span> Wmat, <span class="at">P =</span> Pmat, </span>
<span id="cb134-67"><a href="plsr.html#cb134-67" aria-hidden="true" tabindex="-1"></a>              <span class="at">U =</span> Umat, <span class="at">Q =</span> Qmat, <span class="at">B =</span> Bmat))</span>
<span id="cb134-68"><a href="plsr.html#cb134-68" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb134-69"><a href="plsr.html#cb134-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb134-70"><a href="plsr.html#cb134-70" aria-hidden="true" tabindex="-1"></a>nipals_fit2 <span class="ot">&lt;-</span> <span class="fu">nipals_plsr2</span>(X, Y, <span class="at">A =</span> <span class="dv">3</span>)</span>
<span id="cb134-71"><a href="plsr.html#cb134-71" aria-hidden="true" tabindex="-1"></a>nipals_fit2</span></code></pre></div>
<pre><code>## $T
##             [,1]       [,2]        [,3]
## [1,]   1.5777938 -0.4117531  0.44707709
## [2,]  -2.2993972 -8.0194451 -0.79803681
## [3,]   0.8145895 -5.1398023 -0.30016399
## [4,]  21.3867331  3.2065797 -0.01083136
## [5,] -17.8784038  5.7770058 -1.68928119
## [6,]   9.2701258  3.6198261 -0.09042238
## [7,] -12.8714412  0.9675888  2.44165865
## 
## $W
##            [,1]       [,2]       [,3]
## [1,] -0.1476019  0.4020251 -0.6921766
## [2,] -0.1848598 -0.4862964  0.5027723
## [3,] -0.5065102  0.8236460  0.4768770
## [4,]  0.8312518  0.4651155  0.2794808
## 
## $P
##            [,1]         [,2]       [,3]
## [1,] -0.1648502 -0.002634502 -0.5484068
## [2,] -0.1588038 -0.130002426  0.6241044
## [3,] -0.5486716  0.859489687  0.4559029
## [4,]  0.8040928  0.494337847  0.3192118
## 
## $U
##              [,1]       [,2]      [,3]
## [1,]  11.60599122   9.401433 -8.559602
## [2,]  -0.03696152   3.340983 -7.252566
## [3,]  -9.14720168 -11.437784  9.474719
## [4,]  22.98172912   6.021677 -4.914480
## [5,]  -7.12619591   9.125035 -6.794076
## [6,]   0.47754875  -7.914057  9.259791
## [7,] -18.75490997  -8.537286  8.786214
## 
## $Q
##            [,1]       [,2]       [,3]
## [1,]  0.4832295  0.1202142 0.07948906
## [2,] -0.8754937 -0.9927480 0.99683574
## 
## $B
##           [,1]      [,2]     [,3]
## [1,] 0.8443757 0.0000000 0.000000
## [2,] 0.0000000 0.4255916 0.000000
## [3,] 0.0000000 0.0000000 3.206299</code></pre>
</div>
<div id="plsr-multivariate-transform" class="section level3" number="4.3.4">
<h3><span class="header-section-number">4.3.4</span> 회귀식 변환</h3>
<p>위 NIPALS 알고리즘 수행 결과를 원래 독립변수 <span class="math inline">\(\mathbf{X}\)</span>와 종속변수 <span class="math inline">\(\mathbf{Y}\)</span>에 대한 식으로 변환하는 방법은 아래와 같다.</p>
<p>잠재변수행렬 <span class="math inline">\(\mathbf{T}\)</span>는 하나의 종속변수일 때 살펴봤던 바와 같이 독립변수행렬 <span class="math inline">\(\mathbf{X}\)</span>와 가중치행렬 <span class="math inline">\(\mathbf{W}\)</span>, 그리고 로딩행렬 <span class="math inline">\(\mathbf{P}\)</span>의 연산으로 표현된다.</p>
<p><span class="math display">\[\begin{equation}
\mathbf{T} = \mathbf{X} \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1}
\end{equation}\]</span></p>
<p>이를 식 <a href="plsr.html#eq:plsr-inner-multivariate-matrix">(4.14)</a>에 대입하면,</p>
<p><span class="math display">\[\begin{equation}
\mathbf{U} = \mathbf{X} \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1} \mathbf{B} + \mathbf{H}
\end{equation}\]</span></p>
<p>이를 다시 식 <a href="plsr.html#eq:plsr-y-multivariate-matrix">(4.13)</a>에 대입하면,</p>
<p><span class="math display" id="eq:plsr-multivariate-beta">\[\begin{equation}
\begin{split}
\mathbf{Y} &amp;= \mathbf{X} \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1} \mathbf{B} \mathbf{Q}^\top + \mathbf{H} \mathbf{Q}^\top + \mathbf{F}\\
&amp;= \mathbf{X} \mathbf{B}_{PLS} + \mathbf{G}
\end{split} \tag{4.15}
\end{equation}\]</span></p>
<p>여기에서 <span class="math inline">\(\mathbf{G} = \mathbf{H} \mathbf{Q}^\top + \mathbf{F}\)</span>는 독립변수 <span class="math inline">\(\mathbf{X}\)</span>를 종속변수 <span class="math inline">\(\mathbf{Y}\)</span>에 회귀시킨 뒤 남은 오차항 행렬이다. 따라서, PLS 모형을 원 독립변수 행렬 <span class="math inline">\(\mathbf{X}\)</span>에 대한 모형으로 변환할 때의 회귀계수는 아래와 같이 정리된다.</p>
<p><span class="math display">\[\begin{equation}
\mathbf{B}_{PLS} = \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1} \mathbf{B} \mathbf{Q}^\top
\end{equation}\]</span></p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="plsr.html#cb136-1" aria-hidden="true" tabindex="-1"></a>beta_pls2 <span class="ot">&lt;-</span> nipals_fit2<span class="sc">$</span>W <span class="sc">%*%</span> </span>
<span id="cb136-2"><a href="plsr.html#cb136-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">solve</span>(<span class="fu">t</span>(nipals_fit2<span class="sc">$</span>P) <span class="sc">%*%</span> nipals_fit2<span class="sc">$</span>W) <span class="sc">%*%</span> </span>
<span id="cb136-3"><a href="plsr.html#cb136-3" aria-hidden="true" tabindex="-1"></a>  nipals_fit2<span class="sc">$</span>B <span class="sc">%*%</span> <span class="fu">t</span>(nipals_fit2<span class="sc">$</span>Q)</span>
<span id="cb136-4"><a href="plsr.html#cb136-4" aria-hidden="true" tabindex="-1"></a>beta_pls2</span></code></pre></div>
<pre><code>##             [,1]       [,2]
## [1,] -0.26509645 -2.8773570
## [2,]  0.08864959  2.7249194
## [3,] -0.14258488  0.3377420
## [4,]  0.37330470 -0.7406377</code></pre>
<p>이는 앞 <a href="plsr.html#plsr-multivariate-basic-script">4.3.1</a> 절에서 R 패키지 <code>pls</code>를 통해 얻어진 결과와 동일함을 확인할 수 있다.</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="plsr.html#cb138-1" aria-hidden="true" tabindex="-1"></a><span class="fu">all</span>(<span class="fu">near</span>(beta_pls2, <span class="fu">coef</span>(plsr_multi_fit)[, , <span class="dv">1</span>]))</span></code></pre></div>
<pre><code>## [1] TRUE</code></pre>
</div>
<div id="plsr-multivariate-sst" class="section level3" number="4.3.5">
<h3><span class="header-section-number">4.3.5</span> 제곱합 분해</h3>
<p><span class="math inline">\(\mathbf{Y}\)</span>의 전체제곱합은</p>
<p><span class="math display">\[SST = SSR + SSE\]</span></p>
<p>로 분해되며, 여기서 <span class="math inline">\(SSR\)</span>은 다음과 같이 산출된다.</p>
<p><span class="math display" id="eq:plsr-multivariate-ssr">\[\begin{equation}
\begin{split}
SSR &amp;= \sum_{a = 1}^{A} SSR_a\\
&amp;= \sum_{a = 1}^{A} SS(b_a \mathbf{t}_a \mathbf{q}_a^\top)\\ 
&amp;= \sum_{a = 1}^{A} b_a^2 SS(\mathbf{t}_a)
\end{split} \tag{4.16}
\end{equation}\]</span></p>
<p>이 때, <span class="math inline">\(SSR_a\)</span>는 잠재변수 <span class="math inline">\(\mathbf{t}_a\)</span>에 의해 설명되는 <span class="math inline">\(\mathbf{Y}\)</span>의 변동을 나타낸다.</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="plsr.html#cb140-1" aria-hidden="true" tabindex="-1"></a>SSR_a <span class="ot">&lt;-</span> <span class="fu">diag</span>(</span>
<span id="cb140-2"><a href="plsr.html#cb140-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">t</span>(nipals_fit2<span class="sc">$</span>T <span class="sc">%*%</span> nipals_fit2<span class="sc">$</span>B) <span class="sc">%*%</span> </span>
<span id="cb140-3"><a href="plsr.html#cb140-3" aria-hidden="true" tabindex="-1"></a>    (nipals_fit2<span class="sc">$</span>T <span class="sc">%*%</span> nipals_fit2<span class="sc">$</span>B)</span>
<span id="cb140-4"><a href="plsr.html#cb140-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb140-5"><a href="plsr.html#cb140-5" aria-hidden="true" tabindex="-1"></a>SSR_a</span></code></pre></div>
<pre><code>## [1] 739.40663  26.91455 100.23860</code></pre>
<p><span class="math inline">\(SSR_a\)</span>를 전체제곱합 <span class="math inline">\(SST\)</span>로 나누면 각 잠재변수가 <span class="math inline">\(\mathbf{Y}\)</span>의 변동에 기여하는 비율을 산출할 수 있다.</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="plsr.html#cb142-1" aria-hidden="true" tabindex="-1"></a>SST <span class="ot">&lt;-</span> <span class="fu">sum</span>(Y <span class="sc">^</span> <span class="dv">2</span>)</span>
<span id="cb142-2"><a href="plsr.html#cb142-2" aria-hidden="true" tabindex="-1"></a>SSR_a <span class="sc">/</span> SST</span></code></pre></div>
<pre><code>## [1] 0.58621653 0.02133840 0.07947119</code></pre>
<p>또한, 잠재변수 <span class="math inline">\(\mathbf{t}_a\)</span>가 설명하는 종속변수행렬 <span class="math inline">\(\mathbf{Y}\)</span>의 <span class="math inline">\(j\)</span>번째 열의 변동을 <span class="math inline">\(SSR_{aj}\)</span>라 할 때, 이는 다음과 같이 산출된다.</p>
<p><span class="math display">\[\begin{equation}
SSR_{aj} = q_{ja}^2 SSR_a
\end{equation}\]</span></p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="plsr.html#cb144-1" aria-hidden="true" tabindex="-1"></a>SSR_aj <span class="ot">&lt;-</span> <span class="fu">diag</span>(SSR_a) <span class="sc">%*%</span> <span class="fu">t</span>(nipals_fit2<span class="sc">$</span>Q <span class="sc">^</span> <span class="dv">2</span>)</span>
<span id="cb144-2"><a href="plsr.html#cb144-2" aria-hidden="true" tabindex="-1"></a>SSR_aj</span></code></pre></div>
<pre><code>##             [,1]      [,2]
## [1,] 172.6593685 566.74726
## [2,]   0.3889542  26.52560
## [3,]   0.6333587  99.60524</code></pre>
<p>이렇게 산출된 <span class="math inline">\(SSR_{aj}\)</span>를 <span class="math inline">\(j\)</span>번째 종속변수 <span class="math inline">\(\mathbf{y}_j\)</span>의 제곱합 <span class="math inline">\(SS(\mathbf{y}_j)\)</span>로 나누면, <span class="math inline">\(\mathbf{y}_j\)</span>에 대한 <span class="math inline">\(\mathbf{t}_a\)</span>의 기여도를 얻을 수 있다.</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="plsr.html#cb146-1" aria-hidden="true" tabindex="-1"></a>SS_j <span class="ot">&lt;-</span> <span class="fu">colSums</span>(Y <span class="sc">^</span> <span class="dv">2</span>)</span>
<span id="cb146-2"><a href="plsr.html#cb146-2" aria-hidden="true" tabindex="-1"></a>SSR_aj <span class="sc">%*%</span> <span class="fu">diag</span>(<span class="dv">1</span> <span class="sc">/</span> SS_j)</span></code></pre></div>
<pre><code>##             [,1]       [,2]
## [1,] 0.817051715 0.53975930
## [2,] 0.001840593 0.02526248
## [3,] 0.002997154 0.09486213</code></pre>
<p>위의 결과에서 <span class="math inline">\(\mathbf{y}_1\)</span>의 변동은 잠재변수 <span class="math inline">\(\mathbf{t}_1\)</span>으로 대부분 설명되는 반면, <span class="math inline">\(\mathbf{y}_2\)</span>의 변동은 잠재변수 <span class="math inline">\(\mathbf{t}_2\)</span> 및 <span class="math inline">\(\mathbf{t}_3\)</span>에 의해서도 설명됨을 볼 수 있다.</p>

</div>
</div>
</div>



<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://r-data-mining-book.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
                            
            </section>

          </div>
        </div>
      </div>
<a href="pca.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="classification-analysis.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
