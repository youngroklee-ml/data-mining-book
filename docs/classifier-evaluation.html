<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 6 분류규칙의 성능 평가 | 데이터마이닝 with R</title>
  <meta name="description" content="전치혁 교수님의 책 을 기반으로 한 R 예제">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 6 분류규칙의 성능 평가 | 데이터마이닝 with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://youngroklee-ml.github.io/data-mining-book/" />
  
  <meta property="og:description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  <meta name="github-repo" content="youngroklee-ml/data-mining-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 분류규칙의 성능 평가 | 데이터마이닝 with R" />
  
  <meta name="twitter:description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  

<meta name="author" content="전치혁, 이혜선, 이종석, 이영록">


<meta name="date" content="2019-03-18">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="svm.html">
<link rel="next" href="clustering-overview.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">데이터마이닝 with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>개요</a></li>
<li class="chapter" data-level="1" data-path="classification-analysis.html"><a href="classification-analysis.html"><i class="fa fa-check"></i><b>1</b> 분류분석 개요</a><ul>
<li class="chapter" data-level="1.1" data-path="classification-analysis.html"><a href="classification-analysis.html#classification-packages-install"><i class="fa fa-check"></i><b>1.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="1.2" data-path="classification-analysis.html"><a href="classification-analysis.html#classification-problem-methods"><i class="fa fa-check"></i><b>1.2</b> 분류문제 및 분류기법</a></li>
<li class="chapter" data-level="1.3" data-path="classification-analysis.html"><a href="classification-analysis.html#simple-classification-methods"><i class="fa fa-check"></i><b>1.3</b> 기본적인 분류기법</a><ul>
<li class="chapter" data-level="1.3.1" data-path="classification-analysis.html"><a href="classification-analysis.html#nearest-neighbor-classification"><i class="fa fa-check"></i><b>1.3.1</b> 인접객체법</a></li>
<li class="chapter" data-level="1.3.2" data-path="classification-analysis.html"><a href="classification-analysis.html#naive-bayes"><i class="fa fa-check"></i><b>1.3.2</b> 나이브 베이지안 분류법</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>2</b> 로지스틱 회귀분석</a><ul>
<li class="chapter" data-level="2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-packages-install"><i class="fa fa-check"></i><b>2.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="2.2" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-regression"><i class="fa fa-check"></i><b>2.2</b> 이분 로지스틱 회귀모형</a><ul>
<li class="chapter" data-level="2.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#bianry-logistic-reg-basic-script"><i class="fa fa-check"></i><b>2.2.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="2.2.2" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-reg-model"><i class="fa fa-check"></i><b>2.2.2</b> 회귀모형</a></li>
<li class="chapter" data-level="2.2.3" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-reg-estimation"><i class="fa fa-check"></i><b>2.2.3</b> 회귀계수 추정</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="logistic-regression.html"><a href="logistic-regression.html#nominal-logistic-regression"><i class="fa fa-check"></i><b>2.3</b> 명목 로지스틱 회귀모형</a><ul>
<li class="chapter" data-level="2.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#nominal-logistic-reg-basic-script"><i class="fa fa-check"></i><b>2.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="2.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#baseline-category-logit-model"><i class="fa fa-check"></i><b>2.3.2</b> 기준범주 로짓모형</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="logistic-regression.html"><a href="logistic-regression.html#ordinal-logistic-regression"><i class="fa fa-check"></i><b>2.4</b> 서열 로지스틱 회귀모형</a><ul>
<li class="chapter" data-level="2.4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#ordinal-logistic-basic-script"><i class="fa fa-check"></i><b>2.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="2.4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#cumulative-logit-model"><i class="fa fa-check"></i><b>2.4.2</b> 누적 로짓모형</a></li>
<li class="chapter" data-level="2.4.3" data-path="logistic-regression.html"><a href="logistic-regression.html#adjacent-categories-logit-model"><i class="fa fa-check"></i><b>2.4.3</b> 인근범주 로짓모형</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="da.html"><a href="da.html"><i class="fa fa-check"></i><b>3</b> 판별분석</a><ul>
<li class="chapter" data-level="3.1" data-path="da.html"><a href="da.html#da-overview"><i class="fa fa-check"></i><b>3.1</b> 개요</a></li>
<li class="chapter" data-level="3.2" data-path="da.html"><a href="da.html#da-packages-install"><i class="fa fa-check"></i><b>3.2</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="3.3" data-path="da.html"><a href="da.html#da-fisher"><i class="fa fa-check"></i><b>3.3</b> 피셔 방법</a><ul>
<li class="chapter" data-level="3.3.1" data-path="da.html"><a href="da.html#da-fisher-basic-script"><i class="fa fa-check"></i><b>3.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="3.3.2" data-path="da.html"><a href="da.html#-"><i class="fa fa-check"></i><b>3.3.2</b> 피셔 판별함수</a></li>
<li class="chapter" data-level="3.3.3" data-path="da.html"><a href="da.html#-"><i class="fa fa-check"></i><b>3.3.3</b> 분류 규칙</a></li>
<li class="chapter" data-level="3.3.4" data-path="da.html"><a href="da.html#r----"><i class="fa fa-check"></i><b>3.3.4</b> R 패키지를 이용한 분류규칙 도출</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="da.html"><a href="da.html#lda"><i class="fa fa-check"></i><b>3.4</b> 의사결정론에 의한 선형분류규칙</a><ul>
<li class="chapter" data-level="3.4.1" data-path="da.html"><a href="da.html#lda-basic-script"><i class="fa fa-check"></i><b>3.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="3.4.2" data-path="da.html"><a href="da.html#lda-function"><i class="fa fa-check"></i><b>3.4.2</b> 선형판별함수</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="da.html"><a href="da.html#lda-misclassification-cost"><i class="fa fa-check"></i><b>3.5</b> 오분류비용을 고려한 분류규칙</a></li>
<li class="chapter" data-level="3.6" data-path="da.html"><a href="da.html#qda"><i class="fa fa-check"></i><b>3.6</b> 이차판별분석</a><ul>
<li class="chapter" data-level="3.6.1" data-path="da.html"><a href="da.html#qda-basic-script"><i class="fa fa-check"></i><b>3.6.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="3.6.2" data-path="da.html"><a href="da.html#qda-function"><i class="fa fa-check"></i><b>3.6.2</b> 이차 판별함수</a></li>
<li class="chapter" data-level="3.6.3" data-path="da.html"><a href="da.html#qda-discriminant-rule"><i class="fa fa-check"></i><b>3.6.3</b> 이차판별함수에 의한 분류</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="da.html"><a href="da.html#da-multiclass"><i class="fa fa-check"></i><b>3.7</b> 세 범주 이상의 분류</a><ul>
<li class="chapter" data-level="3.7.1" data-path="da.html"><a href="da.html#mutliclass-da-basic-script"><i class="fa fa-check"></i><b>3.7.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="3.7.2" data-path="da.html"><a href="da.html#mutliclass-generalized-discriminant-function"><i class="fa fa-check"></i><b>3.7.2</b> 일반화된 판별함수</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tree-based-method.html"><a href="tree-based-method.html"><i class="fa fa-check"></i><b>4</b> 트리기반 기법</a><ul>
<li class="chapter" data-level="4.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-overview"><i class="fa fa-check"></i><b>4.1</b> CART 개요</a></li>
<li class="chapter" data-level="4.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-packages-install"><i class="fa fa-check"></i><b>4.2</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="4.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-build"><i class="fa fa-check"></i><b>4.3</b> CART 트리 생성</a><ul>
<li class="chapter" data-level="4.3.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-basic-r-script"><i class="fa fa-check"></i><b>4.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="4.3.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-notation"><i class="fa fa-check"></i><b>4.3.2</b> 기호 정의</a></li>
<li class="chapter" data-level="4.3.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-impurity"><i class="fa fa-check"></i><b>4.3.3</b> 노드 및 트리의 불순도</a></li>
<li class="chapter" data-level="4.3.4" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-split"><i class="fa fa-check"></i><b>4.3.4</b> 분지기준</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-pruning-complete"><i class="fa fa-check"></i><b>4.4</b> 가지치기 및 최종 트리 선정</a><ul>
<li class="chapter" data-level="4.4.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-pruning"><i class="fa fa-check"></i><b>4.4.1</b> 가지치기</a></li>
<li class="chapter" data-level="4.4.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-best-tree"><i class="fa fa-check"></i><b>4.4.2</b> 최적 트리의 선정</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg"><i class="fa fa-check"></i><b>4.5</b> R패키지 내 분류 트리 방법</a><ul>
<li class="chapter" data-level="4.5.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-split"><i class="fa fa-check"></i><b>4.5.1</b> 트리 확장</a></li>
<li class="chapter" data-level="4.5.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-pruning"><i class="fa fa-check"></i><b>4.5.2</b> 가지치기</a></li>
<li class="chapter" data-level="4.5.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-param"><i class="fa fa-check"></i><b>4.5.3</b> 파라미터값 결정</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="svm.html"><a href="svm.html"><i class="fa fa-check"></i><b>5</b> 서포트 벡터 머신</a><ul>
<li class="chapter" data-level="5.1" data-path="svm.html"><a href="svm.html#svm-overview"><i class="fa fa-check"></i><b>5.1</b> 개요</a></li>
<li class="chapter" data-level="5.2" data-path="svm.html"><a href="svm.html#svm-packages-install"><i class="fa fa-check"></i><b>5.2</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="5.3" data-path="svm.html"><a href="svm.html#linear-svm-separable"><i class="fa fa-check"></i><b>5.3</b> 선형 SVM - 분리 가능 경우</a><ul>
<li class="chapter" data-level="5.3.1" data-path="svm.html"><a href="svm.html#linear-svm-separable-basic-script"><i class="fa fa-check"></i><b>5.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="5.3.2" data-path="svm.html"><a href="svm.html#linear-svm-notation"><i class="fa fa-check"></i><b>5.3.2</b> 기호 정의</a></li>
<li class="chapter" data-level="5.3.3" data-path="svm.html"><a href="svm.html#linear-svm-separable-hyperplane"><i class="fa fa-check"></i><b>5.3.3</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="svm.html"><a href="svm.html#linear-svm-inseparable"><i class="fa fa-check"></i><b>5.4</b> 선형 SVM - 분리 불가능 경우</a><ul>
<li class="chapter" data-level="5.4.1" data-path="svm.html"><a href="svm.html#linear-svm-inseparable-basic-script"><i class="fa fa-check"></i><b>5.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="5.4.2" data-path="svm.html"><a href="svm.html#linear-svm-inseparable-hyperplane"><i class="fa fa-check"></i><b>5.4.2</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="svm.html"><a href="svm.html#nonlinear-svm"><i class="fa fa-check"></i><b>5.5</b> 비선형 SVM</a><ul>
<li class="chapter" data-level="5.5.1" data-path="svm.html"><a href="svm.html#nonlinear-svm-basic-script"><i class="fa fa-check"></i><b>5.5.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="5.5.2" data-path="svm.html"><a href="svm.html#nonlinear-svm-hyperplane"><i class="fa fa-check"></i><b>5.5.2</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="svm.html"><a href="svm.html#svm-r-pkg"><i class="fa fa-check"></i><b>5.6</b> R패키지 내 SVM</a><ul>
<li class="chapter" data-level="5.6.1" data-path="svm.html"><a href="svm.html#svm-kernel-function"><i class="fa fa-check"></i><b>5.6.1</b> 커널함수</a></li>
<li class="chapter" data-level="5.6.2" data-path="svm.html"><a href="svm.html#svm-nu-classification"><i class="fa fa-check"></i><b>5.6.2</b> <span class="math inline">\(\nu\)</span>-SVC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html"><i class="fa fa-check"></i><b>6</b> 분류규칙의 성능 평가</a><ul>
<li class="chapter" data-level="6.1" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#classifier-evaluation-packages-install"><i class="fa fa-check"></i><b>6.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="6.2" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#classifier-evaluation-misclassification-rate"><i class="fa fa-check"></i><b>6.2</b> 분류오류율</a></li>
<li class="chapter" data-level="6.3" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#precision-sensitivity-specificity"><i class="fa fa-check"></i><b>6.3</b> 정확도, 민감도 및 특이도</a><ul>
<li class="chapter" data-level="6.3.1" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#confusion-matrix-r-package"><i class="fa fa-check"></i><b>6.3.1</b> R 패키지 내 정오분류표</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#roc-curve"><i class="fa fa-check"></i><b>6.4</b> ROC 곡선</a></li>
<li class="chapter" data-level="6.5" data-path="classifier-evaluation.html"><a href="classifier-evaluation.html#gain-chart"><i class="fa fa-check"></i><b>6.5</b> 이익도표</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="clustering-overview.html"><a href="clustering-overview.html"><i class="fa fa-check"></i><b>7</b> 군집분석 개요</a><ul>
<li class="chapter" data-level="7.1" data-path="clustering-overview.html"><a href="clustering-overview.html#clustering-overview-packages-install"><i class="fa fa-check"></i><b>7.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="7.2" data-path="clustering-overview.html"><a href="clustering-overview.html#clustering-method"><i class="fa fa-check"></i><b>7.2</b> 군집분석 기법</a></li>
<li class="chapter" data-level="7.3" data-path="clustering-overview.html"><a href="clustering-overview.html#object-similarity-metric"><i class="fa fa-check"></i><b>7.3</b> 객체 간의 유사성 척도</a><ul>
<li class="chapter" data-level="7.3.1" data-path="clustering-overview.html"><a href="clustering-overview.html#object-distance-metric"><i class="fa fa-check"></i><b>7.3.1</b> 거리 관련 척도</a></li>
<li class="chapter" data-level="7.3.2" data-path="clustering-overview.html"><a href="clustering-overview.html#object-correlation-metric"><i class="fa fa-check"></i><b>7.3.2</b> 상관계수 관련 척도</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="clustering-overview.html"><a href="clustering-overview.html#category-similarity-metric"><i class="fa fa-check"></i><b>7.4</b> 범주형 객체의 유사성 척도</a><ul>
<li class="chapter" data-level="7.4.1" data-path="clustering-overview.html"><a href="clustering-overview.html#binary-similarity-metric"><i class="fa fa-check"></i><b>7.4.1</b> 이분형 변수의 경우</a></li>
<li class="chapter" data-level="7.4.2" data-path="clustering-overview.html"><a href="clustering-overview.html#ordinal-similarity-metric"><i class="fa fa-check"></i><b>7.4.2</b> 서열형 변수의 경우</a></li>
<li class="chapter" data-level="7.4.3" data-path="clustering-overview.html"><a href="clustering-overview.html#nominal-similarity-metric"><i class="fa fa-check"></i><b>7.4.3</b> 명목형 변수의 경우</a></li>
<li class="chapter" data-level="7.4.4" data-path="clustering-overview.html"><a href="clustering-overview.html#mixed-similarity-metric"><i class="fa fa-check"></i><b>7.4.4</b> 혼합형의 경우</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html"><i class="fa fa-check"></i><b>8</b> 계층적 군집방법</a><ul>
<li class="chapter" data-level="8.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hierarchical-clustering-packages-install"><i class="fa fa-check"></i><b>8.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="8.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#distance-between-clusters"><i class="fa fa-check"></i><b>8.2</b> 군집 간 거리척도 및 연결법</a></li>
<li class="chapter" data-level="8.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method"><i class="fa fa-check"></i><b>8.3</b> 연결법의 군집 알고리즘</a><ul>
<li class="chapter" data-level="8.3.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method-basic-script"><i class="fa fa-check"></i><b>8.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="8.3.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method-algorithm"><i class="fa fa-check"></i><b>8.3.2</b> 연결법 군집 알고리즘</a></li>
<li class="chapter" data-level="8.3.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hclust"><i class="fa fa-check"></i><b>8.3.3</b> R 패키지 내 연결법</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method"><i class="fa fa-check"></i><b>8.4</b> 워드 방법</a><ul>
<li class="chapter" data-level="8.4.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method-basic-script"><i class="fa fa-check"></i><b>8.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="8.4.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method-algorithm"><i class="fa fa-check"></i><b>8.4.2</b> 워드 군집 알고리즘</a></li>
<li class="chapter" data-level="8.4.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-rpackages"><i class="fa fa-check"></i><b>8.4.3</b> R 패키지 내 워드 방법</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana"><i class="fa fa-check"></i><b>8.5</b> 분리적 방법 - 다이아나</a><ul>
<li class="chapter" data-level="8.5.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana-basic-script"><i class="fa fa-check"></i><b>8.5.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="8.5.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana-algorithm"><i class="fa fa-check"></i><b>8.5.2</b> 다이아나 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hierarchical-cluster-number"><i class="fa fa-check"></i><b>8.6</b> 군집수의 결정</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html"><i class="fa fa-check"></i><b>9</b> 비계층적 군집방법</a><ul>
<li class="chapter" data-level="9.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#nonhierarchical-clustering-packages-install"><i class="fa fa-check"></i><b>9.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="9.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans"><i class="fa fa-check"></i><b>9.2</b> K-means 알고리즘</a><ul>
<li class="chapter" data-level="9.2.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-basic-script"><i class="fa fa-check"></i><b>9.2.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="9.2.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-algorithm"><i class="fa fa-check"></i><b>9.2.2</b> 알고리즘</a></li>
<li class="chapter" data-level="9.2.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-user-defined-functions"><i class="fa fa-check"></i><b>9.2.3</b> R 스크립트 구현</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmedoids"><i class="fa fa-check"></i><b>9.3</b> K-medoids 군집방법</a><ul>
<li class="chapter" data-level="9.3.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#pam"><i class="fa fa-check"></i><b>9.3.1</b> PAM 알고리즘</a></li>
<li class="chapter" data-level="9.3.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#clara"><i class="fa fa-check"></i><b>9.3.2</b> CLARA 알고리즘</a></li>
<li class="chapter" data-level="9.3.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#clarans"><i class="fa fa-check"></i><b>9.3.3</b> CLARANS 알고리즘</a></li>
<li class="chapter" data-level="9.3.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-like"><i class="fa fa-check"></i><b>9.3.4</b> K-means-like 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans"><i class="fa fa-check"></i><b>9.4</b> 퍼지 K-means 알고리즘</a><ul>
<li class="chapter" data-level="9.4.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-basic-script"><i class="fa fa-check"></i><b>9.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="9.4.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-algorithm"><i class="fa fa-check"></i><b>9.4.2</b> 알고리즘</a></li>
<li class="chapter" data-level="9.4.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-script-implement"><i class="fa fa-check"></i><b>9.4.3</b> R 스크립트 구현</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering"><i class="fa fa-check"></i><b>9.5</b> 모형기반 군집방법</a><ul>
<li class="chapter" data-level="9.5.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-basic-script"><i class="fa fa-check"></i><b>9.5.1</b> 기본 R script</a></li>
<li class="chapter" data-level="9.5.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-em"><i class="fa fa-check"></i><b>9.5.2</b> EM 알고리즘</a></li>
<li class="chapter" data-level="9.5.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-script-implement"><i class="fa fa-check"></i><b>9.5.3</b> R 스크립트 구현</a></li>
<li class="chapter" data-level="9.5.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#r-packages-model-based-clustering"><i class="fa fa-check"></i><b>9.5.4</b> R 패키지 내 모형기반 군집분석</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html"><i class="fa fa-check"></i><b>10</b> 군집해의 평가 및 해석</a><ul>
<li class="chapter" data-level="10.1" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-solution-evaluation-packages-install"><i class="fa fa-check"></i><b>10.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="10.2" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-solution-evaluation-metric"><i class="fa fa-check"></i><b>10.2</b> 군집해의 평가</a><ul>
<li class="chapter" data-level="10.2.1" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-evaluation-external-index"><i class="fa fa-check"></i><b>10.2.1</b> 외부평가지수</a></li>
<li class="chapter" data-level="10.2.2" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-evaluation-internal-index"><i class="fa fa-check"></i><b>10.2.2</b> 내부평가지수</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="cluster-solution-evaluation.html"><a href="cluster-solution-evaluation.html#cluster-solution-interpretation"><i class="fa fa-check"></i><b>10.3</b> 군집해의 해석</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">데이터마이닝 with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="classifier-evaluation" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> 분류규칙의 성능 평가</h1>
<p>도출된 분류규칙에 대한 평가는 범주를 아는 학습표본이 있으므로 비교적 용이하게 이루어진다. 분류정확도 또는 분류오류율이 기본이 되나, 특히 범주가 2개인 경우에는 다양한 성능평가척도가 개발되어 사용되고 있다.</p>
<div id="classifier-evaluation-packages-install" class="section level2">
<h2><span class="header-section-number">6.1</span> 필요 R 패키지 설치</h2>
<p>본 장에서 필요한 R 패키지들은 아래와 같다.</p>
<table>
<thead>
<tr class="header">
<th align="left">package</th>
<th align="left">version</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">tidyverse</td>
<td align="left">1.2.1</td>
</tr>
<tr class="even">
<td align="left">caret</td>
<td align="left">6.0-81</td>
</tr>
</tbody>
</table>
</div>
<div id="classifier-evaluation-misclassification-rate" class="section level2">
<h2><span class="header-section-number">6.2</span> 분류오류율</h2>
<p>범주를 아는 데이터 <span class="math inline">\(\{(\mathbf{x}_i, y_i)\}_{i = 1, \cdots, N}\)</span>를 학습표본이라 한다.</p>
<ul>
<li><span class="math inline">\(\mathbf{x}_i\)</span>: <span class="math inline">\(p\)</span>개의 독립변수로 이루어진 <span class="math inline">\(i\)</span>번째 객체의 변수벡터 (<span class="math inline">\(\mathbf{x}_i = [x_{i1} \, x_{i2} \, \cdots \, x_{ip}]^\top\)</span>)</li>
<li><span class="math inline">\(J\)</span>: 총 범주 수</li>
<li><span class="math inline">\(y_i\)</span>: <span class="math inline">\(i\)</span>번째 객체의 범주 변수; <span class="math inline">\(y_i \in \{1, 2, \cdots, J\}\)</span></li>
</ul>
<p>분류규칙 <span class="math inline">\(d(\mathbf{x})\)</span>의 성능은 주로 분류오류율(misclassification rate)을 사용하는데, 분류규칙이 추정한 범주와 실제범주가 일치하지 않는 비율을 나타낸다.</p>
<span class="math display" id="eq:misclassification-rate-train">\[\begin{equation}
R(d) = \frac{1}{N} \sum_{i = 1}^{N} I(d(\mathbf{x}_i) \neq y_i)
\tag{6.1}
\end{equation}\]</span>
<p>여기서 함수 지시함수 <span class="math inline">\(I(x)\)</span>는 <span class="math inline">\(x\)</span>가 참(true)일 때 1, 거짓(false)일 때 0의 값을 갖는다.</p>
<p>식 <a href="classifier-evaluation.html#eq:misclassification-rate-train">(6.1)</a>은 학습표본에 대한 오분류율로, 이를 최소화하려할 경우 분류규칙이 해당 학습데이터에만 과적용(overfitting)되는 문제가 발생할 수 있다. 즉, 새로운 데이터에 적용할 때도 오분류율이 최소화될 것이라는 보장이 없다.</p>
<p>이 때문에, 통상 관측수가 상당수 있는 데이터에 대해서는 전체 데이터를 두 부분으로 나누어, 분류규칙을 만드는 데 한 부분을 사용하고, 분류오류율을 산출하는 데 다른 한 부분을 사용하는 방안이 일반적이다. 아래와 같이 범주가 알려져있지만 분류규칙 <span class="math inline">\(d(\mathbf{x})\)</span>를 학습하는 데 사용하지 않은 <span class="math inline">\(L\)</span>개의 테스트 표본 <span class="math inline">\(\{(\mathbf{x}_i, y_i)\}_{i = N + 1, \cdots, N + L}\)</span>이 있다고 하자. 이 때 테스트 표본에 대한 분류오류율을 아래와 같이 계산한다.</p>
<span class="math display" id="eq:misclassification-rate-test">\[\begin{equation}
R^{ts}(d) = \frac{1}{L} \sum_{i = N + 1}^{N + L} I(d(\mathbf{x}_i) \neq y_i)
\tag{6.2}
\end{equation}\]</span>
<p>테스트 표본으로 분리하기에 충분하지 않은 데이터의 경우에는 cross validation 기법을 사용한다.</p>
</div>
<div id="precision-sensitivity-specificity" class="section level2">
<h2><span class="header-section-number">6.3</span> 정확도, 민감도 및 특이도</h2>
<p>의학 분야에서 어떤 질병에 대한 진단방법을 평가할 때 오류율 이와에 정확도, 민감도 및 특이도를 분석하는 경우가 종종 있다. 실제범주가 질병이 있는 경우(<code>1</code> 또는 <code>+</code>로 표기)와 질병이 없는 경우(<code>0</code> 또는 <code>-</code>로 표기)의 두 가지로 분류된다고 하고, 진단 방법이 양성(<code>1</code> 또는 <code>+</code>) 또는 음성(<code>0</code> 또는 <code>-</code>)으로 판정할 때, 아래와 같이 네 가지 경우가 발생한다. 이와 같은 표를 정오분류표(confusion matrix)라 한다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cm &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="st">&#39;a&#39;</span>, <span class="st">&#39;b&#39;</span>, <span class="st">&#39;c&#39;</span>, <span class="st">&#39;d&#39;</span>), <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">byrow =</span> <span class="ot">TRUE</span>)
<span class="kw">attr</span>(cm, <span class="st">&quot;dimnames&quot;</span>) &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="dt">Prediction =</span> <span class="kw">c</span>(<span class="st">&quot;1&quot;</span>, <span class="st">&quot;0&quot;</span>), <span class="dt">Reference =</span> <span class="kw">c</span>(<span class="st">&quot;1&quot;</span>, <span class="st">&quot;0&quot;</span>))
<span class="kw">class</span>(cm) &lt;-<span class="st"> &quot;table&quot;</span>
<span class="kw">print</span>(cm)</code></pre></div>
<pre><code>##           Reference
## Prediction 1 0
##          1 a b
##          0 c d</code></pre>
<p>위 표의 문자들은 다음과 같이 정의된다.</p>
<ul>
<li><span class="math inline">\(a\)</span>: number of true positive prediction</li>
<li><span class="math inline">\(b\)</span>: number of false positive prediction</li>
<li><span class="math inline">\(c\)</span>: number of false negative prediction</li>
<li><span class="math inline">\(d\)</span>: number of true negative prediction</li>
</ul>
<p>여기서 “positive” 또는 “negative”는 “양성” 또는 “음성”으로 추정됨을 나타내고, “true” 또는 “false”는 추정의 사실 또는 거짓을 나타낸다. 이 때 분류오류율은 다음과 같이 산출된다.</p>
<span class="math display" id="eq:cm-misclassification-rate">\[\begin{equation}
\text{misclassifiction rate} = \frac{b + c}{a + b + c + d}
\tag{6.3}
\end{equation}\]</span>
<p>정확도(accuracy)는 오류율의 반대 개념으로, 실제 범주를 제대로 추정한 전체 비율을 나타내며 아래와 같이 산출된다.</p>
<span class="math display" id="eq:cm-accuracy">\[\begin{equation}
\text{accuracy} = \frac{a + d}{a + b + c + d} = 1 - \text{misclassifiction rate}
\tag{6.4}
\end{equation}\]</span>
<p>한편, 민감도(sensitivity)는 실제 질병이 있는 경우를 양성으로 판정하는 비율을 나타내는 것으로, 다음과 같이 산출된다.</p>
<span class="math display" id="eq:cm-sensitivity">\[\begin{equation}
\text{sensitivity} = \frac{a}{a + c}
\tag{6.5}
\end{equation}\]</span>
<p>그리고 특이도(specificity)란 실제 질병이 없는 경우를 음성으로 판정하는 비율을 나타내는 것으로 다음과 같다.</p>
<span class="math display" id="eq:cm-specificity">\[\begin{equation}
\text{specificity} = \frac{d}{b + d}
\tag{6.6}
\end{equation}\]</span>
<p>정확도를 민감도 및 특이도로 표현하면 다음과 같다.</p>
<span class="math display">\[\begin{equation*}
\text{accuracy} = \frac{a + c}{a + b + c + d}\text{sensitivity} + \frac{b + d}{a + b + c + d}\text{specificity}
\end{equation*}\]</span>
<p>민감도 및 특이도를 별도로 산출하여 분석하는 이유 중 하나는, 동일한 정확도를 갖는다 하더라도 민감도와 특이도는 다를 수 있기 때문이다. 경우에 따라서는 높은 민감도를 원하거나 높은 특이도를 원할 수 있다.</p>
<div id="confusion-matrix-r-package" class="section level3">
<h3><span class="header-section-number">6.3.1</span> R 패키지 내 정오분류표</h3>
<p>100개의 객체에 대한 실제범주와 추정범주가 아래와 같이 주어진다고 하자.</p>
<span class="math display">\[\begin{eqnarray*}
y_i &amp;=&amp; \begin{cases}
1 &amp; i = 1, \cdots, 20\\
0 &amp; i = 21, \cdots, 100
\end{cases},\\
\hat{y}_i &amp;=&amp; \begin{cases}
1 &amp; i = 1, \cdots, 15, 91, \cdots, 100\\
0 &amp; i = 16, \cdots, 90
\end{cases}
\end{eqnarray*}\]</span>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> </span><span class="kw">factor</span>(<span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">20</span>), <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">80</span>)), <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>))
y_hat &lt;-<span class="kw">factor</span>(<span class="kw">c</span>(<span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">15</span>), <span class="kw">rep</span>(<span class="dv">0</span>, <span class="dv">75</span>), <span class="kw">rep</span>(<span class="dv">1</span>, <span class="dv">10</span>)), <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>))</code></pre></div>
<p>해당 추정결과에 대한 정오분류표 및 각종 평가지표를 얻기 위해 <code>caret</code> 패키지의 <code>confusionMatrix</code> 함수를 이용한다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cm &lt;-<span class="st"> </span>caret<span class="op">::</span><span class="kw">confusionMatrix</span>(<span class="dt">data =</span> y_hat, <span class="dt">reference =</span> y)</code></pre></div>
<p>우선 정오분류표는 결과 객체의 <code>table</code> component에 저장된다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cm<span class="op">$</span>table</code></pre></div>
<pre><code>##           Reference
## Prediction  1  0
##          1 15 10
##          0  5 70</code></pre>
<p>정확도를 비롯한 각종 전반적인 지표는 <code>overall</code>이라는 component에 벡터 형태로 저장된다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cm<span class="op">$</span>overall</code></pre></div>
<pre><code>##       Accuracy          Kappa  AccuracyLower  AccuracyUpper   AccuracyNull 
##      0.8500000      0.5714286      0.7646925      0.9135456      0.8000000 
## AccuracyPValue  McnemarPValue 
##      0.1285055      0.3016996</code></pre>
<p>또한, 민감도, 특이도를 비롯한 몇 가지 분류성능 지표들은 <code>byClass</code>라는 component에 역시 벡터 형태로 저장된다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cm<span class="op">$</span>byClass</code></pre></div>
<pre><code>##          Sensitivity          Specificity       Pos Pred Value 
##            0.7500000            0.8750000            0.6000000 
##       Neg Pred Value            Precision               Recall 
##            0.9333333            0.6000000            0.7500000 
##                   F1           Prevalence       Detection Rate 
##            0.6666667            0.2000000            0.1500000 
## Detection Prevalence    Balanced Accuracy 
##            0.2500000            0.8125000</code></pre>
</div>
</div>
<div id="roc-curve" class="section level2">
<h2><span class="header-section-number">6.4</span> ROC 곡선</h2>
<p>일반적으로 민감도와 특이도를 동시에 증가시키는 것은 불가능하다. 다시 말하면, 민감도를 높이면 특이도가 감소하고, 또한 반대가 성립하게 된다.</p>
<p>예를 들어 다음과 같이 10개의 객체로 이루어진 학습표본이 있다고 하자.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_df &lt;-<span class="st"> </span><span class="kw">tribble</span>(
  <span class="op">~</span>x, <span class="op">~</span>y,
  <span class="dv">24</span>, <span class="dv">0</span>,
  <span class="dv">35</span>, <span class="dv">0</span>,
  <span class="dv">37</span>, <span class="dv">1</span>,
  <span class="dv">42</span>, <span class="dv">0</span>,
  <span class="dv">49</span>, <span class="dv">1</span>,
  <span class="dv">54</span>, <span class="dv">1</span>,
  <span class="dv">56</span>, <span class="dv">0</span>,
  <span class="dv">68</span>, <span class="dv">1</span>,
  <span class="dv">72</span>, <span class="dv">1</span>,
  <span class="dv">73</span>, <span class="dv">1</span>
) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">y =</span> <span class="kw">factor</span>(y, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>)))</code></pre></div>
<p>분류기준이 만약 <span class="math inline">\(x &lt; 40\)</span>이면 범주 <code>0</code>, <span class="math inline">\(x \geq 40\)</span>이면 범주 <code>1</code>로 추정할 때, 정오분류표는 다음과 같다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cm40 &lt;-<span class="st"> </span>caret<span class="op">::</span><span class="kw">confusionMatrix</span>(
  <span class="kw">factor</span>(<span class="kw">as.integer</span>(train_df<span class="op">$</span>x <span class="op">&gt;=</span><span class="st"> </span><span class="dv">40</span>), <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>)),
  train_df<span class="op">$</span>y
)

cm40<span class="op">$</span>table</code></pre></div>
<pre><code>##           Reference
## Prediction 1 0
##          1 5 2
##          0 1 2</code></pre>
<p>이 때 구해지는 민감도 및 특이도는 아래와 같다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cm40<span class="op">$</span>byClass[<span class="kw">c</span>(<span class="st">&quot;Sensitivity&quot;</span>, <span class="st">&quot;Specificity&quot;</span>)]</code></pre></div>
<pre><code>## Sensitivity Specificity 
##   0.8333333   0.5000000</code></pre>
<p>한편, 분류기준이 만약 <span class="math inline">\(x &lt; 50\)</span>이면 범주 <code>0</code>, <span class="math inline">\(x \geq 50\)</span>이면 범주 <code>1</code>로 추정할 때, 정오분류표는 다음과 같다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cm50 &lt;-<span class="st"> </span>caret<span class="op">::</span><span class="kw">confusionMatrix</span>(
  <span class="kw">factor</span>(<span class="kw">as.integer</span>(train_df<span class="op">$</span>x <span class="op">&gt;=</span><span class="st"> </span><span class="dv">50</span>), <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>)),
  train_df<span class="op">$</span>y
)

cm50<span class="op">$</span>table</code></pre></div>
<pre><code>##           Reference
## Prediction 1 0
##          1 4 1
##          0 2 3</code></pre>
<p>또한, 이 때 구해지는 민감도 및 특이도는 아래와 같다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cm50<span class="op">$</span>byClass[<span class="kw">c</span>(<span class="st">&quot;Sensitivity&quot;</span>, <span class="st">&quot;Specificity&quot;</span>)]</code></pre></div>
<pre><code>## Sensitivity Specificity 
##   0.6666667   0.7500000</code></pre>
<p>위 <span class="math inline">\(x\)</span>값 40을 기준으로 분류를 하는 경우와 비교하여 민감도는 감소하고 특이도는 증가함을 관찰할 수 있다.</p>
<p>분류를 위한 <span class="math inline">\(x\)</span> 기준값(threshold)을 증가시켜가면서 민감도와 특이도가 어떻게 변하는 지 살펴보도록 하자.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">univariate_binary_rule &lt;-<span class="st"> </span><span class="cf">function</span>(x, y, th) {
  cm &lt;-<span class="st"> </span>caret<span class="op">::</span><span class="kw">confusionMatrix</span>(
    <span class="kw">factor</span>(<span class="kw">as.integer</span>(x <span class="op">&gt;=</span><span class="st"> </span>th), <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>)),
    y
  )
  
  <span class="kw">tibble</span>(<span class="dt">threshold =</span> th, 
         <span class="dt">sensitivity =</span> cm<span class="op">$</span>byClass[<span class="st">&quot;Sensitivity&quot;</span>],
         <span class="dt">specificity =</span> cm<span class="op">$</span>byClass[<span class="st">&quot;Specificity&quot;</span>])
}

th &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">sort</span>(train_df<span class="op">$</span>x), <span class="ot">Inf</span>)

roc_df &lt;-<span class="st"> </span><span class="kw">map_dfr</span>(th, univariate_binary_rule, <span class="dt">x =</span> train_df<span class="op">$</span>x, <span class="dt">y =</span> train_df<span class="op">$</span>y)

knitr<span class="op">::</span><span class="kw">kable</span>(
  roc_df, <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
  <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),
  <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;분류기준값($x$)&#39;</span>, <span class="st">&#39;민감도(sensitivity)&#39;</span>, <span class="st">&#39;특이도(specificity)&#39;</span>),
  <span class="dt">caption =</span> <span class="st">&#39;분류기준별 민감도 및 특이도&#39;</span>
)</code></pre></div>
<table>
<caption><span id="tab:roc-data">Table 6.1: </span>분류기준별 민감도 및 특이도</caption>
<thead>
<tr class="header">
<th align="center">분류기준값(<span class="math inline">\(x\)</span>)</th>
<th align="center">민감도(sensitivity)</th>
<th align="center">특이도(specificity)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">24</td>
<td align="center">1.0000000</td>
<td align="center">0.00</td>
</tr>
<tr class="even">
<td align="center">35</td>
<td align="center">1.0000000</td>
<td align="center">0.25</td>
</tr>
<tr class="odd">
<td align="center">37</td>
<td align="center">1.0000000</td>
<td align="center">0.50</td>
</tr>
<tr class="even">
<td align="center">42</td>
<td align="center">0.8333333</td>
<td align="center">0.50</td>
</tr>
<tr class="odd">
<td align="center">49</td>
<td align="center">0.8333333</td>
<td align="center">0.75</td>
</tr>
<tr class="even">
<td align="center">54</td>
<td align="center">0.6666667</td>
<td align="center">0.75</td>
</tr>
<tr class="odd">
<td align="center">56</td>
<td align="center">0.5000000</td>
<td align="center">0.75</td>
</tr>
<tr class="even">
<td align="center">68</td>
<td align="center">0.5000000</td>
<td align="center">1.00</td>
</tr>
<tr class="odd">
<td align="center">72</td>
<td align="center">0.3333333</td>
<td align="center">1.00</td>
</tr>
<tr class="even">
<td align="center">73</td>
<td align="center">0.1666667</td>
<td align="center">1.00</td>
</tr>
<tr class="odd">
<td align="center">Inf</td>
<td align="center">0.0000000</td>
<td align="center">1.00</td>
</tr>
</tbody>
</table>
<p>민감도와 특이도를 동시에 그래프로 나타낸 것 중 ROC(receiver operating characteristic) 곡선이 널리 사용되는데, 이는 분류기의 경계치를 조정하여 가면서 (1 - 특이도)(또는 false positive rate)을 <span class="math inline">\(x\)</span>축에, 민감도를 <span class="math inline">\(y\)</span>축에 도식화한 것이다.</p>
<p>위 Table <a href="classifier-evaluation.html#tab:roc-data">6.1</a>를 바탕으로 ROC 곡선을 작성해보자.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">roc_df <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span>specificity, <span class="dt">y =</span> sensitivity)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_path</span>()</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:roc-example"></span>
<img src="data-mining-book_files/figure-html/roc-example-1.png" alt="ROC 곡선" width="672" />
<p class="caption">
Figure 6.1: ROC 곡선
</p>
</div>
</div>
<div id="gain-chart" class="section level2">
<h2><span class="header-section-number">6.5</span> 이익도표</h2>
<p>이익도표는 마케팅을 위하여 수익을 창출하는 목표고객(target)을 추출할 목적으로 사용되는데, 단순히 분류를 위한 여러 모형을 비교하기 위한 목적으로도 종종 사용되고 있다. 목표 마케팅의 목적에서는, 특정 범주의 고객을 목표고객으로 할 때, 이러한 목표고객의 비율이 상대적으로 높은 서브그룹을 찾고자 하는 것이다. 이를 위해, 우선 전체 데이터를 특정 범주의 사후확률의 순서로 정렬한 후, <span class="math inline">\(K\)</span>개(주로 <span class="math inline">\(K = 10\)</span>을 사용)의 집단으로 구분하고, 각 집단별로 다음과 같은 통계량을 산출한다.</p>
<p><span class="math inline">\(k\)</span>번째 집단 내에서 범주 <span class="math inline">\(j\)</span>에 속한 객체의 수를 <span class="math inline">\(n_{kj}\)</span>라 할 때, 다음과 같은 범주 <span class="math inline">\(j\)</span>에 대한 <span class="math inline">\(k\)</span>번째 집단의 통계량들을 산출할 수 있다. (본 장에서 <span class="math inline">\(K\)</span>개의 집단은 동일한 크기라 가정하자. 즉, 모든 집단 <span class="math inline">\(k\)</span>에 대해 <span class="math inline">\(\sum_{j = 1}^{J} n_{kj} = \frac{N}{K}\)</span>가 성립한다고 하자.)</p>
<span class="math display">\[\begin{eqnarray*}
\text{% captured response} &amp;=&amp; \frac{n_{kj}}{\sum_{k = 1}^{K} n_{kj}} \times 100\\
\text{cumulative % captured response} &amp;=&amp; \frac{\sum_{l = 1}^{k} n_{lj}}{\sum_{k = 1}^{K} n_{kj}} \times 100\\
\text{% response} &amp;=&amp; \frac{n_{kj}}{\sum_{j = 1}^{J} n_{kj}} \times 100\\
\text{lift} &amp;=&amp; \frac{n_{kj}}{\frac{1}{K} \sum_{k = 1}^{K} n_{kj}}
\end{eqnarray*}\]</span>
<p>1,000개의 객체로 이루어진 어떤 데이터의 실제 범주별 빈도가 다음과 같다고 하자.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y_freq &lt;-<span class="st"> </span><span class="kw">tribble</span>(
  <span class="op">~</span>y, <span class="op">~</span>n,
  <span class="dv">1</span>, <span class="dv">437</span>,
  <span class="dv">2</span>, <span class="dv">348</span>,
  <span class="dv">3</span>, <span class="dv">215</span>
) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">y =</span> <span class="kw">factor</span>(y, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)))

y_freq</code></pre></div>
<pre><code>## # A tibble: 3 x 2
##   y         n
##   &lt;fct&gt; &lt;dbl&gt;
## 1 1       437
## 2 2       348
## 3 3       215</code></pre>
<p>한편, 어떤 분류모형을 사용하여 각 객체의 범주 <code>1</code>(특정 범주)에 대한 사후확률을 산출한 후, 전체 객체를 사후확률의 내림차순으로 정렬한 뒤 100개 객체씩 한 집단으로 구분하였다. 각 집단에 속하는 범주 <code>1</code>의 빈도는 다음과 같았다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">freq_within_group &lt;-<span class="st"> </span><span class="kw">tribble</span>(
  <span class="op">~</span>k, <span class="op">~</span>n,
  <span class="dv">1</span>, <span class="dv">92</span>,
  <span class="dv">2</span>, <span class="dv">78</span>,
  <span class="dv">3</span>, <span class="dv">64</span>,
  <span class="dv">4</span>, <span class="dv">57</span>,
  <span class="dv">5</span>, <span class="dv">43</span>,
  <span class="dv">6</span>, <span class="dv">35</span>,
  <span class="dv">7</span>, <span class="dv">29</span>,
  <span class="dv">8</span>, <span class="dv">22</span>,
  <span class="dv">9</span>, <span class="dv">7</span>,
  <span class="dv">10</span>, <span class="dv">10</span>
)

freq_within_group</code></pre></div>
<pre><code>## # A tibble: 10 x 2
##        k     n
##    &lt;dbl&gt; &lt;dbl&gt;
##  1     1    92
##  2     2    78
##  3     3    64
##  4     4    57
##  5     5    43
##  6     6    35
##  7     7    29
##  8     8    22
##  9     9     7
## 10    10    10</code></pre>
<p>이를 바탕으로 각 집단 별 범주 <code>1</code>에 대한 통계량을 산출해보자.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">stat_df &lt;-<span class="st"> </span>freq_within_group <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">cum_n =</span> <span class="kw">cumsum</span>(n)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">captured_response_pct =</span> n <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(n) <span class="op">*</span><span class="st"> </span><span class="dv">100</span>,
    <span class="dt">cum_captured_response_pct =</span> cum_n <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(n) <span class="op">*</span><span class="st"> </span><span class="dv">100</span>,
    <span class="dt">response_pct =</span> n <span class="op">/</span><span class="st"> </span><span class="dv">100</span> <span class="op">*</span><span class="st"> </span><span class="dv">100</span>,
    <span class="dt">lift =</span> n <span class="op">/</span><span class="st"> </span><span class="kw">mean</span>(n)
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>cum_n)

knitr<span class="op">::</span><span class="kw">kable</span>(
  stat_df,
  <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
  <span class="dt">align =</span> <span class="kw">rep</span>(<span class="st">&#39;r&#39;</span>, <span class="dv">6</span>),
  <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;집단&#39;</span>, <span class="st">&#39;범주 1의 빈도&#39;</span>, <span class="st">&#39;% captured response&#39;</span>, 
                <span class="st">&#39;cum. % captured response&#39;</span>, <span class="st">&#39;% response&#39;</span>, <span class="st">&#39;lift&#39;</span>),
  <span class="dt">caption =</span> <span class="st">&#39;이익도표를 위한 통계량&#39;</span>,
  <span class="dt">digits =</span> <span class="dv">2</span>
)</code></pre></div>
<table>
<caption><span id="tab:gain-chart-stat">Table 6.2: </span>이익도표를 위한 통계량</caption>
<thead>
<tr class="header">
<th align="center">집단</th>
<th align="center">범주 1의 빈도</th>
<th align="right">% captured response</th>
<th align="right">cum. % captured response</th>
<th align="right">% response</th>
<th align="right">lift</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">92</td>
<td align="right">21.05</td>
<td align="right">21.05</td>
<td align="right">92</td>
<td align="right">2.11</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">78</td>
<td align="right">17.85</td>
<td align="right">38.90</td>
<td align="right">78</td>
<td align="right">1.78</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">64</td>
<td align="right">14.65</td>
<td align="right">53.55</td>
<td align="right">64</td>
<td align="right">1.46</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">57</td>
<td align="right">13.04</td>
<td align="right">66.59</td>
<td align="right">57</td>
<td align="right">1.30</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">43</td>
<td align="right">9.84</td>
<td align="right">76.43</td>
<td align="right">43</td>
<td align="right">0.98</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">35</td>
<td align="right">8.01</td>
<td align="right">84.44</td>
<td align="right">35</td>
<td align="right">0.80</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">29</td>
<td align="right">6.64</td>
<td align="right">91.08</td>
<td align="right">29</td>
<td align="right">0.66</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">22</td>
<td align="right">5.03</td>
<td align="right">96.11</td>
<td align="right">22</td>
<td align="right">0.50</td>
</tr>
<tr class="odd">
<td align="center">9</td>
<td align="center">7</td>
<td align="right">1.60</td>
<td align="right">97.71</td>
<td align="right">7</td>
<td align="right">0.16</td>
</tr>
<tr class="even">
<td align="center">10</td>
<td align="center">10</td>
<td align="right">2.29</td>
<td align="right">100.00</td>
<td align="right">10</td>
<td align="right">0.23</td>
</tr>
</tbody>
</table>
<p>Table <a href="classifier-evaluation.html#tab:gain-chart-stat">6.2</a>를 바탕으로 네 가지 이익도표를 작성해보자.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">stat_df <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">gather</span>(<span class="dt">key =</span> <span class="st">&quot;stat&quot;</span>, <span class="dt">value =</span> <span class="st">&quot;value&quot;</span>, 
         captured_response_pct<span class="op">:</span>lift) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> k, <span class="dt">y =</span> value)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">facet_wrap</span>(<span class="kw">vars</span>(stat), <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">ncol =</span> <span class="dv">2</span>, <span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>,
             <span class="dt">labeller =</span> <span class="kw">as_labeller</span>(
               <span class="kw">c</span>(<span class="st">&quot;captured_response_pct&quot;</span> =<span class="st"> &quot;% captured response&quot;</span>,
                 <span class="st">&quot;cum_captured_response_pct&quot;</span> =<span class="st"> &quot;cum. % captured response&quot;</span>,
                 <span class="st">&quot;response_pct&quot;</span> =<span class="st"> &quot;% response&quot;</span>,
                 <span class="st">&quot;lift&quot;</span> =<span class="st"> &quot;lift&quot;</span>)
             )) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;집단&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;통계량&quot;</span>)</code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:gain-chart-plot"></span>
<img src="data-mining-book_files/figure-html/gain-chart-plot-1.png" alt="이익도표" width="672" />
<p class="caption">
Figure 6.2: 이익도표
</p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="svm.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="clustering-overview.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
