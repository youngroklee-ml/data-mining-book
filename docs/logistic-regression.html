<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 1 로지스틱 회귀분석 | 데이터마이닝 with R</title>
  <meta name="description" content="전치혁 교수님의 책 을 기반으로 한 R 예제">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 1 로지스틱 회귀분석 | 데이터마이닝 with R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://youngroklee-ml.github.io/data-mining-book/" />
  
  <meta property="og:description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  <meta name="github-repo" content="youngroklee-ml/data-mining-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 1 로지스틱 회귀분석 | 데이터마이닝 with R" />
  
  <meta name="twitter:description" content="전치혁 교수님의 책 을 기반으로 한 R 예제" />
  

<meta name="author" content="전치혁, 이혜선, 이종석, 이영록">


<meta name="date" content="2019-02-09">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="da.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">데이터마이닝 with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>개요</a></li>
<li class="chapter" data-level="1" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>1</b> 로지스틱 회귀분석</a><ul>
<li class="chapter" data-level="1.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logistic-packages-install"><i class="fa fa-check"></i><b>1.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="1.2" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-regression"><i class="fa fa-check"></i><b>1.2</b> 이분 로지스틱 회귀모형</a><ul>
<li class="chapter" data-level="1.2.1" data-path="logistic-regression.html"><a href="logistic-regression.html#bianry-logistic-reg-basic-script"><i class="fa fa-check"></i><b>1.2.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="1.2.2" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-reg-model"><i class="fa fa-check"></i><b>1.2.2</b> 회귀모형</a></li>
<li class="chapter" data-level="1.2.3" data-path="logistic-regression.html"><a href="logistic-regression.html#binary-logistic-reg-estimation"><i class="fa fa-check"></i><b>1.2.3</b> 회귀계수 추정</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="logistic-regression.html"><a href="logistic-regression.html#nominal-logistic-regression"><i class="fa fa-check"></i><b>1.3</b> 명목 로지스틱 회귀모형</a><ul>
<li class="chapter" data-level="1.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#nominal-logistic-reg-basic-script"><i class="fa fa-check"></i><b>1.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="1.3.2" data-path="logistic-regression.html"><a href="logistic-regression.html#baseline-category-logit-model"><i class="fa fa-check"></i><b>1.3.2</b> 기준범주 로짓모형</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="logistic-regression.html"><a href="logistic-regression.html#ordinal-logistic-regression"><i class="fa fa-check"></i><b>1.4</b> 서열 로지스틱 회귀모형</a><ul>
<li class="chapter" data-level="1.4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#ordinal-logistic-basic-script"><i class="fa fa-check"></i><b>1.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="1.4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#cumulative-logit-model"><i class="fa fa-check"></i><b>1.4.2</b> 누적 로짓모형</a></li>
<li class="chapter" data-level="1.4.3" data-path="logistic-regression.html"><a href="logistic-regression.html#adjacent-categories-logit-model"><i class="fa fa-check"></i><b>1.4.3</b> 인근범주 로짓모형</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="da.html"><a href="da.html"><i class="fa fa-check"></i><b>2</b> 판별분석</a><ul>
<li class="chapter" data-level="2.1" data-path="da.html"><a href="da.html#da-overview"><i class="fa fa-check"></i><b>2.1</b> 개요</a></li>
<li class="chapter" data-level="2.2" data-path="da.html"><a href="da.html#da-packages-install"><i class="fa fa-check"></i><b>2.2</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="2.3" data-path="da.html"><a href="da.html#da-fisher"><i class="fa fa-check"></i><b>2.3</b> 피셔 방법</a><ul>
<li class="chapter" data-level="2.3.1" data-path="da.html"><a href="da.html#da-fisher-basic-script"><i class="fa fa-check"></i><b>2.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="2.3.2" data-path="da.html"><a href="da.html#-"><i class="fa fa-check"></i><b>2.3.2</b> 피셔 판별함수</a></li>
<li class="chapter" data-level="2.3.3" data-path="da.html"><a href="da.html#-"><i class="fa fa-check"></i><b>2.3.3</b> 분류 규칙</a></li>
<li class="chapter" data-level="2.3.4" data-path="da.html"><a href="da.html#r----"><i class="fa fa-check"></i><b>2.3.4</b> R 패키지를 이용한 분류규칙 도출</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="da.html"><a href="da.html#lda"><i class="fa fa-check"></i><b>2.4</b> 의사결정론에 의한 선형분류규칙</a><ul>
<li class="chapter" data-level="2.4.1" data-path="da.html"><a href="da.html#lda-basic-script"><i class="fa fa-check"></i><b>2.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="2.4.2" data-path="da.html"><a href="da.html#lda-function"><i class="fa fa-check"></i><b>2.4.2</b> 선형판별함수</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="da.html"><a href="da.html#lda-misclassification-cost"><i class="fa fa-check"></i><b>2.5</b> 오분류비용을 고려한 분류규칙</a></li>
<li class="chapter" data-level="2.6" data-path="da.html"><a href="da.html#qda"><i class="fa fa-check"></i><b>2.6</b> 이차판별분석</a><ul>
<li class="chapter" data-level="2.6.1" data-path="da.html"><a href="da.html#qda-basic-script"><i class="fa fa-check"></i><b>2.6.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="2.6.2" data-path="da.html"><a href="da.html#qda-function"><i class="fa fa-check"></i><b>2.6.2</b> 이차 판별함수</a></li>
<li class="chapter" data-level="2.6.3" data-path="da.html"><a href="da.html#qda-discriminant-rule"><i class="fa fa-check"></i><b>2.6.3</b> 이차판별함수에 의한 분류</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="da.html"><a href="da.html#da-multiclass"><i class="fa fa-check"></i><b>2.7</b> 세 범주 이상의 분류</a><ul>
<li class="chapter" data-level="2.7.1" data-path="da.html"><a href="da.html#mutliclass-da-basic-script"><i class="fa fa-check"></i><b>2.7.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="2.7.2" data-path="da.html"><a href="da.html#mutliclass-generalized-discriminant-function"><i class="fa fa-check"></i><b>2.7.2</b> 일반화된 판별함수</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="tree-based-method.html"><a href="tree-based-method.html"><i class="fa fa-check"></i><b>3</b> 트리기반 기법</a><ul>
<li class="chapter" data-level="3.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-overview"><i class="fa fa-check"></i><b>3.1</b> CART 개요</a></li>
<li class="chapter" data-level="3.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-packages-install"><i class="fa fa-check"></i><b>3.2</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="3.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-build"><i class="fa fa-check"></i><b>3.3</b> CART 트리 생성</a><ul>
<li class="chapter" data-level="3.3.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-basic-r-script"><i class="fa fa-check"></i><b>3.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="3.3.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-notation"><i class="fa fa-check"></i><b>3.3.2</b> 기호 정의</a></li>
<li class="chapter" data-level="3.3.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-impurity"><i class="fa fa-check"></i><b>3.3.3</b> 노드 및 트리의 불순도</a></li>
<li class="chapter" data-level="3.3.4" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-split"><i class="fa fa-check"></i><b>3.3.4</b> 분지기준</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-pruning-complete"><i class="fa fa-check"></i><b>3.4</b> 가지치기 및 최종 트리 선정</a><ul>
<li class="chapter" data-level="3.4.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-pruning"><i class="fa fa-check"></i><b>3.4.1</b> 가지치기</a></li>
<li class="chapter" data-level="3.4.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-best-tree"><i class="fa fa-check"></i><b>3.4.2</b> 최적 트리의 선정</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg"><i class="fa fa-check"></i><b>3.5</b> R패키지 내 분류 트리 방법</a><ul>
<li class="chapter" data-level="3.5.1" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-split"><i class="fa fa-check"></i><b>3.5.1</b> 트리 확장</a></li>
<li class="chapter" data-level="3.5.2" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-pruning"><i class="fa fa-check"></i><b>3.5.2</b> 가지치기</a></li>
<li class="chapter" data-level="3.5.3" data-path="tree-based-method.html"><a href="tree-based-method.html#cart-r-pkg-param"><i class="fa fa-check"></i><b>3.5.3</b> 파라미터값 결정</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="svm.html"><a href="svm.html"><i class="fa fa-check"></i><b>4</b> 서포트 벡터 머신</a><ul>
<li class="chapter" data-level="4.1" data-path="svm.html"><a href="svm.html#svm-overview"><i class="fa fa-check"></i><b>4.1</b> 개요</a></li>
<li class="chapter" data-level="4.2" data-path="svm.html"><a href="svm.html#svm-packages-install"><i class="fa fa-check"></i><b>4.2</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="4.3" data-path="svm.html"><a href="svm.html#linear-svm-separable"><i class="fa fa-check"></i><b>4.3</b> 선형 SVM - 분리 가능 경우</a><ul>
<li class="chapter" data-level="4.3.1" data-path="svm.html"><a href="svm.html#linear-svm-separable-basic-script"><i class="fa fa-check"></i><b>4.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="4.3.2" data-path="svm.html"><a href="svm.html#linear-svm-notation"><i class="fa fa-check"></i><b>4.3.2</b> 기호 정의</a></li>
<li class="chapter" data-level="4.3.3" data-path="svm.html"><a href="svm.html#linear-svm-separable-hyperplane"><i class="fa fa-check"></i><b>4.3.3</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="svm.html"><a href="svm.html#linear-svm-inseparable"><i class="fa fa-check"></i><b>4.4</b> 선형 SVM - 분리 불가능 경우</a><ul>
<li class="chapter" data-level="4.4.1" data-path="svm.html"><a href="svm.html#linear-svm-inseparable-basic-script"><i class="fa fa-check"></i><b>4.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="4.4.2" data-path="svm.html"><a href="svm.html#linear-svm-inseparable-hyperplane"><i class="fa fa-check"></i><b>4.4.2</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="svm.html"><a href="svm.html#nonlinear-svm"><i class="fa fa-check"></i><b>4.5</b> 비선형 SVM</a><ul>
<li class="chapter" data-level="4.5.1" data-path="svm.html"><a href="svm.html#nonlinear-svm-basic-script"><i class="fa fa-check"></i><b>4.5.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="4.5.2" data-path="svm.html"><a href="svm.html#nonlinear-svm-hyperplane"><i class="fa fa-check"></i><b>4.5.2</b> 최적 하이퍼플레인</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="svm.html"><a href="svm.html#svm-r-pkg"><i class="fa fa-check"></i><b>4.6</b> R패키지 내 SVM</a><ul>
<li class="chapter" data-level="4.6.1" data-path="svm.html"><a href="svm.html#svm-kernel-function"><i class="fa fa-check"></i><b>4.6.1</b> 커널함수</a></li>
<li class="chapter" data-level="4.6.2" data-path="svm.html"><a href="svm.html#svm-nu-classification"><i class="fa fa-check"></i><b>4.6.2</b> <span class="math inline">\(\nu\)</span>-SVC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="clustering-overview.html"><a href="clustering-overview.html"><i class="fa fa-check"></i><b>5</b> 군집분석 개요</a><ul>
<li class="chapter" data-level="5.1" data-path="clustering-overview.html"><a href="clustering-overview.html#clustering-overview-packages-install"><i class="fa fa-check"></i><b>5.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="5.2" data-path="clustering-overview.html"><a href="clustering-overview.html#clustering-method"><i class="fa fa-check"></i><b>5.2</b> 군집분석 기법</a></li>
<li class="chapter" data-level="5.3" data-path="clustering-overview.html"><a href="clustering-overview.html#object-similarity-metric"><i class="fa fa-check"></i><b>5.3</b> 객체 간의 유사성 척도</a><ul>
<li class="chapter" data-level="5.3.1" data-path="clustering-overview.html"><a href="clustering-overview.html#object-distance-metric"><i class="fa fa-check"></i><b>5.3.1</b> 거리 관련 척도</a></li>
<li class="chapter" data-level="5.3.2" data-path="clustering-overview.html"><a href="clustering-overview.html#object-correlation-metric"><i class="fa fa-check"></i><b>5.3.2</b> 상관계수 관련 척도</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="clustering-overview.html"><a href="clustering-overview.html#category-similarity-metric"><i class="fa fa-check"></i><b>5.4</b> 범주형 객체의 유사성 척도</a><ul>
<li class="chapter" data-level="5.4.1" data-path="clustering-overview.html"><a href="clustering-overview.html#binary-similarity-metric"><i class="fa fa-check"></i><b>5.4.1</b> 이분형 변수의 경우</a></li>
<li class="chapter" data-level="5.4.2" data-path="clustering-overview.html"><a href="clustering-overview.html#ordinal-similarity-metric"><i class="fa fa-check"></i><b>5.4.2</b> 서열형 변수의 경우</a></li>
<li class="chapter" data-level="5.4.3" data-path="clustering-overview.html"><a href="clustering-overview.html#nominal-similarity-metric"><i class="fa fa-check"></i><b>5.4.3</b> 명목형 변수의 경우</a></li>
<li class="chapter" data-level="5.4.4" data-path="clustering-overview.html"><a href="clustering-overview.html#mixed-similarity-metric"><i class="fa fa-check"></i><b>5.4.4</b> 혼합형의 경우</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html"><i class="fa fa-check"></i><b>6</b> 계층적 군집방법</a><ul>
<li class="chapter" data-level="6.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hierarchical-clustering-packages-install"><i class="fa fa-check"></i><b>6.1</b> 필요 R 패키지 설치</a></li>
<li class="chapter" data-level="6.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#distance-between-clusters"><i class="fa fa-check"></i><b>6.2</b> 군집 간 거리척도 및 연결법</a></li>
<li class="chapter" data-level="6.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method"><i class="fa fa-check"></i><b>6.3</b> 연결법의 군집 알고리즘</a><ul>
<li class="chapter" data-level="6.3.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method-basic-script"><i class="fa fa-check"></i><b>6.3.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="6.3.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#linkage-method-algorithm"><i class="fa fa-check"></i><b>6.3.2</b> 연결법 군집 알고리즘</a></li>
<li class="chapter" data-level="6.3.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hclust"><i class="fa fa-check"></i><b>6.3.3</b> R 패키지 내 연결법</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method"><i class="fa fa-check"></i><b>6.4</b> 워드 방법</a><ul>
<li class="chapter" data-level="6.4.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method-basic-script"><i class="fa fa-check"></i><b>6.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="6.4.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-method-algorithm"><i class="fa fa-check"></i><b>6.4.2</b> 워드 군집 알고리즘</a></li>
<li class="chapter" data-level="6.4.3" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#ward-rpackages"><i class="fa fa-check"></i><b>6.4.3</b> R 패키지 내 워드 방법</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana"><i class="fa fa-check"></i><b>6.5</b> 분리적 방법 - 다이아나</a><ul>
<li class="chapter" data-level="6.5.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana-basic-script"><i class="fa fa-check"></i><b>6.5.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="6.5.2" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#diana-algorithm"><i class="fa fa-check"></i><b>6.5.2</b> 다이아나 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#hierarchical-cluster-number"><i class="fa fa-check"></i><b>6.6</b> 군집수의 결정</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html"><i class="fa fa-check"></i><b>7</b> 비계층적 군집방법</a><ul>
<li class="chapter" data-level="7.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#nonhierarchical-clustering-packages-install"><i class="fa fa-check"></i><b>7.1</b> 필요 R package 설치</a></li>
<li class="chapter" data-level="7.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans"><i class="fa fa-check"></i><b>7.2</b> K-means 알고리즘</a><ul>
<li class="chapter" data-level="7.2.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-basic-script"><i class="fa fa-check"></i><b>7.2.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.2.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-algorithm"><i class="fa fa-check"></i><b>7.2.2</b> 알고리즘</a></li>
<li class="chapter" data-level="7.2.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-user-defined-functions"><i class="fa fa-check"></i><b>7.2.3</b> R 스크립트 구현</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmedoids"><i class="fa fa-check"></i><b>7.3</b> K-medoids 군집방법</a><ul>
<li class="chapter" data-level="7.3.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#pam"><i class="fa fa-check"></i><b>7.3.1</b> PAM 알고리즘</a></li>
<li class="chapter" data-level="7.3.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#clara"><i class="fa fa-check"></i><b>7.3.2</b> CLARA 알고리즘</a></li>
<li class="chapter" data-level="7.3.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#clarans"><i class="fa fa-check"></i><b>7.3.3</b> CLARANS 알고리즘</a></li>
<li class="chapter" data-level="7.3.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#kmeans-like"><i class="fa fa-check"></i><b>7.3.4</b> K-means-like 알고리즘</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans"><i class="fa fa-check"></i><b>7.4</b> 퍼지 K-means 알고리즘</a><ul>
<li class="chapter" data-level="7.4.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-basic-script"><i class="fa fa-check"></i><b>7.4.1</b> 기본 R 스크립트</a></li>
<li class="chapter" data-level="7.4.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-algorithm"><i class="fa fa-check"></i><b>7.4.2</b> 알고리즘</a></li>
<li class="chapter" data-level="7.4.3" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#fuzzy-kmeans-script-implement"><i class="fa fa-check"></i><b>7.4.3</b> R 스크립트 구현</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering"><i class="fa fa-check"></i><b>7.5</b> 모형기반 군집방법</a><ul>
<li class="chapter" data-level="7.5.1" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-basic-script"><i class="fa fa-check"></i><b>7.5.1</b> 기본 R script</a></li>
<li class="chapter" data-level="7.5.2" data-path="nonhierarchical-clustering.html"><a href="nonhierarchical-clustering.html#model-based-clustering-em"><i class="fa fa-check"></i><b>7.5.2</b> EM 알고리즘</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">데이터마이닝 with R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistic-regression" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> 로지스틱 회귀분석</h1>
<p>로지스틱 회귀분석(logistic regression)은 종속변수가 통상 2개의 범주(있음/없음, 불량/양호, 합격/불합격 등)를 다루는 모형을 지칭하나, 3개 이상의 범주를 다루기도 한다. 후자의 경우는 다시 서열형(ordinal) 데이터와 명목형(nominal) 데이터인 경우에 따라 서로 다른 모형이 사용된다.</p>
<div id="logistic-packages-install" class="section level2">
<h2><span class="header-section-number">1.1</span> 필요 R 패키지 설치</h2>
<p>본 장에서 필요한 R 패키지들은 아래와 같다.</p>
<table>
<thead>
<tr class="header">
<th align="left">package</th>
<th align="left">version</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">tidyverse</td>
<td align="left">1.2.1</td>
</tr>
<tr class="even">
<td align="left">stats</td>
<td align="left">3.5.2</td>
</tr>
<tr class="odd">
<td align="left">nnet</td>
<td align="left">7.3-12</td>
</tr>
<tr class="even">
<td align="left">MASS</td>
<td align="left">7.3-51.1</td>
</tr>
<tr class="odd">
<td align="left">VGAM</td>
<td align="left">1.0-6</td>
</tr>
</tbody>
</table>
</div>
<div id="binary-logistic-regression" class="section level2">
<h2><span class="header-section-number">1.2</span> 이분 로지스틱 회귀모형</h2>
<div id="bianry-logistic-reg-basic-script" class="section level3">
<h3><span class="header-section-number">1.2.1</span> 기본 R 스크립트</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_df &lt;-<span class="st"> </span><span class="kw">tribble</span>(
  <span class="op">~</span>id, <span class="op">~</span>x1, <span class="op">~</span>x2, <span class="op">~</span>x3, <span class="op">~</span>y,
  <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">8</span>, <span class="dv">2</span>, <span class="st">&quot;우수&quot;</span>,
  <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">1</span>, <span class="st">&quot;우수&quot;</span>,
  <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">9</span>, <span class="dv">0</span>, <span class="st">&quot;우수&quot;</span>,
  <span class="dv">4</span>, <span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">4</span>, <span class="st">&quot;우수&quot;</span>,
  <span class="dv">5</span>, <span class="dv">1</span>, <span class="dv">8</span>, <span class="dv">2</span>, <span class="st">&quot;우수&quot;</span>,
  <span class="dv">6</span>, <span class="dv">0</span>, <span class="dv">7</span>, <span class="dv">3</span>, <span class="st">&quot;우수&quot;</span>,
  <span class="dv">7</span>, <span class="dv">0</span>, <span class="dv">7</span>, <span class="dv">0</span>, <span class="st">&quot;보통&quot;</span>,
  <span class="dv">8</span>, <span class="dv">1</span>, <span class="dv">6</span>, <span class="dv">1</span>, <span class="st">&quot;보통&quot;</span>,
  <span class="dv">9</span>, <span class="dv">0</span>, <span class="dv">7</span>, <span class="dv">2</span>, <span class="st">&quot;보통&quot;</span>,
  <span class="dv">10</span>, <span class="dv">0</span>, <span class="dv">8</span>, <span class="dv">1</span>, <span class="st">&quot;보통&quot;</span>,
  <span class="dv">11</span>, <span class="dv">0</span>, <span class="dv">5</span>, <span class="dv">2</span>, <span class="st">&quot;보통&quot;</span>,
  <span class="dv">12</span>, <span class="dv">1</span>, <span class="dv">8</span>, <span class="dv">0</span>, <span class="st">&quot;보통&quot;</span>,
  <span class="dv">13</span>, <span class="dv">0</span>, <span class="dv">6</span>, <span class="dv">3</span>, <span class="st">&quot;보통&quot;</span>,
  <span class="dv">14</span>, <span class="dv">1</span>, <span class="dv">7</span>, <span class="dv">2</span>, <span class="st">&quot;보통&quot;</span>,
  <span class="dv">15</span>, <span class="dv">0</span>, <span class="dv">6</span>, <span class="dv">1</span>, <span class="st">&quot;보통&quot;</span>
) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">y =</span> <span class="kw">factor</span>(y, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="st">&quot;보통&quot;</span>, <span class="st">&quot;우수&quot;</span>)))

knitr<span class="op">::</span><span class="kw">kable</span>(train_df, <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
             <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),
             <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;객체번호&#39;</span>, <span class="st">&#39;아침식사여부($x_1$)&#39;</span>, <span class="st">&#39;수면시간($x_2$)&#39;</span>, <span class="st">&#39;서클활동시간($x_3$)&#39;</span>, <span class="st">&#39;범주(y)&#39;</span>),
             <span class="dt">caption =</span> <span class="st">&#39;우수/보통 학생에 대한 설문조사 결과&#39;</span>)</code></pre></div>
<table>
<caption><span id="tab:binary-logistic-reg-train-data">Table 1.1: </span>우수/보통 학생에 대한 설문조사 결과</caption>
<thead>
<tr class="header">
<th align="center">객체번호</th>
<th align="center">아침식사여부(<span class="math inline">\(x_1\)</span>)</th>
<th align="center">수면시간(<span class="math inline">\(x_2\)</span>)</th>
<th align="center">서클활동시간(<span class="math inline">\(x_3\)</span>)</th>
<th align="center">범주(y)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">0</td>
<td align="center">8</td>
<td align="center">2</td>
<td align="center">우수</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">1</td>
<td align="center">7</td>
<td align="center">1</td>
<td align="center">우수</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">0</td>
<td align="center">9</td>
<td align="center">0</td>
<td align="center">우수</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">1</td>
<td align="center">6</td>
<td align="center">4</td>
<td align="center">우수</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">1</td>
<td align="center">8</td>
<td align="center">2</td>
<td align="center">우수</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">0</td>
<td align="center">7</td>
<td align="center">3</td>
<td align="center">우수</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">0</td>
<td align="center">7</td>
<td align="center">0</td>
<td align="center">보통</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">1</td>
<td align="center">6</td>
<td align="center">1</td>
<td align="center">보통</td>
</tr>
<tr class="odd">
<td align="center">9</td>
<td align="center">0</td>
<td align="center">7</td>
<td align="center">2</td>
<td align="center">보통</td>
</tr>
<tr class="even">
<td align="center">10</td>
<td align="center">0</td>
<td align="center">8</td>
<td align="center">1</td>
<td align="center">보통</td>
</tr>
<tr class="odd">
<td align="center">11</td>
<td align="center">0</td>
<td align="center">5</td>
<td align="center">2</td>
<td align="center">보통</td>
</tr>
<tr class="even">
<td align="center">12</td>
<td align="center">1</td>
<td align="center">8</td>
<td align="center">0</td>
<td align="center">보통</td>
</tr>
<tr class="odd">
<td align="center">13</td>
<td align="center">0</td>
<td align="center">6</td>
<td align="center">3</td>
<td align="center">보통</td>
</tr>
<tr class="even">
<td align="center">14</td>
<td align="center">1</td>
<td align="center">7</td>
<td align="center">2</td>
<td align="center">보통</td>
</tr>
<tr class="odd">
<td align="center">15</td>
<td align="center">0</td>
<td align="center">6</td>
<td align="center">1</td>
<td align="center">보통</td>
</tr>
</tbody>
</table>
<p>Table <a href="logistic-regression.html#tab:binary-logistic-reg-train-data">1.1</a>와 같이 세 개의 독립변수 <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>, <span class="math inline">\(x_3\)</span>와 이분형 종속변수 <span class="math inline">\(y\)</span>의 관측값(보통 = 0, 우수 = 1)으로 이루어진 15개의 학습표본을 <code>train_df</code>라는 data frame에 저장한다.</p>
<p>아래와 같이 <code>glm</code> 함수를 이용하여 로지스틱 회귀모형을 간편하게 추정할 수 있다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">glm_fit &lt;-<span class="st"> </span><span class="kw">glm</span>(y <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2 <span class="op">+</span><span class="st"> </span>x3, <span class="dt">family =</span> <span class="kw">binomial</span>(<span class="dt">link =</span> <span class="st">&quot;logit&quot;</span>), <span class="dt">data =</span> train_df)

knitr<span class="op">::</span><span class="kw">kable</span>(
  glm_fit <span class="op">%&gt;%</span><span class="st">  </span>broom<span class="op">::</span><span class="kw">tidy</span>(),
  <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
  <span class="dt">caption =</span> <span class="st">&quot;Table </span><span class="ch">\\</span><span class="st"><a href="logistic-regression.html#tab:binary-logistic-reg-train-data">1.1</a>에 대한 Logistic Regression 결과&quot;</span>
  )</code></pre></div>
<table>
<caption><span id="tab:binary-logistic-reg-coef">Table 1.2: </span>Table <a href="logistic-regression.html#tab:binary-logistic-reg-train-data">1.1</a>에 대한 Logistic Regression 결과</caption>
<thead>
<tr class="header">
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">(Intercept)</td>
<td align="right">-30.510836</td>
<td align="right">18.018256</td>
<td align="right">-1.693329</td>
<td align="right">0.0903929</td>
</tr>
<tr class="even">
<td align="left">x1</td>
<td align="right">2.031278</td>
<td align="right">1.983692</td>
<td align="right">1.023989</td>
<td align="right">0.3058406</td>
</tr>
<tr class="odd">
<td align="left">x2</td>
<td align="right">3.470671</td>
<td align="right">2.074978</td>
<td align="right">1.672631</td>
<td align="right">0.0944000</td>
</tr>
<tr class="even">
<td align="left">x3</td>
<td align="right">2.414387</td>
<td align="right">1.396372</td>
<td align="right">1.729043</td>
<td align="right">0.0838015</td>
</tr>
</tbody>
</table>
<p>Table <a href="logistic-regression.html#tab:binary-logistic-reg-coef">1.2</a>은 추정된 회귀계수 추정치 <code>estmate</code>과 그 표준오차 <code>std.error</code>, 표준화(standardized)된 회귀계수값 <code>statistic</code> (= <code>estmate</code> / <code>std.error</code>), 그리고 귀무가설 <span class="math inline">\(H_0\)</span>: <code>statistic</code> = 0 에 대한 유의확률 <code>p.value</code>를 보여준다.</p>
</div>
<div id="binary-logistic-reg-model" class="section level3">
<h3><span class="header-section-number">1.2.2</span> 회귀모형</h3>
<p>이분 로지스틱 회귀모형은 종속변수가 2가지 범주를 취하는 경우에 사용된다.</p>
<p><span class="math inline">\(N\)</span>개의 객체로 이루어진 학습데이터 <span class="math inline">\(\{(\mathbf{x}_i, y_i)\}_{i = 1, \cdots, N}\)</span>를 아래와 같이 정의하자.</p>
<ul>
<li><span class="math inline">\(\mathbf{x}_i \in \mathbb{R}^p\)</span>: <span class="math inline">\(p\)</span>개의 독립변수로 이루어진 벡터 (<span class="math inline">\(\mathbf{x}_i = [x_{i1} \, x_{i2} \, \cdots \, x_{ip}]^\top\)</span>)</li>
<li><span class="math inline">\(y_i\)</span>: 0 혹은 1의 값을 갖는 이분형 지시변수 (indicator variable)</li>
</ul>
<p><span class="math inline">\(\mathbf{x}_i\)</span> 관측값을 이용하여 <span class="math inline">\(y_i\)</span>의 기대값 <span class="math inline">\(P_i\)</span>을 추정하는 모형을 아래와 같이 로지스틱 함수로 정의하자.</p>
<span class="math display" id="eq:logistic-function">\[\begin{eqnarray}
P_i &amp;=&amp; P(y_i = 1 \,|\, \mathbf{x}_i)\\
&amp;=&amp; E[y_i | \mathbf{x}_i]\\ 
&amp;=&amp; \frac{\exp(\beta_0 + \boldsymbol\beta^\top \mathbf{x}_i)}{1 + \exp(\beta_0 + \boldsymbol\beta^\top \mathbf{x}_i)}
\tag{1.1}
\end{eqnarray}\]</span>
<p>여기에서 <span class="math inline">\(\boldsymbol\beta \in \mathbb{R}^{p}\)</span>는 <span class="math inline">\(\mathbf{x}_i\)</span>와 동일한 차원의 벡터이다 (<span class="math inline">\(\boldsymbol\beta = [\beta_1 \, \beta_2 \, \cdots \, \beta_p]^\top\)</span>).</p>
<p>식 <a href="logistic-regression.html#eq:logistic-function">(1.1)</a>는 모든 <span class="math inline">\(\mathbf{x}_i\)</span>값에 대해 0에서 1 사이의 값을 갖게 되므로 각 범주에 속할 확률을 추정하는 데 적합한 반면, 변수 <span class="math inline">\(\mathbf{x}\)</span> 및 계수들에 대해 선형이 아니므로 추정이 어렵다. 그러나 아래와 같이 로짓(logit) 변환을 통해 선형회귀식으로 변환할 수 있다.</p>
<span class="math display" id="eq:logit-transform">\[\begin{eqnarray}
logit(P_i) &amp;=&amp; \ln \left[ \frac{P_i}{1 - P_i} \right]\\
&amp;=&amp; \ln(\exp(\beta_0 + \boldsymbol\beta^\top \mathbf{x}_i))\\
&amp;=&amp; \beta_0 + \boldsymbol\beta^\top \mathbf{x}_i
\tag{1.2}
\end{eqnarray}\]</span>
<p>식 <a href="logistic-regression.html#eq:logit-transform">(1.2)</a>에서 확률 <span class="math inline">\(P_i\)</span>는 직접적으로 관측되는 것이 아니고 0 또는 1을 갖는 <span class="math inline">\(y_i\)</span>가 관측되므로, <span class="math inline">\(P_i\)</span>를 일종의 잠재변수(latent variable)로 해석할 수 있다.</p>
<span class="math display" id="eq:binary-logistic-latent-interpret">\[\begin{equation}
y_i = \begin{cases}
1 &amp; \text{ if } \beta_0 + \boldsymbol\beta^\top \mathbf{x}_i + \varepsilon_i &gt; 0 \\
0 &amp; \text{ otherwise }
\end{cases}
\tag{1.3}
\end{equation}\]</span>
<p>식 <a href="logistic-regression.html#eq:binary-logistic-latent-interpret">(1.3)</a>에서 <span class="math inline">\(\varepsilon_i\)</span>는 표준로지스틱분포(standard logistic distribution)을 따른다.</p>
</div>
<div id="binary-logistic-reg-estimation" class="section level3">
<h3><span class="header-section-number">1.2.3</span> 회귀계수 추정</h3>
<p>로지스틱 모형에서 회귀계수의 추정을 위해서 주로 최우추정법(maximum likelihood estimation)이 사용된다. <span class="math inline">\(N\)</span>개의 객체로 이루어진 학습데이터에 대해 우도함수는 다음과 같다.</p>
<span class="math display">\[\begin{equation*}
L = \prod_{i = 1}^{N} P_i^{y_i} (1 - P_i)^{1 - y_i}
\end{equation*}\]</span>
<p>그리고 우도함수에 자연로그를 취하면 아래와 같이 전개된다.</p>
<span class="math display" id="eq:binary-logistic-reg-loglik">\[\begin{eqnarray}
\log L &amp;=&amp; \sum_{i = 1}^{N} y_i \log P_i + \sum_{i = 1}^{N} (1 - y_i) \log (1 - P_i)\\
&amp;=&amp; \sum_{i = 1}^{N} y_i \log \frac{P_i}{1 - P_i} + \sum_{i = 1}^{N} \log (1 - P_i)\\
&amp;=&amp; \sum_{i = 1}^{N} y_i (\beta_0 + \boldsymbol\beta^\top \mathbf{x}_i) - \sum_{i = 1}^{N}  \log (1 + \exp (\beta_0 + \boldsymbol\beta^\top \mathbf{x}_i) )\\
&amp;=&amp; \sum_{i = 1}^{N} y_i \left(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij} \right) - \sum_{i = 1}^{N}  \log \left(1 + \exp\left(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij}\right)\right)
\tag{1.4}
\end{eqnarray}\]</span>
<p>식 (eq:binary-logistic-reg-loglik)을 각 회귀계수 <span class="math inline">\(\beta_0, \beta_1, \cdots, \beta_p\)</span>에 대해 편미분하여 최적해를 얻는다. 이를 위해 주로 뉴턴-랩슨 알고리즘(Newton-Raphson algorithm)이나 quasi-Newton 알고리즘이 사용되나 <span class="citation">(전치혁 <a href="#ref-jun2012datamining">2012</a>)</span>, 본 장에서는 우선 안정성은 떨어지지만 보다 간편한 방법으로 경사하강법(gradient descent)을 소개한다.</p>
<div id="binary-logistic-gradient-descent" class="section level4">
<h4><span class="header-section-number">1.2.3.1</span> 경사하강법</h4>
<p>식 <a href="logistic-regression.html#eq:logistic-function">(1.1)</a>과 <span class="math inline">\(P(y_i = 0 \,|\, \mathbf{x}_i) = 1 - P_i\)</span>, 그리고</p>
<span class="math display">\[\begin{equation*}
\frac{\exp(z)}{1 + \exp(z)} = \frac{1}{1 + \exp(-z)}
\end{equation*}\]</span>
<p>임을 고려하면 아래와 같이 범주확률모형을 정의할 수 있다.</p>
<span class="math display">\[\begin{equation*}
P(y = y_i \,|\, \mathbf{x}_i, \beta_0, \boldsymbol\beta) = \frac{1}{1 + \exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}
\end{equation*}\]</span>
<p>이에 따라 로그우도함수 <a href="logistic-regression.html#eq:binary-logistic-reg-loglik">(1.4)</a>는 아래와 같이 정리된다.</p>
<span class="math display">\[\begin{equation*}
\log \prod_{i = 1}^{N} P(y = y_i \,|\, \mathbf{x}_i, \beta_0, \boldsymbol\beta) = - \sum_{i = 1}^{N} \log \left(1 + \exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)\right)
\end{equation*}\]</span>
<p>위 로그우도함수를 최대화하는 문제는 아래 함수를 최소화하는 문제와 동일하다.</p>
<span class="math display" id="eq:binary-logistic-reg-negative-loglik">\[\begin{equation}
f(\beta_0, \boldsymbol\beta) = \sum_{i = 1}^{N} \log \left(1 + \exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)\right)
\tag{1.5}
\end{equation}\]</span>
<p>경사하강법에 따라 아래의 과정을 통해 회귀계수를 추정할 수 있다.</p>
<ol style="list-style-type: decimal">
<li>임의의 값으로 <span class="math inline">\(\beta_0, \beta_1, \cdots, \beta_j\)</span>의 초기 추정값을 설정한다.</li>
<li>식 <a href="logistic-regression.html#eq:binary-logistic-reg-negative-loglik">(1.5)</a>을 각 회귀변수에 대해 편미분한 미분값을 구한다.</li>
<li>2의 값에 학습률(step size)을 곱한 만큼 회귀계수 추정값을 이동시킨다. 방향은 미분값의 반대방향.</li>
<li>수렴할 때까지 2-3의 과정을 반복한다.</li>
</ol>
<p>여기에서 식 <a href="logistic-regression.html#eq:binary-logistic-reg-negative-loglik">(1.5)</a>의 각 회귀변수에 대한 편미분식은 아래와 같다.</p>
<span class="math display">\[\begin{eqnarray*}
\frac{\partial f}{\partial \beta_0} &amp;=&amp; \sum_{i = 1}^{N} (1 - 2y_i) \frac{\exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}{1 + \exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}\\
&amp;=&amp; \sum_{i = 1}^{N} \frac{1 - 2y_i}{1 + \exp\left((2y_i - 1)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}
\end{eqnarray*}\]</span>
<span class="math display">\[\begin{eqnarray*}
\frac{\partial f}{\partial \beta_j} &amp;=&amp; \sum_{i = 1}^{N} (1 - 2y_i)x_{ij} \frac{\exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}{1 + \exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}\\
&amp;=&amp; \sum_{i = 1}^{N} \frac{(1 - 2y_i)x_{ij}}{1 + \exp\left((2y_i - 1)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}
\end{eqnarray*}\]</span>
<p>따라서, 회귀계수 추정값을 이동시키는 함수 <code>update_beta</code>를 아래와 같이 구현할 수 있다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">update_beta &lt;-<span class="st"> </span><span class="cf">function</span>(x, y, <span class="dt">beta0 =</span> <span class="dv">0</span>, <span class="dt">beta =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">dim</span>(x)[<span class="dv">2</span>]), <span class="dt">alpha =</span> <span class="fl">0.01</span>) {
  <span class="co"># 변미분식의 분모</span>
  denominator &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>((<span class="dv">2</span> <span class="op">*</span><span class="st"> </span>y <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span>(beta0 <span class="op">+</span><span class="st"> </span>(x <span class="op">%*%</span><span class="st"> </span>beta)))

  <span class="co"># intercept 이동량 계산</span>
  beta0_numerator &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>y
  beta0_update =<span class="st"> </span><span class="kw">sum</span>(beta0_numerator <span class="op">/</span><span class="st"> </span>denominator)
  
  <span class="co"># intercept 외 회귀계수 이동량 계산</span>
  beta_numerator &lt;-<span class="st"> </span><span class="kw">sweep</span>(x, <span class="dt">MARGIN =</span> <span class="dv">1</span>, <span class="dt">STATS =</span> <span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>y, <span class="dt">FUN =</span> <span class="st">&quot;*&quot;</span>)
  beta_update =<span class="st"> </span><span class="kw">apply</span>(beta_numerator, <span class="dt">MARGIN =</span> <span class="dv">2</span>, 
                      <span class="cf">function</span>(x) <span class="kw">sum</span>(x <span class="op">/</span><span class="st"> </span>denominator))

  <span class="co"># 회귀계수 이동</span>
  beta0 &lt;-<span class="st"> </span>beta0 <span class="op">-</span><span class="st"> </span>alpha <span class="op">*</span><span class="st"> </span>beta0_update
  beta &lt;-<span class="st"> </span>beta <span class="op">-</span><span class="st"> </span>alpha <span class="op">*</span><span class="st"> </span>beta_update

  <span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">beta0 =</span> beta0, <span class="dt">beta =</span> beta))
}</code></pre></div>
<p>위의 함수를 이용하여 아래 <code>estimate_beta</code>처엄 수렴할 때까지 회귀계수 추정값을 계속 이동시킨다. 본 경사하강법은 학습률 파라미터 <code>alpha</code>값에 따라 민감한 단점이 있으며, 특히 <code>alpha</code>값을 크게 설정할 경우에는 추정값이 수렴하지 않고 오히려 실제값에서 계속 멀어지는 현상이 발생하기도 한다. 이러한 단점을 보완하기 위한 여러 방법이 있으나, 본 장에서 자세한 설명은 생략하기로 한다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">caltculate_loglik &lt;-<span class="st"> </span><span class="cf">function</span>(x, y, 
                              <span class="dt">beta0 =</span> <span class="dv">0</span>, 
                              <span class="dt">beta =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">dim</span>(x)[<span class="dv">2</span>])) {
  <span class="kw">sum</span>(y <span class="op">*</span><span class="st"> </span>(beta0 <span class="op">+</span><span class="st"> </span>(x <span class="op">%*%</span><span class="st"> </span>beta))) <span class="op">-</span><span class="st"> </span>
<span class="st">    </span><span class="kw">sum</span>(<span class="kw">log</span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(beta0 <span class="op">+</span><span class="st"> </span>(x <span class="op">%*%</span><span class="st"> </span>beta))))
}

estimate_beta &lt;-<span class="st"> </span><span class="cf">function</span>(x, y, 
                          <span class="dt">beta0 =</span> <span class="dv">0</span>, 
                          <span class="dt">beta =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">dim</span>(x)[<span class="dv">2</span>]), 
                          <span class="dt">alpha =</span> <span class="fl">0.01</span>, 
                          <span class="dt">conv_threshold =</span> <span class="fl">1e-5</span>, 
                          <span class="dt">max_iter =</span> <span class="fl">1e+5</span>) {
  new_beta0 &lt;-<span class="st"> </span>beta0
  new_beta &lt;-<span class="st"> </span>beta
  conv &lt;-<span class="st"> </span><span class="ot">FALSE</span>
  
  i_iter &lt;-<span class="st"> </span><span class="dv">0</span>
  <span class="cf">while</span>(i_iter <span class="op">&lt;</span><span class="st"> </span>max_iter) {
    res &lt;-<span class="st"> </span><span class="kw">update_beta</span>(x, y, new_beta0, new_beta, alpha)
    
    <span class="cf">if</span>(<span class="kw">abs</span>(<span class="kw">caltculate_loglik</span>(x, y, beta0, beta)
           <span class="op">-</span><span class="st"> </span><span class="kw">caltculate_loglik</span>(x, y, res<span class="op">$</span>beta0, res<span class="op">$</span>beta))
       <span class="op">&lt;</span><span class="st"> </span>conv_threshold) {
      conv &lt;-<span class="st"> </span><span class="ot">TRUE</span>
      <span class="cf">break</span>
      }
    
    new_beta0 &lt;-<span class="st"> </span>res<span class="op">$</span>beta0
    new_beta &lt;-<span class="st"> </span>res<span class="op">$</span>beta
    
    i_iter &lt;-<span class="st"> </span>i_iter <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
  }
  
  <span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">conv =</span> conv, <span class="dt">beta0 =</span> new_beta0, <span class="dt">beta =</span> new_beta))
}</code></pre></div>
<p>위에서 정의한 함수를 이용하여 Table <a href="logistic-regression.html#tab:binary-logistic-reg-train-data">1.1</a>의 학습표본에 대한 로지스틱 회귀모형을 추정해보자.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">res &lt;-<span class="st"> </span><span class="kw">estimate_beta</span>(train_df[, <span class="kw">c</span>(<span class="st">&quot;x1&quot;</span>, <span class="st">&quot;x2&quot;</span>, <span class="st">&quot;x3&quot;</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>(), 
                     train_df<span class="op">$</span>y <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.numeric</span>() <span class="op">-</span><span class="st"> </span><span class="dv">1</span>,
                     <span class="dt">alpha =</span> <span class="fl">0.015</span>,
                     <span class="dt">conv_threshold =</span> <span class="fl">1e-6</span>)

<span class="kw">print</span>(res)</code></pre></div>
<pre><code>## $conv
## [1] FALSE
## 
## $beta0
## [1] -30.39189
## 
## $beta
##       x1       x2       x3 
## 2.022808 3.457019 2.405969</code></pre>
<p>위 회귀계수 추정값은 R 함수 <code>glm</code>을 이용한 추정값(Table <a href="logistic-regression.html#tab:binary-logistic-reg-coef">1.2</a>)과 유사함을 볼 수 있다.</p>
</div>
<div id="binary-logistic-irls" class="section level4">
<h4><span class="header-section-number">1.2.3.2</span> 반복재가중최소제곱법</h4>
<p>R의 <code>glm</code> 함수는 반복재가중최소제곱법(iteratively rewighted least squares; IRLS 혹은 IWLS)을 사용한다. 이는 선형회귀식</p>
<span class="math display">\[\begin{equation*}
logit(y_i) = \beta_0 + \boldsymbol\beta^\top \mathbf{x}_i + \varepsilon_i
\end{equation*}\]</span>
<p>을 추정하는 방법인데, 여기에서 <span class="math inline">\(y_i\)</span>는 0 혹은 1이므로, <span class="math inline">\(logit(y_i)\)</span>는 <span class="math inline">\(-\infty\)</span> 혹은 <span class="math inline">\(\infty\)</span>가 되어 회귀식을 추정할 수 없다. 따라서, 식 <a href="logistic-regression.html#eq:logistic-function">(1.1)</a>에 설명된 로지스틱 함수</p>
<span class="math display">\[\begin{equation*}
P = \frac{\exp(\beta_0 + \boldsymbol\beta^\top \mathbf{x})}{1 + \exp(\beta_0 + \boldsymbol\beta^\top \mathbf{x})}
\end{equation*}\]</span>
<p>와 테일러 급수(Taylor series)를 이용하여 <span class="math inline">\(logit(y)\)</span>에 대한 근사함수를 아래와 같이 얻는다.</p>
<span class="math display">\[\begin{eqnarray*}
g(y) &amp;=&amp; logit(P) + (y - P) \frac{\partial logit(P)}{\partial P}\\
&amp;=&amp; \log \frac{P}{1 - P} + (y - P) \left( \frac{1}{P} + \frac{1}{1 - P} \right)
\end{eqnarray*}\]</span>
<p>그리고 아래 선형회귀식을 추정한다.</p>
<span class="math display">\[\begin{equation*}
g(y_i) = \beta_0 + \boldsymbol\beta^\top \mathbf{x}_i + \varepsilon_i
\end{equation*}\]</span>
<p>여기에서 오차항 <span class="math inline">\(\varepsilon_i\)</span>의 분산은 추정된 확률 <span class="math inline">\(P_i\)</span>에 따라 다르므로, 통상적 최소자승법(ordinary least squares; OLS) 대신 오차항의 분산이 동일해지도록 객체마다 가중치를 부여하는 가중최소자승법(weighted least squares; WLS)을 사용한다. 로지스틱 회귀모형에서 각 객체의 가중치는</p>
<span class="math display">\[\begin{equation*}
w_i = P_i (1 - P_i)
\end{equation*}\]</span>
<p>가중치와 회귀계수 추정값은 상호 영향을 미치므로, 수렴할 때까지 반복적으로 가중치와 회귀계수 추정값을 변화시키면서 최종 추정값을 찾아가는 방법이다.</p>
<p>우선 회귀계수 추정값이 주어졌을 때 각 객체에 대한 확률값 <span class="math inline">\(P_i\)</span>와 가중치 <span class="math inline">\(w_i\)</span>를 구하는 함수 <code>calculate_weight</code>를 아래와 같이 구현해보자.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">calculate_weight &lt;-<span class="st"> </span><span class="cf">function</span>(x, <span class="dt">beta0 =</span> <span class="dv">0</span>, 
                             <span class="dt">beta =</span> <span class="kw">rep</span>(<span class="dv">0</span>, <span class="kw">dim</span>(x)[<span class="dv">2</span>])) {
  <span class="co"># 각 객체의 y값이 1일 확률</span>
  P &lt;-<span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span><span class="st"> </span>beta0 <span class="op">-</span><span class="st"> </span>(x <span class="op">%*%</span><span class="st"> </span>beta)))<span class="op">^</span>(<span class="op">-</span><span class="dv">1</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">drop</span>()

  <span class="co"># 가중치 계산</span>
  w &lt;-<span class="st"> </span>P <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>P)

  <span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">P =</span> P, <span class="dt">w =</span> w))
}</code></pre></div>
<p>그리고 확률추정값과 가중치가 주어졌을 때 회귀계수를 구하는 함수 <code>calculate_beta</code>를 아래와 같이 구현해보자. 여기서 회귀계수를 구하는 부분은 R의 선형회귀분석함수 <code>lm</code>을 사용한다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">calculate_beta &lt;-<span class="st"> </span><span class="cf">function</span>(x, y, P, w) {
  <span class="co"># 추정확률값이 0 이나 1인 경우 </span>
  <span class="co"># 여전히 logit 함수가 정의되지 않으므로 회귀계수 결정에서 제외</span>
  logit_derivative &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span>P <span class="op">+</span><span class="st"> </span><span class="dv">1</span><span class="op">/</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>P)
  is_good &lt;-<span class="st"> </span><span class="op">!</span><span class="kw">is.nan</span>(logit_derivative)
  
  <span class="co"># 모든 객체에 대한 추정확률이 0 이나 1인 경우 회귀계수 추정 불가능</span>
  <span class="cf">if</span>(<span class="kw">all</span>(<span class="op">!</span>is_good)) <span class="kw">return</span>(<span class="ot">NULL</span>)
  
  <span class="co"># 테일러 급수 계산</span>
  g_y &lt;-<span class="st"> </span><span class="kw">log</span>(P[is_good]) <span class="op">-</span><span class="st"> </span>
<span class="st">    </span><span class="kw">log</span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>P[is_good]) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span>(y[is_good] <span class="op">-</span><span class="st"> </span>P[is_good]) <span class="op">*</span><span class="st"> </span>logit_derivative
  
  <span class="co"># 가중치최소자승법을 이용한 추정</span>
  df &lt;-<span class="st"> </span><span class="kw">bind_cols</span>(<span class="kw">as_tibble</span>(x) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">                    `</span><span class="dt">colnames&lt;-</span><span class="st">`</span>(<span class="kw">colnames</span>(x)), 
                  <span class="kw">tibble</span>(<span class="dt">g_y =</span> g_y))
  <span class="kw">lm</span>(g_y <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> df, <span class="dt">subset =</span> is_good, <span class="dt">weights =</span> w)
}</code></pre></div>
<p>위에서 정의한 두 함수 <code>calculate_weight</code>과 <code>calculate_beta</code>를 반복적으로 사용하여 Table <a href="logistic-regression.html#tab:binary-logistic-reg-train-data">1.1</a>의 학습표본에 대한 로지스틱 회귀모형을 추정해보자. 모든 객체의 가중치 변화량이 1/10000 보다 작을 경우 모형추정이 수렴한 것으로 간주하도록 하자.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">X &lt;-<span class="st"> </span>train_df[, <span class="kw">c</span>(<span class="st">&quot;x1&quot;</span>, <span class="st">&quot;x2&quot;</span>, <span class="st">&quot;x3&quot;</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()
y &lt;-<span class="st"> </span>train_df<span class="op">$</span>y <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.numeric</span>() <span class="op">-</span><span class="st"> </span><span class="dv">1</span>

weight &lt;-<span class="st"> </span><span class="kw">calculate_weight</span>(X)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">10</span>) {
  wls_fit &lt;-<span class="st"> </span><span class="kw">calculate_beta</span>(X, y, weight<span class="op">$</span>P, weight<span class="op">$</span>w)
  
  <span class="cf">if</span>(<span class="kw">is.null</span>(wls_fit)) {<span class="cf">break</span>}
  
  new_weight &lt;-<span class="st"> </span><span class="kw">calculate_weight</span>(<span class="dt">x =</span> X, 
                                 <span class="dt">beta0 =</span> <span class="kw">coef</span>(wls_fit)[<span class="dv">1</span>], 
                                 <span class="dt">beta =</span> <span class="kw">coef</span>(wls_fit)[<span class="op">-</span><span class="dv">1</span>])
  
  <span class="cf">if</span>(<span class="kw">max</span>(<span class="kw">abs</span>(new_weight<span class="op">$</span>w <span class="op">-</span><span class="st"> </span>weight<span class="op">$</span>w)) <span class="op">&lt;</span><span class="st"> </span><span class="fl">1e-4</span>) {<span class="cf">break</span>}
  
  weight &lt;-<span class="st"> </span>new_weight
}

<span class="kw">coef</span>(wls_fit)</code></pre></div>
<pre><code>## (Intercept)          x1          x2          x3 
##  -30.510837    2.031278    3.470671    2.414387</code></pre>
<p>위 스크립트를 실행시킨 결과 7번째 반복수행에서 결과가 수렴하였으며, 해당 결과는 <code>glm</code> 함수를 사용하였을 때의 결과 (Table <a href="logistic-regression.html#tab:binary-logistic-reg-coef">1.2</a>)과 매우 근사함을 확인할 수 있다.</p>
</div>
</div>
</div>
<div id="nominal-logistic-regression" class="section level2">
<h2><span class="header-section-number">1.3</span> 명목 로지스틱 회귀모형</h2>
<div id="nominal-logistic-reg-basic-script" class="section level3">
<h3><span class="header-section-number">1.3.1</span> 기본 R 스크립트</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_df &lt;-<span class="st"> </span><span class="kw">tribble</span>(
  <span class="op">~</span>id, <span class="op">~</span>x1, <span class="op">~</span>x2, <span class="op">~</span>y,
  <span class="dv">1</span>, <span class="fl">0.09</span>, <span class="fl">5.02</span>, <span class="dv">1</span>,
  <span class="dv">2</span>, <span class="fl">0.1</span>, <span class="fl">5.01</span>, <span class="dv">1</span>,
  <span class="dv">3</span>, <span class="fl">0.12</span>, <span class="fl">4.94</span>, <span class="dv">1</span>,
  <span class="dv">4</span>, <span class="fl">0.12</span>, <span class="fl">5.12</span>, <span class="dv">1</span>,
  <span class="dv">5</span>, <span class="fl">0.12</span>, <span class="fl">5.03</span>, <span class="dv">1</span>,
  <span class="dv">6</span>, <span class="fl">0.12</span>, <span class="fl">4.94</span>, <span class="dv">2</span>,
  <span class="dv">7</span>, <span class="fl">0.1</span>, <span class="fl">5.13</span>, <span class="dv">2</span>,
  <span class="dv">8</span>, <span class="fl">0.1</span>, <span class="fl">4.87</span>, <span class="dv">1</span>,
  <span class="dv">9</span>, <span class="fl">0.1</span>, <span class="fl">5.13</span>, <span class="dv">2</span>,
  <span class="dv">10</span>, <span class="fl">0.11</span>, <span class="fl">4.94</span>, <span class="dv">3</span>,
  <span class="dv">11</span>, <span class="fl">0.11</span>, <span class="fl">4.93</span>, <span class="dv">3</span>,
  <span class="dv">12</span>, <span class="fl">0.09</span>, <span class="fl">5.02</span>, <span class="dv">3</span>,
  <span class="dv">13</span>, <span class="fl">0.1</span>, <span class="fl">5.01</span>, <span class="dv">3</span>,
  <span class="dv">14</span>, <span class="fl">0.09</span>, <span class="fl">4.94</span>, <span class="dv">3</span>,
  <span class="dv">15</span>, <span class="fl">0.1</span>, <span class="fl">5.12</span>, <span class="dv">2</span>,
  <span class="dv">16</span>, <span class="fl">0.12</span>, <span class="fl">4.93</span>, <span class="dv">2</span>,
  <span class="dv">17</span>, <span class="fl">0.1</span>, <span class="dv">5</span>, <span class="dv">1</span>,
  <span class="dv">18</span>, <span class="fl">0.09</span>, <span class="fl">5.01</span>, <span class="dv">3</span>
) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">y =</span> <span class="kw">factor</span>(y, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)))

knitr<span class="op">::</span><span class="kw">kable</span>(train_df, <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
             <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),
             <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;객체번호&#39;</span>, <span class="st">&#39;$x_1$&#39;</span>, <span class="st">&#39;$x_2$&#39;</span>, <span class="st">&#39;불량범주($y$)&#39;</span>),
             <span class="dt">caption =</span> <span class="st">&#39;공정변수-불량 종류 데이터&#39;</span>)</code></pre></div>
<table>
<caption><span id="tab:nominal-logistic-reg-train-data">Table 1.3: </span>공정변수-불량 종류 데이터</caption>
<thead>
<tr class="header">
<th align="center">객체번호</th>
<th align="right"><span class="math inline">\(x_1\)</span></th>
<th align="right"><span class="math inline">\(x_2\)</span></th>
<th align="center">불량범주(<span class="math inline">\(y\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="right">0.09</td>
<td align="right">5.02</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="right">0.10</td>
<td align="right">5.01</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="right">0.12</td>
<td align="right">4.94</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="right">0.12</td>
<td align="right">5.12</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="right">0.12</td>
<td align="right">5.03</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="right">0.12</td>
<td align="right">4.94</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="right">0.10</td>
<td align="right">5.13</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="right">0.10</td>
<td align="right">4.87</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">9</td>
<td align="right">0.10</td>
<td align="right">5.13</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">10</td>
<td align="right">0.11</td>
<td align="right">4.94</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">11</td>
<td align="right">0.11</td>
<td align="right">4.93</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">12</td>
<td align="right">0.09</td>
<td align="right">5.02</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">13</td>
<td align="right">0.10</td>
<td align="right">5.01</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">14</td>
<td align="right">0.09</td>
<td align="right">4.94</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">15</td>
<td align="right">0.10</td>
<td align="right">5.12</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">16</td>
<td align="right">0.12</td>
<td align="right">4.93</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">17</td>
<td align="right">0.10</td>
<td align="right">5.00</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">18</td>
<td align="right">0.09</td>
<td align="right">5.01</td>
<td align="center">3</td>
</tr>
</tbody>
</table>
<p>Table <a href="logistic-regression.html#tab:nominal-logistic-reg-train-data">1.3</a>와 같이 두 개의 독립변수 <span class="math inline">\(x_1\)</span>, <span class="math inline">\(x_2\)</span>에 따라 세 종류의 불량 (<span class="math inline">\(y = 1, 2, 3\)</span>)$이 발생함을 알았다면, 아래와 같이 <code>nnet</code> 패키지의 <code>multinom</code> 함수를 이용하여 공정변수에 따른 불량 종류를 분류하기 위한 로지스틱 회귀모형을 간편하게 추정할 수 있다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">multinom_fit &lt;-<span class="st"> </span>nnet<span class="op">::</span><span class="kw">multinom</span>(
  y <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2, 
  <span class="dt">data =</span> train_df, 
  <span class="dt">maxit =</span> <span class="dv">1000</span>)</code></pre></div>
<pre><code>## # weights:  12 (6 variable)
## initial  value 19.775021 
## iter  10 value 17.825831
## iter  20 value 16.489924
## iter  30 value 16.116751
## iter  40 value 16.044223
## iter  50 value 16.025259
## iter  60 value 16.024629
## iter  70 value 16.016395
## final  value 16.015185 
## converged</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span>(
  multinom_fit <span class="op">%&gt;%</span><span class="st">  </span>broom<span class="op">::</span><span class="kw">tidy</span>(<span class="dt">exponentiate =</span> <span class="ot">FALSE</span>),
  <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
  <span class="dt">caption =</span> <span class="st">&#39;Table </span><span class="ch">\\</span><span class="st"><a href="logistic-regression.html#tab:nominal-logistic-reg-train-data">1.3</a>에 대한 Logistic Regression 결과&#39;</span>
  )</code></pre></div>
<table>
<caption><span id="tab:nominal-logistic-reg-coef">Table 1.4: </span>Table <a href="logistic-regression.html#tab:nominal-logistic-reg-train-data">1.3</a>에 대한 Logistic Regression 결과</caption>
<thead>
<tr class="header">
<th align="left">y.level</th>
<th align="left">term</th>
<th align="right">estimate</th>
<th align="right">std.error</th>
<th align="right">statistic</th>
<th align="right">p.value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2</td>
<td align="left">(Intercept)</td>
<td align="right">-53.924661</td>
<td align="right">45.402992</td>
<td align="right">-1.1876896</td>
<td align="right">0.2349557</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">x1</td>
<td align="right">31.545749</td>
<td align="right">62.162158</td>
<td align="right">0.5074751</td>
<td align="right">0.6118215</td>
</tr>
<tr class="odd">
<td align="left">2</td>
<td align="left">x2</td>
<td align="right">9.992311</td>
<td align="right">8.479305</td>
<td align="right">1.1784352</td>
<td align="right">0.2386231</td>
</tr>
<tr class="even">
<td align="left">3</td>
<td align="left">(Intercept)</td>
<td align="right">64.191145</td>
<td align="right">57.282533</td>
<td align="right">1.1206059</td>
<td align="right">0.2624556</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">x1</td>
<td align="right">-101.817613</td>
<td align="right">65.516143</td>
<td align="right">-1.5540844</td>
<td align="right">0.1201643</td>
</tr>
<tr class="even">
<td align="left">3</td>
<td align="left">x2</td>
<td align="right">-10.810865</td>
<td align="right">10.915881</td>
<td align="right">-0.9903795</td>
<td align="right">0.3219887</td>
</tr>
</tbody>
</table>
<p><code>multinom</code> 함수는 범주 <code>y</code>의 값 1, 2, 3중 첫번째 값인 1을 기준범주(reference category)로 사용한다.</p>
</div>
<div id="baseline-category-logit-model" class="section level3">
<h3><span class="header-section-number">1.3.2</span> 기준범주 로짓모형</h3>
<p>종속변수가 셋 이상의 범주를 갖고 있으나 자연스러운 순서가 없는 경우, 기준범주 로짓모형이 널리 사용된다.</p>
<p><span class="math inline">\(N\)</span>개의 객체로 이루어진 학습데이터 <span class="math inline">\(\{(\mathbf{x}_i, y_i)\}_{i = 1, \cdots, N}\)</span>를 아래와 같이 정의하자.</p>
<ul>
<li><span class="math inline">\(\mathbf{x}_i \in \mathbb{R}^p\)</span>: <span class="math inline">\(p\)</span>개의 독립변수로 이루어진 벡터 (<span class="math inline">\(\mathbf{x}_i = [x_{i1} \, x_{i2} \, \cdots \, x_{ip}]^\top\)</span>)</li>
<li><span class="math inline">\(J\)</span>: 범주 수</li>
<li><span class="math inline">\(y_i\)</span>: 객체 <span class="math inline">\(i\)</span>에 대한 종속변수값 <span class="math inline">\(\in \{1, 2, \cdots, J\}\)</span></li>
</ul>
<p>각 객체 <span class="math inline">\(i\)</span>가 각 범주에 해당할 확률을 <span class="math inline">\(\pi_{ij}\)</span>라 하자.</p>
<span class="math display">\[\begin{equation*}
\pi_{ij} = P(y_i = j \, | \, \mathbf{x}_i), \, j = 1, \cdots, J
\end{equation*}\]</span>
<p>이 때, 모든 <span class="math inline">\(i\)</span>에 대하여</p>
<span class="math display">\[\begin{equation*}
\sum_{j = 1}^{J} \pi_{ij} = 1
\end{equation*}\]</span>
<p>이 성립한다. 여기에서 범주 1을 기준 범주(reference category 혹은 baseline category)로 간주하여 범주별로 다음과 같은 회귀모형을 정의한다 (교재 <span class="citation">(전치혁 <a href="#ref-jun2012datamining">2012</a>)</span>에는 범주 <span class="math inline">\(J\)</span>를 기준 범주로 간주).</p>
<span class="math display">\[\begin{equation*}
\log \left( \frac{\pi_{ij}}{\pi_{i1}} \right) = \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i, \, j = 2, \cdots, J
\end{equation*}\]</span>
<p>이를 <span class="math inline">\(\pi_{ij}\)</span>에 대해 풀면, 아래와 같은 해가 얻어진다 <span class="citation">(Czepiel <a href="#ref-czepiel2002maximum">2002</a>)</span>.</p>
<span class="math display" id="eq:multi-nominal-prob-sol">\[\begin{equation}
\begin{split}
\pi_{ij} &amp;=&amp; \frac{\exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}{1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}, \, j = 2, \cdots, J\\
\pi_{i1} &amp;=&amp; \frac{1}{1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}
\end{split}
\tag{1.6}
\end{equation}\]</span>
<p>위 모수 추정을 위해 최우추정법을 사용해보자. 우선, 종속변수를 변환한 지시변수를 아래와 같이 정의한다.</p>
<span class="math display">\[\begin{equation*}
v_{ij} = \begin{cases}
1 &amp; \text{ if } y_i = j\\
0 &amp; \text{ otherwise }
\end{cases}
\end{equation*}\]</span>
<p>이를 이용해 우도 함수를</p>
<span class="math display">\[\begin{eqnarray*}
L &amp;=&amp; \prod_{i = 1}^{n} \prod_{j = 1}^{J} \left( \pi_{ij} \right)^{v_{ij}} \\
&amp;=&amp; \prod_{i = 1}^{n} \pi_{i1}^{1 - \sum{j = 2}^{J} v_{ij}} \prod_{j = 2}^{J} \left( \pi_{ij} \right)^{v_{ij}}\\
&amp;=&amp; \prod_{i = 1}^{n} \frac{\pi_{i1}}{\pi_{i1}^{\sum{j = 2}^{J} v_{ij}}} \prod_{j = 2}^{J} \left( \pi_{ij} \right)^{v_{ij}}\\
&amp;=&amp; \prod_{i = 1}^{n} \frac{\pi_{i1}}{\prod_{j = 2}^{J} \pi_{i1}^{v_{ij}}} \prod_{j = 2}^{J} \left( \pi_{ij} \right)^{v_{ij}}\\
&amp;=&amp; \prod_{i = 1}^{n} \pi_{i1} \prod_{j = 2}^{J} \left( \frac{\pi_{ij}}{\pi_{i1}} \right)^{v_{ij}}
\end{eqnarray*}\]</span>
<p>와 같이 표현할 수 있으며, 여기에 식 <a href="logistic-regression.html#eq:multi-nominal-prob-sol">(1.6)</a>을 이용하면 아래와 같이 정리할 수 있다.</p>
<span class="math display">\[\begin{eqnarray*}
L &amp;=&amp; \prod_{i = 1}^{n} \frac{1}{1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)} \prod_{j = 2}^{J} \left( \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right) \right)^{v_{ij}}\\
&amp;=&amp; \prod_{i = 1}^{n} \left( 1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right) \right)^{-1} \prod_{j = 2}^{J} \left( \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right) \right)^{v_{ij}}
\end{eqnarray*}\]</span>
<p>이에 따라 로그 우도함수는 다음과 같이 정의된다.</p>
<span class="math display" id="eq:multi-nominal-logit-loglik">\[\begin{equation}
\log L = \sum_{i = 1}^{n} \left( - \log \left( 1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right) \right) + \sum_{j = 2}^{J} v_{ij} \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right) \right) 
\tag{1.7}
\end{equation}\]</span>
<p>식 <a href="logistic-regression.html#eq:multi-nominal-logit-loglik">(1.7)</a>을 각 계수에 대해 미분하면 아래와 같이 정리된다.</p>
<span class="math display" id="eq:multi-nominal-logit-loglik-diff">\[\begin{equation}
\begin{split}
\frac{\partial \log L}{\partial \beta_{0,j}} &amp;=&amp; \sum_{i = 1}^{n} v_{ij} - \frac{\exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}{1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}\\
\frac{\partial \log L}{\partial \beta_{k,j}} &amp;=&amp; \sum_{i = 1}^{n} v_{ij} x_{ik} - \frac{x_{ik} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}{1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}, \, k = 1, \cdots, p
\end{split}
\tag{1.8}
\end{equation}\]</span>
<p>따라서, 명목 로지스틱 회귀분석은 식 <a href="logistic-regression.html#eq:multi-nominal-logit-loglik-diff">(1.8)</a>이 표현하는 <span class="math inline">\((J - 1) \times (p + 1)\)</span>개의 미분식을 모두 0으로 만드는 계수값을 찾는 문제가 된다. 이에 대한 closed form solution은 존재하지 않으므로, 각종 알고리즘을 이용하여 해를 찾아야 한다. Newton-Raphson method에 의해 해를 찾는 방법은 <span class="citation">Czepiel (<a href="#ref-czepiel2002maximum">2002</a>)</span> 에 보다 자세하게 설명되어 있다.</p>
<p>Table <a href="logistic-regression.html#tab:nominal-logistic-reg-train-data">1.3</a>의 학습데이터에 대해 명목 로지스틱 회귀모형을 학습하여 범주를 추정한 결과는 아래와 같다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">multinom_fit &lt;-<span class="st"> </span>nnet<span class="op">::</span><span class="kw">multinom</span>(
  y <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2, 
  <span class="dt">data =</span> train_df, 
  <span class="dt">maxit =</span> <span class="dv">1000</span>)</code></pre></div>
<pre><code>## # weights:  12 (6 variable)
## initial  value 19.775021 
## iter  10 value 17.825831
## iter  20 value 16.489924
## iter  30 value 16.116751
## iter  40 value 16.044223
## iter  50 value 16.025259
## iter  60 value 16.024629
## iter  70 value 16.016395
## final  value 16.015185 
## converged</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predict_df &lt;-<span class="st"> </span><span class="kw">predict</span>(multinom_fit, train_df, <span class="dt">type =</span> <span class="st">&quot;probs&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_data_frame</span>() <span class="op">%&gt;%</span>
<span class="st">  `</span><span class="dt">colnames&lt;-</span><span class="st">`</span>(<span class="kw">c</span>(<span class="st">&quot;p1&quot;</span>, <span class="st">&quot;p2&quot;</span>, <span class="st">&quot;p3&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pred_class =</span> <span class="kw">predict</span>(multinom_fit, train_df, <span class="dt">type =</span> <span class="st">&quot;class&quot;</span>))

<span class="kw">bind_cols</span>(train_df, predict_df) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>x1, <span class="op">-</span>x2) <span class="op">%&gt;%</span>
<span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>(
    <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
    <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),
    <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;객체번호&#39;</span>, <span class="st">&#39;불량범주 $y_i$&#39;</span>, 
                  <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">pi_{i1}$&#39;</span>, <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">pi_{i2}$&#39;</span>, <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">pi_{i3}$&#39;</span>, <span class="st">&#39;추정범주 $</span><span class="ch">\\</span><span class="st">hat{y}_i$&#39;</span>),
    <span class="dt">caption =</span> <span class="st">&#39;명목 로지스틱 회귀모형 범주 추정 결과&#39;</span>,
    <span class="dt">digits =</span> <span class="dv">3</span>
  )</code></pre></div>
<table>
<caption><span id="tab:nominal-logistic-prediction">Table 1.5: </span>명목 로지스틱 회귀모형 범주 추정 결과</caption>
<thead>
<tr class="header">
<th align="center">객체번호</th>
<th align="center">불량범주 <span class="math inline">\(y_i\)</span></th>
<th align="right"><span class="math inline">\(\pi_{i1}\)</span></th>
<th align="right"><span class="math inline">\(\pi_{i2}\)</span></th>
<th align="right"><span class="math inline">\(\pi_{i3}\)</span></th>
<th align="center">추정범주 <span class="math inline">\(\hat{y}_i\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">1</td>
<td align="right">0.283</td>
<td align="right">0.112</td>
<td align="right">0.604</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">1</td>
<td align="right">0.425</td>
<td align="right">0.209</td>
<td align="right">0.365</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">1</td>
<td align="right">0.589</td>
<td align="right">0.271</td>
<td align="right">0.141</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">1</td>
<td align="right">0.262</td>
<td align="right">0.729</td>
<td align="right">0.009</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">1</td>
<td align="right">0.450</td>
<td align="right">0.509</td>
<td align="right">0.041</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">2</td>
<td align="right">0.589</td>
<td align="right">0.271</td>
<td align="right">0.141</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">2</td>
<td align="right">0.349</td>
<td align="right">0.570</td>
<td align="right">0.082</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">1</td>
<td align="right">0.199</td>
<td align="right">0.024</td>
<td align="right">0.777</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">9</td>
<td align="center">2</td>
<td align="right">0.349</td>
<td align="right">0.570</td>
<td align="right">0.082</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">10</td>
<td align="center">3</td>
<td align="right">0.501</td>
<td align="right">0.168</td>
<td align="right">0.331</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">11</td>
<td align="center">3</td>
<td align="right">0.490</td>
<td align="right">0.149</td>
<td align="right">0.361</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">12</td>
<td align="center">3</td>
<td align="right">0.283</td>
<td align="right">0.112</td>
<td align="right">0.604</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">13</td>
<td align="center">3</td>
<td align="right">0.425</td>
<td align="right">0.209</td>
<td align="right">0.365</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">14</td>
<td align="center">3</td>
<td align="right">0.160</td>
<td align="right">0.029</td>
<td align="right">0.811</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">15</td>
<td align="center">2</td>
<td align="right">0.365</td>
<td align="right">0.540</td>
<td align="right">0.095</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">16</td>
<td align="center">2</td>
<td align="right">0.595</td>
<td align="right">0.247</td>
<td align="right">0.158</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">17</td>
<td align="center">1</td>
<td align="right">0.416</td>
<td align="right">0.186</td>
<td align="right">0.398</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">18</td>
<td align="center">3</td>
<td align="right">0.268</td>
<td align="right">0.096</td>
<td align="right">0.636</td>
<td align="center">3</td>
</tr>
</tbody>
</table>
<p><code>nnet</code> 패키지 외에도 <code>glmnet</code>, <code>mlogit</code>, <code>VGAM</code> 등의 R 패키지들을 사용해 명목형 로지스틱 회귀모형을 추정할 수 있다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">VGAM<span class="op">::</span><span class="kw">vglm</span>(y <span class="op">~</span><span class="st"> </span>x1 <span class="op">+</span><span class="st"> </span>x2,
           <span class="dt">data =</span> train_df,
           <span class="dt">family =</span> VGAM<span class="op">::</span>multinomial)</code></pre></div>
<pre><code>## 
## Call:
## VGAM::vglm(formula = y ~ x1 + x2, family = VGAM::multinomial, 
##     data = train_df)
## 
## 
## Coefficients:
## (Intercept):1 (Intercept):2          x1:1          x1:2          x2:1 
##     -64.56378    -118.15274     102.65063     133.29235      10.86829 
##          x2:2 
##      20.81307 
## 
## Degrees of Freedom: 36 Total; 30 Residual
## Residual deviance: 32.03007 
## Log-likelihood: -16.01503 
## 
## This is a multinomial logit model with 3 levels</code></pre>
</div>
</div>
<div id="ordinal-logistic-regression" class="section level2">
<h2><span class="header-section-number">1.4</span> 서열 로지스틱 회귀모형</h2>
<p>본 장에서는 종속변수가 3개 이상의 범주를 가지며, 각 범주 간에 서열이 있는 경우에 대한 로지스틱 회귀모형을 소개한다.</p>
<div id="ordinal-logistic-basic-script" class="section level3">
<h3><span class="header-section-number">1.4.1</span> 기본 R 스크립트</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">train_df &lt;-<span class="st"> </span><span class="kw">tribble</span>(
  <span class="op">~</span>N, <span class="op">~</span>L, <span class="op">~</span>y,
  <span class="dv">25</span>, <span class="dv">5</span>, <span class="dv">3</span>,
  <span class="dv">25</span>, <span class="dv">10</span>, <span class="dv">3</span>,
  <span class="dv">25</span>, <span class="dv">20</span>, <span class="dv">2</span>,
  <span class="dv">25</span>, <span class="dv">30</span>, <span class="dv">1</span>,
  <span class="dv">32</span>, <span class="dv">5</span>, <span class="dv">3</span>,
  <span class="dv">32</span>, <span class="dv">10</span>, <span class="dv">3</span>,
  <span class="dv">32</span>, <span class="dv">20</span>, <span class="dv">2</span>,
  <span class="dv">32</span>, <span class="dv">30</span>, <span class="dv">1</span>,
  <span class="dv">42</span>, <span class="dv">5</span>, <span class="dv">1</span>,
  <span class="dv">42</span>, <span class="dv">10</span>, <span class="dv">3</span>,
  <span class="dv">42</span>, <span class="dv">20</span>, <span class="dv">1</span>,
  <span class="dv">42</span>, <span class="dv">30</span>, <span class="dv">1</span>
) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">y =</span> <span class="kw">as.ordered</span>(y))

knitr<span class="op">::</span><span class="kw">kable</span>(train_df, <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
             <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),
             <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;잡음(N)&#39;</span>, <span class="st">&#39;손실(L)&#39;</span>, <span class="st">&#39;만족도($y$)&#39;</span>),
             <span class="dt">caption =</span> <span class="st">&#39;성능변수에 따른 통신 만족도&#39;</span>)</code></pre></div>
<table>
<caption><span id="tab:ordinal-logistic-reg-train-data">Table 1.6: </span>성능변수에 따른 통신 만족도</caption>
<thead>
<tr class="header">
<th align="center">잡음(N)</th>
<th align="center">손실(L)</th>
<th align="center">만족도(<span class="math inline">\(y\)</span>)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">25</td>
<td align="center">5</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">25</td>
<td align="center">10</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">25</td>
<td align="center">20</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">25</td>
<td align="center">30</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">32</td>
<td align="center">5</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">32</td>
<td align="center">10</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">32</td>
<td align="center">20</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">32</td>
<td align="center">30</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">42</td>
<td align="center">5</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">42</td>
<td align="center">10</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">42</td>
<td align="center">20</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">42</td>
<td align="center">30</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>Table <a href="logistic-regression.html#tab:ordinal-logistic-reg-train-data">1.6</a>은 벨 연구소에서 한 통신장치에 대하여 실시한 조사 결과를 나타낸 것이다. 주요 성능변수인 회선잡음(circuit noise: N)과 소리크기 손실(loudness loss: L)이 이용자의 주관적인 만족도에 미치는 영향을 분석하기 위한 것이다. 만족도는 원결과<span class="citation">(Cavanaugh, Hatch, and Sullivan <a href="#ref-cavanaugh1976models">1976</a>)</span>를 가공하여 다음과 같이 3가지로 분류하였다.</p>
<span class="math display">\[\begin{equation*}
y = \begin{cases}
1 &amp; \mbox{good}\\
2 &amp; \mbox{fair}\\
3 &amp; \mbox{poor}
\end{cases}
\end{equation*}\]</span>
<p>본 장에서는 두 가지 모형을 다룬다. 우선 누적 로짓모형(cumulative logit model)은 아래와 같이 <code>MASS</code> 패키지의 <code>polr</code> 함수를 사용하여 추정할 수 있다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">MASS<span class="op">::</span><span class="kw">polr</span>(y <span class="op">~</span><span class="st"> </span>N <span class="op">+</span><span class="st"> </span>L, <span class="dt">data =</span> train_df) <span class="op">%&gt;%</span>
<span class="st">  </span>broom<span class="op">::</span><span class="kw">tidy</span>()</code></pre></div>
<pre><code>## # A tibble: 4 x 5
##   term  estimate std.error statistic coefficient_type
##   &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;           
## 1 N       -0.224     0.146     -1.53 coefficient     
## 2 L       -0.300     0.137     -2.19 coefficient     
## 3 1|2    -13.0       6.46      -2.02 zeta            
## 4 2|3    -11.4       6.17      -1.85 zeta</code></pre>
<p>인근범주 로짓모형(adjacent-categories logit model)은 아래와 같이 <code>VGAM</code> 패키지의 <code>vglm</code> 함수를 이용하여 추정할 수 있다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">VGAM<span class="op">::</span><span class="kw">vglm</span>(y <span class="op">~</span><span class="st"> </span>N <span class="op">+</span><span class="st"> </span>L,
           <span class="dt">data =</span> train_df,
           <span class="dt">family =</span> VGAM<span class="op">::</span><span class="kw">acat</span>(<span class="dt">reverse =</span> <span class="ot">TRUE</span>))</code></pre></div>
<pre><code>## 
## Call:
## VGAM::vglm(formula = y ~ N + L, family = VGAM::acat(reverse = TRUE), 
##     data = train_df)
## 
## 
## Coefficients:
## (Intercept):1 (Intercept):2           N:1           N:2           L:1 
##  -12.94227208   -6.10597713    0.31431599    0.04643039    0.17500408 
##           L:2 
##    0.29578067 
## 
## Degrees of Freedom: 24 Total; 18 Residual
## Residual deviance: 11.67769 
## Log-likelihood: -5.838847 
## 
## This is an adjacent categories model with 3 levels</code></pre>
</div>
<div id="cumulative-logit-model" class="section level3">
<h3><span class="header-section-number">1.4.2</span> 누적 로짓모형</h3>
<p>객체 <span class="math inline">\(i\)</span>가 범주 <span class="math inline">\(j\)</span> 이하에 속할 누적확률을 <span class="math inline">\(\kappa_{ij}\)</span>라 하자.</p>
<span class="math display">\[\begin{equation*}
\kappa_{ij} = P(y_i \leq j \, | \, \mathbf{x}_i), \, j = 1, \cdots, J
\end{equation*}\]</span>
<p>누적 로짓모형은 범주 누적확률의 로짓변환에 대한 선형 회귀모형이다.</p>
<span class="math display" id="eq:cumulative-logit">\[\begin{equation}
\log \left( \frac{\kappa_{ij}}{1 - \kappa_{ij}} \right) = \beta_{0,j} + \boldsymbol\beta^\top \mathbf{x}_i, \, j = 1, \cdots, J - 1
\tag{1.9}
\end{equation}\]</span>
<p>식 <a href="logistic-regression.html#eq:cumulative-logit">(1.9)</a>은 독립변수에 대한 계수 <span class="math inline">\(\boldsymbol\beta\)</span>가 모든 범주에 대해 동일하며 절편(intercept) <span class="math inline">\(\beta_{0,j}\)</span>만 범주에 따라 다른 비례 승산 모형(proportional odds model)이다. 즉, 범주에 관계없이 각 독립변수가 한 단위 증가할 때마다 로그 승산비는 동일하게 증가한다.</p>
<p>모형의 추정은 <a href="logistic-regression.html#baseline-category-logit-model">1.3.2</a>절과 유사하게 다항분포를 사용한 최우추정법을 사용할 수 있다. 각 객체 <span class="math inline">\(i\)</span>가 범주 <span class="math inline">\(j\)</span>에 속할 확률은 아래와 같다.</p>
<span class="math display" id="eq:cumulative-logit-prob">\[\begin{equation*}
\begin{split}
\pi_{ij} &amp;=&amp; \kappa_{ij} - \kappa_{i,j-1}\\
&amp;=&amp; \frac{\exp (\beta_{0,j} + \boldsymbol\beta^\top \mathbf{x}_i)}{1 + \exp (\beta_{0,j} + \boldsymbol\beta^\top \mathbf{x}_i)} - \frac{\exp (\beta_{0,j-1} + \boldsymbol\beta^\top \mathbf{x}_i)}{1 + \exp (\beta_{0,j-1} + \boldsymbol\beta^\top \mathbf{x}_i)}, \, j = 2, \cdots, J - 1\\
&amp; &amp;\\
\pi_{i1} &amp;=&amp; \kappa_{i1}\\
&amp;=&amp; \frac{\exp (\beta_{0,1} + \boldsymbol\beta^\top \mathbf{x}_i)}{1 + \exp (\beta_{0,1} + \boldsymbol\beta^\top \mathbf{x}_i)}\\
&amp; &amp;\\
\pi_{iJ} &amp;=&amp; 1 - \kappa_{i,J-1}\\
&amp;=&amp; 1 - \frac{\exp (\beta_{0,J-1} + \boldsymbol\beta^\top \mathbf{x}_i)}{1 + \exp (\beta_{0,J-1} + \boldsymbol\beta^\top \mathbf{x}_i)}
\end{split}
\tag{1.10}
\end{equation*}\]</span>
<p>로그 우도함수는</p>
<span class="math display">\[\begin{equation*}
\sum_{i = 1}^{n} \sum_{j = 1}^{J} \log \pi_{ij}
\end{equation*}\]</span>
<p>이며, 이에 위에서 정리한 <span class="math inline">\(\pi_{ij}\)</span>식을 대입하여 전개할 수 있다. 이 로그 우도함수는 concave 함수이므로<span class="citation">(Pratt <a href="#ref-pratt1981concavity">1981</a>)</span>, 각 계수에 대해 편미분하여 0이 되도록 하는 값을 구하는 방식으로 회귀모형을 추정할 수 있다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">polr_fit &lt;-<span class="st"> </span>MASS<span class="op">::</span><span class="kw">polr</span>(y <span class="op">~</span><span class="st"> </span>N <span class="op">+</span><span class="st"> </span>L, <span class="dt">data =</span> train_df)

<span class="kw">print</span>(polr_fit)</code></pre></div>
<pre><code>## Call:
## MASS::polr(formula = y ~ N + L, data = train_df)
## 
## Coefficients:
##          N          L 
## -0.2236292 -0.2998833 
## 
## Intercepts:
##       1|2       2|3 
## -13.03527 -11.39902 
## 
## Residual Deviance: 12.8825 
## AIC: 20.8825</code></pre>
<p>위와 같이 <code>polr</code> 함수 실행 시 얻어지는 각 변수들에 대한 계수들의 부호는 교재<span class="citation">(전치혁 <a href="#ref-jun2012datamining">2012</a>)</span>의 내용과 반대인데, 이는 <code>polr</code> 함수는 아래와 같은 모형을 추정하기 때문이다.</p>
<span class="math display">\[\begin{equation*}
\log \left( \frac{\kappa_{ij}}{1 - \kappa_{ij}} \right) = \beta_{0,j} - \boldsymbol\beta^\top \mathbf{x}_i, \, j = 1, \cdots, J - 1
\end{equation*}\]</span>
<p>위 모형에서 <code>polr</code> 함수 실행 결과 추정된 절편값은 <span class="math inline">\(\beta_{0,1} = -13.0352721\)</span>, <span class="math inline">\(\beta_{0,2} = -11.3990207\)</span> 이며, 두 변수 <span class="math inline">\(N\)</span>, <span class="math inline">\(L\)</span>에 대한 회귀계수는 각각 -0.2236292, -0.2998833로 추정된다.</p>
<p>추정된 회귀계수를 식 <a href="logistic-regression.html#eq:cumulative-logit-prob">(1.10)</a>에 대입하면 각 객체 <span class="math inline">\(i\)</span>가 각 범주 <span class="math inline">\(j\)</span>에 속할 확률을 Table <a href="logistic-regression.html#tab:cumulative-logit-prediction">1.7</a>와 같이 얻을 수 있다. 아래 R 스크립트에서 사용한 <code>predict</code>라는 함수가 해당 계산을 수행한다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predict_df &lt;-<span class="st"> </span><span class="kw">predict</span>(polr_fit, train_df, <span class="dt">type =</span> <span class="st">&quot;probs&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_data_frame</span>() <span class="op">%&gt;%</span>
<span class="st">  `</span><span class="dt">colnames&lt;-</span><span class="st">`</span>(<span class="kw">c</span>(<span class="st">&quot;p1&quot;</span>, <span class="st">&quot;p2&quot;</span>, <span class="st">&quot;p3&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pred_class =</span> <span class="kw">predict</span>(polr_fit, train_df, <span class="dt">type =</span> <span class="st">&quot;class&quot;</span>))

<span class="kw">bind_cols</span>(train_df, predict_df) <span class="op">%&gt;%</span>
<span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>(
    <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
    <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),
    <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;잡음(N)&#39;</span>, <span class="st">&#39;손실(L)&#39;</span>, <span class="st">&#39;실제범주 $y_i$&#39;</span>, 
                  <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">pi_{i1}$&#39;</span>, <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">pi_{i2}$&#39;</span>, <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">pi_{i3}$&#39;</span>, <span class="st">&#39;추정범주 $</span><span class="ch">\\</span><span class="st">hat{y}_i$&#39;</span>),
    <span class="dt">caption =</span> <span class="st">&#39;Table </span><span class="ch">\\</span><span class="st"><a href="logistic-regression.html#tab:ordinal-logistic-reg-train-data">1.6</a>에 대한 누적 로짓모형의 추정범주&#39;</span>,
    <span class="dt">digits =</span> <span class="dv">4</span>
  )</code></pre></div>
<table>
<caption><span id="tab:cumulative-logit-prediction">Table 1.7: </span>Table <a href="logistic-regression.html#tab:ordinal-logistic-reg-train-data">1.6</a>에 대한 누적 로짓모형의 추정범주</caption>
<thead>
<tr class="header">
<th align="center">잡음(N)</th>
<th align="center">손실(L)</th>
<th align="center">실제범주 <span class="math inline">\(y_i\)</span></th>
<th align="right"><span class="math inline">\(\pi_{i1}\)</span></th>
<th align="right"><span class="math inline">\(\pi_{i2}\)</span></th>
<th align="right"><span class="math inline">\(\pi_{i3}\)</span></th>
<th align="center">추정범주 <span class="math inline">\(\hat{y}_i\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">25</td>
<td align="center">5</td>
<td align="center">3</td>
<td align="right">0.0026</td>
<td align="right">0.0107</td>
<td align="right">0.9867</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">25</td>
<td align="center">10</td>
<td align="center">3</td>
<td align="right">0.0116</td>
<td align="right">0.0452</td>
<td align="right">0.9432</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">25</td>
<td align="center">20</td>
<td align="center">2</td>
<td align="right">0.1905</td>
<td align="right">0.3567</td>
<td align="right">0.4528</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">25</td>
<td align="center">30</td>
<td align="center">1</td>
<td align="right">0.8252</td>
<td align="right">0.1352</td>
<td align="right">0.0396</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">32</td>
<td align="center">5</td>
<td align="center">3</td>
<td align="right">0.0124</td>
<td align="right">0.0481</td>
<td align="right">0.9395</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">32</td>
<td align="center">10</td>
<td align="center">3</td>
<td align="right">0.0531</td>
<td align="right">0.1706</td>
<td align="right">0.7763</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">32</td>
<td align="center">20</td>
<td align="center">2</td>
<td align="right">0.5296</td>
<td align="right">0.3230</td>
<td align="right">0.1474</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">32</td>
<td align="center">30</td>
<td align="center">1</td>
<td align="right">0.9576</td>
<td align="right">0.0338</td>
<td align="right">0.0085</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">42</td>
<td align="center">5</td>
<td align="center">1</td>
<td align="right">0.1049</td>
<td align="right">0.2709</td>
<td align="right">0.6241</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">42</td>
<td align="center">10</td>
<td align="center">3</td>
<td align="right">0.3443</td>
<td align="right">0.3852</td>
<td align="right">0.2705</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center">42</td>
<td align="center">20</td>
<td align="center">1</td>
<td align="right">0.9133</td>
<td align="right">0.0685</td>
<td align="right">0.0181</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">42</td>
<td align="center">30</td>
<td align="center">1</td>
<td align="right">0.9953</td>
<td align="right">0.0038</td>
<td align="right">0.0009</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
</div>
<div id="adjacent-categories-logit-model" class="section level3">
<h3><span class="header-section-number">1.4.3</span> 인근범주 로짓모형</h3>
<p>인근범주 로짓모형은 아래와 같이 인접한 두 범주의 확률 비율에 대한 회귀모형이다.</p>
<span class="math display" id="eq:adjacent-category-logit">\[\begin{equation}
\log \left( \frac{\pi_{ij}}{\pi_{i,j+1}} \right) = \beta_{0,j} + \boldsymbol\beta^\top \mathbf{x}_i, \, j = 1, \cdots, J - 1
\tag{1.11}
\end{equation}\]</span>
<p>따라서, <span class="math inline">\(\pi_{ij}\)</span>간에 다음과 같은 관계식이 성립한다.</p>
<span class="math display">\[\begin{equation*}
\begin{split}
\pi_{ij} &amp;=&amp; \exp (\beta_{0,j} + \boldsymbol\beta^\top \mathbf{x}_i) \pi_{i,j+1}
&amp;=&amp; \pi_{iJ} \exp \left(\sum_{k = j}^{J - 1} \beta_{0,k} + (J - j) \boldsymbol\beta^\top \mathbf{x}_i\right), \, j = 1, \cdots, J-1\\
\sum_{j = 1}^{J} \pi_{ij} &amp;=&amp; 1
\end{split}
\end{equation*}\]</span>
<p>이를 정리하면</p>
<span class="math display" id="eq:adjacent-category-prob">\[\begin{equation}
\begin{split}
\pi_{ij} &amp;=&amp; \frac{\exp \left( \sum_{l = j}^{J - 1} \beta_{0,l} + (J - j) \boldsymbol\beta^\top \mathbf{x}_i \right)}{1 + \sum_{k = 1}^{J - 1} \exp \left( \sum_{l = k}^{J - 1} \beta_{0,l} + (J - k) \boldsymbol\beta^\top \mathbf{x}_i \right)}, \, j = 1, \cdots, J - 1\\
\pi_{iJ} &amp;=&amp; \frac{1}{1 + \sum_{k = 1}^{J - 1} \exp \left( \sum_{l = k}^{J - 1} \beta_{0,l} + (J - k) \boldsymbol\beta^\top \mathbf{x}_i \right)}
\end{split}
\tag{1.12}
\end{equation}\]</span>
<p>와 같다. 이는 <a href="logistic-regression.html#baseline-category-logit-model">1.3.2</a>절에서 살펴보았던 명목형 로지스틱 회귀모형에 비해 다소 복잡하지만 비슷한 형태이며, 역시 최우추정법을 이용하여 모형을 추정할 수 있다.</p>
<p>R에서는 <code>VGAM</code> 패키지의 <code>vglm</code> 함수를 이용할 때 파라미터 <code>family</code>의 값을 <code>VGAM</code> 패키지의 <code>acat</code> 함수를 설정함으로써 인근범주 로짓모형을 추정할 수 있다. 이 때 <code>acat</code> 함수의 <code>parallel</code> 파라미터값을 <code>TRUE</code>로 설정함으로써 식 <a href="logistic-regression.html#eq:adjacent-category-logit">(1.11)</a>에서와 같이 비례 승산 모형(proportional odds model)을 정의한다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">vglm_fit &lt;-<span class="st"> </span>VGAM<span class="op">::</span><span class="kw">vglm</span>(
  y <span class="op">~</span><span class="st"> </span>N <span class="op">+</span><span class="st"> </span>L,
  <span class="dt">data =</span> train_df,
  <span class="dt">family =</span> VGAM<span class="op">::</span><span class="kw">acat</span>(<span class="dt">reverse =</span> <span class="ot">TRUE</span>, <span class="dt">parallel =</span> <span class="ot">TRUE</span>)
  )

<span class="kw">print</span>(<span class="kw">coef</span>(vglm_fit))</code></pre></div>
<pre><code>## (Intercept):1 (Intercept):2             N             L 
##    -9.0658976    -8.9018134     0.1725867     0.2082167</code></pre>
<p>추정된 모형을 위 식 <a href="logistic-regression.html#eq:adjacent-category-prob">(1.12)</a>에 대입하면 각 객체 <span class="math inline">\(i\)</span>가 각 범주 <span class="math inline">\(j\)</span>에 속할 확률을 추정할 수 있다. <code>VGAM</code> 패키지의 <code>predictvglm</code> 함수가 해당 계산을 수행한다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predict_df &lt;-<span class="st"> </span>VGAM<span class="op">::</span><span class="kw">predictvglm</span>(vglm_fit, train_df, <span class="st">&quot;response&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_data_frame</span>() <span class="op">%&gt;%</span>
<span class="st">  `</span><span class="dt">colnames&lt;-</span><span class="st">`</span>(<span class="kw">c</span>(<span class="st">&quot;p1&quot;</span>, <span class="st">&quot;p2&quot;</span>, <span class="st">&quot;p3&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pred_class =</span> <span class="kw">ordered</span>(<span class="kw">apply</span>(., <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="kw">which.max</span>(x))))

<span class="kw">bind_cols</span>(train_df, predict_df) <span class="op">%&gt;%</span>
<span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>(
    <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
    <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),
    <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;잡음(N)&#39;</span>, <span class="st">&#39;손실(L)&#39;</span>, <span class="st">&#39;실제범주 $y_i$&#39;</span>, 
                  <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">pi_{i1}$&#39;</span>, <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">pi_{i2}$&#39;</span>, <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">pi_{i3}$&#39;</span>, <span class="st">&#39;추정범주 $</span><span class="ch">\\</span><span class="st">hat{y}_i$&#39;</span>),
    <span class="dt">caption =</span> <span class="st">&#39;Table </span><span class="ch">\\</span><span class="st"><a href="logistic-regression.html#tab:ordinal-logistic-reg-train-data">1.6</a>에 대한 인근범주 로짓모형의 추정범주&#39;</span>,
    <span class="dt">digits =</span> <span class="dv">4</span>
  )</code></pre></div>
<table>
<caption><span id="tab:adjacent-category-logit-prediction">Table 1.8: </span>Table <a href="logistic-regression.html#tab:ordinal-logistic-reg-train-data">1.6</a>에 대한 인근범주 로짓모형의 추정범주</caption>
<thead>
<tr class="header">
<th align="center">잡음(N)</th>
<th align="center">손실(L)</th>
<th align="center">실제범주 <span class="math inline">\(y_i\)</span></th>
<th align="right"><span class="math inline">\(\pi_{i1}\)</span></th>
<th align="right"><span class="math inline">\(\pi_{i2}\)</span></th>
<th align="right"><span class="math inline">\(\pi_{i3}\)</span></th>
<th align="center">추정범주 <span class="math inline">\(\hat{y}_i\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">25</td>
<td align="center">5</td>
<td align="center">3</td>
<td align="right">0.0007</td>
<td align="right">0.0280</td>
<td align="right">0.9713</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">25</td>
<td align="center">10</td>
<td align="center">3</td>
<td align="right">0.0052</td>
<td align="right">0.0751</td>
<td align="right">0.9197</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">25</td>
<td align="center">20</td>
<td align="center">2</td>
<td align="right">0.1804</td>
<td align="right">0.3244</td>
<td align="right">0.4952</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">25</td>
<td align="center">30</td>
<td align="center">1</td>
<td align="right">0.7894</td>
<td align="right">0.1770</td>
<td align="right">0.0337</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">32</td>
<td align="center">5</td>
<td align="center">3</td>
<td align="right">0.0072</td>
<td align="right">0.0874</td>
<td align="right">0.9054</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">32</td>
<td align="center">10</td>
<td align="center">3</td>
<td align="right">0.0474</td>
<td align="right">0.2045</td>
<td align="right">0.7480</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">32</td>
<td align="center">20</td>
<td align="center">2</td>
<td align="right">0.5611</td>
<td align="right">0.3015</td>
<td align="right">0.1375</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">32</td>
<td align="center">30</td>
<td align="center">1</td>
<td align="right">0.9339</td>
<td align="right">0.0626</td>
<td align="right">0.0036</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">42</td>
<td align="center">5</td>
<td align="center">1</td>
<td align="right">0.1393</td>
<td align="right">0.3026</td>
<td align="right">0.5581</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">42</td>
<td align="center">10</td>
<td align="center">3</td>
<td align="right">0.4411</td>
<td align="right">0.3385</td>
<td align="right">0.2204</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">42</td>
<td align="center">20</td>
<td align="center">1</td>
<td align="right">0.9063</td>
<td align="right">0.0867</td>
<td align="right">0.0070</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">42</td>
<td align="center">30</td>
<td align="center">1</td>
<td align="right">0.9881</td>
<td align="right">0.0118</td>
<td align="right">0.0001</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>비례 승산 모형(proportional odds model)이 아닌 인근범주 로짓모형은 아래와 같다.</p>
<span class="math display" id="eq:adjacent-category-logit-nonproportional">\[\begin{equation}
\log \left( \frac{\pi_{ij}}{\pi_{i,j+1}} \right) = \beta_{0,j} + \boldsymbol\beta_j^\top \mathbf{x}_i, \, j = 1, \cdots, J - 1
\tag{1.13}
\end{equation}\]</span>
<p>해당 모형은 <code>acat</code> 함수의 <code>parallel</code> 파라미터 값을 <code>FALSE</code>로 설정함으로써 추정할 수 있다.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">vglm_fit &lt;-<span class="st"> </span>VGAM<span class="op">::</span><span class="kw">vglm</span>(
  y <span class="op">~</span><span class="st"> </span>N <span class="op">+</span><span class="st"> </span>L,
  <span class="dt">data =</span> train_df,
  <span class="dt">family =</span> VGAM<span class="op">::</span><span class="kw">acat</span>(<span class="dt">reverse =</span> <span class="ot">TRUE</span>, <span class="dt">parallel =</span> <span class="ot">FALSE</span>)
  )

<span class="kw">print</span>(<span class="kw">coef</span>(vglm_fit))</code></pre></div>
<pre><code>## (Intercept):1 (Intercept):2           N:1           N:2           L:1 
##  -12.94227208   -6.10597713    0.31431599    0.04643039    0.17500408 
##           L:2 
##    0.29578067</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">predict_df &lt;-<span class="st"> </span>VGAM<span class="op">::</span><span class="kw">predictvglm</span>(vglm_fit, train_df, <span class="st">&quot;response&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">as_data_frame</span>() <span class="op">%&gt;%</span>
<span class="st">  `</span><span class="dt">colnames&lt;-</span><span class="st">`</span>(<span class="kw">c</span>(<span class="st">&quot;p1&quot;</span>, <span class="st">&quot;p2&quot;</span>, <span class="st">&quot;p3&quot;</span>)) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(<span class="dt">pred_class =</span> <span class="kw">ordered</span>(<span class="kw">apply</span>(., <span class="dv">1</span>, <span class="cf">function</span>(x) <span class="kw">which.max</span>(x))))

<span class="kw">bind_cols</span>(train_df, predict_df) <span class="op">%&gt;%</span>
<span class="st">  </span>knitr<span class="op">::</span><span class="kw">kable</span>(
    <span class="dt">booktabs =</span> <span class="ot">TRUE</span>,
    <span class="dt">align =</span> <span class="kw">c</span>(<span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>, <span class="st">&#39;r&#39;</span>),
    <span class="dt">col.names =</span> <span class="kw">c</span>(<span class="st">&#39;잡음(N)&#39;</span>, <span class="st">&#39;손실(L)&#39;</span>, <span class="st">&#39;실제범주 $y_i$&#39;</span>, 
                  <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">pi_{i1}$&#39;</span>, <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">pi_{i2}$&#39;</span>, <span class="st">&#39;$</span><span class="ch">\\</span><span class="st">pi_{i3}$&#39;</span>, <span class="st">&#39;추정범주 $</span><span class="ch">\\</span><span class="st">hat{y}_i$&#39;</span>),
    <span class="dt">caption =</span> <span class="st">&#39;Table </span><span class="ch">\\</span><span class="st"><a href="logistic-regression.html#tab:ordinal-logistic-reg-train-data">1.6</a>에 대한 인근범주 로짓모형의 추정범주 (비례 승산 모형이 아닌 경우)&#39;</span>,
    <span class="dt">digits =</span> <span class="dv">4</span>
  )</code></pre></div>
<table>
<caption><span id="tab:adjacent-category-logit-prediction-nonproportional">Table 1.9: </span>Table <a href="logistic-regression.html#tab:ordinal-logistic-reg-train-data">1.6</a>에 대한 인근범주 로짓모형의 추정범주 (비례 승산 모형이 아닌 경우)</caption>
<thead>
<tr class="header">
<th align="center">잡음(N)</th>
<th align="center">손실(L)</th>
<th align="center">실제범주 <span class="math inline">\(y_i\)</span></th>
<th align="right"><span class="math inline">\(\pi_{i1}\)</span></th>
<th align="right"><span class="math inline">\(\pi_{i2}\)</span></th>
<th align="right"><span class="math inline">\(\pi_{i3}\)</span></th>
<th align="center">추정범주 <span class="math inline">\(\hat{y}_i\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">25</td>
<td align="center">5</td>
<td align="center">3</td>
<td align="right">0.0004</td>
<td align="right">0.0303</td>
<td align="right">0.9693</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">25</td>
<td align="center">10</td>
<td align="center">3</td>
<td align="right">0.0043</td>
<td align="right">0.1200</td>
<td align="right">0.8757</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">25</td>
<td align="center">20</td>
<td align="center">2</td>
<td align="right">0.1295</td>
<td align="right">0.6313</td>
<td align="right">0.2392</td>
<td align="center">2</td>
</tr>
<tr class="even">
<td align="center">25</td>
<td align="center">30</td>
<td align="center">1</td>
<td align="right">0.5365</td>
<td align="right">0.4546</td>
<td align="right">0.0089</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">32</td>
<td align="center">5</td>
<td align="center">3</td>
<td align="right">0.0055</td>
<td align="right">0.0412</td>
<td align="right">0.9533</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">32</td>
<td align="center">10</td>
<td align="center">3</td>
<td align="right">0.0488</td>
<td align="right">0.1517</td>
<td align="right">0.7995</td>
<td align="center">3</td>
</tr>
<tr class="odd">
<td align="center">32</td>
<td align="center">20</td>
<td align="center">2</td>
<td align="right">0.5924</td>
<td align="right">0.3200</td>
<td align="right">0.0876</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">32</td>
<td align="center">30</td>
<td align="center">1</td>
<td align="right">0.9131</td>
<td align="right">0.0857</td>
<td align="right">0.0012</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">42</td>
<td align="center">5</td>
<td align="center">1</td>
<td align="right">0.1667</td>
<td align="right">0.0536</td>
<td align="right">0.7797</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center">42</td>
<td align="center">10</td>
<td align="center">3</td>
<td align="right">0.6335</td>
<td align="right">0.0850</td>
<td align="right">0.2815</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">42</td>
<td align="center">20</td>
<td align="center">1</td>
<td align="right">0.9734</td>
<td align="right">0.0227</td>
<td align="right">0.0039</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">42</td>
<td align="center">30</td>
<td align="center">1</td>
<td align="right">0.9959</td>
<td align="right">0.0040</td>
<td align="right">0.0000</td>
<td align="center">1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-jun2012datamining">
<p>전치혁. 2012. <em>데이터마이닝 기법과 응용</em>. 한나래출판사.</p>
</div>
<div id="ref-czepiel2002maximum">
<p>Czepiel, Scott A. 2002. “Maximum Likelihood Estimation of Logistic Regression Models: Theory and Implementation.” <em>Available at Czep. Net/Stat/Mlelr. Pdf</em>.</p>
</div>
<div id="ref-cavanaugh1976models">
<p>Cavanaugh, JR, RW Hatch, and JL Sullivan. 1976. “Models for the Subjective Effects of Loss, Noise, and Talker Echo on Telephone Connections.” <em>Bell System Technical Journal</em> 55 (9). Wiley Online Library: 1319–71.</p>
</div>
<div id="ref-pratt1981concavity">
<p>Pratt, John W. 1981. “Concavity of the Log Likelihood.” <em>Journal of the American Statistical Association</em> 76 (373). Taylor &amp; Francis: 103–6.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="da.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"search": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
