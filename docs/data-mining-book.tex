\documentclass[]{book}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{hyperref}
\hypersetup{unicode=true,
            pdftitle={데이터마이닝 with R},
            pdfauthor={전치혁, 이혜선, 이종석, 이영록},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\IfFileExists{parskip.sty}{%
\usepackage{parskip}
}{% else
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}

%%% Change title format to be more compact
\usepackage{titling}

% Create subtitle command for use in maketitle
\providecommand{\subtitle}[1]{
  \posttitle{
    \begin{center}\large#1\end{center}
    }
}

\setlength{\droptitle}{-2em}

  \title{데이터마이닝 with R}
    \pretitle{\vspace{\droptitle}\centering\huge}
  \posttitle{\par}
    \author{전치혁, 이혜선, 이종석, 이영록}
    \preauthor{\centering\large\emph}
  \postauthor{\par}
      \predate{\centering\large\emph}
  \postdate{\par}
    \date{2019-06-28}

\usepackage{booktabs}
\usepackage[utf]{kotex}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\chapter*{개요}
\addcontentsline{toc}{chapter}{개요}

본 사이트는 전치혁 교수님의 책 \href{http://www.hannarae.net/books/area.php?ptype=view\&prdcode=1409250010}{}을 기반으로 한 R 예제를 제공할 목적으로 만들어졌으며, 지속적으로 업데이트될 예정입니다. 본 사이트의 R 예제들은 R 3.6.0 version에서 수행되었으며, R 프로그램은 \href{https://cran.r-project.org}{CRAN}에서 다운로드받아 설치할 수 있습니다.

본 사이트는 R을 이용한 데이터마이닝 수행에 초점을 두고 있으며, 예제 수행을 위해서는 기본적인 R 프로그래밍 지식이 필요합니다. R 프로그래밍에 대한 지식은 아래와 같은 자료들로부터 얻을 수 있습니다.

\begin{itemize}
\tightlist
\item
  R for Data Science (by Hadley Wickham \& Garrett Grolemund): \url{https://r4ds.had.co.nz}
\item
  Advanced R (by Hadley Wickham): \url{https://adv-r.hadley.nz}
\end{itemize}

\hypertarget{regression}{%
\chapter{회귀분석}\label{regression}}

\hypertarget{regression-packages-install}{%
\section{필요 R 패키지 설치}\label{regression-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.2.1\\
\hline
stats & 3.6.0\\
\hline
broom & 0.5.2\\
\hline
\end{tabular}

\hypertarget{multiple-linear-regression}{%
\section{다중회귀모형}\label{multiple-linear-regression}}

아래와 같이 \(n\)개의 객체와 \(k\)개의 독립변수(\(\mathbf{x}\))로 이루어지고 하나의 종속변수(\(y\))로 이루어진 선형 회귀모형을 정의하자.

\begin{equation}
y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_k x_{ik} + \epsilon_i
\label{eq:multiple-linear-regression}
\end{equation}

이 때, 오차항 \(\epsilon_i\)은 서로 독립이고 동일한 정규분포 \(N(0, \sigma^2)\)을 따른다.

위 회귀모형은 아래와 같이 행렬의 연산으로 표한할 수 있다.

\begin{equation}
\mathbf{y} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\epsilon} \label{eq:multiple-linear-regression-matrix}
\end{equation}

이 때,

\[
\mathbf{y} = \left[ \begin{array}{c}
y_1 \\ y_2 \\ y_3 \\ \vdots \\ y_n
\end{array} \right]
\]

\[
\mathbf{X} = \left[ \begin{array}{c c c c c}
1 & x_{11} & x_{12} & \cdots & x_{1k}\\
1 & x_{21} & x_{22} & \cdots & x_{2k}\\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x_{n1} & x_{n2} & \cdots & x_{nk}
\end{array} \right]
\]

\[
\boldsymbol{\beta} = \left[ \begin{array}{c}
\beta_0 \\ \beta_1 \\ \beta_2 \\ \vdots \\ \beta_k
\end{array} \right]
\]

\[
\boldsymbol{\epsilon} = \left[ \begin{array}{c}
\epsilon_1 \\ \epsilon_2 \\ \epsilon_3 \\ \vdots \\ \epsilon_n
\end{array} \right]
\]

로 정의되며,

\[
E[\boldsymbol{\epsilon}] = \mathbf{0}, \, Var[\boldsymbol{\epsilon}] = \sigma^2 \mathbf{I} 
\]

이다.

\hypertarget{regression-response-confidence-prediction}{%
\section{반응치에 대한 추정 및 예측}\label{regression-response-confidence-prediction}}

\hypertarget{regression-response-confidence}{%
\subsection{평균반응치의 추정}\label{regression-response-confidence}}

\hypertarget{regression-response-confidence-basic-script}{%
\subsubsection{기본 R 스트립트}\label{regression-response-confidence-basic-script}}

다음과 같은 10명의 나이(age), 키(height), 몸무게(weight)에 대한 데이터가 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{age, }\OperatorTok{~}\NormalTok{height, }\OperatorTok{~}\NormalTok{weight,}
  \DecValTok{21}\NormalTok{, }\DecValTok{170}\NormalTok{, }\DecValTok{60}\NormalTok{,}
  \DecValTok{47}\NormalTok{, }\DecValTok{167}\NormalTok{, }\DecValTok{65}\NormalTok{,}
  \DecValTok{36}\NormalTok{, }\DecValTok{173}\NormalTok{, }\DecValTok{67}\NormalTok{,}
  \DecValTok{15}\NormalTok{, }\DecValTok{165}\NormalTok{, }\DecValTok{54}\NormalTok{,}
  \DecValTok{54}\NormalTok{, }\DecValTok{168}\NormalTok{, }\DecValTok{73}\NormalTok{,}
  \DecValTok{25}\NormalTok{, }\DecValTok{177}\NormalTok{, }\DecValTok{71}\NormalTok{,}
  \DecValTok{32}\NormalTok{, }\DecValTok{169}\NormalTok{, }\DecValTok{68}\NormalTok{,}
  \DecValTok{18}\NormalTok{, }\DecValTok{172}\NormalTok{, }\DecValTok{62}\NormalTok{,}
  \DecValTok{43}\NormalTok{, }\DecValTok{171}\NormalTok{, }\DecValTok{66}\NormalTok{,}
  \DecValTok{28}\NormalTok{, }\DecValTok{175}\NormalTok{, }\DecValTok{68}
\NormalTok{)}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  train_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
  \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'나이 (age)'}\NormalTok{, }\StringTok{'키 (height)'}\NormalTok{, }\StringTok{'몸무게 (weight)'}\NormalTok{),}
  \DataTypeTok{caption =} \StringTok{'나이, 키, 몸무게 데이터'}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:regression-age-height-weight-data}나이, 키, 몸무게 데이터}
\centering
\begin{tabular}{rrr}
\toprule
나이 (age) & 키 (height) & 몸무게 (weight)\\
\midrule
21 & 170 & 60\\
47 & 167 & 65\\
36 & 173 & 67\\
15 & 165 & 54\\
54 & 168 & 73\\
\addlinespace
25 & 177 & 71\\
32 & 169 & 68\\
18 & 172 & 62\\
43 & 171 & 66\\
28 & 175 & 68\\
\bottomrule
\end{tabular}
\end{table}

회귀모형을 아래와 같이 학습한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_fit <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(weight }\OperatorTok{~}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{height, }\DataTypeTok{data =}\NormalTok{ train_df)}
\end{Highlighting}
\end{Shaded}

추정된 회귀계수는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{coef}\NormalTok{(lm_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  (Intercept)          age       height 
## -108.1671993    0.3291212    0.9552913
\end{verbatim}

추정계수벡터의 분산-공분산 행렬은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{vcov}\NormalTok{(lm_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              (Intercept)          age        height
## (Intercept) 1774.3280624 -0.671107283 -10.264885141
## age           -0.6711073  0.004794717   0.003035476
## height       -10.2648851  0.003035476   0.059566804
\end{verbatim}

나이가 40, 키가 170인 사람들의 평균 몸무게에 대한 95\% 신뢰구간은 아래와 같이 구할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(lm_fit, }\DataTypeTok{newdata =} \KeywordTok{tibble}\NormalTok{(}\DataTypeTok{age =} \DecValTok{40}\NormalTok{, }\DataTypeTok{height =} \DecValTok{170}\NormalTok{),}
        \DataTypeTok{interval =} \StringTok{"confidence"}\NormalTok{, }\DataTypeTok{level =} \FloatTok{0.95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        fit      lwr      upr
## 1 67.39718 65.01701 69.77735
\end{verbatim}

\hypertarget{regression-response-confidence-variance}{%
\subsubsection{평균 반응치의 분산 추정}\label{regression-response-confidence-variance}}

새로운 독립변수에 대한 벡터를 아래와 같이 \(\mathbf{x}_0\)라 하면, 평균반응치의 추정량은 아래와 같이 표현된다.

\begin{equation}
\hat{y}_0 = \mathbf{x}_0^\top \hat{\boldsymbol{\beta}} \label{eq:response-estimate}
\end{equation}

식 \eqref{eq:response-estimate}의 분산은 아래와 같다.

\begin{eqnarray}
Var(\hat{y}_0) &=& \mathbf{x}_0^\top Var(\hat{\boldsymbol{\beta}}) \mathbf{x}_0\\
&=& \sigma^2 \mathbf{x}_0^\top \left(\mathbf{X}^\top \mathbf{X}\right)^{-1} \mathbf{x}_0 \label{eq:response-estimate-variance}
\end{eqnarray}

위 식 \eqref{eq:response-estimate-variance}에서 \(\sigma^2\) 대신 그 추정값인 \(MSE\) (mean squared error)를 대입하여 평균반응치의 분산을 추정한다.

\begin{equation}
\hat{Var}(\hat{y}_0) = MSE \times \left( \mathbf{x}_0^\top \left(\mathbf{X}^\top \mathbf{X}\right)^{-1} \mathbf{x}_0 \right) \label{eq:response-estimate-variance-est}
\end{equation}

우선 Table \ref{tab:regression-age-height-weight-data}에 대해 회귀모형 추정치 \(\hat{\boldsymbol{\beta}}\)와 \(MSE\)값을 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n <-}\StringTok{ }\KeywordTok{nrow}\NormalTok{(train_df)}
\NormalTok{X <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}
  \DataTypeTok{intercept =} \KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, n), }
\NormalTok{  train_df[, }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"height"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{()}
\NormalTok{)}
\NormalTok{y <-}\StringTok{ }\NormalTok{train_df[, }\KeywordTok{c}\NormalTok{(}\StringTok{"weight"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{()}
\NormalTok{k <-}\StringTok{ }\KeywordTok{ncol}\NormalTok{(X) }\OperatorTok{-}\StringTok{ }\DecValTok{1}

\CommentTok{# regression coefficient}
\NormalTok{beta_hat <-}\StringTok{ }\KeywordTok{solve}\NormalTok{(}\KeywordTok{t}\NormalTok{(X) }\OperatorTok{%*%}\StringTok{ }\NormalTok{X) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{t}\NormalTok{(X) }\OperatorTok{%*%}\StringTok{ }\NormalTok{y}

\CommentTok{# response estimate}
\NormalTok{y_hat <-}\StringTok{ }\NormalTok{X }\OperatorTok{%*%}\StringTok{ }\NormalTok{beta_hat}

\CommentTok{# MSE}
\NormalTok{MSE <-}\StringTok{ }\KeywordTok{sum}\NormalTok{((y }\OperatorTok{-}\StringTok{ }\NormalTok{y_hat) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{) }\OperatorTok{/}\StringTok{ }\NormalTok{(n }\OperatorTok{-}\StringTok{ }\NormalTok{k }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

이후, 나이가 40, 키가 170인 객체 \(\mathbf{x}_0\)에 대한 평균 반응치 \(\hat{y}_0\)의 95\% 신뢰구간을 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# variance of y_hat on new_x}
\NormalTok{new_x <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}
  \DataTypeTok{intercept =} \DecValTok{1}\NormalTok{,}
  \DataTypeTok{age =} \DecValTok{40}\NormalTok{,}
  \DataTypeTok{height =} \DecValTok{170}
\NormalTok{), }\DataTypeTok{ncol =} \DecValTok{1}\NormalTok{)}

\NormalTok{new_y_hat <-}\StringTok{ }\KeywordTok{t}\NormalTok{(new_x) }\OperatorTok{%*%}\StringTok{ }\NormalTok{beta_hat}

\NormalTok{var_new_y_hat <-}\StringTok{ }\NormalTok{MSE }\OperatorTok{*}\StringTok{ }\KeywordTok{t}\NormalTok{(new_x) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{solve}\NormalTok{(}\KeywordTok{t}\NormalTok{(X) }\OperatorTok{%*%}\StringTok{ }\NormalTok{X) }\OperatorTok{%*%}\StringTok{ }\NormalTok{new_x}
\NormalTok{se_new_y_hat <-}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(var_new_y_hat)}

\NormalTok{lci <-}\StringTok{ }\NormalTok{new_y_hat }\OperatorTok{+}\StringTok{ }\KeywordTok{qt}\NormalTok{(}\FloatTok{0.025}\NormalTok{, n }\OperatorTok{-}\StringTok{ }\NormalTok{k }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{*}\StringTok{ }\NormalTok{se_new_y_hat}
\NormalTok{uci <-}\StringTok{ }\NormalTok{new_y_hat }\OperatorTok{+}\StringTok{ }\KeywordTok{qt}\NormalTok{(}\FloatTok{0.975}\NormalTok{, n }\OperatorTok{-}\StringTok{ }\NormalTok{k }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{*}\StringTok{ }\NormalTok{se_new_y_hat}

\KeywordTok{str_glue}\NormalTok{(}\StringTok{"(\{format(lci, nsmall = 3L)\}, \{format(uci, nsmall = 3L)\})"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (65.01701, 69.77735)
\end{verbatim}

\hypertarget{regression-response-prediction}{%
\subsection{미래반응치의 예측}\label{regression-response-prediction}}

\hypertarget{regression-response-prediction-basic-script}{%
\subsubsection{기본 R 스트립트}\label{regression-response-prediction-basic-script}}

\ref{regression-response-confidence} 절에서 추정한 회귀모형을 통해, 새로운 독립변수값(나이 = 40, 키 = 170)을 지닌 특정 객체에 대한 몸무게의 예측구간을 구한다. 이는 한 객체의 몸무게의 예측구간으로, \ref{regression-response-confidence} 절에서 구한 평균 몸무게의 신뢰구간보다 넓다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(lm_fit, }\DataTypeTok{newdata =} \KeywordTok{tibble}\NormalTok{(}\DataTypeTok{age =} \DecValTok{40}\NormalTok{, }\DataTypeTok{height =} \DecValTok{170}\NormalTok{),}
        \DataTypeTok{interval =} \StringTok{"prediction"}\NormalTok{, }\DataTypeTok{level =} \FloatTok{0.95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        fit      lwr     upr
## 1 67.39718 60.68745 74.1069
\end{verbatim}

\hypertarget{regression-response-prediction-interval}{%
\subsubsection{미래 반응치의 예측구간 추정}\label{regression-response-prediction-interval}}

독립변수값들에 대응하는 미래반응치인 \(y_0\)의 예측치는 평균반응치의 추정치와 동일하며, 반응치의 예측구간을 구하기 위해서는 예측오차의 분산을 알아야 하는데, 이는 아래와 같이 식 \eqref{eq:response-estimate-variance}보다 \(\sigma^2\)이 더 크게 된다.

\begin{eqnarray}
Var(y_0 - \hat{y}_0) &=& Var(y_0) + Var(\hat{y}_0)\\
&=& \sigma^2 + \sigma^2 \mathbf{x}_0^\top \left(\mathbf{X}^\top \mathbf{X}\right)^{-1} \mathbf{x}_0 \\
&=& \sigma^2 \left( 1 + \mathbf{x}_0^\top \left(\mathbf{X}^\top \mathbf{X}\right)^{-1} \mathbf{x}_0 \right)
\label{eq:response-prediction-variance}
\end{eqnarray}

위 식 \eqref{eq:response-prediction-variance}에서 \(\sigma^2\) 대신 \(MSE\)를 대입함으로써 예측오차 분산을 추정할 수 있다.

\begin{equation}
\hat{Var}(y_0 - \hat{y}_0) = MSE \times \left( 1 + \mathbf{x}_0^\top \left(\mathbf{X}^\top \mathbf{X}\right)^{-1} \mathbf{x}_0 \right)
\label{eq:response-prediction-variance-est}
\end{equation}

앞 절에서 추정한 회귀모형을 이용하여, 나이가 40, 키가 170인 객체 \(\mathbf{x}_0\)에 대한 미래 반응치 \(y_0\)의 95\% 예측구간을 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# variance of y_hat on new_x}
\NormalTok{new_x <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}
  \DataTypeTok{intercept =} \DecValTok{1}\NormalTok{,}
  \DataTypeTok{age =} \DecValTok{40}\NormalTok{,}
  \DataTypeTok{height =} \DecValTok{170}
\NormalTok{), }\DataTypeTok{ncol =} \DecValTok{1}\NormalTok{)}

\NormalTok{new_y_hat <-}\StringTok{ }\KeywordTok{t}\NormalTok{(new_x) }\OperatorTok{%*%}\StringTok{ }\NormalTok{beta_hat}

\NormalTok{var_new_y_pred <-}\StringTok{ }\NormalTok{MSE }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{t}\NormalTok{(new_x) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{solve}\NormalTok{(}\KeywordTok{t}\NormalTok{(X) }\OperatorTok{%*%}\StringTok{ }\NormalTok{X) }\OperatorTok{%*%}\StringTok{ }\NormalTok{new_x)}
\NormalTok{se_new_y_pred <-}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(var_new_y_pred)}

\NormalTok{lci <-}\StringTok{ }\NormalTok{new_y_hat }\OperatorTok{+}\StringTok{ }\KeywordTok{qt}\NormalTok{(}\FloatTok{0.025}\NormalTok{, n }\OperatorTok{-}\StringTok{ }\NormalTok{k }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{*}\StringTok{ }\NormalTok{se_new_y_pred}
\NormalTok{uci <-}\StringTok{ }\NormalTok{new_y_hat }\OperatorTok{+}\StringTok{ }\KeywordTok{qt}\NormalTok{(}\FloatTok{0.975}\NormalTok{, n }\OperatorTok{-}\StringTok{ }\NormalTok{k }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{*}\StringTok{ }\NormalTok{se_new_y_pred}

\KeywordTok{str_glue}\NormalTok{(}\StringTok{"(\{format(lci, nsmall = 3L)\}, \{format(uci, nsmall = 3L)\})"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (60.68745, 74.1069)
\end{verbatim}

\hypertarget{regression-indicator-variable}{%
\section{지시변수와 회귀모형}\label{regression-indicator-variable}}

\hypertarget{regression-indicator-variable-basic-script}{%
\subsection{기본 R 스트립트}\label{regression-indicator-variable-basic-script}}

어떤 열연코일의 인장강도(TS)에 권취온도(CT)가 어떤 영향을 미치는가를 조사하기 위해 TS를 종속변수, CT를 독립변수로 하여 회귀분석을 실시하기로 하였다. 수집된 데이터에는 두 개의 두께 그룹(2mm, 6mm)이 포함되어 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{ct, }\OperatorTok{~}\NormalTok{thickness, }\OperatorTok{~}\NormalTok{ts,}
  \DecValTok{540}\NormalTok{, }\DecValTok{2}\NormalTok{, }\FloatTok{52.5}\NormalTok{,}
  \DecValTok{660}\NormalTok{, }\DecValTok{2}\NormalTok{, }\FloatTok{50.2}\NormalTok{,}
  \DecValTok{610}\NormalTok{, }\DecValTok{2}\NormalTok{, }\FloatTok{51.3}\NormalTok{,}
  \DecValTok{710}\NormalTok{, }\DecValTok{2}\NormalTok{, }\FloatTok{49.1}\NormalTok{,}
  \DecValTok{570}\NormalTok{, }\DecValTok{6}\NormalTok{, }\FloatTok{50.8}\NormalTok{,}
  \DecValTok{700}\NormalTok{, }\DecValTok{6}\NormalTok{, }\FloatTok{48.7}\NormalTok{,}
  \DecValTok{560}\NormalTok{, }\DecValTok{6}\NormalTok{, }\FloatTok{51.2}\NormalTok{,}
  \DecValTok{600}\NormalTok{, }\DecValTok{6}\NormalTok{, }\FloatTok{50.8}\NormalTok{,}
  \DecValTok{680}\NormalTok{, }\DecValTok{6}\NormalTok{, }\FloatTok{49.3}\NormalTok{,}
  \DecValTok{530}\NormalTok{, }\DecValTok{6}\NormalTok{, }\FloatTok{51.5}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{thickness =} \KeywordTok{factor}\NormalTok{(thickness, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{str}\NormalTok{(train_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Classes 'tbl_df', 'tbl' and 'data.frame':    10 obs. of  3 variables:
##  $ ct       : num  540 660 610 710 570 700 560 600 680 530
##  $ thickness: Factor w/ 2 levels "6","2": 2 2 2 2 1 1 1 1 1 1
##  $ ts       : num  52.5 50.2 51.3 49.1 50.8 48.7 51.2 50.8 49.3 51.5
\end{verbatim}

두께를 \texttt{factor}로 지정하고 회귀모형을 추정하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_fit <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(ts }\OperatorTok{~}\StringTok{ }\NormalTok{ct }\OperatorTok{+}\StringTok{ }\NormalTok{thickness, }\DataTypeTok{data =}\NormalTok{ train_df)}
\end{Highlighting}
\end{Shaded}

회귀 계수는 아래와 같이 얻어진다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{coef}\NormalTok{(lm_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept)          ct  thickness2 
## 61.10796610 -0.01767797  0.80415254
\end{verbatim}

두께 그룹에 따라 CT에 대한 TS의 기울기가 다르다고 예상되면 CT와 두께 간에 교호작용(interaction)이 존재한다고 말하며, 이 때 회귀모형은 다음과 같이 추정한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm_interaction_fit <-}\StringTok{ }\KeywordTok{lm}\NormalTok{(}
\NormalTok{  ts }\OperatorTok{~}\StringTok{ }\NormalTok{ct }\OperatorTok{+}\StringTok{ }\NormalTok{thickness }\OperatorTok{+}\StringTok{ }\NormalTok{ct}\OperatorTok{:}\NormalTok{thickness, }
  \DataTypeTok{data =}\NormalTok{ train_df}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

교호작용이 추가된 회귀 결과는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{(lm_interaction_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 5
##   term          estimate std.error statistic  p.value
##   <chr>            <dbl>     <dbl>     <dbl>    <dbl>
## 1 (Intercept)   60.1       0.750       80.2  2.53e-10
## 2 ct            -0.0161    0.00123    -13.1  1.23e- 5
## 3 thickness2     3.28      1.21         2.71 3.52e- 2
## 4 ct:thickness2 -0.00399   0.00194     -2.05 8.57e- 2
\end{verbatim}

두께에 따른 CT와 TS의 관계를 그래프로 살펴보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new_df <-}\StringTok{ }\KeywordTok{crossing}\NormalTok{(}
  \DataTypeTok{ct =} \KeywordTok{seq}\NormalTok{(}\DecValTok{500}\NormalTok{, }\DecValTok{750}\NormalTok{, }\DataTypeTok{by =} \DecValTok{10}\NormalTok{),}
  \DataTypeTok{thickness =} \KeywordTok{factor}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{2}\NormalTok{), }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{)}

\NormalTok{new_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{ts_hat =} \KeywordTok{predict}\NormalTok{(lm_interaction_fit, .)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ ct, }\DataTypeTok{y =}\NormalTok{ ts_hat)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{color =}\NormalTok{ thickness)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ ct, }\DataTypeTok{y =}\NormalTok{ ts, }\DataTypeTok{color =}\NormalTok{ thickness), }\DataTypeTok{data =}\NormalTok{ train_df) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{color =} \StringTok{"thickness"}\NormalTok{, }\DataTypeTok{x =} \StringTok{"CT"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"TS"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/regression-ct-ts-by-thickness-plot-1} 

}

\caption{두께에 따른 CT와 TS의 관계}\label{fig:regression-ct-ts-by-thickness-plot}
\end{figure}

\hypertarget{pca}{%
\chapter{주성분분석}\label{pca}}

\hypertarget{pca-packages-install}{%
\section{필요 R 패키지 설치}\label{pca-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.2.1\\
\hline
stats & 3.6.0\\
\hline
broom & 0.5.2\\
\hline
Matrix & 1.2-17\\
\hline
nipals & 0.5\\
\hline
\end{tabular}

\hypertarget{pca-matrix-factorization}{%
\section{행렬의 분해}\label{pca-matrix-factorization}}

\hypertarget{pca-matrix-factorization-basic-script}{%
\subsection{기본 R 스트립트}\label{pca-matrix-factorization-basic-script}}

아래 Table \ref{tab:pca-matrix-factorization-data}는 국내 18개 증권회사의 주요 재무제표를 나열한 것이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{company, }\OperatorTok{~}\NormalTok{roa, }\OperatorTok{~}\NormalTok{roe, }\OperatorTok{~}\NormalTok{bis, }\OperatorTok{~}\NormalTok{de_ratio, }\OperatorTok{~}\NormalTok{turnover,}
  \StringTok{"SK증권"}\NormalTok{, }\FloatTok{2.43}\NormalTok{, }\FloatTok{11.10}\NormalTok{, }\FloatTok{18.46}\NormalTok{, }\FloatTok{441.67}\NormalTok{, }\FloatTok{0.90}\NormalTok{,}
  \StringTok{"교보증권"}\NormalTok{, }\FloatTok{3.09}\NormalTok{, }\FloatTok{9.95}\NormalTok{, }\FloatTok{29.46}\NormalTok{, }\FloatTok{239.43}\NormalTok{, }\FloatTok{0.90}\NormalTok{,}
  \StringTok{"대신증권"}\NormalTok{, }\FloatTok{2.22}\NormalTok{, }\FloatTok{6.86}\NormalTok{, }\FloatTok{28.62}\NormalTok{, }\FloatTok{249.36}\NormalTok{, }\FloatTok{0.69}\NormalTok{,}
  \StringTok{"대우증권"}\NormalTok{, }\FloatTok{5.76}\NormalTok{, }\FloatTok{23.19}\NormalTok{, }\FloatTok{23.47}\NormalTok{, }\FloatTok{326.09}\NormalTok{, }\FloatTok{1.43}\NormalTok{,}
  \StringTok{"동부증권"}\NormalTok{, }\FloatTok{1.60}\NormalTok{, }\FloatTok{5.64}\NormalTok{, }\FloatTok{25.64}\NormalTok{, }\FloatTok{289.98}\NormalTok{, }\FloatTok{1.42}\NormalTok{,}
  \StringTok{"메리츠증권"}\NormalTok{, }\FloatTok{3.53}\NormalTok{, }\FloatTok{10.64}\NormalTok{, }\FloatTok{32.25}\NormalTok{, }\FloatTok{210.10}\NormalTok{, }\FloatTok{1.17}\NormalTok{,}
  \StringTok{"미래에셋증권"}\NormalTok{, }\FloatTok{4.26}\NormalTok{, }\FloatTok{15.56}\NormalTok{, }\FloatTok{24.40}\NormalTok{, }\FloatTok{309.78}\NormalTok{, }\FloatTok{0.81}\NormalTok{,}
  \StringTok{"부국증권"}\NormalTok{, }\FloatTok{3.86}\NormalTok{, }\FloatTok{5.50}\NormalTok{, }\FloatTok{70.74}\NormalTok{, }\FloatTok{41.36}\NormalTok{, }\FloatTok{0.81}\NormalTok{,}
  \StringTok{"브릿지증권"}\NormalTok{, }\FloatTok{4.09}\NormalTok{, }\FloatTok{6.44}\NormalTok{, }\FloatTok{64.38}\NormalTok{, }\FloatTok{55.32}\NormalTok{, }\FloatTok{0.32}\NormalTok{,}
  \StringTok{"삼성증권"}\NormalTok{, }\FloatTok{2.73}\NormalTok{, }\FloatTok{10.68}\NormalTok{, }\FloatTok{24.41}\NormalTok{, }\FloatTok{309.59}\NormalTok{, }\FloatTok{0.64}\NormalTok{,}
  \StringTok{"서울증권"}\NormalTok{, }\FloatTok{2.03}\NormalTok{, }\FloatTok{4.50}\NormalTok{, }\FloatTok{42.53}\NormalTok{, }\FloatTok{135.12}\NormalTok{, }\FloatTok{0.59}\NormalTok{,}
  \StringTok{"신영증권"}\NormalTok{, }\FloatTok{1.96}\NormalTok{, }\FloatTok{8.92}\NormalTok{, }\FloatTok{18.48}\NormalTok{, }\FloatTok{441.19}\NormalTok{, }\FloatTok{1.07}\NormalTok{,}
  \StringTok{"신흥증권"}\NormalTok{, }\FloatTok{3.25}\NormalTok{, }\FloatTok{7.96}\NormalTok{, }\FloatTok{40.42}\NormalTok{, }\FloatTok{147.41}\NormalTok{, }\FloatTok{1.19}\NormalTok{,}
  \StringTok{"우리투자증권"}\NormalTok{, }\FloatTok{2.01}\NormalTok{, }\FloatTok{10.28}\NormalTok{, }\FloatTok{17.46}\NormalTok{, }\FloatTok{472.78}\NormalTok{, }\FloatTok{1.25}\NormalTok{,}
  \StringTok{"유화증권"}\NormalTok{, }\FloatTok{2.28}\NormalTok{, }\FloatTok{3.65}\NormalTok{, }\FloatTok{63.71}\NormalTok{, }\FloatTok{56.96}\NormalTok{, }\FloatTok{0.12}\NormalTok{,}
  \StringTok{"한양증권"}\NormalTok{, }\FloatTok{4.51}\NormalTok{, }\FloatTok{7.50}\NormalTok{, }\FloatTok{63.52}\NormalTok{, }\FloatTok{57.44}\NormalTok{, }\FloatTok{0.80}\NormalTok{,}
  \StringTok{"한화증권"}\NormalTok{, }\FloatTok{3.29}\NormalTok{, }\FloatTok{12.37}\NormalTok{, }\FloatTok{24.47}\NormalTok{, }\FloatTok{308.63}\NormalTok{, }\FloatTok{0.57}\NormalTok{,}
  \StringTok{"현대증권"}\NormalTok{, }\FloatTok{1.73}\NormalTok{, }\FloatTok{7.57}\NormalTok{, }\FloatTok{19.59}\NormalTok{, }\FloatTok{410.45}\NormalTok{, }\FloatTok{1.19}
\NormalTok{)}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  train_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{align =} \KeywordTok{rep}\NormalTok{(}\StringTok{"r"}\NormalTok{, }\KeywordTok{ncol}\NormalTok{(train_df)),}
  \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}
    \StringTok{"회사"}\NormalTok{,}
    \StringTok{"총자본 순이익율 ($x_1$)"}\NormalTok{,}
    \StringTok{"자기자본 순이익율 ($x_2$)"}\NormalTok{,}
    \StringTok{"자기자본비율 ($x_3$)"}\NormalTok{,}
    \StringTok{"부채비율 ($x_4$)"}\NormalTok{,}
    \StringTok{"자기자본 회전율 ($x_5$)"}
\NormalTok{  ),}
  \DataTypeTok{caption =} \StringTok{"국내 증권회사의 주요 재무제표"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:pca-matrix-factorization-data}국내 증권회사의 주요 재무제표}
\centering
\begin{tabular}{rrrrrr}
\toprule
회사 & 총자본 순이익율 (\$x\_1\$) & 자기자본 순이익율 (\$x\_2\$) & 자기자본비율 (\$x\_3\$) & 부채비율 (\$x\_4\$) & 자기자본 회전율 (\$x\_5\$)\\
\midrule
SK증권 & 2.43 & 11.10 & 18.46 & 441.67 & 0.90\\
교보증권 & 3.09 & 9.95 & 29.46 & 239.43 & 0.90\\
대신증권 & 2.22 & 6.86 & 28.62 & 249.36 & 0.69\\
대우증권 & 5.76 & 23.19 & 23.47 & 326.09 & 1.43\\
동부증권 & 1.60 & 5.64 & 25.64 & 289.98 & 1.42\\
\addlinespace
메리츠증권 & 3.53 & 10.64 & 32.25 & 210.10 & 1.17\\
미래에셋증권 & 4.26 & 15.56 & 24.40 & 309.78 & 0.81\\
부국증권 & 3.86 & 5.50 & 70.74 & 41.36 & 0.81\\
브릿지증권 & 4.09 & 6.44 & 64.38 & 55.32 & 0.32\\
삼성증권 & 2.73 & 10.68 & 24.41 & 309.59 & 0.64\\
\addlinespace
서울증권 & 2.03 & 4.50 & 42.53 & 135.12 & 0.59\\
신영증권 & 1.96 & 8.92 & 18.48 & 441.19 & 1.07\\
신흥증권 & 3.25 & 7.96 & 40.42 & 147.41 & 1.19\\
우리투자증권 & 2.01 & 10.28 & 17.46 & 472.78 & 1.25\\
유화증권 & 2.28 & 3.65 & 63.71 & 56.96 & 0.12\\
\addlinespace
한양증권 & 4.51 & 7.50 & 63.52 & 57.44 & 0.80\\
한화증권 & 3.29 & 12.37 & 24.47 & 308.63 & 0.57\\
현대증권 & 1.73 & 7.57 & 19.59 & 410.45 & 1.19\\
\bottomrule
\end{tabular}
\end{table}

이에 대하여 R 기본 \texttt{stats} 패키지 내의 \texttt{prcomp} 함수를 이용하여 주성분 분석을 수행할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pca_fit <-}\StringTok{ }\KeywordTok{prcomp}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{roa }\OperatorTok{+}\StringTok{ }\NormalTok{roe }\OperatorTok{+}\StringTok{ }\NormalTok{bis }\OperatorTok{+}\StringTok{ }\NormalTok{de_ratio }\OperatorTok{+}\StringTok{ }\NormalTok{turnover,}
                  \DataTypeTok{data =}\NormalTok{ train_df, }\DataTypeTok{scale =} \OtherTok{TRUE}\NormalTok{)}

\NormalTok{pca_fit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Standard deviations (1, .., p=5):
## [1] 1.6617648 1.2671437 0.7419994 0.2531070 0.1351235
## 
## Rotation (n x k) = (5 x 5):
##                  PC1         PC2           PC3          PC4         PC5
## roa       0.07608427 -0.77966993  0.0008915975 -0.140755404  0.60540325
## roe      -0.39463007 -0.56541218 -0.2953216494  0.117644166 -0.65078503
## bis       0.56970191 -0.16228156  0.2412221065 -0.637721889 -0.42921686
## de_ratio -0.55982770  0.19654293 -0.2565972887 -0.748094314  0.14992183
## turnover -0.44778451 -0.08636803  0.8881182665 -0.003668418 -0.05711464
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(pca_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Importance of components:
##                           PC1    PC2    PC3     PC4     PC5
## Standard deviation     1.6618 1.2671 0.7420 0.25311 0.13512
## Proportion of Variance 0.5523 0.3211 0.1101 0.01281 0.00365
## Cumulative Proportion  0.5523 0.8734 0.9835 0.99635 1.00000
\end{verbatim}

각 주성분에 대한 고유값을 스크리 도표로 나타내면 아래 Figure \ref{fig:pca-screeplot}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{screeplot}\NormalTok{(pca_fit, }\DataTypeTok{main =} \OtherTok{NULL}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/pca-screeplot-1} 

}

\caption{고유치 스크리 도표}\label{fig:pca-screeplot}
\end{figure}

\hypertarget{pca-ss}{%
\subsection{변수의 변동과 제곱합}\label{pca-ss}}

총 \(k\)개의 독립변수가 있고 각 독립변수에 대하여 \(n\)개의 관측치가 있다고 하자. 이 때, \(x_{ij}\)를 \(j\)번째 독립변수에 대한 \(i\)번째 관측치라 하자. 즉, 관측데이터는 아래와 같은 행렬로 표현할 수 있다.

\begin{equation*}
\mathbf{X} = \left[ \begin{array}{c c c c}
x_{11} & x_{12} & \cdots & x_{1k}\\
x_{21} & x_{22} & \cdots & x_{2k}\\
\vdots & \vdots & \ddots & \vdots \\
x_{n1} & x_{n2} & \cdots & x_{nk}
\end{array} \right]
\end{equation*}

주성분분석에서는 통상 원데이터를 그대로 사용하지 않고 적절한 변환을 취하는데, 주로 평균조정(mean-centered) 데이터를 이용한다. 이는 아래와 같이 독립변수에 대하여 표본평균을 뺌으로써 조정된 변수의 평균이 0이 되도록 하는 것이다.

\begin{equation}
x_{ij} \leftarrow x_{ij} - \frac{1}{n} \sum_{l = 1}^{n} x_{lj} \label{eq:pca-mean-centering}
\end{equation}

이후에 별도의 언급이 없는 한, 행렬 \(\mathbf{X}\) 및 변수값 \(x_{ij}\)는 식 \eqref{eq:pca-mean-centering}을 이용하여 평균조정된 것으로 가정한다.

이 밖에도 다른 변환이 사용되는 경우가 있는데, 특히 단위 등이 서로 상이할 경우에는 평균조정 이후 추가로 각 변수의 분산이 1이 되도록 분산조정을 한다.

\begin{equation*}
z_{ij} \leftarrow \frac{x_{ij}}{\sqrt{\frac{1}{n - 1} \sum_{l =1}^{n} x_{lj}^2}} \label{eq:pca-scaling}
\end{equation*}

이 때, 식 \eqref{eq:pca-scaling}에서 분모 부분은 변수의 표본 표준편차로 \(s_j\)로 표현된다.

\begin{equation*}
s_{j} = \sqrt{\frac{1}{n - 1} \sum_{l =1}^{n} x_{lj}^2}
\end{equation*}

이후 분산조정을 이용하는 경우 행렬 \(\mathbf{Z}\) 및 변수값 \(z_{ij}\)로 표현한다.

\begin{equation*}
\mathbf{Z} = \left[ \begin{array}{c c c c}
z_{11} & z_{12} & \cdots & z_{1k}\\
z_{21} & z_{22} & \cdots & z_{2k}\\
\vdots & \vdots & \ddots & \vdots \\
z_{n1} & z_{n2} & \cdots & z_{nk}
\end{array} \right]
\end{equation*}

변수벡터 \(\mathbf{x}_j = [x_{1j} \, x_{2j} \, \cdots \, x_{nj}]^\top\)에 대한 제곱합의 정의는 아래와 같다.

\begin{equation}
SS(\mathbf{x}_j) = \mathbf{x}_j^\top \mathbf{x}_j = \sum_{i = 1}^{n} x_{ij}^2
\end{equation}

따라서, 평균조정된 변수에 대해 제곱합고 표본분산은 다음과 같은 관계가 있다.

\begin{equation*}
SS(\mathbf{x}_j) = (n - 1) s_j^2
\end{equation*}

변수행렬 \(\mathbf{X}\)에 대한 제곱합은 각 변수들의 제곱합의 총합(총변동)으로 정의된다.

\begin{equation}
SS(\mathbf{X}) = \sum_{j = 1}^{k} SS(\mathbf{x}_j) = \sum_{j = 1}^{k} \sum_{i = 1}^{n} x_{ij}^2
\end{equation}

Table \ref{tab:pca-matrix-factorization-data} 데이터에 대하여 각 변수의 제곱합을 계산해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) x }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(x)) }\OperatorTok{%>%}\StringTok{  }\CommentTok{# mean-centering}
\StringTok{  }\KeywordTok{summarize_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{sum}\NormalTok{(x }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)) }\CommentTok{# sum of squares by variable}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 5
##     roa   roe   bis de_ratio turnover
##   <dbl> <dbl> <dbl>    <dbl>    <dbl>
## 1  21.9  355. 5591.  347817.     2.23
\end{verbatim}

전체 데이터 행렬에 대한 제곱합은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) x }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(x)) }\OperatorTok{%>%}\StringTok{  }\CommentTok{# mean-centering}
\StringTok{  }\KeywordTok{summarize_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{sum}\NormalTok{(x }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }\CommentTok{# sum of squares by variable}
\StringTok{  }\NormalTok{\{}\KeywordTok{sum}\NormalTok{(.)\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 353786.6
\end{verbatim}

위 결과에서 부채비율(\texttt{de\_ratio})의 변동이 총변동의 대부분을 차지하고, 자기자본 회전율(\texttt{turnover})이 총변동에 미치는 영향은 미미한데, 이는 각 변수들이 측정하는 값의 분포(범위)가 크게 다르기 때문이다. 이러한 경우, 일반적으로 분산조정을 추가로 적용한 뒤 주성분분석을 수행한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{standardized_df <-}\StringTok{ }\NormalTok{train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) x }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(x)) }\OperatorTok{%>%}\StringTok{  }\CommentTok{# mean-centering}
\StringTok{  }\KeywordTok{mutate_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) x }\OperatorTok{/}\StringTok{ }\KeywordTok{sd}\NormalTok{(x))  }\CommentTok{# scaling}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{standardized_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 18 x 6
##    company          roa     roe    bis de_ratio turnover
##    <chr>          <dbl>   <dbl>  <dbl>    <dbl>    <dbl>
##  1 SK증권       -0.533   0.383  -0.918  1.34      0.0507
##  2 교보증권      0.0484  0.131  -0.312 -0.0749    0.0507
##  3 대신증권     -0.718  -0.545  -0.358 -0.00551  -0.530 
##  4 대우증권      2.40    3.03   -0.642  0.531     1.52  
##  5 동부증권     -1.26   -0.812  -0.522  0.278     1.49  
##  6 메리츠증권    0.436   0.282  -0.158 -0.280     0.797 
##  7 미래에셋증권  1.08    1.36   -0.591  0.417    -0.198 
##  8 부국증권      0.726  -0.843   1.96  -1.46     -0.198 
##  9 브릿지증권    0.929  -0.637   1.61  -1.36     -1.55  
## 10 삼성증권     -0.269   0.291  -0.590  0.416    -0.668 
## 11 서울증권     -0.885  -1.06    0.409 -0.804    -0.806 
## 12 신영증권     -0.947  -0.0942 -0.917  1.34      0.521 
## 13 신흥증권      0.189  -0.304   0.293 -0.718     0.852 
## 14 우리투자증권 -0.903   0.203  -0.973  1.56      1.02  
## 15 유화증권     -0.665  -1.25    1.58  -1.35     -2.11  
## 16 한양증권      1.30   -0.405   1.57  -1.35     -0.226 
## 17 한화증권      0.225   0.661  -0.587  0.409    -0.861 
## 18 현대증권     -1.15   -0.390  -0.856  1.12      0.852
\end{verbatim}

분산조정 이후의 각 변수의 제곱합은 모두 \(n - 1\)이 되는데, 이는 각 변수의 표본분산이 모두 1로 조정되기 때문이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{standardized_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{sum}\NormalTok{(x }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)) }\CommentTok{# sum of squares by variable}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 5
##     roa   roe   bis de_ratio turnover
##   <dbl> <dbl> <dbl>    <dbl>    <dbl>
## 1    17  17.0    17       17      17.
\end{verbatim}

따라서, 분산조정 이후 총변동은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{total_ss <-}\StringTok{ }\NormalTok{standardized_df }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarize_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{sum}\NormalTok{(x }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }\CommentTok{# sum of squares by variable}
\StringTok{  }\NormalTok{\{}\KeywordTok{sum}\NormalTok{(.)\}}

\NormalTok{total_ss}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 85
\end{verbatim}

\hypertarget{pca-intro}{%
\subsection{주성분의 이해 및 행렬의 분해}\label{pca-intro}}

주성분분석은 원래의 변수들의 선형조합으로 서로 직교하는 새로운 변수들을 생성하는 것이라 할 수 있다. 이 때, 원래 변수의 수 \(k\)보다 작은 \(A\)개의 새로운 변수들이 원 데이터 행렬 \(\mathbf{X}\) 총변동의 대부분을 설명한다고 하면, 해당 새로운 변수들만을 사용하여 여러 가지 분석을 대신할 수 있다는 것이 주성분분석의 개념이라 하겠다.

새로운 변수 \(\mathbf{t}_1, \cdots, \mathbf{t}_A\)들은 다음과 같은 형태로 표현된다.

\begin{equation}
\mathbf{t}_a = \sum_{j = 1}^{k} p_{aj} \mathbf{x}_j, \, a = 1, \cdots, A
\end{equation}

결과적으로 주성분분석은 위와 같이 표현되는 새로운 변수를 만들 때 필요한 계수 \(p_{aj}\)를 구하는 것이라 할 수 있겠다. \(\mathbf{t}_1\)이 \(\mathbf{X}\)의 변동을 가장 많이 설명하도록, \(\mathbf{t}_2\)는 \(\mathbf{t}_1\)이 설명하지 못한 변동을 가장 많이 설명하도록 하는 방식으로 \(A\)개의 새로운 변수를 순차적으로 찾아내는 것이 기본적인 원리이다.

Table \ref{tab:pca-matrix-factorization-data} 데이터에 대하여 분산조정을 적용한 후 아래 식을 이용하여 새로운 변수를 도출해보자.

\[
t_1 = 0.07608427 \times roa - 0.39463007 \times roe + 0.56970191 \times bis - 0.55982770 \times de\_ratio - 0.44778451 \times turnover
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new_df <-}\StringTok{ }\NormalTok{standardized_df }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{t_1 =} \FloatTok{0.07608427} \OperatorTok{*}\StringTok{ }\NormalTok{roa }\OperatorTok{-}\StringTok{ }\FloatTok{0.39463007} \OperatorTok{*}\StringTok{ }\NormalTok{roe }
         \OperatorTok{+}\StringTok{ }\FloatTok{0.56970191} \OperatorTok{*}\StringTok{ }\NormalTok{bis }\OperatorTok{-}\StringTok{ }\FloatTok{0.55982770} \OperatorTok{*}\StringTok{ }\NormalTok{de_ratio }
         \OperatorTok{-}\StringTok{ }\FloatTok{0.44778451} \OperatorTok{*}\StringTok{ }\NormalTok{turnover) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(company, t_}\DecValTok{1}\NormalTok{) }\CommentTok{# new variable}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(new_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 18 x 2
##    company         t_1
##    <chr>         <dbl>
##  1 SK증권       -1.49 
##  2 교보증권     -0.206
##  3 대신증권      0.197
##  4 대우증권     -2.35 
##  5 동부증권     -0.895
##  6 메리츠증권   -0.368
##  7 미래에셋증권 -0.935
##  8 부국증권      2.41 
##  9 브릿지증권    2.70 
## 10 삼성증권     -0.405
## 11 서울증권      1.40 
## 12 신영증권     -1.54 
## 13 신흥증권      0.322
## 14 우리투자증권 -2.03 
## 15 유화증권      3.04 
## 16 한양증권      2.01 
## 17 한화증권     -0.421
## 18 현대증권     -1.43
\end{verbatim}

이 때, 새로운 변수 \(\mathbf{t}_1\)는 분산조정된 행렬 \(\mathbf{Z}\)의 총변동의 약 55\%를 설명한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t1_ss <-}\StringTok{ }\NormalTok{new_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{sum}\NormalTok{(x }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{))}

\NormalTok{t1_ss }\OperatorTok{/}\StringTok{ }\NormalTok{total_ss}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         t_1
## 1 0.5522924
\end{verbatim}

위 새로운 변수 \(\mathbf{t}_1\)는 실제로 행렬 \(\mathbf{Z}\)로부터 얻어지는 첫 번째 주성분이며, 행렬 \(\mathbf{Z}\)의 변동에 가장 많이 기여하는 하나의 선형조합이다.

행렬 \(\mathbf{Z}\)(혹은 \(\mathbf{X}\))로부터 주성분을 얻는 방법은 여러 가지가 있으며, 아래에서 하나씩 설명하기로 한다.

\hypertarget{-singular-value-decomposition-pca-svd}{%
\subsection{특이치분해 (Singular Value Decomposition) \{pca-svd\}}\label{-singular-value-decomposition-pca-svd}}

분산조정된 \(\mathbf{Z}\)에 대해 주성분분석을 수행한다고 가정하자. 분산조정을 하지 않고 주성분분석을 수행하는 경우 아래 행렬 \(\mathbf{Z}\) 대신 \(\mathbf{X}\)를 사용하면 된다.

임의의 \((n \times k)\) 행렬 \(\mathbf{Z}\)는 다음과 같이 분해된다.

\begin{equation}
\mathbf{Z} = \mathbf{U} \mathbf{D} \mathbf{V}^\top \label{eq:pca-svd}
\end{equation}

이 때, \(r = \min\{n, k\}\)라 할 때,

\begin{itemize}
\tightlist
\item
  \(\mathbf{U}\): \((n \times r)\) 직교 (orthogonal) 행렬
\item
  \(\mathbf{D}\): \((r \times r)\) 대각 (diagonal) 행렬. rank 수만큼의 비음 대각원소들을 가지며, 각 비음 대각원소를 힝렬 \(\mathbf{Z}\)의 특이치(singular value)라 하고, 특이치가 내림차순으로 정렬되는 형태로 행렬이 구성된다.
\item
  \(\mathbf{V}\): \((k \times r)\) 직교 (orthogonal) 행렬
\end{itemize}

아래와 같이, R 함수 \texttt{svd}를 이용하여 분해한 행렬들을 곱한 결과가 원래 행렬 \(\mathbf{Z}\)와 동일함을 확인할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Z <-}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(standardized_df[, }\DecValTok{-1}\NormalTok{])}
\NormalTok{svd_Z <-}\StringTok{ }\KeywordTok{svd}\NormalTok{(Z)}
\NormalTok{Z_rec <-}\StringTok{ }\NormalTok{svd_Z}\OperatorTok{$}\NormalTok{u }\OperatorTok{%*%}\StringTok{ }\KeywordTok{diag}\NormalTok{(svd_Z}\OperatorTok{$}\NormalTok{d) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{t}\NormalTok{(svd_Z}\OperatorTok{$}\NormalTok{v)}
\KeywordTok{all}\NormalTok{(}\KeywordTok{near}\NormalTok{(Z, Z_rec))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

이 때, 행렬 \(\mathbf{V}\)의 각 열벡터가 각 주성분을 도출하는 선형식의 계수가 된다. 즉, 행렬 \(\mathbf{V}\)의 첫 번째 열이 위에서 살펴본 새로운 변수 \(\mathbf{t}_1\)를 도출하는 선형식의 계수이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svd_Z}\OperatorTok{$}\NormalTok{v[, }\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  0.07608427 -0.39463007  0.56970191 -0.55982770 -0.44778451
\end{verbatim}

특이치는 아래와 같이 추출된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svd_Z}\OperatorTok{$}\NormalTok{d}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6.8516318 5.2245674 3.0593417 1.0435870 0.5571285
\end{verbatim}

이 특이치들은 아래 분광분해에서 살펴볼 고유치의 제곱근이다.

\hypertarget{-spectral-decomposition-pca-spectral}{%
\subsection{분광분해 (Spectral Decomposition) \{pca-spectral\}}\label{-spectral-decomposition-pca-spectral}}

임의의 정방행렬 \(\mathbf{A}\)에 대하여

\[\mathbf{A}\mathbf{v} = \lambda\mathbf{v} \]

가 성립하는 벡터 \(\mathbf{v} \neq \mathbf{0}\)과 상수 \(\lambda\)가 존재할 때, 상수 \(\lambda\)를 행렬 \(\mathbf{A}\)의 고유치(eigenvalue)라 하며, \(\mathbf{v}\)를 이에 대응하는 고유벡터(eigenvector)라 한다. 통상 \(\mathbf{v}^\top \mathbf{v} = 1\)을 가정한다.

분광분해는 정방행렬을 고유치와 고유벡터의 곱으로 분해하는 방법이다. \((r \times r)\) 정방행렬 \(\mathbf{A}\)에 대해 \(r\)개의 고유치 \(\lambda_1, \cdots, \lambda_r\)와 고유벡터 \(\mathbf{v}_1, \cdots, \mathbf{v}_r\)이 존재한다고 할 때, 행렬 \(\mathbf{A}\)는 다음과 같이 정리된다.

\[
\mathbf{A}\left[\mathbf{v}_1 \, \cdots \, \mathbf{v}_r\right] = \left[\mathbf{v}_1 \, \cdots \, \mathbf{v}_r\right] \left[ \begin{array}{c c c c}
\lambda_1 & 0 & \cdots & 0\\
0 & \lambda_2 &  & 0\\
\vdots &  & \ddots & 0\\
0 & 0 & \cdots & \lambda_r
\end{array} \right] \\
\mathbf{A} = \mathbf{A} \left[\mathbf{v}_1 \, \cdots \, \mathbf{v}_r\right] \left[\mathbf{v}_1 \, \cdots \, \mathbf{v}_r\right]^{-1} = \left[\mathbf{v}_1 \, \cdots \, \mathbf{v}_r\right] \left[ \begin{array}{c c c c}
\lambda_1 & 0 & \cdots & 0\\
0 & \lambda_2 &  & 0\\
\vdots &  & \ddots & 0\\
0 & 0 & \cdots & \lambda_r
\end{array} \right] \left[\mathbf{v}_1 \, \cdots \, \mathbf{v}_r\right]^{-1} = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^{-1}
\]

특히 행렬 \(\mathbf{A}\)가 대칭(symmetric)행렬인 경우, 고유벡터들은 서로 직교하므로 (\(\mathbf{V}\mathbf{V}^\top = \mathbf{I}\)), 위 식을 아래와 같이 표현할 수 있다.

\[ \mathbf{A} = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^\top \]

주성분 분석을 위해 정방행렬 \(\mathbf{Z}^\top \mathbf{Z}\)를 분해를 살펴보자. 식 \eqref{eq:pca-svd}로부터,

\[
\mathbf{Z}^\top \mathbf{Z} = \mathbf{V} \mathbf{D}^\top \mathbf{U}^\top \mathbf{U} \mathbf{D} \mathbf{V}^\top = \mathbf{V} \mathbf{D}^2 \mathbf{V}^\top = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^\top
\]

즉, 분광분해를 통해 도출된 고유벡터들의 행렬 \(\mathbf{V}\)의 각 열벡터가 각 주성분을 도출하는 선형식의 계수를 나타내며, 대각행렬 \(\mathbf{\Lambda}\)의 각 대각원소값인 고유치는 특이치의 제곱임을 알 수 있다.

R 함수 \texttt{eigen}을 이용하여 분광분해를 아래와 같이 수행하여 보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eig_Z <-}\StringTok{ }\KeywordTok{eigen}\NormalTok{(}\KeywordTok{t}\NormalTok{(Z) }\OperatorTok{%*%}\StringTok{ }\NormalTok{Z, }\DataTypeTok{symmetric =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{eig_Z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## eigen() decomposition
## $values
## [1] 46.9448582 27.2961041  9.3595718  1.0890737  0.3103922
## 
## $vectors
##             [,1]        [,2]          [,3]         [,4]        [,5]
## [1,] -0.07608427 -0.77966993  0.0008915975 -0.140755404  0.60540325
## [2,]  0.39463007 -0.56541218 -0.2953216494  0.117644166 -0.65078503
## [3,] -0.56970191 -0.16228156  0.2412221065 -0.637721889 -0.42921686
## [4,]  0.55982770  0.19654293 -0.2565972887 -0.748094314  0.14992183
## [5,]  0.44778451 -0.08636803  0.8881182665 -0.003668418 -0.05711464
\end{verbatim}

결과에서 \texttt{values}는 행렬 \(\mathbf{Z}^\top \mathbf{Z}\)의 고유치(eigenvalue)들이다. 이들이 앞 장의 특이치 분해에서 얻은 특이치들의 제곱임을 확인하여 보자.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{all}\NormalTok{(}\KeywordTok{near}\NormalTok{(eig_Z}\OperatorTok{$}\NormalTok{values, svd_Z}\OperatorTok{$}\NormalTok{d }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

또한 분광분해 결과 \texttt{vectors}의 각 열은 행렬 \(\mathbf{Z}^\top \mathbf{Z}\)의 고유벡터(eigenvector)들이다. 이들이 앞 장의 특이치 분해에서 얻은 계수 행렬과 동일함을 확인하여 보자.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{all}\NormalTok{(}\KeywordTok{near}\NormalTok{(eig_Z}\OperatorTok{$}\NormalTok{vectors, svd_Z}\OperatorTok{$}\NormalTok{v))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

이 경우 두 행렬이 동일하지 않게 나타날 수 있는데, 그 이유는 경우에 따라 어떤 주성분을 생성하는 선형계수 부호가 정반대인 형태로 얻어질 수 있기 때문이다. 주성분의 설명력은 선형계수의 부호에 영향을 받지 않는다.

두 행렬의 계수 부호가 서로 동일하게 조정한 뒤 행렬을 비교해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sign_adjust <-}\StringTok{ }\DecValTok{1} \OperatorTok{-}\StringTok{ }\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{((eig_Z}\OperatorTok{$}\NormalTok{vectors }\OperatorTok{*}\StringTok{ }\NormalTok{svd_Z}\OperatorTok{$}\NormalTok{v) }\OperatorTok{<}\StringTok{ }\DecValTok{0}\NormalTok{)}
\KeywordTok{all}\NormalTok{(}\KeywordTok{near}\NormalTok{(eig_Z}\OperatorTok{$}\NormalTok{vectors }\OperatorTok{*}\StringTok{ }\NormalTok{sign_adjust, svd_Z}\OperatorTok{$}\NormalTok{v))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

위 각 고유값들을 고유값들의 총합으로 나누면, 각 고유벡터에 해당하는 주성분이 설명하는 총변동의 비율을 얻을 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eig_Z}\OperatorTok{$}\NormalTok{values }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(eig_Z}\OperatorTok{$}\NormalTok{values)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.552292449 0.321130636 0.110112610 0.012812632 0.003651673
\end{verbatim}

평균 및 분산 조정된 \(\mathbf{Z}\)의 분산-공분산 행렬은 아래와 같다.

\[\frac{1}{n - 1} \mathbf{Z}^\top \mathbf{Z}\]

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{all}\NormalTok{(}\KeywordTok{near}\NormalTok{(}\KeywordTok{cov}\NormalTok{(Z), }\KeywordTok{t}\NormalTok{(Z) }\OperatorTok{%*%}\StringTok{ }\NormalTok{Z }\OperatorTok{/}\StringTok{ }\NormalTok{(}\KeywordTok{nrow}\NormalTok{(Z) }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

여기에 위에서 구한 분광분해를 대입하면,

\[\frac{1}{n - 1} \mathbf{Z}^\top \mathbf{Z} = \frac{1}{n - 1} \mathbf{V} \mathbf{\Lambda} \mathbf{V}^\top =  \mathbf{V} \left( \frac{1}{n - 1} \mathbf{\Lambda} \right) \mathbf{V}^\top\]

따라서, \(\mathbf{Z}\)의 분산-공분산 행렬에 대한 분광분해 결과, 고유벡터 행렬 \(\mathbf{V}\)는 앞에서 구한 \(\mathbf{Z}^\top \mathbf{Z}\)의 고유벡터 행렬들과 동일하며, 고유값은 앞에서 구한 \(\mathbf{Z}^\top \mathbf{Z}\)의 고유값을 \((n - 1)\)으로 나눈 값이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eig_cov_Z <-}\StringTok{ }\KeywordTok{eigen}\NormalTok{(}\KeywordTok{cov}\NormalTok{(Z))}
\NormalTok{eig_cov_Z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## eigen() decomposition
## $values
## [1] 2.76146225 1.60565318 0.55056305 0.06406316 0.01825836
## 
## $vectors
##             [,1]        [,2]          [,3]         [,4]        [,5]
## [1,] -0.07608427  0.77966993  0.0008915975 -0.140755404  0.60540325
## [2,]  0.39463007  0.56541218 -0.2953216494  0.117644166 -0.65078503
## [3,] -0.56970191  0.16228156  0.2412221065 -0.637721889 -0.42921686
## [4,]  0.55982770 -0.19654293 -0.2565972887 -0.748094314  0.14992183
## [5,]  0.44778451  0.08636803  0.8881182665 -0.003668418 -0.05711464
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{all}\NormalTok{(}\KeywordTok{near}\NormalTok{(eig_cov_Z}\OperatorTok{$}\NormalTok{values, eig_Z}\OperatorTok{$}\NormalTok{values }\OperatorTok{/}\StringTok{ }\NormalTok{(}\KeywordTok{nrow}\NormalTok{(Z) }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

또한 이 결과는 평균 및 분산조정 이전 원 데이터의 상관행렬(correlation matrix)에 대해 분광분해를 수행한 결과와 동일하다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eig_cor_raw <-}\StringTok{ }\KeywordTok{eigen}\NormalTok{(}\KeywordTok{cor}\NormalTok{(train_df[, }\DecValTok{-1}\NormalTok{]))}
\NormalTok{eig_cor_raw}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## eigen() decomposition
## $values
## [1] 2.76146225 1.60565318 0.55056305 0.06406316 0.01825836
## 
## $vectors
##             [,1]        [,2]          [,3]         [,4]        [,5]
## [1,] -0.07608427  0.77966993  0.0008915975 -0.140755404  0.60540325
## [2,]  0.39463007  0.56541218 -0.2953216494  0.117644166 -0.65078503
## [3,] -0.56970191  0.16228156  0.2412221065 -0.637721889 -0.42921686
## [4,]  0.55982770 -0.19654293 -0.2565972887 -0.748094314  0.14992183
## [5,]  0.44778451  0.08636803  0.8881182665 -0.003668418 -0.05711464
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{all}\NormalTok{(}\KeywordTok{near}\NormalTok{(eig_cov_Z}\OperatorTok{$}\NormalTok{values, eig_cor_raw}\OperatorTok{$}\NormalTok{values))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{all}\NormalTok{(}\KeywordTok{near}\NormalTok{(eig_cov_Z}\OperatorTok{$}\NormalTok{vectors, eig_cor_raw}\OperatorTok{$}\NormalTok{vectors))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\hypertarget{pca-nipals}{%
\subsection{NIPALS 알고리즘}\label{pca-nipals}}

NIPALS(Nonlinear Iterative Paritial Least Squares) 알고리즘은 반복적(iterative) 알고리즘을 이용하여 변동 기여율이 가장 큰 주성분부터 가장 작은 주성분까지 순차적으로 고유벡터와 주성분 스코어를 구하는 방법이다.

우선, 특이치 분해에서 사용한 식을 단순화하여, 분산조정된 행렬 \(\mathbf{Z}\)가 아래와 같이 주성분 스코어 행렬 \(\mathbf{T}\)와 고유벡터 행렬 \(\mathbf{V}\)로 분해된다고 하자. (분산조정 대신 평균조정만을 원할 경우 \(\mathbf{Z}\) 대신 \(\mathbf{X}\)를 사용)

\[ \mathbf{Z} = \mathbf{U} \mathbf{D} \mathbf{V}^\top = \mathbf{T} \mathbf{V}^\top \]

즉, 주성분 스코어 \(\mathbf{T}\)는 아래와 같다.

\[ \mathbf{T} = \mathbf{Z} \mathbf{V} \]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{T_mat <-}\StringTok{ }\NormalTok{Z }\OperatorTok{%*%}\StringTok{ }\NormalTok{svd_Z}\OperatorTok{$}\NormalTok{v}
\NormalTok{T_mat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             [,1]       [,2]        [,3]        [,4]         [,5]
##  [1,] -1.4870243  0.6066594 -0.63361774 -0.29625002  0.020293731
##  [2,] -0.2063797 -0.0804627 -0.04965017  0.26323513  0.063581473
##  [3,]  0.1968538  0.9704605 -0.39507856  0.27123746  0.103351746
##  [4,] -2.3542884 -3.5056480  0.16252734  0.02524924 -0.249920974
##  [5,] -0.8953707  1.4552899  1.36265905  0.20161775 -0.055517167
##  [6,] -0.3682082 -0.5976313  0.65857722  0.27901317  0.060458248
##  [7,] -0.9354306 -1.4144519 -0.82574638  0.07358977  0.095960908
##  [8,]  2.4129728 -0.6785064  0.92207607 -0.36161577 -0.062593521
##  [9,]  2.6991862 -0.7596591 -0.45091077 -0.21030378  0.168645128
## [10,] -0.4050098  0.2800099 -0.92835441  0.13993488  0.001811118
## [11,]  1.3958199  1.1353513 -0.09819177  0.34335126 -0.094986796
## [12,] -1.5381192  1.1576616 -0.07467334 -0.29404424  0.052430946
## [13,]  0.3217681 -0.2378023  1.10180230  0.28507243  0.030666763
## [14,] -2.0306806  0.9646122  0.20906175 -0.39639758 -0.085778570
## [15,]  3.0389460  0.8841645 -0.77478769 -0.04079854 -0.349688462
## [16,]  2.0064063 -1.2831337  0.64388897 -0.22077705  0.188366871
## [17,] -0.4211779 -0.2987099 -1.20644766  0.11766274  0.068250991
## [18,] -1.4302634  1.4017959  0.37686579 -0.17977686  0.044667568
\end{verbatim}

NIPALS 알고리즘은 아래와 같이 주성분 스코어 행렬 \(\mathbf{T}\)의 열과 고유벡터행렬 \(\mathbf{V}\)의 열을 동시에 구한다.

\begin{itemize}
\tightlist
\item
  \textbf{{[}단계 0{]}} 반복알고리즘 수행을 위한 초기화를 한다. \(h \leftarrow 1\), \(\mathbf{Z}_h \leftarrow \mathbf{Z}\).
\item
  \textbf{{[}단계 1{]}} 데이터 행렬 \(\mathbf{Z}_h\)의 임의의 열 하나를 주성분 스코어 벡터 \(\mathbf{t}_h\)로 선정한다.
\item
  \textbf{{[}단계 2{]}} 로딩벡터를 구한다. \(\mathbf{v}_h \leftarrow \mathbf{Z}_h \mathbf{t}_h \left/ \sqrt{\mathbf{t}_h^\top \mathbf{t}_h} \right.\)
\item
  \textbf{{[}단계 3{]}} 로딩벡터의 크기가 1이 되도록 한다. \(\mathbf{v}_h \leftarrow \mathbf{v}_h \left/ \sqrt{\mathbf{v}_h^\top \mathbf{v}_h} \right.\)
\item
  \textbf{{[}단계 4{]}} 주성분 스코어 벡터를 로딩벡터에 기반하여 계산한다. \(\mathbf{t}_h \leftarrow \mathbf{Z}_h \mathbf{v}_h\)
\item
  \textbf{{[}단계 5{]}} 주성분 스코어 벡터 \(\mathbf{t}_h\)가 수렴하였으면 {[}단계 6{]}으로 진행하고, 그렇지 않으면 {[}단계 2{]}로 돌아간다.
\item
  \textbf{{[}단계 6{]}} 데이터 행렬 \(\mathbf{Z}_h\)로부터 새로 얻어진 주성분 벡터 \(\mathbf{t}_h\)와 고유벡터 \(\mathbf{v}_h\)가 설명하는 부분을 제거하고 나머지 변동만을 담은 새로운 데이터 행렬 \(\mathbf{Z}_{h + 1}\)을 구한다.
  \[ \mathbf{Z}_{h + 1} \leftarrow \mathbf{Z}_{h} - \mathbf{t}_h \mathbf{v}_h^\top \]
\item
  \textbf{{[}단계 7{]}} \(h \leftarrow h + 1\)로 업데이트하고, {[}단계 1{]}로 돌아간다. {[}단계 1{]} - {[}단계 7{]}의 과정을 \(\mathbf{Z}\)의 rank 수만큼의 주성분을 얻을 때까지 반복한다.
\end{itemize}

위 반복 알고리즘을 수행하는 함수를 아래와 같이 구성해보자. 아래 함수에서 입력변수 \texttt{X}는 데이터 행렬으로, 평균조정된 행렬 \(\mathbf{X}\)나 분산조정된 \(\mathbf{Z}\) 모두 사용 가능하다. 입력변수 \texttt{r}은 추출하고자 하는 주성분의 개수이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nipals_pca <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(X, }\DataTypeTok{r =} \OtherTok{NULL}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is_empty}\NormalTok{(r) }\OperatorTok{||}\StringTok{ }\NormalTok{(r }\OperatorTok{>}\StringTok{ }\KeywordTok{min}\NormalTok{(}\KeywordTok{dim}\NormalTok{(X)))) \{}
\NormalTok{    r <-}\StringTok{ }\KeywordTok{min}\NormalTok{(}\KeywordTok{dim}\NormalTok{(X))}
\NormalTok{  \}}
  
\NormalTok{  Th <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\OtherTok{NA}\NormalTok{, }\DataTypeTok{nrow =} \KeywordTok{nrow}\NormalTok{(X), }\DataTypeTok{ncol =}\NormalTok{ r)}
\NormalTok{  Vh <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\OtherTok{NA}\NormalTok{, }\DataTypeTok{nrow =}\NormalTok{ r, }\DataTypeTok{ncol =}\NormalTok{ r)}
  
  \ControlFlowTok{for}\NormalTok{ (h }\ControlFlowTok{in} \KeywordTok{seq_len}\NormalTok{(}\KeywordTok{ncol}\NormalTok{(X))) \{}
    \CommentTok{# 단계 1}
\NormalTok{    j <-}\StringTok{ }\KeywordTok{sample}\NormalTok{(}\KeywordTok{ncol}\NormalTok{(X), }\DecValTok{1}\NormalTok{)}
\NormalTok{    Th[, h] <-}\StringTok{ }\NormalTok{X[, j]}
    
    \ControlFlowTok{while}\NormalTok{ (}\OtherTok{TRUE}\NormalTok{) \{}
      \CommentTok{# 단계 2}
\NormalTok{      Vh[, h] <-}\StringTok{ }\KeywordTok{t}\NormalTok{(}\KeywordTok{t}\NormalTok{(Th[, h]) }\OperatorTok{%*%}\StringTok{ }\NormalTok{X }\OperatorTok{/}\StringTok{ }\NormalTok{(}\KeywordTok{norm}\NormalTok{(Th[, h], }\StringTok{"2"}\NormalTok{) }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{))}
      
      \CommentTok{# 단계 3}
\NormalTok{      Vh[, h] <-}\StringTok{ }\NormalTok{Vh[, h] }\OperatorTok{/}\StringTok{ }\KeywordTok{norm}\NormalTok{(Vh[, h], }\StringTok{"2"}\NormalTok{)}
      
      \CommentTok{# 단계 4}
\NormalTok{      th <-}\StringTok{ }\NormalTok{X }\OperatorTok{%*%}\StringTok{ }\NormalTok{Vh[, h]}
      
      \CommentTok{# 단계 5}
      \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{all}\NormalTok{(}\KeywordTok{near}\NormalTok{(Th[, h], th))) }\ControlFlowTok{break}
\NormalTok{      Th[, h] <-}\StringTok{ }\NormalTok{th}
\NormalTok{    \}}
    
    \CommentTok{#단계 6}
\NormalTok{    X <-}\StringTok{ }\NormalTok{X }\OperatorTok{-}\StringTok{ }\NormalTok{Th[, h] }\OperatorTok{%*%}\StringTok{ }\KeywordTok{t}\NormalTok{(Vh[, h])}
\NormalTok{  \}}
  
  \KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{T =}\NormalTok{ Th, }\DataTypeTok{V =}\NormalTok{ Vh))}
\NormalTok{\}}

\NormalTok{nipals_Z <-}\StringTok{ }\KeywordTok{nipals_pca}\NormalTok{(Z)}
\NormalTok{nipals_Z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $T
##             [,1]       [,2]        [,3]        [,4]        [,5]
##  [1,] -1.4870243 -0.6066594 -0.63361774  0.29625002 -0.02029373
##  [2,] -0.2063797  0.0804627 -0.04965018 -0.26323513 -0.06358148
##  [3,]  0.1968538 -0.9704605 -0.39507856 -0.27123746 -0.10335175
##  [4,] -2.3542884  3.5056480  0.16252734 -0.02524925  0.24992097
##  [5,] -0.8953707 -1.4552900  1.36265905 -0.20161775  0.05551716
##  [6,] -0.3682082  0.5976313  0.65857722 -0.27901317 -0.06045825
##  [7,] -0.9354306  1.4144520 -0.82574637 -0.07358976 -0.09596091
##  [8,]  2.4129728  0.6785064  0.92207607  0.36161576  0.06259353
##  [9,]  2.6991862  0.7596591 -0.45091077  0.21030379 -0.16864512
## [10,] -0.4050098 -0.2800099 -0.92835441 -0.13993488 -0.00181112
## [11,]  1.3958199 -1.1353513 -0.09819178 -0.34335127  0.09498679
## [12,] -1.5381192 -1.1576616 -0.07467334  0.29404424 -0.05243094
## [13,]  0.3217681  0.2378023  1.10180230 -0.28507243 -0.03066677
## [14,] -2.0306806 -0.9646122  0.20906176  0.39639757  0.08577858
## [15,]  3.0389460 -0.8841645 -0.77478770  0.04079852  0.34968846
## [16,]  2.0064063  1.2831337  0.64388897  0.22077706 -0.18836687
## [17,] -0.4211779  0.2987099 -1.20644766 -0.11766274 -0.06825099
## [18,] -1.4302634 -1.4017959  0.37686579  0.17977686 -0.04466756
## 
## $V
##             [,1]        [,2]          [,3]         [,4]        [,5]
## [1,]  0.07608428  0.77966993  0.0008916027  0.140755413 -0.60540325
## [2,] -0.39463007  0.56541218 -0.2953216458 -0.117644174  0.65078502
## [3,]  0.56970191  0.16228156  0.2412221083  0.637721879  0.42921690
## [4,] -0.55982770 -0.19654293 -0.2565972891  0.748094319 -0.14992178
## [5,] -0.44778451  0.08636803  0.8881182671  0.003668408  0.05711464
\end{verbatim}

위 분해된 행렬의 곱이 원 데이터 행렬 \(\mathbf{Z}\)과 일치하는지 확인해보자.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{all}\NormalTok{(}\KeywordTok{near}\NormalTok{(Z, nipals_Z}\OperatorTok{$}\NormalTok{T }\OperatorTok{%*%}\StringTok{ }\KeywordTok{t}\NormalTok{(nipals_Z}\OperatorTok{$}\NormalTok{V)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

R 패키지 \texttt{nipals}내의 함수 \texttt{nipals}가 이 장에서 설명한 NIPALS 알고리즘에 기반한 주성분 분석을 아래와 같이 제공한다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(nipals)}
\KeywordTok{nipals}\NormalTok{(Z, }\DataTypeTok{center =} \OtherTok{FALSE}\NormalTok{, }\DataTypeTok{scale =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $eig
## [1] 6.8516317 5.2245674 3.0593417 1.0435869 0.5571285
## 
## $scores
##               PC1         PC2         PC3         PC4          PC5
##  [1,] -0.21705404 -0.11608067 -0.20710543  0.28388475 -0.036368396
##  [2,] -0.03011834  0.01540551 -0.01623006 -0.25221776 -0.114174269
##  [3,]  0.02869590 -0.18575892 -0.12913406 -0.25987079 -0.185560165
##  [4,] -0.34348333  0.67105909  0.05310696 -0.02428657  0.448582844
##  [5,] -0.13073246 -0.27851123  0.44541637 -0.19321728  0.099609669
##  [6,] -0.05371865  0.11440401  0.21526389 -0.26733867 -0.108571464
##  [7,] -0.13647563  0.27074924 -0.26991736 -0.07048155 -0.172255999
##  [8,]  0.35219939  0.12981093  0.30139420  0.34648877  0.112419837
##  [9,]  0.39397535  0.14532356 -0.14739177  0.20158102 -0.302663550
## [10,] -0.05912155 -0.05359220 -0.30344792 -0.13408884 -0.003277662
## [11,]  0.20367981 -0.21735017 -0.03209051 -0.32904441  0.170427304
## [12,] -0.22453126 -0.22153804 -0.02440174  0.28178254 -0.094052577
## [13,]  0.04697085  0.04551641  0.36014173 -0.27315578 -0.055099430
## [14,] -0.29641393 -0.18457147  0.06834143  0.37981073  0.154041866
## [15,]  0.44350417 -0.16932257 -0.25324815  0.03896920  0.627670066
## [16,]  0.29288258  0.24554714  0.21046020  0.21162296 -0.338060584
## [17,] -0.06146040  0.05717479 -0.39435062 -0.11272299 -0.122527440
## [18,] -0.20879845 -0.26826541  0.12319285  0.17228468 -0.080140048
## 
## $loadings
##                  PC1        PC2           PC3          PC4         PC5
## roa       0.07627711  0.7796534  0.0008551484  0.140974596 -0.60534928
## roe      -0.39449021  0.5654941 -0.2953469599 -0.117893972  0.65074198
## bis       0.56974203  0.1621586  0.2412197864  0.637556663  0.42945678
## de_ratio -0.55987629 -0.1964075 -0.2565837179  0.748154680 -0.14963952
## turnover -0.44776314  0.0865197  0.8881144365  0.003640124  0.05711403
## 
## $fitted
## NULL
## 
## $ncomp
## [1] 5
## 
## $R2
## [1] 0.552292435 0.321130644 0.110112610 0.012812631 0.003651673
## 
## $iter
## [1] 14  4  4  6  3
\end{verbatim}

평균 및 분산조정 이전의 원래 데이터를 입력하고, 파라미터 \texttt{center}(평균조정) 및 \texttt{scale}(분산조정)의 값을 모두 \texttt{TRUE}로 설정하면 동일한 결과를 얻을 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(nipals)}
\KeywordTok{nipals}\NormalTok{(train_df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{center =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{scale =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $eig
## [1] 6.8516317 5.2245674 3.0593417 1.0435869 0.5571285
## 
## $scores
##               PC1         PC2         PC3         PC4          PC5
##  [1,] -0.21705404 -0.11608067 -0.20710543  0.28388475 -0.036368396
##  [2,] -0.03011834  0.01540551 -0.01623006 -0.25221776 -0.114174269
##  [3,]  0.02869590 -0.18575892 -0.12913406 -0.25987079 -0.185560165
##  [4,] -0.34348333  0.67105909  0.05310696 -0.02428657  0.448582844
##  [5,] -0.13073246 -0.27851123  0.44541637 -0.19321728  0.099609669
##  [6,] -0.05371865  0.11440401  0.21526389 -0.26733867 -0.108571464
##  [7,] -0.13647563  0.27074924 -0.26991736 -0.07048155 -0.172255999
##  [8,]  0.35219939  0.12981093  0.30139420  0.34648877  0.112419837
##  [9,]  0.39397535  0.14532356 -0.14739177  0.20158102 -0.302663550
## [10,] -0.05912155 -0.05359220 -0.30344792 -0.13408884 -0.003277662
## [11,]  0.20367981 -0.21735017 -0.03209051 -0.32904441  0.170427304
## [12,] -0.22453126 -0.22153804 -0.02440174  0.28178254 -0.094052577
## [13,]  0.04697085  0.04551641  0.36014173 -0.27315578 -0.055099430
## [14,] -0.29641393 -0.18457147  0.06834143  0.37981073  0.154041866
## [15,]  0.44350417 -0.16932257 -0.25324815  0.03896920  0.627670066
## [16,]  0.29288258  0.24554714  0.21046020  0.21162296 -0.338060584
## [17,] -0.06146040  0.05717479 -0.39435062 -0.11272299 -0.122527440
## [18,] -0.20879845 -0.26826541  0.12319285  0.17228468 -0.080140048
## 
## $loadings
##                  PC1        PC2           PC3          PC4         PC5
## roa       0.07627711  0.7796534  0.0008551484  0.140974596 -0.60534928
## roe      -0.39449021  0.5654941 -0.2953469599 -0.117893972  0.65074198
## bis       0.56974203  0.1621586  0.2412197864  0.637556663  0.42945678
## de_ratio -0.55987629 -0.1964075 -0.2565837179  0.748154680 -0.14963952
## turnover -0.44776314  0.0865197  0.8881144365  0.003640124  0.05711403
## 
## $fitted
## NULL
## 
## $ncomp
## [1] 5
## 
## $R2
## [1] 0.552292435 0.321130644 0.110112610 0.012812631 0.003651673
## 
## $iter
## [1] 14  4  4  6  3
\end{verbatim}

\hypertarget{pca-regression}{%
\section{주성분 회귀분석}\label{pca-regression}}

\hypertarget{classification-analysis}{%
\chapter{분류분석 개요}\label{classification-analysis}}

분류분석(classification analysis)은 다수의 속성(attribute) 또는 변수를 갖는 객체(object)를 사전에 정해진 그룹 또는 범주(class, category) 중의 하나로 분류하는 것이다. 예를 들어, 기업의 3개의 재무제표를 기준으로 우량 또는 불량으로 분류하는 것은 범주수가 2이고 변수수가 3인 분류분석 문제가 될 것이다. 이를 위해서는 이미 범주(우량 또는 불량)가 알려진 여러 기업에 대하여 3개의 재무제표 데이터를 수집한 후 효율적인 분류규칙(classification rule)을 만들어야 할 것이다. 여기서 효율적이라 함은 기존 객체를 잘 분류할 뿐만 아니라 새로운 객체 역시 잘 분류함을 의미한다. 분류규칙을 만들기 위해서는 기존의 범주가 알려진 객체 데이터를 수집하여야 하며, 이를 학습표본(learning sample)이라 한다.

\hypertarget{classification-packages-install}{%
\section{필요 R 패키지 설치}\label{classification-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.2.1\\
\hline
stats & 3.6.0\\
\hline
class & 7.3-15\\
\hline
\end{tabular}

\hypertarget{classification-problem-methods}{%
\section{분류문제 및 분류기법}\label{classification-problem-methods}}

분류문제를 설명하기 위하여 \(N\)개의 객체로 이루어진 학습데이터 \(\{(\mathbf{x}_i, y_i)\}_{i = 1, \cdots, N}\)를 아래와 같이 정의하자.

\begin{itemize}
\tightlist
\item
  \(\mathbf{x}_i\): \(p\)개의 독립변수로 이루어진 \(i\)번째 객체의 변수벡터 (\(\mathbf{x}_i = [x_{i1} \, x_{i2} \, \cdots \, x_{ip}]^\top\))
\item
  \(J\): 총 범주 수
\item
  \(y_i\): \(i\)번째 객체의 범주 변수; \(y_i \in \{1, 2, \cdots, J\}\)
\end{itemize}

이 때 학습표본을 다음과 같이 나타낼 수 있다.

\begin{equation*}
\{(\mathbf{x}_1, y_1), (\mathbf{x}_2, y_2), \cdots, (\mathbf{x}_N, y_N)\}
\end{equation*}

분류문제는 새로운 객체를 범주 중의 하나로 분류하기 위하여 학습표본을 바탕으로 분류규칙을 만드는 것이다. 이 때 분류규칙은 객체의 변수벡터의 함수로 도출되므로 이를 \(r(\mathbf{x})\)로 나타낸다. 이 때, \(r(\mathbf{x})\)는 \(1, \cdots, J\) 중 하나의 값을 가지며, 이를 분류기(classifier)라 부르기도 한다. 분류규칙의 성능을 관찰하기 위하여 우선 학습표본에 적용하여 실제범주와 추정된 범주를 비교한다. 즉, \(r(\mathbf{x}_i)\)와 \(y_i\)를 비교하여 오분류율 등을 분석한다. 다시 말하면, \(r(\mathbf{x}_i) = y_i\) 이면 올바르게 분류된 것이나, 그렇지 않으면 잘못 분류된 것이다. 학습표본에 있는 전체 객체는 서로 배타적인 \(J\)개의 집합으로 나누어진다. 분류규칙의 성능평가에 대한 보다 자세한 설명은 이후 \ref{classifier-evaluation}장에서 하기로 한다.

분류를 위한 방법론은 무수하게 많은데, 크게 아래와 같이 대별된다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  통계적 방법: 로지스틱 회귀분석, 반별분석 등 다변량 통계이론에 바탕을 둔 방법
\item
  트리기반 기법: CART, C4.5, CHAID 등 트리 형태의 분지방법을 이용하는 기법
\item
  비선형 최적화 기법: 서포트 벡터 머신(support vector machine; SVM) 등
\item
  기계학습 기법: 신경망(neural network) 등의 블랙박스 형태의 기법
\end{enumerate}

\ref{logistic-regression}장에서는 로지스틱 회귀분석을, \ref{da}장에서는 판별분석에 의한 분류분석을, \ref{tree-based-method}장에서는 트리기반 기법을 다루며, \ref{svm}장에서는 서포트 벡터 머신을 다루고자 한다.

\hypertarget{simple-classification-methods}{%
\section{기본적인 분류기법}\label{simple-classification-methods}}

본 절에서는 위에서 언급하지 않은 기본적인 몇 가지 분류기법에 대하여 설명하고자 한다.

\hypertarget{nearest-neighbor-classification}{%
\subsection{인접객체법}\label{nearest-neighbor-classification}}

인접객체법(nearest neighbor classification)은 학습 데이터를 활용하지만 규칙을 도출하는 기법은 아니다. 분류하고자 하는 새로운 객체에 대하여 학습 데이터에 있는 가장 가까운 몇 개의 객체들을 찾은 후 이들 인접객체들의 다수 범주로 분류하는 기법이다. \(k\)개의 인접객체를 고려할 때, \(k\)-인접객체법(k-nearest neighbor method)이라 한다. 가까운 정도의 척도는 유사성 척도 또는 유클리드 거리 등의 비유사성 척도가 사용되는데, 이들에 대한 자세한 설명은 \ref{clustering-overview}장에서 이루어진다.

\hypertarget{nearest-neighbor-classificaiton-basic-script}{%
\subsubsection{기본 R 스트립트}\label{nearest-neighbor-classificaiton-basic-script}}

다음과 같은 7개의 객체에 대한 학습표본이 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{id, }\OperatorTok{~}\NormalTok{x1, }\OperatorTok{~}\NormalTok{x2, }\OperatorTok{~}\NormalTok{y,}
  \DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{2}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{factor}\NormalTok{(y, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)))}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  train_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
  \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'$x_1$'}\NormalTok{, }\StringTok{'$x_2$'}\NormalTok{, }\StringTok{'범주'}\NormalTok{),}
  \DataTypeTok{caption =} \StringTok{'인접객체법 학습표본'}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:knn-classification-data}인접객체법 학습표본}
\centering
\begin{tabular}{rrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 범주\\
\midrule
1 & 5 & 7 & 1\\
2 & 4 & 3 & 2\\
3 & 7 & 8 & 2\\
4 & 8 & 6 & 2\\
5 & 3 & 6 & 1\\
\addlinespace
6 & 2 & 5 & 1\\
7 & 9 & 6 & 2\\
\bottomrule
\end{tabular}
\end{table}

\texttt{class} 패키지의 \texttt{knn.cv} 함수는 학습표본의 각각의 객체에 대해 그 객체를 제외한 나머지 학습표본 중 객체에서 가장 가까운(유클리드 거리 기반) \(k\)개의 객체의 범주값을 이용하여 대상 학습표본의 범주값을 추정하는 leave-one-out cross validation을 수행한다. 아래 스크립트는 Table \ref{tab:knn-classification-data}의 학습표본 데이터에 대해 3-인접객체 leave-one-out cross validation 결과 추정된 범주값을 산출한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y_hat <-}\StringTok{ }\NormalTok{class}\OperatorTok{::}\KeywordTok{knn.cv}\NormalTok{(}
  \DataTypeTok{train =}\NormalTok{ train_df[, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)],}
  \DataTypeTok{cl =}\NormalTok{ train_df}\OperatorTok{$}\NormalTok{y,}
  \DataTypeTok{k =} \DecValTok{3}
\NormalTok{)}

\NormalTok{train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{y_hat =}\NormalTok{ y_hat) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'$x_1$'}\NormalTok{, }\StringTok{'$x_2$'}\NormalTok{, }\StringTok{'실제범주'}\NormalTok{, }\StringTok{'추정범주'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'인접객체법 추정범주 - 학습데이터'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:knn-classification-cv}인접객체법 추정범주 - 학습데이터}
\centering
\begin{tabular}{rrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & 추정범주\\
\midrule
1 & 5 & 7 & 1 & 2\\
2 & 4 & 3 & 2 & 1\\
3 & 7 & 8 & 2 & 2\\
4 & 8 & 6 & 2 & 2\\
5 & 3 & 6 & 1 & 1\\
\addlinespace
6 & 2 & 5 & 1 & 1\\
7 & 9 & 6 & 2 & 2\\
\bottomrule
\end{tabular}
\end{table}

\texttt{class} 패키지의 \texttt{knn} 함수는 새로운 객체에 대해 인접한 학습데이터를 이용하여 범주를 추정하는 함수이다. 아래 스크립트는 두 개의 새로운 객체 \((6, 7)^\top\)과 \((4, 2)^\top\)에 대해 3-인근객체법으로 추정범주를 구하는 스크립트이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{id, }\OperatorTok{~}\NormalTok{x1, }\OperatorTok{~}\NormalTok{x2,}
  \DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}
\NormalTok{)}

\NormalTok{y_hat <-}\StringTok{ }\NormalTok{class}\OperatorTok{::}\KeywordTok{knn}\NormalTok{(}
  \DataTypeTok{train =}\NormalTok{ train_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(x1, x2),}
  \DataTypeTok{test =}\NormalTok{ test_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(x1, x2),}
  \DataTypeTok{cl =}\NormalTok{ train_df}\OperatorTok{$}\NormalTok{y,}
  \DataTypeTok{k =} \DecValTok{3}
\NormalTok{)}

\NormalTok{test_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{y_hat =}\NormalTok{ y_hat) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'$x_1$'}\NormalTok{, }\StringTok{'$x_2$'}\NormalTok{, }\StringTok{'추정범주'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'인접객체법 추정범주 - 새로운 객체'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:knn-classification-test}인접객체법 추정범주 - 새로운 객체}
\centering
\begin{tabular}{rrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 추정범주\\
\midrule
8 & 6 & 7 & 2\\
9 & 4 & 2 & 1\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{nearest-neighbor-classification-algorithm}{%
\subsubsection{인접객체법 알고리즘}\label{nearest-neighbor-classification-algorithm}}

\(k\)-인접객체법의 알고리즘은 다음과 같다.

\begin{itemize}
\tightlist
\item
  \textbf{{[}단계 1{]}} \(k\)값을 정한다.
\item
  \textbf{{[}단계 2{]}} 분류하고자 하는 새로운 객체 \(\mathbf{z}\)에 대하여

  \begin{itemize}
  \tightlist
  \item
    2-1. 학습표본에 있는 각 객체 \(\mathbf{x}_i\)와의 거리 \(d(\mathbf{z}, \mathbf{x}_i)\)를 산출한다.
  \item
    2-2. 위의 거리가 짧은 순으로 \(k\)개의 객체를 선정한다.
  \item
    2-3. \(k\)개의 인근객체가 취하는 범주 중 최빈값을 새로운 객체 \(\mathbf{z}\)의 범주로 정한다.
  \end{itemize}
\end{itemize}

위 알고리즘을 학습표본 Table \ref{tab:knn-classification-data}와 두 새로운 객체 \((6, 7)^\top\) 및 \((4, 2)^\top\)에 적용해보자.

{[}단계 1{]} 우선 각 학습표본 객체에 대해 \(k\)값을 변화시키며 인접객체법으로 분류해보자. 이 때, 각 객체 스스로는 인접객체에 포함되지 않는다.

우선 아래 스크립트는 각 학습 객체간 유클리드 거리를 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_pairwise_dist <-}\StringTok{ }\KeywordTok{dist}\NormalTok{(train_df[, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)], }\DataTypeTok{upper =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{()}

\NormalTok{train_pairwise_dist}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 42 x 3
##    item1 item2 distance
##    <int> <int>    <dbl>
##  1     2     1     4.12
##  2     3     1     2.24
##  3     4     1     3.16
##  4     5     1     2.24
##  5     6     1     3.61
##  6     7     1     4.12
##  7     1     2     4.12
##  8     3     2     5.83
##  9     4     2     5   
## 10     5     2     3.16
## # ... with 32 more rows
\end{verbatim}

각 객체별로 가장 인접한 객체 순으로 순서(rank)를 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_nn_rank <-}\StringTok{ }\NormalTok{train_pairwise_dist }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{nn_rank =} \KeywordTok{rank}\NormalTok{(distance, }\DataTypeTok{ties.method =} \StringTok{"random"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(item1, nn_rank)}

\NormalTok{train_nn_rank}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 42 x 4
##    item1 item2 distance nn_rank
##    <int> <int>    <dbl>   <int>
##  1     1     5     2.24       1
##  2     1     3     2.24       2
##  3     1     4     3.16       3
##  4     1     6     3.61       4
##  5     1     2     4.12       5
##  6     1     7     4.12       6
##  7     2     6     2.83       1
##  8     2     5     3.16       2
##  9     2     1     4.12       3
## 10     2     4     5          4
## # ... with 32 more rows
\end{verbatim}

이후 각 \(k\)값에 대하여 각 객체 대해 \(k\)-인접객체법에 대한 추정범주를 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loo_cv <-}\StringTok{ }\KeywordTok{bind_cols}\NormalTok{(}
\NormalTok{  train_nn_rank }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(item1, nn_rank),}
  \KeywordTok{map2_dfr}\NormalTok{(}
\NormalTok{    train_nn_rank}\OperatorTok{$}\NormalTok{item1,}
\NormalTok{    train_nn_rank}\OperatorTok{$}\NormalTok{nn_rank,}
    \ControlFlowTok{function}\NormalTok{(.x, .y, df, y) \{}
\NormalTok{      df }\OperatorTok{%>%}
\StringTok{        }\KeywordTok{filter}\NormalTok{(}
\NormalTok{          item1 }\OperatorTok{==}\StringTok{ }\NormalTok{.x,}
\NormalTok{          nn_rank }\OperatorTok{<=}\StringTok{ }\NormalTok{.y}
\NormalTok{        ) }\OperatorTok{%>%}
\StringTok{        }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ y[item2]) }\OperatorTok{%>%}
\StringTok{        }\KeywordTok{count}\NormalTok{(y) }\OperatorTok{%>%}
\StringTok{        }\KeywordTok{slice}\NormalTok{(}\KeywordTok{which.max}\NormalTok{(n))}
\NormalTok{    \},}
    \DataTypeTok{df =}\NormalTok{ train_nn_rank,}
    \DataTypeTok{y =}\NormalTok{ train_df}\OperatorTok{$}\NormalTok{y}
\NormalTok{  )}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{k =}\NormalTok{ nn_rank, }\DataTypeTok{y_hat =}\NormalTok{ y) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ train_df}\OperatorTok{$}\NormalTok{y[item1])}

\NormalTok{loo_cv}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 42 x 5
##    item1     k y_hat     n y    
##    <int> <int> <fct> <int> <fct>
##  1     1     1 1         1 1    
##  2     1     2 1         1 1    
##  3     1     3 2         2 1    
##  4     1     4 1         2 1    
##  5     1     5 2         3 1    
##  6     1     6 2         4 1    
##  7     2     1 1         1 2    
##  8     2     2 1         2 2    
##  9     2     3 1         3 2    
## 10     2     4 1         3 2    
## # ... with 32 more rows
\end{verbatim}

학습객체들의 \(k\)-인접객체법 추정범주와 실제범주가 같은 비율을 정확도라 하여, 각 \(k\)값에 대해 정확도를 계산해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loo_cv }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{is_correct =}\NormalTok{ (y }\OperatorTok{==}\StringTok{ }\NormalTok{y_hat)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(k) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{accuracy =} \KeywordTok{mean}\NormalTok{(is_correct)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(accuracy))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##       k accuracy
##   <int>    <dbl>
## 1     1    0.714
## 2     2    0.714
## 3     3    0.714
## 4     4    0.714
## 5     5    0.429
## 6     6    0
\end{verbatim}

위의 결과에 기반하여, 정확도가 가장 높은 경우의 \(k\)들 중 가장 큰 값인 \(k = 3\) 을 최적 \(k\)값으로 선정하자.

{[}단계 2{]} 두 새로운 객체에 대한 3-인접객체법 추정범주를 구해보자.

우선 새로운 객체들과 기존 학습표본 객체들간의 거리를 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{id, }\OperatorTok{~}\NormalTok{x1, }\OperatorTok{~}\NormalTok{x2,}
  \DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}
\NormalTok{)}

\NormalTok{test_train_dist <-}\StringTok{ }\NormalTok{flexclust}\OperatorTok{::}\KeywordTok{dist2}\NormalTok{(}
\NormalTok{  test_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(x1, x2), }
\NormalTok{  train_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(x1, x2)}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{as_tibble}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  `}\DataTypeTok{names<-}\StringTok{`}\NormalTok{(}\KeywordTok{seq_len}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(train_df))) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{item1 =} \KeywordTok{seq_len}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(test_df))) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather}\NormalTok{(}\DataTypeTok{key =} \StringTok{"item2"}\NormalTok{, }\DataTypeTok{value =} \StringTok{"distance"}\NormalTok{, }\OperatorTok{-}\NormalTok{item1) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{item2 =} \KeywordTok{as.numeric}\NormalTok{(item2))}

\NormalTok{test_train_dist}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 14 x 3
##    item1 item2 distance
##    <int> <dbl>    <dbl>
##  1     1     1     1   
##  2     2     1     5.10
##  3     1     2     4.47
##  4     2     2     1   
##  5     1     3     1.41
##  6     2     3     6.71
##  7     1     4     2.24
##  8     2     4     5.66
##  9     1     5     3.16
## 10     2     5     4.12
## 11     1     6     4.47
## 12     2     6     3.61
## 13     1     7     3.16
## 14     2     7     6.40
\end{verbatim}

각 새로운 객체에 대하여 가장 인접한 3개의 학습표본만 남긴다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_nn <-}\StringTok{ }\NormalTok{test_train_dist }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(distance) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{nn_rank =} \KeywordTok{row_number}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(nn_rank }\OperatorTok{<=}\StringTok{ }\DecValTok{3}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{()}

\NormalTok{test_nn}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 4
##   item1 item2 distance nn_rank
##   <int> <dbl>    <dbl>   <int>
## 1     1     1     1          1
## 2     2     2     1          1
## 3     1     3     1.41       2
## 4     1     4     2.24       3
## 5     2     6     3.61       2
## 6     2     5     4.12       3
\end{verbatim}

해당 인접 학습표본들의 범주값을 관측하여, 가장 자주 발견되는 범주값을 새로운 객체의 범주값으로 추정한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_yhat <-}\StringTok{ }\NormalTok{test_nn }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{id =}\NormalTok{ test_df}\OperatorTok{$}\NormalTok{id[item1],}
    \DataTypeTok{y =}\NormalTok{ train_df}\OperatorTok{$}\NormalTok{y[item2]}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(id, y) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(n)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{y_hat =}\NormalTok{ y)}

\NormalTok{test_yhat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 3
##      id y_hat     n
##   <dbl> <fct> <int>
## 1     8 2         2
## 2     9 1         2
\end{verbatim}

위 결과, 객체 \((6, 7)^\top\)는 범주 2로, 객체 \((4, 2)^\top\)는 범주 1로 분류된다.

\hypertarget{naive-bayes}{%
\subsection{나이브 베이지안 분류법}\label{naive-bayes}}

나이브 베이지안(Naive Bayesian) 분류법이란 속성변수들과 범주변수가 확률분포를 따른다고 간주하여 베이즈 정리와 조건부 독립성을 활용한 분류기법이다. 속성변수들이 범주형일 때 주로 사용되나, 연속형인 경우에도 확률분포의 형태를 가정하여 사용할 수 있다. 본 장에서는 범주형 변수인 경우를 설명한다.

\hypertarget{naive-bayes-basic-script}{%
\subsubsection{기본 R 스크립트}\label{naive-bayes-basic-script}}

아래와 같은 9명의 고객에 대한 학습표본이 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{id, }\OperatorTok{~}\NormalTok{x1, }\OperatorTok{~}\NormalTok{x2, }\OperatorTok{~}\NormalTok{y,}
  \DecValTok{1}\NormalTok{, }\StringTok{"남"}\NormalTok{, }\StringTok{"20대"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\StringTok{"남"}\NormalTok{, }\StringTok{"20대"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\StringTok{"남"}\NormalTok{, }\StringTok{"30대"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\StringTok{"남"}\NormalTok{, }\StringTok{"40대"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\StringTok{"여"}\NormalTok{, }\StringTok{"10대"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\StringTok{"여"}\NormalTok{, }\StringTok{"20대"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\StringTok{"여"}\NormalTok{, }\StringTok{"20대"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{8}\NormalTok{, }\StringTok{"여"}\NormalTok{, }\StringTok{"30대"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\StringTok{"여"}\NormalTok{, }\StringTok{"40대"}\NormalTok{, }\DecValTok{2}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{factor}\NormalTok{(y, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)))}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  train_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
  \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'고객번호'}\NormalTok{, }\StringTok{'성별 ($x_1$)'}\NormalTok{, }\StringTok{'나이 ($x_2$)'}\NormalTok{, }\StringTok{'범주 ($y$)'}\NormalTok{),}
  \DataTypeTok{caption =} \StringTok{'나이브 베이지안 분류법 학습표본'}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:naive-bayes-data}나이브 베이지안 분류법 학습표본}
\centering
\begin{tabular}{rrrr}
\toprule
고객번호 & 성별 (\$x\_1\$) & 나이 (\$x\_2\$) & 범주 (\$y\$)\\
\midrule
1 & 남 & 20대 & 1\\
2 & 남 & 20대 & 2\\
3 & 남 & 30대 & 1\\
4 & 남 & 40대 & 1\\
5 & 여 & 10대 & 1\\
\addlinespace
6 & 여 & 20대 & 2\\
7 & 여 & 20대 & 1\\
8 & 여 & 30대 & 2\\
9 & 여 & 40대 & 2\\
\bottomrule
\end{tabular}
\end{table}

\texttt{e1071} 패키지의 \texttt{naiveBayes} 함수를 이용하면, 객체가 각 범주에 속할 조건부 확률분포 모델을 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nb_fit <-}\StringTok{ }\NormalTok{e1071}\OperatorTok{::}\KeywordTok{naiveBayes}\NormalTok{(}\DataTypeTok{formula =}\NormalTok{ y }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, }\DataTypeTok{data =}\NormalTok{ train_df)}

\KeywordTok{print}\NormalTok{(nb_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Naive Bayes Classifier for Discrete Predictors
## 
## Call:
## naiveBayes.default(x = X, y = Y, laplace = laplace)
## 
## A-priori probabilities:
## Y
##         1         2 
## 0.5555556 0.4444444 
## 
## Conditional probabilities:
##    x1
## Y     남   여
##   1 0.60 0.40
##   2 0.25 0.75
## 
##    x2
## Y   10대 20대 30대 40대
##   1 0.20 0.40 0.20 0.20
##   2 0.00 0.50 0.25 0.25
\end{verbatim}

추정된 모델을 학습표본에 적용하여 범주를 추정해보자.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 범주 추정값}
\NormalTok{y_hat <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(nb_fit, train_df)}

\CommentTok{# 사후확률 추정값}
\NormalTok{nb_posterior <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(nb_fit, train_df, }\DataTypeTok{type =} \StringTok{"raw"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{as_tibble}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  `}\DataTypeTok{colnames<-}\StringTok{`}\NormalTok{(}\KeywordTok{str_c}\NormalTok{(}\StringTok{"p"}\NormalTok{, }\KeywordTok{levels}\NormalTok{(train_df}\OperatorTok{$}\NormalTok{y)))}

\NormalTok{train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{y_hat =}\NormalTok{ y_hat) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_cols}\NormalTok{(nb_posterior) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'고객번호'}\NormalTok{, }\StringTok{'성별 ($x_1$)'}\NormalTok{, }\StringTok{'나이 ($x_2$)'}\NormalTok{, }
                  \StringTok{'실제범주 ($y$)'}\NormalTok{, }\StringTok{'추정범주 ($}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{hat\{y\}$)'}\NormalTok{, }
                  \KeywordTok{str_c}\NormalTok{(}\StringTok{'사후확률 ($y$ = '}\NormalTok{, }\KeywordTok{levels}\NormalTok{(train_df}\OperatorTok{$}\NormalTok{y), }\StringTok{')'}\NormalTok{)),}
    \DataTypeTok{caption =} \StringTok{'나이브 베이지안 분류법에 의한 추정 범주'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:naive-bayes-posterior}나이브 베이지안 분류법에 의한 추정 범주}
\centering
\begin{tabular}{rrrrrrr}
\toprule
고객번호 & 성별 (\$x\_1\$) & 나이 (\$x\_2\$) & 실제범주 (\$y\$) & 추정범주 (\$\textbackslash{}hat\{y\}\$) & 사후확률 (\$y\$ = 1) & 사후확률 (\$y\$ = 2)\\
\midrule
1 & 남 & 20대 & 1 & 1 & 0.7058824 & 0.2941176\\
2 & 남 & 20대 & 2 & 1 & 0.7058824 & 0.2941176\\
3 & 남 & 30대 & 1 & 1 & 0.7058824 & 0.2941176\\
4 & 남 & 40대 & 1 & 1 & 0.7058824 & 0.2941176\\
5 & 여 & 10대 & 1 & 1 & 0.9925558 & 0.0074442\\
\addlinespace
6 & 여 & 20대 & 2 & 2 & 0.3478261 & 0.6521739\\
7 & 여 & 20대 & 1 & 2 & 0.3478261 & 0.6521739\\
8 & 여 & 30대 & 2 & 2 & 0.3478261 & 0.6521739\\
9 & 여 & 40대 & 2 & 2 & 0.3478261 & 0.6521739\\
\bottomrule
\end{tabular}
\end{table}

또한, 학습표본에 포함되지 않은 10대 남자인 새로운 고객에 대한 범주가 아래와 같이 추정된다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(nb_fit, }\KeywordTok{tibble}\NormalTok{(}\DataTypeTok{x1 =} \StringTok{"남"}\NormalTok{, }\DataTypeTok{x2 =} \StringTok{"10대"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
## Levels: 1 2
\end{verbatim}

\hypertarget{naive-bayes-algorithm}{%
\subsubsection{알고리즘}\label{naive-bayes-algorithm}}

어떤 객체 \(\mathbf{x}\)에 대해 범주가 \(y\)일 조건부 확률분포는 베이즈 정리에 의하여 다음과 같이 표현된다.

\begin{equation}
P(y \, | \, \mathbf{x}) \propto P(y) P(\mathbf{x} \, | \, y), \, y = 1, \cdots, J \label{eq:bayes-posterior}
\end{equation}

여기서 \(P(y)\)는 임의의 객체가 범주 \(y\)에 속할 사전확률을 의미하며, \(P(y \, | \, \mathbf{x})\)는 객체 속성변수 \(\mathbf{x}\)의 관측값에 따른 범주 \(y\)의 사후확률을 나타낸다. 그리고 \(P(\mathbf{x} \, | \, y)\)는 범주 \(y\)에 속한 객체들의 속성변수 분포를 나타낸다.

나이브 베이지안 분류법에서는 속성변수들의 조건부 결합확률분포 \(P(\mathbf{x} \, | \, y)\)에 대한 조건부 독립성을 가정하여, \(p\)개의 변수로 이루어진 객체 속성변수 벡터 \(\mathbf{x} = (x_1, x_2, \cdots, x_p)\)에 대하여 다음이 성립한고 가정한다.

\begin{equation*}
P(x_a \, | x_{a + 1}, x_{a + 2}, \cdots, x_p, y) = P(x_a \,|\, y)
\end{equation*}

이 때, 식 \eqref{eq:bayes-posterior}는 아래와 같이 표현될 수 있다.

\begin{equation}
P(y \, | \, \mathbf{x}) \propto P(y) \prod_{a = 1}^{p} P(x_a \, | \, y), \, y = 1, \cdots, J \label{eq:naive-bayes-posterior}
\end{equation}

우선, 학습표본 \ref{tab:naive-bayes-data}을 이용하여 범주의 사전확률 \(P(y)\)를 추정해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior_prob <-}\StringTok{ }\NormalTok{train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(y) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{prior =}\NormalTok{ n }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(n)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{n)}

\NormalTok{prior_prob}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 2
##   y     prior
##   <fct> <dbl>
## 1 1     0.556
## 2 2     0.444
\end{verbatim}

또한, 학습표본 \ref{tab:naive-bayes-data}에 대해 각 변수의 조건부 확률 \(P(x_a \,|\, y)\)를 추정해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{condition_prob <-}\StringTok{ }\NormalTok{train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather}\NormalTok{(}\DataTypeTok{key =} \StringTok{"variable"}\NormalTok{, }\DataTypeTok{value =} \StringTok{"value"}\NormalTok{, x1, x2) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(y, variable, value) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{cond_prob =}\NormalTok{ n }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(n)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{n) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{complete}\NormalTok{(y, }\KeywordTok{nesting}\NormalTok{(variable, value), }\DataTypeTok{fill =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{cond_prob =} \DecValTok{0}\NormalTok{))}

\NormalTok{condition_prob}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 12 x 4
##    y     variable value cond_prob
##    <fct> <chr>    <chr>     <dbl>
##  1 1     x1       남         0.6 
##  2 1     x1       여         0.4 
##  3 1     x2       10대       0.2 
##  4 1     x2       20대       0.4 
##  5 1     x2       30대       0.2 
##  6 1     x2       40대       0.2 
##  7 2     x1       남         0.25
##  8 2     x1       여         0.75
##  9 2     x2       10대       0   
## 10 2     x2       20대       0.5 
## 11 2     x2       30대       0.25
## 12 2     x2       40대       0.25
\end{verbatim}

추정된 확률을 식 \eqref{eq:naive-bayes-posterior}에 적용하여, 각 학습데이터에 대한 범주의 사후확률을 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior_prob <-}\StringTok{ }\NormalTok{train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{y) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather}\NormalTok{(}\DataTypeTok{key =} \StringTok{"variable"}\NormalTok{, }\DataTypeTok{value =} \StringTok{"value"}\NormalTok{, x1, x2) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(condition_prob, }\DataTypeTok{by =} \KeywordTok{c}\NormalTok{(}\StringTok{"variable"}\NormalTok{, }\StringTok{"value"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(id, y) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{cond_prob =} \KeywordTok{reduce}\NormalTok{(cond_prob, }\StringTok{`}\DataTypeTok{*}\StringTok{`}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(prior_prob, }\DataTypeTok{by =} \StringTok{"y"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{posterior_unadjust =}\NormalTok{ prior }\OperatorTok{*}\StringTok{ }\NormalTok{cond_prob) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{posterior =}\NormalTok{ posterior_unadjust }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(posterior_unadjust)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(id, y, posterior) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{()}

\NormalTok{posterior_prob }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{spread}\NormalTok{(}\DataTypeTok{key =}\NormalTok{ y, }\DataTypeTok{value =}\NormalTok{ posterior)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 9 x 3
##      id   `1`   `2`
##   <dbl> <dbl> <dbl>
## 1     1 0.706 0.294
## 2     2 0.706 0.294
## 3     3 0.706 0.294
## 4     4 0.706 0.294
## 5     5 1     0    
## 6     6 0.348 0.652
## 7     7 0.348 0.652
## 8     8 0.348 0.652
## 9     9 0.348 0.652
\end{verbatim}

추정범주는 사후확률이 가장 큰 범주를 선택한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior_prob }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(id) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{top_n}\NormalTok{(}\DecValTok{1}\NormalTok{, posterior) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 9 x 3
## # Groups:   id [9]
##      id y     posterior
##   <dbl> <fct>     <dbl>
## 1     1 1         0.706
## 2     2 1         0.706
## 3     3 1         0.706
## 4     4 1         0.706
## 5     5 1         1    
## 6     6 2         0.652
## 7     7 2         0.652
## 8     8 2         0.652
## 9     9 2         0.652
\end{verbatim}

\hypertarget{naive-bayes-pkg}{%
\subsubsection{R 패키지 내 나이브 베이지안 분류법}\label{naive-bayes-pkg}}

위 \ref{naive-bayes-basic-script}절에서 살펴본 바와 같이 \texttt{e1071} 패키지 내의 \texttt{naiveBayes} 함수를 이용하여 분류 모델을 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nb_fit <-}\StringTok{ }\NormalTok{e1071}\OperatorTok{::}\KeywordTok{naiveBayes}\NormalTok{(}\DataTypeTok{formula =}\NormalTok{ y }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, }\DataTypeTok{data =}\NormalTok{ train_df)}
\end{Highlighting}
\end{Shaded}

위 \texttt{naiveBayes} 모델 객체의 component 중 \texttt{apriori}는 객체가 각 범주에 속할 사전분포를 나타내는 \texttt{table} 형태의 객체로, 본 예에서 학습표본 중 각 범주에 속한 객체 수를 나타낸다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{str}\NormalTok{(nb_fit}\OperatorTok{$}\NormalTok{apriori)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  'table' int [1:2(1d)] 5 4
##  - attr(*, "dimnames")=List of 1
##   ..$ Y: chr [1:2] "1" "2"
\end{verbatim}

아래와 같이, 각 범주에 속한 객체 수를 전체 객체 수로 나눔으로써 추정된 사전분포(prior distribution)을 확인할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nb_fit}\OperatorTok{$}\NormalTok{apriori }\OperatorTok{%>%}
\StringTok{  }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{p =}\NormalTok{ n }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(n))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 3
##   Y         n     p
##   <chr> <int> <dbl>
## 1 1         5 0.556
## 2 2         4 0.444
\end{verbatim}

각 변수별 조건부 확률은 \texttt{tables}라는 리스트 객체에서 변수별로 확인할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nb_fit}\OperatorTok{$}\NormalTok{tables}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $x1
##    x1
## Y     남   여
##   1 0.60 0.40
##   2 0.25 0.75
## 
## $x2
##    x2
## Y   10대 20대 30대 40대
##   1 0.20 0.40 0.20 0.20
##   2 0.00 0.50 0.25 0.25
\end{verbatim}

\texttt{predict} 함수를 이용하여 사후확률을 구할 때, \texttt{threshold} 파라미터값을 이용하여 최소 사후확률값을 지정할 수 있다. 기본값은 0.001로, 추정 사후확률값이 최소 0.1\%보다 커야한다는 것을 의미한다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(nb_fit, }\DataTypeTok{newdata =}\NormalTok{ train_df[}\DecValTok{5}\NormalTok{, ], }\DataTypeTok{type =} \StringTok{"raw"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              1           2
## [1,] 0.9925558 0.007444169
\end{verbatim}

해당 파라미터값을 0.01으로 지정할 경우, 위에서 범주 2에 속할 사후확률이 보다 크게 얻어짐을 확인할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(nb_fit, }\DataTypeTok{newdata =}\NormalTok{ train_df[}\DecValTok{5}\NormalTok{, ], }\DataTypeTok{type =} \StringTok{"raw"}\NormalTok{, }\DataTypeTok{threshold =} \FloatTok{0.01}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              1          2
## [1,] 0.9302326 0.06976744
\end{verbatim}

\hypertarget{logistic-regression}{%
\chapter{로지스틱 회귀분석}\label{logistic-regression}}

로지스틱 회귀분석(logistic regression)은 종속변수가 통상 2개의 범주(있음/없음, 불량/양호, 합격/불합격 등)를 다루는 모형을 지칭하나, 3개 이상의 범주를 다루기도 한다. 후자의 경우는 다시 서열형(ordinal) 데이터와 명목형(nominal) 데이터인 경우에 따라 서로 다른 모형이 사용된다.

\hypertarget{logistic-packages-install}{%
\section{필요 R 패키지 설치}\label{logistic-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.2.1\\
\hline
stats & 3.6.0\\
\hline
nnet & 7.3-12\\
\hline
MASS & 7.3-51.4\\
\hline
VGAM & 1.1-1\\
\hline
\end{tabular}

\hypertarget{binary-logistic-regression}{%
\section{이분 로지스틱 회귀모형}\label{binary-logistic-regression}}

\hypertarget{bianry-logistic-reg-basic-script}{%
\subsection{기본 R 스크립트}\label{bianry-logistic-reg-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{id, }\OperatorTok{~}\NormalTok{x1, }\OperatorTok{~}\NormalTok{x2, }\OperatorTok{~}\NormalTok{x3, }\OperatorTok{~}\NormalTok{y,}
  \DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"우수"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"우수"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{0}\NormalTok{, }\StringTok{"우수"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{4}\NormalTok{, }\StringTok{"우수"}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"우수"}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"우수"}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{0}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{8}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{10}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{11}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{12}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{0}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{13}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{14}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{15}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"보통"}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{factor}\NormalTok{(y, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"보통"}\NormalTok{, }\StringTok{"우수"}\NormalTok{)))}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(train_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
             \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
             \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'아침식사여부($x_1$)'}\NormalTok{, }\StringTok{'수면시간($x_2$)'}\NormalTok{, }\StringTok{'서클활동시간($x_3$)'}\NormalTok{, }\StringTok{'범주(y)'}\NormalTok{),}
             \DataTypeTok{caption =} \StringTok{'우수/보통 학생에 대한 설문조사 결과'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:binary-logistic-reg-train-data}우수/보통 학생에 대한 설문조사 결과}
\centering
\begin{tabular}{rrrrr}
\toprule
객체번호 & 아침식사여부(\$x\_1\$) & 수면시간(\$x\_2\$) & 서클활동시간(\$x\_3\$) & 범주(y)\\
\midrule
1 & 0 & 8 & 2 & 우수\\
2 & 1 & 7 & 1 & 우수\\
3 & 0 & 9 & 0 & 우수\\
4 & 1 & 6 & 4 & 우수\\
5 & 1 & 8 & 2 & 우수\\
\addlinespace
6 & 0 & 7 & 3 & 우수\\
7 & 0 & 7 & 0 & 보통\\
8 & 1 & 6 & 1 & 보통\\
9 & 0 & 7 & 2 & 보통\\
10 & 0 & 8 & 1 & 보통\\
\addlinespace
11 & 0 & 5 & 2 & 보통\\
12 & 1 & 8 & 0 & 보통\\
13 & 0 & 6 & 3 & 보통\\
14 & 1 & 7 & 2 & 보통\\
15 & 0 & 6 & 1 & 보통\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:binary-logistic-reg-train-data}와 같이 세 개의 독립변수 \(x_1\), \(x_2\), \(x_3\)와 이분형 종속변수 \(y\)의 관측값(보통 = 0, 우수 = 1)으로 이루어진 15개의 학습표본을 \texttt{train\_df}라는 data frame에 저장한다.

아래와 같이 \texttt{glm} 함수를 이용하여 로지스틱 회귀모형을 간편하게 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{glm_fit <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2 }\OperatorTok{+}\StringTok{ }\NormalTok{x3, }\DataTypeTok{family =} \KeywordTok{binomial}\NormalTok{(}\DataTypeTok{link =} \StringTok{"logit"}\NormalTok{), }\DataTypeTok{data =}\NormalTok{ train_df)}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  glm_fit }\OperatorTok{%>%}\StringTok{  }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{(),}
  \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{caption =} \StringTok{"위 우수/보통 학생 설문조사 데이터에 대한 Logistic Regression 결과"}
\CommentTok{#  caption = "Table \textbackslash{}\textbackslash{}@ref(tab:binary-logistic-reg-train-data)에 대한 Logistic Regression 결과"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:binary-logistic-reg-coef}위 우수/보통 학생 설문조사 데이터에 대한 Logistic Regression 결과}
\centering
\begin{tabular}{lrrrr}
\toprule
term & estimate & std.error & statistic & p.value\\
\midrule
(Intercept) & -30.510836 & 18.018256 & -1.693329 & 0.0903929\\
x1 & 2.031278 & 1.983692 & 1.023989 & 0.3058406\\
x2 & 3.470671 & 2.074978 & 1.672631 & 0.0944000\\
x3 & 2.414387 & 1.396372 & 1.729043 & 0.0838015\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:binary-logistic-reg-coef}은 추정된 회귀계수 추정치 \texttt{estmate}과 그 표준오차 \texttt{std.error}, 표준화(standardized)된 회귀계수값 \texttt{statistic} (= \texttt{estmate} / \texttt{std.error}), 그리고 귀무가설 \(H_0\): \texttt{statistic} = 0 에 대한 유의확률 \texttt{p.value}를 보여준다.

\hypertarget{binary-logistic-reg-model}{%
\subsection{회귀모형}\label{binary-logistic-reg-model}}

이분 로지스틱 회귀모형은 종속변수가 2가지 범주를 취하는 경우에 사용된다.

\(N\)개의 객체로 이루어진 학습데이터 \(\{(\mathbf{x}_i, y_i)\}_{i = 1, \cdots, N}\)를 아래와 같이 정의하자.

\begin{itemize}
\tightlist
\item
  \(\mathbf{x}_i \in \mathbb{R}^p\): \(p\)개의 독립변수로 이루어진 벡터 (\(\mathbf{x}_i = [x_{i1} \, x_{i2} \, \cdots \, x_{ip}]^\top\))
\item
  \(y_i\): 0 혹은 1의 값을 갖는 이분형 지시변수 (indicator variable)
\end{itemize}

\(\mathbf{x}_i\) 관측값을 이용하여 \(y_i\)의 기대값 \(P_i\)을 추정하는 모형을 아래와 같이 로지스틱 함수로 정의하자.

\begin{eqnarray}
P_i &=& P(y_i = 1 \,|\, \mathbf{x}_i)\\
&=& E[y_i | \mathbf{x}_i]\\ 
&=& \frac{\exp(\beta_0 + \boldsymbol\beta^\top \mathbf{x}_i)}{1 + \exp(\beta_0 + \boldsymbol\beta^\top \mathbf{x}_i)}
\label{eq:logistic-function}
\end{eqnarray}

여기에서 \(\boldsymbol\beta \in \mathbb{R}^{p}\)는 \(\mathbf{x}_i\)와 동일한 차원의 벡터이다 (\(\boldsymbol\beta = [\beta_1 \, \beta_2 \, \cdots \, \beta_p]^\top\)).

식 \eqref{eq:logistic-function}는 모든 \(\mathbf{x}_i\)값에 대해 0에서 1 사이의 값을 갖게 되므로 각 범주에 속할 확률을 추정하는 데 적합한 반면, 변수 \(\mathbf{x}\) 및 계수들에 대해 선형이 아니므로 추정이 어렵다. 그러나 아래와 같이 로짓(logit) 변환을 통해 선형회귀식으로 변환할 수 있다.

\begin{eqnarray}
logit(P_i) &=& \ln \left[ \frac{P_i}{1 - P_i} \right]\\
&=& \ln(\exp(\beta_0 + \boldsymbol\beta^\top \mathbf{x}_i))\\
&=& \beta_0 + \boldsymbol\beta^\top \mathbf{x}_i
\label{eq:logit-transform}
\end{eqnarray}

식 \eqref{eq:logit-transform}에서 확률 \(P_i\)는 직접적으로 관측되는 것이 아니고 0 또는 1을 갖는 \(y_i\)가 관측되므로, \(P_i\)를 일종의 잠재변수(latent variable)로 해석할 수 있다.

\begin{equation}
y_i = \begin{cases}
1 & \text{ if } \beta_0 + \boldsymbol\beta^\top \mathbf{x}_i + \varepsilon_i > 0 \\
0 & \text{ otherwise }
\end{cases}
\label{eq:binary-logistic-latent-interpret}
\end{equation}

식 \eqref{eq:binary-logistic-latent-interpret}에서 \(\varepsilon_i\)는 표준로지스틱분포(standard logistic distribution)을 따른다.

\hypertarget{binary-logistic-reg-estimation}{%
\subsection{회귀계수 추정}\label{binary-logistic-reg-estimation}}

로지스틱 모형에서 회귀계수의 추정을 위해서 주로 최우추정법(maximum likelihood estimation)이 사용된다. \(N\)개의 객체로 이루어진 학습데이터에 대해 우도함수는 다음과 같다.

\begin{equation*}
L = \prod_{i = 1}^{N} P_i^{y_i} (1 - P_i)^{1 - y_i}
\end{equation*}

그리고 우도함수에 자연로그를 취하면 아래와 같이 전개된다.

\begin{eqnarray}
\log L &=& \sum_{i = 1}^{N} y_i \log P_i + \sum_{i = 1}^{N} (1 - y_i) \log (1 - P_i)\\
&=& \sum_{i = 1}^{N} y_i \log \frac{P_i}{1 - P_i} + \sum_{i = 1}^{N} \log (1 - P_i)\\
&=& \sum_{i = 1}^{N} y_i (\beta_0 + \boldsymbol\beta^\top \mathbf{x}_i) - \sum_{i = 1}^{N}  \log (1 + \exp (\beta_0 + \boldsymbol\beta^\top \mathbf{x}_i) )\\
&=& \sum_{i = 1}^{N} y_i \left(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij} \right) - \sum_{i = 1}^{N}  \log \left(1 + \exp\left(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij}\right)\right)
\label{eq:binary-logistic-reg-loglik}
\end{eqnarray}

식 (eq:binary-logistic-reg-loglik)을 각 회귀계수 \(\beta_0, \beta_1, \cdots, \beta_p\)에 대해 편미분하여 최적해를 얻는다. 이를 위해 주로 뉴턴-랩슨 알고리즘(Newton-Raphson algorithm)이나 quasi-Newton 알고리즘이 사용되나 \citep{jun2012datamining}, 본 장에서는 우선 안정성은 떨어지지만 보다 간편한 방법으로 경사하강법(gradient descent)을 소개한다.

\hypertarget{binary-logistic-gradient-descent}{%
\subsubsection{경사하강법}\label{binary-logistic-gradient-descent}}

식 \eqref{eq:logistic-function}과 \(P(y_i = 0 \,|\, \mathbf{x}_i) = 1 - P_i\), 그리고

\begin{equation*}
\frac{\exp(z)}{1 + \exp(z)} = \frac{1}{1 + \exp(-z)}
\end{equation*}

임을 고려하면 아래와 같이 범주확률모형을 정의할 수 있다.

\begin{equation*}
P(y = y_i \,|\, \mathbf{x}_i, \beta_0, \boldsymbol\beta) = \frac{1}{1 + \exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}
\end{equation*}

이에 따라 로그우도함수 \eqref{eq:binary-logistic-reg-loglik}는 아래와 같이 정리된다.

\begin{equation*}
\log \prod_{i = 1}^{N} P(y = y_i \,|\, \mathbf{x}_i, \beta_0, \boldsymbol\beta) = - \sum_{i = 1}^{N} \log \left(1 + \exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)\right)
\end{equation*}

위 로그우도함수를 최대화하는 문제는 아래 함수를 최소화하는 문제와 동일하다.

\begin{equation}
f(\beta_0, \boldsymbol\beta) = \sum_{i = 1}^{N} \log \left(1 + \exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)\right)
\label{eq:binary-logistic-reg-negative-loglik}
\end{equation}

경사하강법에 따라 아래의 과정을 통해 회귀계수를 추정할 수 있다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  임의의 값으로 \(\beta_0, \beta_1, \cdots, \beta_j\)의 초기 추정값을 설정한다.
\item
  식 \eqref{eq:binary-logistic-reg-negative-loglik}을 각 회귀변수에 대해 편미분한 미분값을 구한다.
\item
  2의 값에 학습률(step size)을 곱한 만큼 회귀계수 추정값을 이동시킨다. 방향은 미분값의 반대방향.
\item
  수렴할 때까지 2-3의 과정을 반복한다.
\end{enumerate}

여기에서 식 \eqref{eq:binary-logistic-reg-negative-loglik}의 각 회귀변수에 대한 편미분식은 아래와 같다.

\begin{eqnarray*}
\frac{\partial f}{\partial \beta_0} &=& \sum_{i = 1}^{N} (1 - 2y_i) \frac{\exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}{1 + \exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}\\
&=& \sum_{i = 1}^{N} \frac{1 - 2y_i}{1 + \exp\left((2y_i - 1)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}
\end{eqnarray*}

\begin{eqnarray*}
\frac{\partial f}{\partial \beta_j} &=& \sum_{i = 1}^{N} (1 - 2y_i)x_{ij} \frac{\exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}{1 + \exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}\\
&=& \sum_{i = 1}^{N} \frac{(1 - 2y_i)x_{ij}}{1 + \exp\left((2y_i - 1)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}
\end{eqnarray*}

따라서, 회귀계수 추정값을 이동시키는 함수 \texttt{update\_beta}를 아래와 같이 구현할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{update_beta <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, y, }\DataTypeTok{beta0 =} \DecValTok{0}\NormalTok{, }\DataTypeTok{beta =} \KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{dim}\NormalTok{(x)[}\DecValTok{2}\NormalTok{]), }\DataTypeTok{alpha =} \FloatTok{0.01}\NormalTok{) \{}
  \CommentTok{# 변미분식의 분모}
\NormalTok{  denominator <-}\StringTok{ }\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{exp}\NormalTok{((}\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{y }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{*}\StringTok{ }\NormalTok{(beta0 }\OperatorTok{+}\StringTok{ }\NormalTok{(x }\OperatorTok{%*%}\StringTok{ }\NormalTok{beta)))}

  \CommentTok{# intercept 이동량 계산}
\NormalTok{  beta0_numerator <-}\StringTok{ }\DecValTok{1} \OperatorTok{-}\StringTok{ }\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{y}
\NormalTok{  beta0_update =}\StringTok{ }\KeywordTok{sum}\NormalTok{(beta0_numerator }\OperatorTok{/}\StringTok{ }\NormalTok{denominator)}
  
  \CommentTok{# intercept 외 회귀계수 이동량 계산}
\NormalTok{  beta_numerator <-}\StringTok{ }\KeywordTok{sweep}\NormalTok{(x, }\DataTypeTok{MARGIN =} \DecValTok{1}\NormalTok{, }\DataTypeTok{STATS =} \DecValTok{1} \OperatorTok{-}\StringTok{ }\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{y, }\DataTypeTok{FUN =} \StringTok{"*"}\NormalTok{)}
\NormalTok{  beta_update =}\StringTok{ }\KeywordTok{apply}\NormalTok{(beta_numerator, }\DataTypeTok{MARGIN =} \DecValTok{2}\NormalTok{, }
                      \ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{sum}\NormalTok{(x }\OperatorTok{/}\StringTok{ }\NormalTok{denominator))}

  \CommentTok{# 회귀계수 이동}
\NormalTok{  beta0 <-}\StringTok{ }\NormalTok{beta0 }\OperatorTok{-}\StringTok{ }\NormalTok{alpha }\OperatorTok{*}\StringTok{ }\NormalTok{beta0_update}
\NormalTok{  beta <-}\StringTok{ }\NormalTok{beta }\OperatorTok{-}\StringTok{ }\NormalTok{alpha }\OperatorTok{*}\StringTok{ }\NormalTok{beta_update}

  \KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{beta0 =}\NormalTok{ beta0, }\DataTypeTok{beta =}\NormalTok{ beta))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위의 함수를 이용하여 아래 \texttt{estimate\_beta}처엄 수렴할 때까지 회귀계수 추정값을 계속 이동시킨다. 본 경사하강법은 학습률 파라미터 \texttt{alpha}값에 따라 민감한 단점이 있으며, 특히 \texttt{alpha}값을 크게 설정할 경우에는 추정값이 수렴하지 않고 오히려 실제값에서 계속 멀어지는 현상이 발생하기도 한다. 이러한 단점을 보완하기 위한 여러 방법이 있으나, 본 장에서 자세한 설명은 생략하기로 한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caltculate_loglik <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, y, }
                              \DataTypeTok{beta0 =} \DecValTok{0}\NormalTok{, }
                              \DataTypeTok{beta =} \KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{dim}\NormalTok{(x)[}\DecValTok{2}\NormalTok{])) \{}
  \KeywordTok{sum}\NormalTok{(y }\OperatorTok{*}\StringTok{ }\NormalTok{(beta0 }\OperatorTok{+}\StringTok{ }\NormalTok{(x }\OperatorTok{%*%}\StringTok{ }\NormalTok{beta))) }\OperatorTok{-}\StringTok{ }
\StringTok{    }\KeywordTok{sum}\NormalTok{(}\KeywordTok{log}\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{exp}\NormalTok{(beta0 }\OperatorTok{+}\StringTok{ }\NormalTok{(x }\OperatorTok{%*%}\StringTok{ }\NormalTok{beta))))}
\NormalTok{\}}

\NormalTok{estimate_beta <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, y, }
                          \DataTypeTok{beta0 =} \DecValTok{0}\NormalTok{, }
                          \DataTypeTok{beta =} \KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{dim}\NormalTok{(x)[}\DecValTok{2}\NormalTok{]), }
                          \DataTypeTok{alpha =} \FloatTok{0.01}\NormalTok{, }
                          \DataTypeTok{conv_threshold =} \FloatTok{1e-5}\NormalTok{, }
                          \DataTypeTok{max_iter =} \FloatTok{1e+5}\NormalTok{) \{}
\NormalTok{  new_beta0 <-}\StringTok{ }\NormalTok{beta0}
\NormalTok{  new_beta <-}\StringTok{ }\NormalTok{beta}
\NormalTok{  conv <-}\StringTok{ }\OtherTok{FALSE}
  
\NormalTok{  i_iter <-}\StringTok{ }\DecValTok{0}
  \ControlFlowTok{while}\NormalTok{(i_iter }\OperatorTok{<}\StringTok{ }\NormalTok{max_iter) \{}
\NormalTok{    res <-}\StringTok{ }\KeywordTok{update_beta}\NormalTok{(x, y, new_beta0, new_beta, alpha)}
    
    \ControlFlowTok{if}\NormalTok{(}\KeywordTok{abs}\NormalTok{(}\KeywordTok{caltculate_loglik}\NormalTok{(x, y, beta0, beta)}
           \OperatorTok{-}\StringTok{ }\KeywordTok{caltculate_loglik}\NormalTok{(x, y, res}\OperatorTok{$}\NormalTok{beta0, res}\OperatorTok{$}\NormalTok{beta))}
       \OperatorTok{<}\StringTok{ }\NormalTok{conv_threshold) \{}
\NormalTok{      conv <-}\StringTok{ }\OtherTok{TRUE}
      \ControlFlowTok{break}
\NormalTok{      \}}
    
\NormalTok{    new_beta0 <-}\StringTok{ }\NormalTok{res}\OperatorTok{$}\NormalTok{beta0}
\NormalTok{    new_beta <-}\StringTok{ }\NormalTok{res}\OperatorTok{$}\NormalTok{beta}
    
\NormalTok{    i_iter <-}\StringTok{ }\NormalTok{i_iter }\OperatorTok{+}\StringTok{ }\DecValTok{1}
\NormalTok{  \}}
  
  \KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{conv =}\NormalTok{ conv, }\DataTypeTok{beta0 =}\NormalTok{ new_beta0, }\DataTypeTok{beta =}\NormalTok{ new_beta))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위에서 정의한 함수를 이용하여 Table \ref{tab:binary-logistic-reg-train-data}의 학습표본에 대한 로지스틱 회귀모형을 추정해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res <-}\StringTok{ }\KeywordTok{estimate_beta}\NormalTok{(train_df[, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{(), }
\NormalTok{                     train_df}\OperatorTok{$}\NormalTok{y }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{() }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{,}
                     \DataTypeTok{alpha =} \FloatTok{0.015}\NormalTok{,}
                     \DataTypeTok{conv_threshold =} \FloatTok{1e-6}\NormalTok{)}

\KeywordTok{print}\NormalTok{(res)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $conv
## [1] FALSE
## 
## $beta0
## [1] -30.39189
## 
## $beta
##       x1       x2       x3 
## 2.022808 3.457019 2.405969
\end{verbatim}

위 회귀계수 추정값은 R 함수 \texttt{glm}을 이용한 추정값(Table \ref{tab:binary-logistic-reg-coef})과 유사함을 볼 수 있다.

\hypertarget{binary-logistic-irls}{%
\subsubsection{반복재가중최소제곱법}\label{binary-logistic-irls}}

R의 \texttt{glm} 함수는 반복재가중최소제곱법(iteratively rewighted least squares; IRLS 혹은 IWLS)을 사용한다. 이는 선형회귀식

\begin{equation*}
logit(y_i) = \beta_0 + \boldsymbol\beta^\top \mathbf{x}_i + \varepsilon_i
\end{equation*}

을 추정하는 방법인데, 여기에서 \(y_i\)는 0 혹은 1이므로, \(logit(y_i)\)는 \(-\infty\) 혹은 \(\infty\)가 되어 회귀식을 추정할 수 없다. 따라서, 식 \eqref{eq:logistic-function}에 설명된 로지스틱 함수

\begin{equation*}
P = \frac{\exp(\beta_0 + \boldsymbol\beta^\top \mathbf{x})}{1 + \exp(\beta_0 + \boldsymbol\beta^\top \mathbf{x})}
\end{equation*}

와 테일러 급수(Taylor series)를 이용하여 \(logit(y)\)에 대한 근사함수를 아래와 같이 얻는다.

\begin{eqnarray*}
g(y) &=& logit(P) + (y - P) \frac{\partial logit(P)}{\partial P}\\
&=& \log \frac{P}{1 - P} + (y - P) \left( \frac{1}{P} + \frac{1}{1 - P} \right)
\end{eqnarray*}

그리고 아래 선형회귀식을 추정한다.

\begin{equation*}
g(y_i) = \beta_0 + \boldsymbol\beta^\top \mathbf{x}_i + \varepsilon_i
\end{equation*}

여기에서 오차항 \(\varepsilon_i\)의 분산은 추정된 확률 \(P_i\)에 따라 다르므로, 통상적 최소자승법(ordinary least squares; OLS) 대신 오차항의 분산이 동일해지도록 객체마다 가중치를 부여하는 가중최소자승법(weighted least squares; WLS)을 사용한다. 로지스틱 회귀모형에서 각 객체의 가중치는

\begin{equation*}
w_i = P_i (1 - P_i)
\end{equation*}

가중치와 회귀계수 추정값은 상호 영향을 미치므로, 수렴할 때까지 반복적으로 가중치와 회귀계수 추정값을 변화시키면서 최종 추정값을 찾아가는 방법이다.

우선 회귀계수 추정값이 주어졌을 때 각 객체에 대한 확률값 \(P_i\)와 가중치 \(w_i\)를 구하는 함수 \texttt{calculate\_weight}를 아래와 같이 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calculate_weight <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, }\DataTypeTok{beta0 =} \DecValTok{0}\NormalTok{, }
                             \DataTypeTok{beta =} \KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\KeywordTok{dim}\NormalTok{(x)[}\DecValTok{2}\NormalTok{])) \{}
  \CommentTok{# 각 객체의 y값이 1일 확률}
\NormalTok{  P <-}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\StringTok{ }\NormalTok{beta0 }\OperatorTok{-}\StringTok{ }\NormalTok{(x }\OperatorTok{%*%}\StringTok{ }\NormalTok{beta)))}\OperatorTok{^}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{drop}\NormalTok{()}

  \CommentTok{# 가중치 계산}
\NormalTok{  w <-}\StringTok{ }\NormalTok{P }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{P)}

  \KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{P =}\NormalTok{ P, }\DataTypeTok{w =}\NormalTok{ w))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

그리고 확률추정값과 가중치가 주어졌을 때 회귀계수를 구하는 함수 \texttt{calculate\_beta}를 아래와 같이 구현해보자. 여기서 회귀계수를 구하는 부분은 R의 선형회귀분석함수 \texttt{lm}을 사용한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calculate_beta <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, y, P, w) \{}
  \CommentTok{# 추정확률값이 0 이나 1인 경우 }
  \CommentTok{# 여전히 logit 함수가 정의되지 않으므로 회귀계수 결정에서 제외}
\NormalTok{  logit_derivative <-}\StringTok{ }\DecValTok{1}\OperatorTok{/}\NormalTok{P }\OperatorTok{+}\StringTok{ }\DecValTok{1}\OperatorTok{/}\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{P)}
\NormalTok{  is_good <-}\StringTok{ }\OperatorTok{!}\KeywordTok{is.nan}\NormalTok{(logit_derivative)}
  
  \CommentTok{# 모든 객체에 대한 추정확률이 0 이나 1인 경우 회귀계수 추정 불가능}
  \ControlFlowTok{if}\NormalTok{(}\KeywordTok{all}\NormalTok{(}\OperatorTok{!}\NormalTok{is_good)) }\KeywordTok{return}\NormalTok{(}\OtherTok{NULL}\NormalTok{)}
  
  \CommentTok{# 테일러 급수 계산}
\NormalTok{  g_y <-}\StringTok{ }\KeywordTok{log}\NormalTok{(P[is_good]) }\OperatorTok{-}\StringTok{ }
\StringTok{    }\KeywordTok{log}\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{P[is_good]) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\NormalTok{(y[is_good] }\OperatorTok{-}\StringTok{ }\NormalTok{P[is_good]) }\OperatorTok{*}\StringTok{ }\NormalTok{logit_derivative}
  
  \CommentTok{# 가중치최소자승법을 이용한 추정}
\NormalTok{  df <-}\StringTok{ }\KeywordTok{bind_cols}\NormalTok{(}\KeywordTok{as_tibble}\NormalTok{(x) }\OperatorTok{%>%}\StringTok{ }
\StringTok{                    `}\DataTypeTok{colnames<-}\StringTok{`}\NormalTok{(}\KeywordTok{colnames}\NormalTok{(x)), }
                  \KeywordTok{tibble}\NormalTok{(}\DataTypeTok{g_y =}\NormalTok{ g_y))}
  \KeywordTok{lm}\NormalTok{(g_y }\OperatorTok{~}\StringTok{ }\NormalTok{., }\DataTypeTok{data =}\NormalTok{ df, }\DataTypeTok{subset =}\NormalTok{ is_good, }\DataTypeTok{weights =}\NormalTok{ w)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위에서 정의한 두 함수 \texttt{calculate\_weight}과 \texttt{calculate\_beta}를 반복적으로 사용하여 Table \ref{tab:binary-logistic-reg-train-data}의 학습표본에 대한 로지스틱 회귀모형을 추정해보자. 모든 객체의 가중치 변화량이 1/10000 보다 작을 경우 모형추정이 수렴한 것으로 간주하도록 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X <-}\StringTok{ }\NormalTok{train_df[, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{()}
\NormalTok{y <-}\StringTok{ }\NormalTok{train_df}\OperatorTok{$}\NormalTok{y }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{() }\OperatorTok{-}\StringTok{ }\DecValTok{1}

\NormalTok{weight <-}\StringTok{ }\KeywordTok{calculate_weight}\NormalTok{(X)}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{) \{}
\NormalTok{  wls_fit <-}\StringTok{ }\KeywordTok{calculate_beta}\NormalTok{(X, y, weight}\OperatorTok{$}\NormalTok{P, weight}\OperatorTok{$}\NormalTok{w)}
  
  \ControlFlowTok{if}\NormalTok{(}\KeywordTok{is.null}\NormalTok{(wls_fit)) \{}\ControlFlowTok{break}\NormalTok{\}}
  
\NormalTok{  new_weight <-}\StringTok{ }\KeywordTok{calculate_weight}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ X, }
                                 \DataTypeTok{beta0 =} \KeywordTok{coef}\NormalTok{(wls_fit)[}\DecValTok{1}\NormalTok{], }
                                 \DataTypeTok{beta =} \KeywordTok{coef}\NormalTok{(wls_fit)[}\OperatorTok{-}\DecValTok{1}\NormalTok{])}
  
  \ControlFlowTok{if}\NormalTok{(}\KeywordTok{max}\NormalTok{(}\KeywordTok{abs}\NormalTok{(new_weight}\OperatorTok{$}\NormalTok{w }\OperatorTok{-}\StringTok{ }\NormalTok{weight}\OperatorTok{$}\NormalTok{w)) }\OperatorTok{<}\StringTok{ }\FloatTok{1e-4}\NormalTok{) \{}\ControlFlowTok{break}\NormalTok{\}}
  
\NormalTok{  weight <-}\StringTok{ }\NormalTok{new_weight}
\NormalTok{\}}

\KeywordTok{coef}\NormalTok{(wls_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept)          x1          x2          x3 
##  -30.510837    2.031278    3.470671    2.414387
\end{verbatim}

위 스크립트를 실행시킨 결과 7번째 반복수행에서 결과가 수렴하였으며, 해당 결과는 \texttt{glm} 함수를 사용하였을 때의 결과 (Table \ref{tab:binary-logistic-reg-coef})과 매우 근사함을 확인할 수 있다.

\hypertarget{nominal-logistic-regression}{%
\section{명목 로지스틱 회귀모형}\label{nominal-logistic-regression}}

\hypertarget{nominal-logistic-reg-basic-script}{%
\subsection{기본 R 스크립트}\label{nominal-logistic-reg-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{id, }\OperatorTok{~}\NormalTok{x1, }\OperatorTok{~}\NormalTok{x2, }\OperatorTok{~}\NormalTok{y,}
  \DecValTok{1}\NormalTok{, }\FloatTok{0.09}\NormalTok{, }\FloatTok{5.02}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{5.01}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\FloatTok{0.12}\NormalTok{, }\FloatTok{4.94}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\FloatTok{0.12}\NormalTok{, }\FloatTok{5.12}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\FloatTok{0.12}\NormalTok{, }\FloatTok{5.03}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\FloatTok{0.12}\NormalTok{, }\FloatTok{4.94}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{5.13}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{8}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{4.87}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{5.13}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{10}\NormalTok{, }\FloatTok{0.11}\NormalTok{, }\FloatTok{4.94}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{11}\NormalTok{, }\FloatTok{0.11}\NormalTok{, }\FloatTok{4.93}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{12}\NormalTok{, }\FloatTok{0.09}\NormalTok{, }\FloatTok{5.02}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{13}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{5.01}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{14}\NormalTok{, }\FloatTok{0.09}\NormalTok{, }\FloatTok{4.94}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{15}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{5.12}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{16}\NormalTok{, }\FloatTok{0.12}\NormalTok{, }\FloatTok{4.93}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{17}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{18}\NormalTok{, }\FloatTok{0.09}\NormalTok{, }\FloatTok{5.01}\NormalTok{, }\DecValTok{3}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{factor}\NormalTok{(y, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)))}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(train_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
             \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
             \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'$x_1$'}\NormalTok{, }\StringTok{'$x_2$'}\NormalTok{, }\StringTok{'불량범주($y$)'}\NormalTok{),}
             \DataTypeTok{caption =} \StringTok{'공정변수-불량 종류 데이터'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:nominal-logistic-reg-train-data}공정변수-불량 종류 데이터}
\centering
\begin{tabular}{rrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 불량범주(\$y\$)\\
\midrule
1 & 0.09 & 5.02 & 1\\
2 & 0.10 & 5.01 & 1\\
3 & 0.12 & 4.94 & 1\\
4 & 0.12 & 5.12 & 1\\
5 & 0.12 & 5.03 & 1\\
\addlinespace
6 & 0.12 & 4.94 & 2\\
7 & 0.10 & 5.13 & 2\\
8 & 0.10 & 4.87 & 1\\
9 & 0.10 & 5.13 & 2\\
10 & 0.11 & 4.94 & 3\\
\addlinespace
11 & 0.11 & 4.93 & 3\\
12 & 0.09 & 5.02 & 3\\
13 & 0.10 & 5.01 & 3\\
14 & 0.09 & 4.94 & 3\\
15 & 0.10 & 5.12 & 2\\
\addlinespace
16 & 0.12 & 4.93 & 2\\
17 & 0.10 & 5.00 & 1\\
18 & 0.09 & 5.01 & 3\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:nominal-logistic-reg-train-data}와 같이 두 개의 독립변수 \(x_1\), \(x_2\)에 따라 세 종류의 불량 (\(y = 1, 2, 3\))\$이 발생함을 알았다면, 아래와 같이 \texttt{nnet} 패키지의 \texttt{multinom} 함수를 이용하여 공정변수에 따른 불량 종류를 분류하기 위한 로지스틱 회귀모형을 간편하게 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{multinom_fit <-}\StringTok{ }\NormalTok{nnet}\OperatorTok{::}\KeywordTok{multinom}\NormalTok{(}
\NormalTok{  y }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, }
  \DataTypeTok{data =}\NormalTok{ train_df, }
  \DataTypeTok{maxit =} \DecValTok{1000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # weights:  12 (6 variable)
## initial  value 19.775021 
## iter  10 value 17.825831
## iter  20 value 16.489924
## iter  30 value 16.116751
## iter  40 value 16.044223
## iter  50 value 16.025259
## iter  60 value 16.024629
## iter  70 value 16.016395
## final  value 16.015185 
## converged
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  multinom_fit }\OperatorTok{%>%}\StringTok{  }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{(}\DataTypeTok{exponentiate =} \OtherTok{FALSE}\NormalTok{),}
  \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{caption =} \StringTok{'위 공정변수-불량종류 데이터에 대한 Logistic Regression 결과'}
\CommentTok{#  caption = 'Table \textbackslash{}\textbackslash{}@ref(tab:nominal-logistic-reg-train-data)에 대한 Logistic Regression 결과'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:nominal-logistic-reg-coef}위 공정변수-불량종류 데이터에 대한 Logistic Regression 결과}
\centering
\begin{tabular}{llrrrr}
\toprule
y.level & term & estimate & std.error & statistic & p.value\\
\midrule
2 & (Intercept) & -53.924661 & 45.402992 & -1.1876896 & 0.2349557\\
2 & x1 & 31.545749 & 62.162158 & 0.5074751 & 0.6118215\\
2 & x2 & 9.992311 & 8.479305 & 1.1784352 & 0.2386231\\
3 & (Intercept) & 64.191145 & 57.282533 & 1.1206059 & 0.2624556\\
3 & x1 & -101.817613 & 65.516143 & -1.5540844 & 0.1201643\\
\addlinespace
3 & x2 & -10.810865 & 10.915881 & -0.9903795 & 0.3219887\\
\bottomrule
\end{tabular}
\end{table}

\texttt{multinom} 함수는 범주 \texttt{y}의 값 1, 2, 3중 첫번째 값인 1을 기준범주(reference category)로 사용한다.

\hypertarget{baseline-category-logit-model}{%
\subsection{기준범주 로짓모형}\label{baseline-category-logit-model}}

종속변수가 셋 이상의 범주를 갖고 있으나 자연스러운 순서가 없는 경우, 기준범주 로짓모형이 널리 사용된다.

\(N\)개의 객체로 이루어진 학습데이터 \(\{(\mathbf{x}_i, y_i)\}_{i = 1, \cdots, N}\)를 아래와 같이 정의하자.

\begin{itemize}
\tightlist
\item
  \(\mathbf{x}_i \in \mathbb{R}^p\): \(p\)개의 독립변수로 이루어진 벡터 (\(\mathbf{x}_i = [x_{i1} \, x_{i2} \, \cdots \, x_{ip}]^\top\))
\item
  \(J\): 범주 수
\item
  \(y_i\): 객체 \(i\)에 대한 종속변수값 \(\in \{1, 2, \cdots, J\}\)
\end{itemize}

각 객체 \(i\)가 각 범주에 해당할 확률을 \(\pi_{ij}\)라 하자.

\begin{equation*}
\pi_{ij} = P(y_i = j \, | \, \mathbf{x}_i), \, j = 1, \cdots, J
\end{equation*}

이 때, 모든 \(i\)에 대하여

\begin{equation*}
\sum_{j = 1}^{J} \pi_{ij} = 1
\end{equation*}

이 성립한다. 여기에서 범주 1을 기준 범주(reference category 혹은 baseline category)로 간주하여 범주별로 다음과 같은 회귀모형을 정의한다 (교재 \citep{jun2012datamining}에는 범주 \(J\)를 기준 범주로 간주).

\begin{equation*}
\log \left( \frac{\pi_{ij}}{\pi_{i1}} \right) = \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i, \, j = 2, \cdots, J
\end{equation*}

이를 \(\pi_{ij}\)에 대해 풀면, 아래와 같은 해가 얻어진다 \citep{czepiel2002maximum}.

\begin{equation}
\begin{split}
\pi_{ij} &= \frac{\exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}{1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}, \, j = 2, \cdots, J\\
\pi_{i1} &= \frac{1}{1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}
\end{split}
\label{eq:multi-nominal-prob-sol}
\end{equation}

위 모수 추정을 위해 최우추정법을 사용해보자. 우선, 종속변수를 변환한 지시변수를 아래와 같이 정의한다.

\begin{equation*}
v_{ij} = \begin{cases}
1 & \text{ if } y_i = j\\
0 & \text{ otherwise }
\end{cases}
\end{equation*}

이를 이용해 우도 함수를

\begin{eqnarray*}
L &=& \prod_{i = 1}^{n} \prod_{j = 1}^{J} \left( \pi_{ij} \right)^{v_{ij}} \\
&=& \prod_{i = 1}^{n} \pi_{i1}^{1 - \sum_{j = 2}^{J} v_{ij}} \prod_{j = 2}^{J} \left( \pi_{ij} \right)^{v_{ij}}\\
&=& \prod_{i = 1}^{n} \frac{\pi_{i1}}{\pi_{i1}^{\sum_{j = 2}^{J} v_{ij}}} \prod_{j = 2}^{J} \left( \pi_{ij} \right)^{v_{ij}}\\
&=& \prod_{i = 1}^{n} \frac{\pi_{i1}}{\prod_{j = 2}^{J} \pi_{i1}^{v_{ij}}} \prod_{j = 2}^{J} \left( \pi_{ij} \right)^{v_{ij}}\\
&=& \prod_{i = 1}^{n} \pi_{i1} \prod_{j = 2}^{J} \left( \frac{\pi_{ij}}{\pi_{i1}} \right)^{v_{ij}}
\end{eqnarray*}

와 같이 표현할 수 있으며, 여기에 식 \eqref{eq:multi-nominal-prob-sol}을 이용하면 아래와 같이 정리할 수 있다.

\begin{eqnarray*}
L &=& \prod_{i = 1}^{n} \frac{1}{1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)} \prod_{j = 2}^{J} \left( \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right) \right)^{v_{ij}}\\
&=& \prod_{i = 1}^{n} \left( 1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right) \right)^{-1} \prod_{j = 2}^{J} \left( \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right) \right)^{v_{ij}}
\end{eqnarray*}

이에 따라 로그 우도함수는 다음과 같이 정의된다.

\begin{equation}
\log L = \sum_{i = 1}^{n} \left( - \log \left( 1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right) \right) + \sum_{j = 2}^{J} v_{ij} \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right) \right) 
\label{eq:multi-nominal-logit-loglik}
\end{equation}

식 \eqref{eq:multi-nominal-logit-loglik}을 각 계수에 대해 미분하면 아래와 같이 정리된다.

\begin{equation}
\begin{split}
\frac{\partial \log L}{\partial \beta_{0,j}} &= \sum_{i = 1}^{n} v_{ij} - \frac{\exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}{1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}\\
\frac{\partial \log L}{\partial \beta_{k,j}} &= \sum_{i = 1}^{n} v_{ij} x_{ik} - \frac{x_{ik} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}{1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}, \, k = 1, \cdots, p
\end{split}
\label{eq:multi-nominal-logit-loglik-diff}
\end{equation}

따라서, 명목 로지스틱 회귀분석은 식 \eqref{eq:multi-nominal-logit-loglik-diff}이 표현하는 \((J - 1) \times (p + 1)\)개의 미분식을 모두 0으로 만드는 계수값을 찾는 문제가 된다. 이에 대한 closed form solution은 존재하지 않으므로, 각종 알고리즘을 이용하여 해를 찾아야 한다. Newton-Raphson method에 의해 해를 찾는 방법은 \citet{czepiel2002maximum} 에 보다 자세하게 설명되어 있다.

Table \ref{tab:nominal-logistic-reg-train-data}의 학습데이터에 대해 명목 로지스틱 회귀모형을 학습하여 범주를 추정한 결과는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{multinom_fit <-}\StringTok{ }\NormalTok{nnet}\OperatorTok{::}\KeywordTok{multinom}\NormalTok{(}
\NormalTok{  y }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, }
  \DataTypeTok{data =}\NormalTok{ train_df, }
  \DataTypeTok{maxit =} \DecValTok{1000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # weights:  12 (6 variable)
## initial  value 19.775021 
## iter  10 value 17.825831
## iter  20 value 16.489924
## iter  30 value 16.116751
## iter  40 value 16.044223
## iter  50 value 16.025259
## iter  60 value 16.024629
## iter  70 value 16.016395
## final  value 16.015185 
## converged
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predict_df <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(multinom_fit, train_df, }\DataTypeTok{type =} \StringTok{"probs"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{as_data_frame}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  `}\DataTypeTok{colnames<-}\StringTok{`}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"p1"}\NormalTok{, }\StringTok{"p2"}\NormalTok{, }\StringTok{"p3"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pred_class =} \KeywordTok{predict}\NormalTok{(multinom_fit, train_df, }\DataTypeTok{type =} \StringTok{"class"}\NormalTok{))}

\KeywordTok{bind_cols}\NormalTok{(train_df, predict_df) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{x1, }\OperatorTok{-}\NormalTok{x2) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'불량범주 $y_i$'}\NormalTok{, }
                  \StringTok{'$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{pi_\{i1\}$'}\NormalTok{, }\StringTok{'$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{pi_\{i2\}$'}\NormalTok{, }\StringTok{'$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{pi_\{i3\}$'}\NormalTok{, }\StringTok{'추정범주 $}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{hat\{y\}_i$'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'명목 로지스틱 회귀모형 범주 추정 결과'}\NormalTok{,}
    \DataTypeTok{digits =} \DecValTok{3}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:nominal-logistic-prediction}명목 로지스틱 회귀모형 범주 추정 결과}
\centering
\begin{tabular}{rrrrrr}
\toprule
객체번호 & 불량범주 \$y\_i\$ & \$\textbackslash{}pi\_\{i1\}\$ & \$\textbackslash{}pi\_\{i2\}\$ & \$\textbackslash{}pi\_\{i3\}\$ & 추정범주 \$\textbackslash{}hat\{y\}\_i\$\\
\midrule
1 & 1 & 0.283 & 0.112 & 0.604 & 3\\
2 & 1 & 0.425 & 0.209 & 0.365 & 1\\
3 & 1 & 0.589 & 0.271 & 0.141 & 1\\
4 & 1 & 0.262 & 0.729 & 0.009 & 2\\
5 & 1 & 0.450 & 0.509 & 0.041 & 2\\
\addlinespace
6 & 2 & 0.589 & 0.271 & 0.141 & 1\\
7 & 2 & 0.349 & 0.570 & 0.082 & 2\\
8 & 1 & 0.199 & 0.024 & 0.777 & 3\\
9 & 2 & 0.349 & 0.570 & 0.082 & 2\\
10 & 3 & 0.501 & 0.168 & 0.331 & 1\\
\addlinespace
11 & 3 & 0.490 & 0.149 & 0.361 & 1\\
12 & 3 & 0.283 & 0.112 & 0.604 & 3\\
13 & 3 & 0.425 & 0.209 & 0.365 & 1\\
14 & 3 & 0.160 & 0.029 & 0.811 & 3\\
15 & 2 & 0.365 & 0.540 & 0.095 & 2\\
\addlinespace
16 & 2 & 0.595 & 0.247 & 0.158 & 1\\
17 & 1 & 0.416 & 0.186 & 0.398 & 1\\
18 & 3 & 0.268 & 0.096 & 0.636 & 3\\
\bottomrule
\end{tabular}
\end{table}

\texttt{nnet} 패키지 외에도 \texttt{glmnet}, \texttt{mlogit}, \texttt{VGAM} 등의 R 패키지들을 사용해 명목형 로지스틱 회귀모형을 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{VGAM}\OperatorTok{::}\KeywordTok{vglm}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2,}
           \DataTypeTok{data =}\NormalTok{ train_df,}
           \DataTypeTok{family =}\NormalTok{ VGAM}\OperatorTok{::}\NormalTok{multinomial)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## VGAM::vglm(formula = y ~ x1 + x2, family = VGAM::multinomial, 
##     data = train_df)
## 
## 
## Coefficients:
## (Intercept):1 (Intercept):2          x1:1          x1:2          x2:1 
##     -64.56378    -118.15274     102.65063     133.29235      10.86829 
##          x2:2 
##      20.81307 
## 
## Degrees of Freedom: 36 Total; 30 Residual
## Residual deviance: 32.03007 
## Log-likelihood: -16.01503 
## 
## This is a multinomial logit model with 3 levels
\end{verbatim}

\hypertarget{ordinal-logistic-regression}{%
\section{서열 로지스틱 회귀모형}\label{ordinal-logistic-regression}}

본 장에서는 종속변수가 3개 이상의 범주를 가지며, 각 범주 간에 서열이 있는 경우에 대한 로지스틱 회귀모형을 소개한다.

\hypertarget{ordinal-logistic-basic-script}{%
\subsection{기본 R 스크립트}\label{ordinal-logistic-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{N, }\OperatorTok{~}\NormalTok{L, }\OperatorTok{~}\NormalTok{y,}
  \DecValTok{25}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{25}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{25}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{25}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{32}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{32}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{32}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{32}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{42}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{42}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{42}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{42}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{1}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{as.ordered}\NormalTok{(y))}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(train_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
             \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
             \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'잡음(N)'}\NormalTok{, }\StringTok{'손실(L)'}\NormalTok{, }\StringTok{'만족도($y$)'}\NormalTok{),}
             \DataTypeTok{caption =} \StringTok{'성능변수에 따른 통신 만족도'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:ordinal-logistic-reg-train-data}성능변수에 따른 통신 만족도}
\centering
\begin{tabular}{rrr}
\toprule
잡음(N) & 손실(L) & 만족도(\$y\$)\\
\midrule
25 & 5 & 3\\
25 & 10 & 3\\
25 & 20 & 2\\
25 & 30 & 1\\
32 & 5 & 3\\
\addlinespace
32 & 10 & 3\\
32 & 20 & 2\\
32 & 30 & 1\\
42 & 5 & 1\\
42 & 10 & 3\\
\addlinespace
42 & 20 & 1\\
42 & 30 & 1\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:ordinal-logistic-reg-train-data}은 벨 연구소에서 한 통신장치에 대하여 실시한 조사 결과를 나타낸 것이다. 주요 성능변수인 회선잡음(circuit noise: N)과 소리크기 손실(loudness loss: L)이 이용자의 주관적인 만족도에 미치는 영향을 분석하기 위한 것이다. 만족도는 원결과\citep{cavanaugh1976models}를 가공하여 다음과 같이 3가지로 분류하였다.

\begin{equation*}
y = \begin{cases}
1 & \mbox{good}\\
2 & \mbox{fair}\\
3 & \mbox{poor}
\end{cases}
\end{equation*}

본 장에서는 두 가지 모형을 다룬다. 우선 누적 로짓모형(cumulative logit model)은 아래와 같이 \texttt{MASS} 패키지의 \texttt{polr} 함수를 사용하여 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{MASS}\OperatorTok{::}\KeywordTok{polr}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{N }\OperatorTok{+}\StringTok{ }\NormalTok{L, }\DataTypeTok{data =}\NormalTok{ train_df) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 5
##   term  estimate std.error statistic coefficient_type
##   <chr>    <dbl>     <dbl>     <dbl> <chr>           
## 1 N       -0.224     0.146     -1.53 coefficient     
## 2 L       -0.300     0.137     -2.19 coefficient     
## 3 1|2    -13.0       6.46      -2.02 zeta            
## 4 2|3    -11.4       6.17      -1.85 zeta
\end{verbatim}

인근범주 로짓모형(adjacent-categories logit model)은 아래와 같이 \texttt{VGAM} 패키지의 \texttt{vglm} 함수를 이용하여 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{VGAM}\OperatorTok{::}\KeywordTok{vglm}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{N }\OperatorTok{+}\StringTok{ }\NormalTok{L,}
           \DataTypeTok{data =}\NormalTok{ train_df,}
           \DataTypeTok{family =}\NormalTok{ VGAM}\OperatorTok{::}\KeywordTok{acat}\NormalTok{(}\DataTypeTok{reverse =} \OtherTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## VGAM::vglm(formula = y ~ N + L, family = VGAM::acat(reverse = TRUE), 
##     data = train_df)
## 
## 
## Coefficients:
## (Intercept):1 (Intercept):2           N:1           N:2           L:1 
##  -12.94227208   -6.10597713    0.31431599    0.04643039    0.17500408 
##           L:2 
##    0.29578067 
## 
## Degrees of Freedom: 24 Total; 18 Residual
## Residual deviance: 11.67769 
## Log-likelihood: -5.838847 
## 
## This is an adjacent categories model with 3 levels
\end{verbatim}

\hypertarget{cumulative-logit-model}{%
\subsection{누적 로짓모형}\label{cumulative-logit-model}}

객체 \(i\)가 범주 \(j\) 이하에 속할 누적확률을 \(\kappa_{ij}\)라 하자.

\begin{equation*}
\kappa_{ij} = P(y_i \leq j \, | \, \mathbf{x}_i), \, j = 1, \cdots, J
\end{equation*}

누적 로짓모형은 범주 누적확률의 로짓변환에 대한 선형 회귀모형이다.

\begin{equation}
\log \left( \frac{\kappa_{ij}}{1 - \kappa_{ij}} \right) = \beta_{0,j} + \boldsymbol\beta^\top \mathbf{x}_i, \, j = 1, \cdots, J - 1
\label{eq:cumulative-logit}
\end{equation}

식 \eqref{eq:cumulative-logit}은 독립변수에 대한 계수 \(\boldsymbol\beta\)가 모든 범주에 대해 동일하며 절편(intercept) \(\beta_{0,j}\)만 범주에 따라 다른 비례 승산 모형(proportional odds model)이다. 즉, 범주에 관계없이 각 독립변수가 한 단위 증가할 때마다 로그 승산비는 동일하게 증가한다.

모형의 추정은 \ref{baseline-category-logit-model}절과 유사하게 다항분포를 사용한 최우추정법을 사용할 수 있다. 각 객체 \(i\)가 범주 \(j\)에 속할 확률은 아래와 같다.

\begin{equation*}
\begin{split}
\pi_{ij} &= \kappa_{ij} - \kappa_{i,j-1}\\
&= \frac{\exp (\beta_{0,j} + \boldsymbol\beta^\top \mathbf{x}_i)}{1 + \exp (\beta_{0,j} + \boldsymbol\beta^\top \mathbf{x}_i)} - \frac{\exp (\beta_{0,j-1} + \boldsymbol\beta^\top \mathbf{x}_i)}{1 + \exp (\beta_{0,j-1} + \boldsymbol\beta^\top \mathbf{x}_i)}, \, j = 2, \cdots, J - 1\\
& \\
\pi_{i1} &= \kappa_{i1}\\
&= \frac{\exp (\beta_{0,1} + \boldsymbol\beta^\top \mathbf{x}_i)}{1 + \exp (\beta_{0,1} + \boldsymbol\beta^\top \mathbf{x}_i)}\\
& \\
\pi_{iJ} &= 1 - \kappa_{i,J-1}\\
&= 1 - \frac{\exp (\beta_{0,J-1} + \boldsymbol\beta^\top \mathbf{x}_i)}{1 + \exp (\beta_{0,J-1} + \boldsymbol\beta^\top \mathbf{x}_i)}
\end{split}
\label{eq:cumulative-logit-prob}
\end{equation*}

로그 우도함수는

\begin{equation*}
\sum_{i = 1}^{n} \sum_{j = 1}^{J} \log \pi_{ij}
\end{equation*}

이며, 이에 위에서 정리한 \(\pi_{ij}\)식을 대입하여 전개할 수 있다. 이 로그 우도함수는 concave 함수이므로\citep{pratt1981concavity}, 각 계수에 대해 편미분하여 0이 되도록 하는 값을 구하는 방식으로 회귀모형을 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{polr_fit <-}\StringTok{ }\NormalTok{MASS}\OperatorTok{::}\KeywordTok{polr}\NormalTok{(y }\OperatorTok{~}\StringTok{ }\NormalTok{N }\OperatorTok{+}\StringTok{ }\NormalTok{L, }\DataTypeTok{data =}\NormalTok{ train_df)}

\KeywordTok{print}\NormalTok{(polr_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## MASS::polr(formula = y ~ N + L, data = train_df)
## 
## Coefficients:
##          N          L 
## -0.2236292 -0.2998833 
## 
## Intercepts:
##       1|2       2|3 
## -13.03527 -11.39902 
## 
## Residual Deviance: 12.8825 
## AIC: 20.8825
\end{verbatim}

위와 같이 \texttt{polr} 함수 실행 시 얻어지는 각 변수들에 대한 계수들의 부호는 교재\citep{jun2012datamining}의 내용과 반대인데, 이는 \texttt{polr} 함수는 아래와 같은 모형을 추정하기 때문이다.

\begin{equation*}
\log \left( \frac{\kappa_{ij}}{1 - \kappa_{ij}} \right) = \beta_{0,j} - \boldsymbol\beta^\top \mathbf{x}_i, \, j = 1, \cdots, J - 1
\end{equation*}

위 모형에서 \texttt{polr} 함수 실행 결과 추정된 절편값은 \(\beta_{0,1} = -13.0352721\), \(\beta_{0,2} = -11.3990207\) 이며, 두 변수 \(N\), \(L\)에 대한 회귀계수는 각각 -0.2236292, -0.2998833로 추정된다.

추정된 회귀계수를 식 \eqref{eq:cumulative-logit-prob}에 대입하면 각 객체 \(i\)가 각 범주 \(j\)에 속할 확률을 Table \ref{tab:cumulative-logit-prediction}와 같이 얻을 수 있다. 아래 R 스크립트에서 사용한 \texttt{predict}라는 함수가 해당 계산을 수행한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predict_df <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(polr_fit, train_df, }\DataTypeTok{type =} \StringTok{"probs"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{as_data_frame}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  `}\DataTypeTok{colnames<-}\StringTok{`}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"p1"}\NormalTok{, }\StringTok{"p2"}\NormalTok{, }\StringTok{"p3"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pred_class =} \KeywordTok{predict}\NormalTok{(polr_fit, train_df, }\DataTypeTok{type =} \StringTok{"class"}\NormalTok{))}

\KeywordTok{bind_cols}\NormalTok{(train_df, predict_df) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'잡음(N)'}\NormalTok{, }\StringTok{'손실(L)'}\NormalTok{, }\StringTok{'실제범주 $y_i$'}\NormalTok{, }
                  \StringTok{'$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{pi_\{i1\}$'}\NormalTok{, }\StringTok{'$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{pi_\{i2\}$'}\NormalTok{, }\StringTok{'$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{pi_\{i3\}$'}\NormalTok{, }\StringTok{'추정범주 $}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{hat\{y\}_i$'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'위 통신 만족도 데이터에 대한 누적 로짓모형의 추정범주'}\NormalTok{,}
\CommentTok{#    caption = 'Table \textbackslash{}\textbackslash{}@ref(tab:ordinal-logistic-reg-train-data)에 대한 누적 로짓모형의 추정범주',}
    \DataTypeTok{digits =} \DecValTok{4}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:cumulative-logit-prediction}위 통신 만족도 데이터에 대한 누적 로짓모형의 추정범주}
\centering
\begin{tabular}{rrrrrrr}
\toprule
잡음(N) & 손실(L) & 실제범주 \$y\_i\$ & \$\textbackslash{}pi\_\{i1\}\$ & \$\textbackslash{}pi\_\{i2\}\$ & \$\textbackslash{}pi\_\{i3\}\$ & 추정범주 \$\textbackslash{}hat\{y\}\_i\$\\
\midrule
25 & 5 & 3 & 0.0026 & 0.0107 & 0.9867 & 3\\
25 & 10 & 3 & 0.0116 & 0.0452 & 0.9432 & 3\\
25 & 20 & 2 & 0.1905 & 0.3567 & 0.4528 & 3\\
25 & 30 & 1 & 0.8252 & 0.1352 & 0.0396 & 1\\
32 & 5 & 3 & 0.0124 & 0.0481 & 0.9395 & 3\\
\addlinespace
32 & 10 & 3 & 0.0531 & 0.1706 & 0.7763 & 3\\
32 & 20 & 2 & 0.5296 & 0.3230 & 0.1474 & 1\\
32 & 30 & 1 & 0.9576 & 0.0338 & 0.0085 & 1\\
42 & 5 & 1 & 0.1049 & 0.2709 & 0.6241 & 3\\
42 & 10 & 3 & 0.3443 & 0.3852 & 0.2705 & 2\\
\addlinespace
42 & 20 & 1 & 0.9133 & 0.0685 & 0.0181 & 1\\
42 & 30 & 1 & 0.9953 & 0.0038 & 0.0009 & 1\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{adjacent-categories-logit-model}{%
\subsection{인근범주 로짓모형}\label{adjacent-categories-logit-model}}

인근범주 로짓모형은 아래와 같이 인접한 두 범주의 확률 비율에 대한 회귀모형이다.

\begin{equation}
\log \left( \frac{\pi_{ij}}{\pi_{i,j+1}} \right) = \beta_{0,j} + \boldsymbol\beta^\top \mathbf{x}_i, \, j = 1, \cdots, J - 1
\label{eq:adjacent-category-logit}
\end{equation}

따라서, \(\pi_{ij}\)간에 다음과 같은 관계식이 성립한다.

\begin{equation*}
\begin{split}
\pi_{ij} &= \exp (\beta_{0,j} + \boldsymbol\beta^\top \mathbf{x}_i) \pi_{i,j+1}\\
&= \pi_{iJ} \exp \left(\sum_{k = j}^{J - 1} \beta_{0,k} + (J - j) \boldsymbol\beta^\top \mathbf{x}_i\right), \, j = 1, \cdots, J-1\\
\sum_{j = 1}^{J} \pi_{ij} &= 1
\end{split}
\end{equation*}

이를 정리하면

\begin{equation}
\begin{split}
\pi_{ij} &= \frac{\exp \left( \sum_{l = j}^{J - 1} \beta_{0,l} + (J - j) \boldsymbol\beta^\top \mathbf{x}_i \right)}{1 + \sum_{k = 1}^{J - 1} \exp \left( \sum_{l = k}^{J - 1} \beta_{0,l} + (J - k) \boldsymbol\beta^\top \mathbf{x}_i \right)}, \, j = 1, \cdots, J - 1\\
\pi_{iJ} &= \frac{1}{1 + \sum_{k = 1}^{J - 1} \exp \left( \sum_{l = k}^{J - 1} \beta_{0,l} + (J - k) \boldsymbol\beta^\top \mathbf{x}_i \right)}
\end{split}
\label{eq:adjacent-category-prob}
\end{equation}

와 같다. 이는 \ref{baseline-category-logit-model}절에서 살펴보았던 명목형 로지스틱 회귀모형에 비해 다소 복잡하지만 비슷한 형태이며, 역시 최우추정법을 이용하여 모형을 추정할 수 있다.

R에서는 \texttt{VGAM} 패키지의 \texttt{vglm} 함수를 이용할 때 파라미터 \texttt{family}의 값을 \texttt{VGAM} 패키지의 \texttt{acat} 함수를 설정함으로써 인근범주 로짓모형을 추정할 수 있다. 이 때 \texttt{acat} 함수의 \texttt{parallel} 파라미터값을 \texttt{TRUE}로 설정함으로써 식 \eqref{eq:adjacent-category-logit}에서와 같이 비례 승산 모형(proportional odds model)을 정의한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vglm_fit <-}\StringTok{ }\NormalTok{VGAM}\OperatorTok{::}\KeywordTok{vglm}\NormalTok{(}
\NormalTok{  y }\OperatorTok{~}\StringTok{ }\NormalTok{N }\OperatorTok{+}\StringTok{ }\NormalTok{L,}
  \DataTypeTok{data =}\NormalTok{ train_df,}
  \DataTypeTok{family =}\NormalTok{ VGAM}\OperatorTok{::}\KeywordTok{acat}\NormalTok{(}\DataTypeTok{reverse =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{parallel =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{  )}

\KeywordTok{print}\NormalTok{(}\KeywordTok{coef}\NormalTok{(vglm_fit))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept):1 (Intercept):2             N             L 
##    -9.0658976    -8.9018134     0.1725867     0.2082167
\end{verbatim}

추정된 모형을 위 식 \eqref{eq:adjacent-category-prob}에 대입하면 각 객체 \(i\)가 각 범주 \(j\)에 속할 확률을 추정할 수 있다. \texttt{VGAM} 패키지의 \texttt{predictvglm} 함수가 해당 계산을 수행한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predict_df <-}\StringTok{ }\NormalTok{VGAM}\OperatorTok{::}\KeywordTok{predictvglm}\NormalTok{(vglm_fit, train_df, }\StringTok{"response"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{as_data_frame}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  `}\DataTypeTok{colnames<-}\StringTok{`}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"p1"}\NormalTok{, }\StringTok{"p2"}\NormalTok{, }\StringTok{"p3"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pred_class =} \KeywordTok{ordered}\NormalTok{(}\KeywordTok{apply}\NormalTok{(., }\DecValTok{1}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{which.max}\NormalTok{(x))))}

\KeywordTok{bind_cols}\NormalTok{(train_df, predict_df) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'잡음(N)'}\NormalTok{, }\StringTok{'손실(L)'}\NormalTok{, }\StringTok{'실제범주 $y_i$'}\NormalTok{, }
                  \StringTok{'$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{pi_\{i1\}$'}\NormalTok{, }\StringTok{'$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{pi_\{i2\}$'}\NormalTok{, }\StringTok{'$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{pi_\{i3\}$'}\NormalTok{, }\StringTok{'추정범주 $}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{hat\{y\}_i$'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'위 통신 만족도 데이터에 대한 인근범주 로짓모형의 추정범주'}\NormalTok{,}
\CommentTok{#    caption = 'Table \textbackslash{}\textbackslash{}@ref(tab:ordinal-logistic-reg-train-data)에 대한 인근범주 로짓모형의 추정범주',}
    \DataTypeTok{digits =} \DecValTok{4}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:adjacent-category-logit-prediction}위 통신 만족도 데이터에 대한 인근범주 로짓모형의 추정범주}
\centering
\begin{tabular}{rrrrrrr}
\toprule
잡음(N) & 손실(L) & 실제범주 \$y\_i\$ & \$\textbackslash{}pi\_\{i1\}\$ & \$\textbackslash{}pi\_\{i2\}\$ & \$\textbackslash{}pi\_\{i3\}\$ & 추정범주 \$\textbackslash{}hat\{y\}\_i\$\\
\midrule
25 & 5 & 3 & 0.0007 & 0.0280 & 0.9713 & 3\\
25 & 10 & 3 & 0.0052 & 0.0751 & 0.9197 & 3\\
25 & 20 & 2 & 0.1804 & 0.3244 & 0.4952 & 3\\
25 & 30 & 1 & 0.7894 & 0.1770 & 0.0337 & 1\\
32 & 5 & 3 & 0.0072 & 0.0874 & 0.9054 & 3\\
\addlinespace
32 & 10 & 3 & 0.0474 & 0.2045 & 0.7480 & 3\\
32 & 20 & 2 & 0.5611 & 0.3015 & 0.1375 & 1\\
32 & 30 & 1 & 0.9339 & 0.0626 & 0.0036 & 1\\
42 & 5 & 1 & 0.1393 & 0.3026 & 0.5581 & 3\\
42 & 10 & 3 & 0.4411 & 0.3385 & 0.2204 & 1\\
\addlinespace
42 & 20 & 1 & 0.9063 & 0.0867 & 0.0070 & 1\\
42 & 30 & 1 & 0.9881 & 0.0118 & 0.0001 & 1\\
\bottomrule
\end{tabular}
\end{table}

비례 승산 모형(proportional odds model)이 아닌 인근범주 로짓모형은 아래와 같다.

\begin{equation}
\log \left( \frac{\pi_{ij}}{\pi_{i,j+1}} \right) = \beta_{0,j} + \boldsymbol\beta_j^\top \mathbf{x}_i, \, j = 1, \cdots, J - 1
\label{eq:adjacent-category-logit-nonproportional}
\end{equation}

해당 모형은 \texttt{acat} 함수의 \texttt{parallel} 파라미터 값을 \texttt{FALSE}로 설정함으로써 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vglm_fit <-}\StringTok{ }\NormalTok{VGAM}\OperatorTok{::}\KeywordTok{vglm}\NormalTok{(}
\NormalTok{  y }\OperatorTok{~}\StringTok{ }\NormalTok{N }\OperatorTok{+}\StringTok{ }\NormalTok{L,}
  \DataTypeTok{data =}\NormalTok{ train_df,}
  \DataTypeTok{family =}\NormalTok{ VGAM}\OperatorTok{::}\KeywordTok{acat}\NormalTok{(}\DataTypeTok{reverse =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{parallel =} \OtherTok{FALSE}\NormalTok{)}
\NormalTok{  )}

\KeywordTok{print}\NormalTok{(}\KeywordTok{coef}\NormalTok{(vglm_fit))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept):1 (Intercept):2           N:1           N:2           L:1 
##  -12.94227208   -6.10597713    0.31431599    0.04643039    0.17500408 
##           L:2 
##    0.29578067
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predict_df <-}\StringTok{ }\NormalTok{VGAM}\OperatorTok{::}\KeywordTok{predictvglm}\NormalTok{(vglm_fit, train_df, }\StringTok{"response"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{as_data_frame}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  `}\DataTypeTok{colnames<-}\StringTok{`}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"p1"}\NormalTok{, }\StringTok{"p2"}\NormalTok{, }\StringTok{"p3"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pred_class =} \KeywordTok{ordered}\NormalTok{(}\KeywordTok{apply}\NormalTok{(., }\DecValTok{1}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{which.max}\NormalTok{(x))))}

\KeywordTok{bind_cols}\NormalTok{(train_df, predict_df) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'잡음(N)'}\NormalTok{, }\StringTok{'손실(L)'}\NormalTok{, }\StringTok{'실제범주 $y_i$'}\NormalTok{, }
                  \StringTok{'$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{pi_\{i1\}$'}\NormalTok{, }\StringTok{'$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{pi_\{i2\}$'}\NormalTok{, }\StringTok{'$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{pi_\{i3\}$'}\NormalTok{, }\StringTok{'추정범주 $}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{hat\{y\}_i$'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'위 통신 만족도 데이터에 대한 인근범주 로짓모형의 추정범주 (비례 승산 모형이 아닌 경우)'}\NormalTok{,}
\CommentTok{#    caption = 'Table \textbackslash{}\textbackslash{}@ref(tab:ordinal-logistic-reg-train-data)에 대한 인근범주 로짓모형의 추정범주 (비례 승산 모형이 아닌 경우)',}
    \DataTypeTok{digits =} \DecValTok{4}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:adjacent-category-logit-prediction-nonproportional}위 통신 만족도 데이터에 대한 인근범주 로짓모형의 추정범주 (비례 승산 모형이 아닌 경우)}
\centering
\begin{tabular}{rrrrrrr}
\toprule
잡음(N) & 손실(L) & 실제범주 \$y\_i\$ & \$\textbackslash{}pi\_\{i1\}\$ & \$\textbackslash{}pi\_\{i2\}\$ & \$\textbackslash{}pi\_\{i3\}\$ & 추정범주 \$\textbackslash{}hat\{y\}\_i\$\\
\midrule
25 & 5 & 3 & 0.0004 & 0.0303 & 0.9693 & 3\\
25 & 10 & 3 & 0.0043 & 0.1200 & 0.8757 & 3\\
25 & 20 & 2 & 0.1295 & 0.6313 & 0.2392 & 2\\
25 & 30 & 1 & 0.5365 & 0.4546 & 0.0089 & 1\\
32 & 5 & 3 & 0.0055 & 0.0412 & 0.9533 & 3\\
\addlinespace
32 & 10 & 3 & 0.0488 & 0.1517 & 0.7995 & 3\\
32 & 20 & 2 & 0.5924 & 0.3200 & 0.0876 & 1\\
32 & 30 & 1 & 0.9131 & 0.0857 & 0.0012 & 1\\
42 & 5 & 1 & 0.1667 & 0.0536 & 0.7797 & 3\\
42 & 10 & 3 & 0.6335 & 0.0850 & 0.2815 & 1\\
\addlinespace
42 & 20 & 1 & 0.9734 & 0.0227 & 0.0039 & 1\\
42 & 30 & 1 & 0.9959 & 0.0040 & 0.0000 & 1\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{da}{%
\chapter{판별분석}\label{da}}

\hypertarget{da-overview}{%
\section{개요}\label{da-overview}}

판별분석(discriminant analysis)은 범주들을 가장 잘 구별하는 변수들의 하나 또는 다수의 함수를 도출하여 이를 기반으로 분류규칙을 제시한다. 본 장에서는 변수의 분포에 대한 가정이 필요 없는 피셔(Fisher) 방법과 다변량 정규분포를 가정하는 선형 및 비선형 판별분석을 설명한다.

\hypertarget{da-packages-install}{%
\section{필요 R 패키지 설치}\label{da-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.2.1\\
\hline
MASS & 7.3-51.4\\
\hline
mvtnorm & 1.0-10\\
\hline
\end{tabular}

\hypertarget{da-fisher}{%
\section{피셔 방법}\label{da-fisher}}

\hypertarget{da-fisher-basic-script}{%
\subsection{기본 R 스크립트}\label{da-fisher-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{id =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{9}\NormalTok{),}
  \DataTypeTok{x1 =} \KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{5}\NormalTok{),}
  \DataTypeTok{x2 =} \KeywordTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{4}\NormalTok{),}
  \DataTypeTok{class =} \KeywordTok{factor}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{)}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(train_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
             \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
             \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'$x_1$'}\NormalTok{, }\StringTok{'$x_2$'}\NormalTok{, }\StringTok{'범주'}\NormalTok{),}
             
             \DataTypeTok{caption =} \StringTok{'판별분석 학습표본 데이터'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:da-train-data-table}판별분석 학습표본 데이터}
\centering
\begin{tabular}{rrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 범주\\
\midrule
1 & 5 & 7 & 1\\
2 & 4 & 3 & 2\\
3 & 7 & 8 & 2\\
4 & 8 & 6 & 2\\
5 & 3 & 6 & 1\\
\addlinespace
6 & 2 & 5 & 1\\
7 & 6 & 6 & 1\\
8 & 9 & 6 & 2\\
9 & 5 & 4 & 2\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:da-train-data-table}와 같이 두 독립변수 \emph{x1}, \emph{x2}와 이분형 종속변수 \emph{class}의 관측값으로 이루어진 9개의 학습표본을 \emph{train\_df}라는 data frame에 저장한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fisher_da <-}\StringTok{ }\NormalTok{MASS}\OperatorTok{::}\KeywordTok{lda}\NormalTok{(class }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, train_df)}

\KeywordTok{print}\NormalTok{(fisher_da)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## lda(class ~ x1 + x2, data = train_df)
## 
## Prior probabilities of groups:
##         1         2 
## 0.4444444 0.5555556 
## 
## Group means:
##    x1  x2
## 1 4.0 6.0
## 2 6.6 5.4
## 
## Coefficients of linear discriminants:
##           LD1
## x1  0.6850490
## x2 -0.7003859
\end{verbatim}

\hypertarget{-}{%
\subsection{피셔 판별함수}\label{-}}

각 객체는 변수벡터 \(\mathbf{x} \in \mathbb{R}^p\)와 범주 \(y \in \{1, 2\}\)로 이루어진다고 하자. 아래는 변수 \(\mathbf{x}\)의 기대치와 분산-공분산행렬(varinace-covariance matrix)을 나타낸다.

\begin{eqnarray*}
\boldsymbol\mu_1 = E(\mathbf{x} | y = 1)\\
\boldsymbol\mu_2 = E(\mathbf{x} | y = 2)\\
\boldsymbol\Sigma = Var(\mathbf{x} | y = 1) = Var(\mathbf{x} | y = 2)
\end{eqnarray*}

다음과 같이 변수들의 선형조합으로 새로운 변수 \(z\)를 형성하는 함수를 피셔 판별함수(Fisher's discriminant function)라 한다.

\begin{equation}
z = \mathbf{w}^\top \mathbf{x} \label{eq:fisher-discriminant-function}
\end{equation}

여기서 계수벡터 \(\mathbf{w} \in \mathbb{R}^p\)는 통상 아래와 같이 변수 \(z\)의 범주간 평균 차이 대 변수 \(z\)의 분산의 비율을 최대화하는 것으로 결정한다.

\begin{equation}
{\arg\!\min}_{\mathbf{w}} \frac{\mathbf{w}^\top ( \boldsymbol\mu_1 - \boldsymbol\mu_2 )}{\mathbf{w}^\top \boldsymbol\Sigma \mathbf{w}} \label{eq:fisher-discriminant-function-coef}
\end{equation}

위 식 \eqref{eq:fisher-discriminant-function-coef}의 해는

\begin{equation*}
\mathbf{w} \propto \boldsymbol\Sigma^{-1}(\boldsymbol\mu_1 - \boldsymbol\mu_2)
\end{equation*}

의 조건을 만족하며, 편의상 비례상수를 1로 두면 아래와 같은 해가 얻어진다.

\begin{equation}
\mathbf{w} = \boldsymbol\Sigma^{-1}(\boldsymbol\mu_1 - \boldsymbol\mu_2) \label{eq:fisher-discriminant-function-coef-sol}
\end{equation}

실제 모집단의 평균 및 분산을 알지 못하는 경우, 학습표본으로부터 \(\boldsymbol\mu_1, \boldsymbol\mu_2, \boldsymbol\Sigma\)의 추정치를 얻어 식 \eqref{eq:fisher-discriminant-function-coef-sol}에 대입하는 방식으로 판별계수를 추정한다. 자세한 내용은 교재 \citep{jun2012datamining} 참조.

Table \ref{tab:da-train-data-table}에 주어진 학습표본을 이용하여 피셔 판별함수를 구해보도록 하자. 우선 각 범주별 평균벡터 \(\hat{\boldsymbol\mu}_1, \hat{\boldsymbol\mu}_2\)를 아래와 같이 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mu_hat <-}\StringTok{ }\NormalTok{train_df }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(class) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{x1 =} \KeywordTok{mean}\NormalTok{(x1),}
            \DataTypeTok{x2 =} \KeywordTok{mean}\NormalTok{(x2)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(class)}

\KeywordTok{print}\NormalTok{(mu_hat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 3
##   class    x1    x2
##   <fct> <dbl> <dbl>
## 1 1       4     6  
## 2 2       6.6   5.4
\end{verbatim}

또한 범주별 표본 분산-공분산행렬 \(\mathbf{S}_1, \mathbf{S}_2\)를 다음과 같이 구한다. 리스트 \texttt{S\_within\_group}의 첫번째 원소는 범주 1의 분산-공분산행렬 \(\mathbf{S}_1\), 두번째 원소는 범주 2의 분산-공분산행렬 \(\mathbf{S}_2\)를 나타낸다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{S_within_group <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(}
  \KeywordTok{unique}\NormalTok{(train_df}\OperatorTok{$}\NormalTok{class) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{sort}\NormalTok{(), }\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{    train_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(class }\OperatorTok{==}\StringTok{ }\NormalTok{x) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(x1, x2) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{var}\NormalTok{()}
\NormalTok{  \}}
\NormalTok{)}

\KeywordTok{print}\NormalTok{(S_within_group)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
##          x1        x2
## x1 3.333333 1.0000000
## x2 1.000000 0.6666667
## 
## [[2]]
##      x1   x2
## x1 4.30 2.95
## x2 2.95 3.80
\end{verbatim}

위에서 얻은 범주별 표본 분산-공분산행렬을 이용하여 합동 분산-공분산행렬을 아래와 같이 추정한다.

\begin{equation*}
\hat{\boldsymbol\Sigma} = \mathbf{S}_p = \frac{(n_1 - 1)\mathbf{S}_1 + (n_2 - 1)\mathbf{S}_2}{n_1 + n_2 - 2}
\end{equation*}

이 때 \(n_1, n_2\)는 각각 범주 1, 2에 속한 학습표본 객체의 수를 나타낸다. 아래 R 스크립트에서는 임의의 범주 표본수 벡터 \texttt{n}과 범주별 표본 분산-공분산행렬 리스트 \texttt{S}에 대해 합동 분산-공분산행렬을 구하는 함수 \texttt{pooled\_variance}를 정의하고, 주어진 학습표본에 대한 입력값을 대입하여 합동 분산-공분산행렬 추정치 \texttt{Sigma\_hat}을 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pooled_variance <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n, S) \{}
  \KeywordTok{lapply}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{length}\NormalTok{(n), }\ControlFlowTok{function}\NormalTok{(i) (n[i] }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)}\OperatorTok{*}\NormalTok{S[[i]]) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{Reduce}\NormalTok{(}\StringTok{`}\DataTypeTok{+}\StringTok{`}\NormalTok{, .) }\OperatorTok{%>%}
\StringTok{    `}\DataTypeTok{/}\StringTok{`}\NormalTok{(}\KeywordTok{sum}\NormalTok{(n) }\OperatorTok{-}\StringTok{ }\KeywordTok{length}\NormalTok{(n))}
\NormalTok{\}}

\NormalTok{n_obs <-}\StringTok{ }\NormalTok{train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(class) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pi =}\NormalTok{ n }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(n)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(class)}

\NormalTok{Sigma_hat <-}\StringTok{ }\KeywordTok{pooled_variance}\NormalTok{(n_obs}\OperatorTok{$}\NormalTok{n, S_within_group)}

\KeywordTok{print}\NormalTok{(Sigma_hat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          x1       x2
## x1 3.885714 2.114286
## x2 2.114286 2.457143
\end{verbatim}

위에서 구한 추정치들을 이용하여 아래와 같이 판별함수 계수 추정치 \(\hat{\mathbf{w}}\)를 구한다.

\begin{equation*}
\hat{\mathbf{w}} = \hat{\boldsymbol\Sigma}^{-1}(\hat{\boldsymbol\mu}_1 - \hat{\boldsymbol\mu}_2) 
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w_hat <-}\StringTok{ }\KeywordTok{solve}\NormalTok{(Sigma_hat) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{t}\NormalTok{(mu_hat[}\DecValTok{1}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{'x1'}\NormalTok{, }\StringTok{'x2'}\NormalTok{)] }\OperatorTok{-}\StringTok{ }\NormalTok{mu_hat[}\DecValTok{2}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{'x1'}\NormalTok{, }\StringTok{'x2'}\NormalTok{)])}

\KeywordTok{print}\NormalTok{(w_hat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         [,1]
## x1 -1.508039
## x2  1.541801
\end{verbatim}

\hypertarget{-}{%
\subsection{분류 규칙}\label{-}}

피셔 판별함수에 따른 분류 경계값은 학습표본에 대한 판별함수값의 평균으로 아래와 같이 구할 수 있다.

\begin{equation*}
\bar{z} = \frac{1}{N} \sum_i^N \hat{\mathbf{w}}^\top \mathbf{x}_i
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z_mean <-}\StringTok{ }\KeywordTok{t}\NormalTok{(w_hat) }\OperatorTok{%*%}\StringTok{ }\NormalTok{(train_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(x1, x2) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{colMeans}\NormalTok{()) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{drop}\NormalTok{()}

\KeywordTok{print}\NormalTok{(z_mean)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.526438
\end{verbatim}

위 결과를 통해, 분류규칙은 다음과 같이 주어진다.

\begin{itemize}
\tightlist
\item
  \(\hat{\mathbf{w}}^\top \mathbf{x} \ge \bar{z}\) 이면, \(\mathbf{x}\)를 범주 1로 분류
\item
  \(\hat{\mathbf{w}}^\top \mathbf{x} < \bar{z}\) 이면, \(\mathbf{x}\)를 범주 2로 분류
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_prediction_df <-}\StringTok{ }\NormalTok{train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{z =}\NormalTok{ w_hat[}\DecValTok{1}\NormalTok{]}\OperatorTok{*}\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{w_hat[}\DecValTok{2}\NormalTok{]}\OperatorTok{*}\NormalTok{x2,}
    \DataTypeTok{predicted_class =} \KeywordTok{factor}\NormalTok{(}\KeywordTok{if_else}\NormalTok{(z }\OperatorTok{>=}\StringTok{ }\NormalTok{z_mean, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{    )}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(train_prediction_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
             \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
             \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'$x_1$'}\NormalTok{, }\StringTok{'$x_2$'}\NormalTok{, }\StringTok{'실제범주'}\NormalTok{, }\StringTok{'$z$'}\NormalTok{, }\StringTok{'추정범주'}\NormalTok{),}
             \DataTypeTok{caption =} \StringTok{'학습표본에 대한 피셔 분류 결과'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:fisher-da-result}학습표본에 대한 피셔 분류 결과}
\centering
\begin{tabular}{rrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$z\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & 3.2524116 & 1\\
2 & 4 & 3 & 2 & -1.4067524 & 2\\
3 & 7 & 8 & 2 & 1.7781350 & 1\\
4 & 8 & 6 & 2 & -2.8135048 & 2\\
5 & 3 & 6 & 1 & 4.7266881 & 1\\
\addlinespace
6 & 2 & 5 & 1 & 4.6929260 & 1\\
7 & 6 & 6 & 1 & 0.2025723 & 2\\
8 & 9 & 6 & 2 & -4.3215434 & 2\\
9 & 5 & 4 & 2 & -1.3729904 & 2\\
\bottomrule
\end{tabular}
\end{table}

위 결과 객체 3, 7가 오분류된다.

\hypertarget{r----}{%
\subsection{R 패키지를 이용한 분류규칙 도출}\label{r----}}

패키지 \texttt{MASS}내의 함수 \texttt{lda} 수행 시 얻어지는 판별계수 \(\hat{\mathbf{w}}\)는 위 결과와는 사뭇 다른데, \texttt{lda} 함수의 경우 아래와 같이 1) 제약식을 포함하여 비례계수를 구하기 때문에 계수의 크기가 달라지며, 2) 목적함수를 최소화하는 대신 최대화하는 값을 찾기 때문에 부호가 달라진다.

\begin{equation*}
\begin{split}
\max \text{  } & \mathbf{w}^\top ( \boldsymbol\mu_1 - \boldsymbol\mu_2 )\\
\text{s.t. } & \mathbf{w}^\top \boldsymbol\Sigma \mathbf{w} = 1
\end{split}
\end{equation*}

이에 따른 \texttt{lda} 함수의 계수 추정 결과는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fisher_da <-}\StringTok{ }\NormalTok{MASS}\OperatorTok{::}\KeywordTok{lda}\NormalTok{(class }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, train_df)}

\NormalTok{w_hat_lda <-}\StringTok{ }\NormalTok{fisher_da}\OperatorTok{$}\NormalTok{scaling}
\KeywordTok{print}\NormalTok{(w_hat_lda)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           LD1
## x1  0.6850490
## x2 -0.7003859
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z_mean_lda <-}\StringTok{ }\KeywordTok{t}\NormalTok{(fisher_da}\OperatorTok{$}\NormalTok{scaling) }\OperatorTok{%*%}\StringTok{ }\NormalTok{(train_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(x1, x2) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{colMeans}\NormalTok{()) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{drop}\NormalTok{()}
\KeywordTok{print}\NormalTok{(z_mean_lda)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        LD1 
## -0.2391423
\end{verbatim}

위 결과는 아래와 같은 계산을 통해 앞 장에서 보았던 결과와 동일한 분류 경계식으로 표현될 수 있음을 볼 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{scale_adjust <-}\StringTok{ }\KeywordTok{t}\NormalTok{(w_hat) }\OperatorTok{%*%}\StringTok{ }\NormalTok{Sigma_hat }\OperatorTok{%*%}\StringTok{ }\NormalTok{w_hat }\OperatorTok{%>%}\StringTok{ }\KeywordTok{drop}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }\KeywordTok{sqrt}\NormalTok{()}
\NormalTok{sign_adjust <-}\StringTok{ }\DecValTok{-1}

\NormalTok{w_hat <-}\StringTok{ }\NormalTok{w_hat_lda }\OperatorTok{*}\StringTok{ }\NormalTok{scale_adjust }\OperatorTok{*}\StringTok{ }\NormalTok{sign_adjust}
\KeywordTok{print}\NormalTok{(w_hat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          LD1
## x1 -1.508039
## x2  1.541801
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z_mean <-}\StringTok{ }\NormalTok{z_mean_lda }\OperatorTok{*}\StringTok{ }\NormalTok{scale_adjust }\OperatorTok{*}\StringTok{ }\NormalTok{sign_adjust }
\KeywordTok{print}\NormalTok{(z_mean)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      LD1 
## 0.526438
\end{verbatim}

아래 스크립트는 위 \texttt{lda} 함수로부터의 경계식 추정을 기반으로 아래 수식값을 계산한다.

\begin{equation*}
\hat{\mathbf{w}}^\top \mathbf{x} - \bar{z}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{predict}\NormalTok{(fisher_da, train_df)}\OperatorTok{$}\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          LD1
## 1 -1.2383140
## 2  0.8781805
## 3 -0.5686020
## 4  1.5172187
## 5 -1.9080261
## 6 -1.8926892
## 7  0.1471208
## 8  2.2022677
## 9  0.8628436
\end{verbatim}

피셔 분류규칙에 따라 해당 값이 0보다 작으면 범주 1, 0보다 크면 범주 2로 분류한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{centered_z =} \KeywordTok{predict}\NormalTok{(fisher_da, .)}\OperatorTok{$}\NormalTok{x,}
    \DataTypeTok{predicted_class =} \KeywordTok{factor}\NormalTok{(}\KeywordTok{if_else}\NormalTok{(centered_z }\OperatorTok{<=}\StringTok{ }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
             \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
             \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'$x_1$'}\NormalTok{, }\StringTok{'$x_2$'}\NormalTok{, }
                           \StringTok{'실제범주'}\NormalTok{, }\StringTok{'$z - }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{bar\{z\}$'}\NormalTok{, }\StringTok{'추정범주'}\NormalTok{),}
             \DataTypeTok{caption =} \StringTok{'학습표본에 대한 피셔 분류 결과 - `MASS::lda` 분류 경계식 기준'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:fisher-da-result-lda}학습표본에 대한 피셔 분류 결과 - `MASS::lda` 분류 경계식 기준}
\centering
\begin{tabular}{rrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$z - \textbackslash{}bar\{z\}\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & -1.2383140 & 1\\
2 & 4 & 3 & 2 & 0.8781805 & 2\\
3 & 7 & 8 & 2 & -0.5686020 & 1\\
4 & 8 & 6 & 2 & 1.5172187 & 2\\
5 & 3 & 6 & 1 & -1.9080261 & 1\\
\addlinespace
6 & 2 & 5 & 1 & -1.8926892 & 1\\
7 & 6 & 6 & 1 & 0.1471208 & 2\\
8 & 9 & 6 & 2 & 2.2022677 & 2\\
9 & 5 & 4 & 2 & 0.8628436 & 2\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:fisher-da-result-lda}는 Table \ref{tab:fisher-da-result}와 동일한 범주 추정 결과를 보인다.

\hypertarget{lda}{%
\section{의사결정론에 의한 선형분류규칙}\label{lda}}

다음과 같이 객체가 각 범주에 속할 사전확률과 각 범주 내에서의 분류변수의 확률밀도함수에 대한 기호를 정의한다.

\begin{itemize}
\tightlist
\item
  \(\pi_k\): 임의의 객체가 범주 \(k\)에 속할 사전확률
\item
  \(f_k(\mathbf{x})\): 범주 \(k\)에 대한 변수의 확률밀도함수
\end{itemize}

이 때 통상적으로 \(\mathbf{x}\)는 다변량 정규분포를 따르는 것으로 가정하여 아래와 같이 평균벡터 \(\boldsymbol\mu_k\)와 분산-공분산행렬 \(\boldsymbol\Sigma\)로 확률밀도함수를 정의할 수 있다. 이 때 분산-공분산행렬 \(\boldsymbol\Sigma\)는 모든 범주에 대해 동일하다고 가정한다.

\begin{equation}
f_k(\mathbf{x}) = \frac{1}{(2\pi)^{p/2}|\boldsymbol\Sigma|^{1/2}} \exp \{ -\frac{1}{2} \left(\mathbf{x} - \boldsymbol\mu_k\right)^\top \boldsymbol\Sigma^{-1} \left(\mathbf{x} - \boldsymbol\mu_k\right) \}
\label{eq:mv-gaussian-dist}
\end{equation}

본 장에서는 두 범주(\(k = 1, 2\)) 분류 문제만 다루며, 세 범주 이상에 대한 분류 문제는 뒷 장에서 추가적으로 다루기로 한다.

\hypertarget{lda-basic-script}{%
\subsection{기본 R 스크립트}\label{lda-basic-script}}

Table \ref{tab:da-train-data-table}의 학습표본에 대해 선형판별분석을 적용하는 R 스크립트는 아래에 보이는 것처럼 피셔 판별함수를 구하기 위한 동일하며, \texttt{prior} 파라미터를 정의하지 않음으로써 \(\pi_1\)과 \(\pi_2\)를 학습표본의 범주 1, 2의 비율로 설정한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lda_fit <-}\StringTok{ }\NormalTok{MASS}\OperatorTok{::}\KeywordTok{lda}\NormalTok{(class }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, train_df)}

\KeywordTok{print}\NormalTok{(lda_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## lda(class ~ x1 + x2, data = train_df)
## 
## Prior probabilities of groups:
##         1         2 
## 0.4444444 0.5555556 
## 
## Group means:
##    x1  x2
## 1 4.0 6.0
## 2 6.6 5.4
## 
## Coefficients of linear discriminants:
##           LD1
## x1  0.6850490
## x2 -0.7003859
\end{verbatim}

\hypertarget{lda-function}{%
\subsection{선형판별함수}\label{lda-function}}

두 범주 문제에 있어서, 범주를 알지 못하는 변수 \(\mathbf{x}\)에 대한 확률밀도함수는 아래와 같다.

\begin{equation*}
f(\mathbf{x}) = \pi_1 f_1(\mathbf{x}) + \pi_2 f_2(\mathbf{x})
\end{equation*}

베이즈 정리(Bayes's theorem)에 따라 변수 \(\mathbf{x}\)값이 주어졌을 때 범주 \(k\)에 속할 사후확률(posterior)은 아래와 같이 구할 수 있다.

\begin{equation}
P(y = k \, | \, \mathbf{x}) = \frac{\pi_k f_k(\mathbf{x})}{f(\mathbf{x})}
\label{eq:lda-posterior}
\end{equation}

각 범주에 대한 사후확률을 계산하여, 확률이 높은 쪽으로 범주를 추정한다.

\begin{equation}
\hat{y} = \begin{cases}
    1, & \text{if } P(y = 1 \, | \, \mathbf{x}) \ge P(y = 2 \, | \, \mathbf{x})\\
    2, & \text{otherwise}
\end{cases}
\label{eq:lda-posterior-rule}
\end{equation}

이를 다시 정리하면 아래와 같다.

\begin{equation*}
\hat{y} = \begin{cases}
    1, & \text{if } \frac{f_1(\mathbf{x})}{f_2(\mathbf{x})} \ge \frac{\pi_2}{\pi_1}\\
    2, & \text{otherwise}
\end{cases}
\end{equation*}

위 분류규칙에 식 \eqref{eq:mv-gaussian-dist}을 대입하여 정리하면 다음과 같다. 보다 자세한 내용은 교재 \citep{jun2012datamining} 참조.

\begin{equation*}
\hat{y} = \begin{cases}
    1, & \text{if } \boldsymbol\mu_1^\top \boldsymbol\Sigma^{-1}\mathbf{x} - \frac{1}{2} \boldsymbol\mu_1^\top \boldsymbol\Sigma^{-1} \boldsymbol\mu_1 + \ln \pi_1 \ge \boldsymbol\mu_2^\top \boldsymbol\Sigma^{-1}\mathbf{x} - \frac{1}{2} \boldsymbol\mu_2^\top \boldsymbol\Sigma^{-1} \boldsymbol\mu_2 + \ln \pi_2  \\
    2, & \text{otherwise}
\end{cases}
\end{equation*}

따라서, 각 범주에 대한 판별함수를

\begin{equation}
u_k(\mathbf{x}) = \boldsymbol\mu_k^\top \boldsymbol\Sigma^{-1}\mathbf{x} - \frac{1}{2} \boldsymbol\mu_k^\top \boldsymbol\Sigma^{-1} \boldsymbol\mu_k + \ln \pi_k
\label{eq:lda-discriminant-function}
\end{equation}

라 하면, 아래와 같이 분류규칙을 정의할 수 있다.

\begin{equation}
\hat{y} = \begin{cases}
    1, & \text{if } u_1(\mathbf{x}) \ge u_2(\mathbf{x})  \\
    2, & \text{otherwise}
\end{cases}
\label{eq:lda-discriminant-rule}
\end{equation}

Table \ref{tab:da-train-data-table}의 학습표본에 대해 판별함수값을 계산하고 범주를 추정하면 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{discriminant_func <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(X, mu, Sigma, pi) \{}
\NormalTok{  Sigma_inv <-}\StringTok{ }\KeywordTok{solve}\NormalTok{(Sigma)}
\NormalTok{  (}\KeywordTok{t}\NormalTok{(mu) }\OperatorTok{%*%}\StringTok{ }\NormalTok{Sigma_inv }\OperatorTok{%*%}\StringTok{ }\NormalTok{X }\OperatorTok{%>%}\StringTok{ }\KeywordTok{drop}\NormalTok{()) }\OperatorTok{-}\StringTok{  }
\StringTok{    }\FloatTok{0.5} \OperatorTok{*}\StringTok{ }\NormalTok{(}\KeywordTok{t}\NormalTok{(mu) }\OperatorTok{%*%}\StringTok{ }\NormalTok{Sigma_inv }\OperatorTok{%*%}\StringTok{ }\NormalTok{mu }\OperatorTok{%>%}\StringTok{ }\KeywordTok{drop}\NormalTok{()) }\OperatorTok{+}\StringTok{ }
\StringTok{    }\KeywordTok{log}\NormalTok{(pi)}
\NormalTok{\}}

\NormalTok{lda_discriminant_result_df <-}\StringTok{ }\NormalTok{train_df }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{u1 =} \KeywordTok{discriminant_func}\NormalTok{(}
\NormalTok{      .[}\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{t}\NormalTok{(),}
\NormalTok{      mu_hat[}\DecValTok{1}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unlist}\NormalTok{(),}
\NormalTok{      Sigma_hat,}
\NormalTok{      n_obs}\OperatorTok{$}\NormalTok{pi[}\DecValTok{1}\NormalTok{]}
\NormalTok{      ),}
    \DataTypeTok{u2 =} \KeywordTok{discriminant_func}\NormalTok{(}
\NormalTok{      .[}\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{t}\NormalTok{(),}
\NormalTok{      mu_hat[}\DecValTok{2}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unlist}\NormalTok{(),}
\NormalTok{      Sigma_hat,}
\NormalTok{      n_obs}\OperatorTok{$}\NormalTok{pi[}\DecValTok{2}\NormalTok{]}
\NormalTok{      )}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{predicted_class =} \KeywordTok{factor}\NormalTok{(}\KeywordTok{if_else}\NormalTok{(u1 }\OperatorTok{>=}\StringTok{ }\NormalTok{u2, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{    )}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  lda_discriminant_result_df,}
  \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{align =} \KeywordTok{rep}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\KeywordTok{dim}\NormalTok{(lda_discriminant_result_df)[}\DecValTok{2}\NormalTok{]),}
  \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'$x_1$'}\NormalTok{, }\StringTok{'$x_2$'}\NormalTok{,}
                \StringTok{'실제범주'}\NormalTok{, }\StringTok{'$u_1(}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$'}\NormalTok{, }\StringTok{'$u_2(}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$'}\NormalTok{,}
                \StringTok{'추정범주'}\NormalTok{),}
  \DataTypeTok{caption =} \StringTok{'학습표본에 대한 LDA 적용 결과: 판별함수값 및 추정범주'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:lda-disriminant-result}학습표본에 대한 LDA 적용 결과: 판별함수값 및 추정범주}
\centering
\begin{tabular}{rrrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$u\_1(\textbackslash{}mathbf\{x\})\$ & \$u\_2(\textbackslash{}mathbf\{x\})\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & 9.2051470 & 6.971538 & 1\\
2 & 4 & 3 & 2 & -1.9363321 & 0.489223 & 2\\
3 & 7 & 8 & 2 & 11.0057900 & 10.246458 & 1\\
4 & 8 & 6 & 2 & 4.5909990 & 8.423307 & 2\\
5 & 3 & 6 & 1 & 7.4045039 & 3.696619 & 1\\
\addlinespace
6 & 2 & 5 & 1 & 5.0411598 & 1.367036 & 1\\
7 & 6 & 6 & 1 & 5.7164010 & 6.532631 & 2\\
8 & 9 & 6 & 2 & 4.0282981 & 9.368644 & 2\\
9 & 5 & 4 & 2 & 0.4270119 & 2.818805 & 2\\
\bottomrule
\end{tabular}
\end{table}

또한 식 \eqref{eq:lda-posterior}에 따른 사후확률과 식 \eqref{eq:lda-posterior-rule}에 따른 추정범주는 아래와 같이 얻어진다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lda_posterior_result_df <-}\StringTok{ }\NormalTok{train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{f1 =}\NormalTok{ mvtnorm}\OperatorTok{::}\KeywordTok{dmvnorm}\NormalTok{(}
\NormalTok{      .[}\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)],}
\NormalTok{      mu_hat[}\DecValTok{1}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unlist}\NormalTok{(),}
\NormalTok{      Sigma_hat),}
    \DataTypeTok{f2 =}\NormalTok{ mvtnorm}\OperatorTok{::}\KeywordTok{dmvnorm}\NormalTok{(}
\NormalTok{      .[}\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)],}
\NormalTok{      mu_hat[}\DecValTok{2}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unlist}\NormalTok{(),}
\NormalTok{      Sigma_hat),}
    \DataTypeTok{f =}\NormalTok{ n_obs}\OperatorTok{$}\NormalTok{pi[}\DecValTok{1}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{f1 }\OperatorTok{+}\StringTok{ }\NormalTok{n_obs}\OperatorTok{$}\NormalTok{pi[}\DecValTok{2}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{f2}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{p1 =}\NormalTok{ n_obs}\OperatorTok{$}\NormalTok{pi[}\DecValTok{1}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{f1 }\OperatorTok{/}\StringTok{ }\NormalTok{f,}
    \DataTypeTok{p2 =}\NormalTok{ n_obs}\OperatorTok{$}\NormalTok{pi[}\DecValTok{2}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{f2 }\OperatorTok{/}\StringTok{ }\NormalTok{f}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{predicted_class =} \KeywordTok{factor}\NormalTok{(}\KeywordTok{if_else}\NormalTok{(p1 }\OperatorTok{>=}\StringTok{ }\NormalTok{p2, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}
\NormalTok{    id, x1, x2, class, p1, p2, predicted_class}
\NormalTok{  )}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  lda_posterior_result_df,}
  \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{align =} \KeywordTok{rep}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\KeywordTok{dim}\NormalTok{(lda_posterior_result_df)[}\DecValTok{2}\NormalTok{]),}
  \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'$x_1$'}\NormalTok{, }\StringTok{'$x_2$'}\NormalTok{,}
                \StringTok{'실제범주'}\NormalTok{, }
                \StringTok{'$P(y = 1 | }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$'}\NormalTok{, }
                \StringTok{'$P(y = 2 | }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$'}\NormalTok{,}
                \StringTok{'추정범주'}\NormalTok{),}
  \DataTypeTok{caption =} \StringTok{'학습표본에 대한 LDA 적용 결과: 사후확률 및 추정범주'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:lda-posterior-result}학습표본에 대한 LDA 적용 결과: 사후확률 및 추정범주}
\centering
\begin{tabular}{rrrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$P(y = 1 | \textbackslash{}mathbf\{x\})\$ & \$P(y = 2 | \textbackslash{}mathbf\{x\})\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & 0.9032273 & 0.0967727 & 1\\
2 & 4 & 3 & 2 & 0.0812446 & 0.9187554 & 2\\
3 & 7 & 8 & 2 & 0.6812088 & 0.3187912 & 1\\
4 & 8 & 6 & 2 & 0.0212004 & 0.9787996 & 2\\
5 & 3 & 6 & 1 & 0.9760579 & 0.0239421 & 1\\
\addlinespace
6 & 2 & 5 & 1 & 0.9752562 & 0.0247438 & 1\\
7 & 6 & 6 & 1 & 0.3065644 & 0.6934356 & 2\\
8 & 9 & 6 & 2 & 0.0047713 & 0.9952287 & 2\\
9 & 5 & 4 & 2 & 0.0838007 & 0.9161993 & 2\\
\bottomrule
\end{tabular}
\end{table}

패키지 \texttt{MASS}내의 함수 \texttt{lda}를 통해 위 Table \ref{tab:lda-posterior-result} 결과를 간편하게 얻을 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lda_fit <-}\StringTok{ }\NormalTok{MASS}\OperatorTok{::}\KeywordTok{lda}\NormalTok{(class }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, train_df)}

\NormalTok{train_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{bind_cols}\NormalTok{(}
  \KeywordTok{predict}\NormalTok{(lda_fit, train_df)}\OperatorTok{$}\NormalTok{posterior }\OperatorTok{%>%}\StringTok{ }
\StringTok{    `}\DataTypeTok{colnames<-}\StringTok{`}\NormalTok{(}\KeywordTok{paste0}\NormalTok{(}\StringTok{"p"}\NormalTok{, }\KeywordTok{colnames}\NormalTok{(.))) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as_data_frame}\NormalTok{()}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{predicted_class =} \KeywordTok{predict}\NormalTok{(lda_fit, .)}\OperatorTok{$}\NormalTok{class}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 9 x 7
##      id    x1    x2 class      p1     p2 predicted_class
##   <int> <dbl> <dbl> <fct>   <dbl>  <dbl> <fct>          
## 1     1     5     7 1     0.903   0.0968 1              
## 2     2     4     3 2     0.0812  0.919  2              
## 3     3     7     8 2     0.681   0.319  1              
## 4     4     8     6 2     0.0212  0.979  2              
## 5     5     3     6 1     0.976   0.0239 1              
## 6     6     2     5 1     0.975   0.0247 1              
## 7     7     6     6 1     0.307   0.693  2              
## 8     8     9     6 2     0.00477 0.995  2              
## 9     9     5     4 2     0.0838  0.916  2
\end{verbatim}

위 결과들은 교재 \citep{jun2012datamining}의 예제 결과와는 다소 차이가 있는데, 이는 교재에서는 사전확률을 학습표본 내 비율 대신 \(\pi_1 = \pi_2 = 0.5\)로 지정하였기 때문이다. 교재와 동일한 결과는 아래의 스크립트처럼 \texttt{lda} 함수 실행 시 사전확률 파리미터 \texttt{prior}의 값을 지정함으로써 얻을 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lda_fit_equal_prior <-}\StringTok{ }\NormalTok{MASS}\OperatorTok{::}\KeywordTok{lda}\NormalTok{(class }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, train_df, }\DataTypeTok{prior =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\DecValTok{2}\NormalTok{, }\DecValTok{1}\OperatorTok{/}\DecValTok{2}\NormalTok{))}

\NormalTok{train_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{bind_cols}\NormalTok{(}
  \KeywordTok{predict}\NormalTok{(lda_fit_equal_prior, train_df)}\OperatorTok{$}\NormalTok{posterior }\OperatorTok{%>%}\StringTok{ }
\StringTok{    `}\DataTypeTok{colnames<-}\StringTok{`}\NormalTok{(}\KeywordTok{paste0}\NormalTok{(}\StringTok{"p"}\NormalTok{, }\KeywordTok{colnames}\NormalTok{(.))) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as_data_frame}\NormalTok{()}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{predicted_class =} \KeywordTok{predict}\NormalTok{(lda_fit_equal_prior, .)}\OperatorTok{$}\NormalTok{class}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{rep}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\KeywordTok{dim}\NormalTok{(lda_posterior_result_df)[}\DecValTok{2}\NormalTok{]),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'$x_1$'}\NormalTok{, }\StringTok{'$x_2$'}\NormalTok{,}
                \StringTok{'실제범주'}\NormalTok{, }
                \StringTok{'$P(y = 1 | }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$'}\NormalTok{, }
                \StringTok{'$P(y = 2 | }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$'}\NormalTok{,}
                \StringTok{'추정범주'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'학습표본에 대한 LDA 적용 결과: 사후확률 및 추정범주 (사전확률 = 0.5)'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:lda-posterior-result-equal-prior}학습표본에 대한 LDA 적용 결과: 사후확률 및 추정범주 (사전확률 = 0.5)}
\centering
\begin{tabular}{rrrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$P(y = 1 | \textbackslash{}mathbf\{x\})\$ & \$P(y = 2 | \textbackslash{}mathbf\{x\})\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & 0.9210538 & 0.0789462 & 1\\
2 & 4 & 3 & 2 & 0.0995341 & 0.9004659 & 2\\
3 & 7 & 8 & 2 & 0.7275992 & 0.2724008 & 1\\
4 & 8 & 6 & 2 & 0.0263608 & 0.9736392 & 2\\
5 & 3 & 6 & 1 & 0.9807542 & 0.0192458 & 1\\
\addlinespace
6 & 2 & 5 & 1 & 0.9801065 & 0.0198935 & 1\\
7 & 6 & 6 & 1 & 0.3559269 & 0.6440731 & 2\\
8 & 9 & 6 & 2 & 0.0059571 & 0.9940429 & 2\\
9 & 5 & 4 & 2 & 0.1026013 & 0.8973987 & 2\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{lda-misclassification-cost}{%
\section{오분류비용을 고려한 분류규칙}\label{lda-misclassification-cost}}

위 Table \ref{tab:lda-posterior-result}의 객체 3, 7와 같이 선형분류함수가 모든 객체의 범주를 정확하게 추정하지 못하고 오분류가 발생하는 경우가 있다. 이 때 다음과 같이 두 종류의 오분류 비용이 있다고 가정하자.

\begin{itemize}
\tightlist
\item
  \(C(1 \, | \, 2)\): 범주 2를 1로 잘못 분류 시 초래 비용
\item
  \(C(2 \, | \, 1)\): 범주 1를 2로 잘못 분류 시 초래 비용
\end{itemize}

이 때 총 기대 오분류 비용은 다음과 같다.

\begin{equation}
C(1 \, | \, 2) \pi_2 \int_{\mathbf{x} \in R_1} f_2(\mathbf{x}) d\mathbf{x} + C(2 \, | \, 1) \pi_1 \int_{\mathbf{x} \in R_2} f_1(\mathbf{x}) d\mathbf{x}
\label{eq:expected-misclassification-cost}
\end{equation}

여기에서 \(R_1 \subset \mathbb{R}^p, R_2 = \mathbb{R}^p - R_{1}\)는 판별함수에 의해 각각 범주 1, 2로 분류되는 판별변수 영역을 나타낸다. 즉,

\begin{equation*}
\hat{y} = \begin{cases}
    1, & \text{if } \mathbf{x} \in R_1  \\
    2, & \text{otherwise}
\end{cases}
\end{equation*}

식 \eqref{eq:expected-misclassification-cost}을 최소화하는 영역 \(R_1, R_2\)는 아래와 같다.

\begin{eqnarray*}
R_1 &=& \left\{\mathbf{x} \in \mathbb{R}^p \, :  \, \frac{f_1(\mathbf{x})}{f_2(\mathbf{x})} \ge \frac{\pi_2}{\pi_1} \left( \frac{C(1 \, | \, 2)}{C(2 \, | \, 1)} \right) \right\}\\
R_2 &=& \left\{\mathbf{x} \in \mathbb{R}^p \, :  \, \frac{f_1(\mathbf{x})}{f_2(\mathbf{x})} < \frac{\pi_2}{\pi_1} \left( \frac{C(1 \, | \, 2)}{C(2 \, | \, 1)} \right) \right\}
\end{eqnarray*}

위 중 \(R_1\)에 대한 식을 아래와 같이 단계적으로 전개할 수 있다.

\begin{eqnarray*}
R_1 &=& \left\{\mathbf{x} \in \mathbb{R}^p \, :  \, \frac{\pi_1 f_1(\mathbf{x})}{\pi_2 f_2(\mathbf{x})} \ge \frac{C(1 \, | \, 2)}{C(2 \, | \, 1)} \right\}\\
&=& \left\{\mathbf{x} \in \mathbb{R}^p \, :  \, \frac{\frac{\pi_1 f_1(\mathbf{x})}{\pi_1 f_1(\mathbf{x}) + \pi_2 f_2(\mathbf{x})}}{\frac{\pi_2 f_2(\mathbf{x})}{\pi_1 f_1(\mathbf{x}) + \pi_2 f_2(\mathbf{x})}} \ge \frac{C(1 \, | \, 2)}{C(2 \, | \, 1)} \right\}\\
&=& \left\{\mathbf{x} \in \mathbb{R}^p \, :  \, \frac{P(y = 1 \, | \, \mathbf{x})}{P(y = 2 \, | \, \mathbf{x})} \ge \frac{C(1 \, | \, 2)}{C(2 \, | \, 1)} \right\}\\
&=& \left\{\mathbf{x} \in \mathbb{R}^p \, :  \, C(2 \, | \, 1) P(y = 1 \, | \, \mathbf{x}) \ge C(1 \, | \, 2) P(y = 2 \, | \, \mathbf{x}) \right\}
\end{eqnarray*}

따라서 오분류비용을 고려한 분류규칙은 1) 사후확률에 오분류 비용을 곱한 뒤, 2) 그 값이 큰 범주로 분류하여 오분류비용을 최소화한다.

Table \ref{tab:lda-posterior-result}에 오분류비용 \(C(1 \, | \, 2) = 1, C(2 \, | \, 1) = 5\)를 적용한 결과는 아래와 같이 구할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lda_fit <-}\StringTok{ }\NormalTok{MASS}\OperatorTok{::}\KeywordTok{lda}\NormalTok{(class }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, train_df)}

\NormalTok{misclassification_cost <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{)}

\NormalTok{lda_unequal_cost_result_df <-}\StringTok{ }\NormalTok{train_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{bind_cols}\NormalTok{(}
  \KeywordTok{predict}\NormalTok{(lda_fit, train_df)}\OperatorTok{$}\NormalTok{posterior }\OperatorTok{%*%}\StringTok{ }\KeywordTok{diag}\NormalTok{(misclassification_cost) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{as_data_frame}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    `}\DataTypeTok{names<-}\StringTok{`}\NormalTok{(}\KeywordTok{paste0}\NormalTok{(}\StringTok{"s"}\NormalTok{, lda_fit}\OperatorTok{$}\NormalTok{lev)) }
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{predicted_class =} \KeywordTok{factor}\NormalTok{(}\KeywordTok{if_else}\NormalTok{(s1 }\OperatorTok{>=}\StringTok{ }\NormalTok{s2, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{    )}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  lda_unequal_cost_result_df,}
  \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{align =} \KeywordTok{rep}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\KeywordTok{dim}\NormalTok{(lda_unequal_cost_result_df)[}\DecValTok{2}\NormalTok{]),}
  \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'$x_1$'}\NormalTok{, }\StringTok{'$x_2$'}\NormalTok{,}
                \StringTok{'실제범주'}\NormalTok{, }
                \StringTok{'$C(2 }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{, | }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{, 1) P(y = 1 | }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$'}\NormalTok{, }
                \StringTok{'$C(1 }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{, | }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{, 2) P(y = 2 | }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$'}\NormalTok{,}
                \StringTok{'추정범주'}\NormalTok{),}
  \DataTypeTok{caption =} \StringTok{'학습표본에 대한 오분류 비용을 고려한 LDA 적용 결과'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:lda-unequal-cost-result}학습표본에 대한 오분류 비용을 고려한 LDA 적용 결과}
\centering
\begin{tabular}{rrrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$C(2 \textbackslash{}, | \textbackslash{}, 1) P(y = 1 | \textbackslash{}mathbf\{x\})\$ & \$C(1 \textbackslash{}, | \textbackslash{}, 2) P(y = 2 | \textbackslash{}mathbf\{x\})\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & 4.5161363 & 0.0967727 & 1\\
2 & 4 & 3 & 2 & 0.4062232 & 0.9187554 & 2\\
3 & 7 & 8 & 2 & 3.4060438 & 0.3187912 & 1\\
4 & 8 & 6 & 2 & 0.1060019 & 0.9787996 & 2\\
5 & 3 & 6 & 1 & 4.8802897 & 0.0239421 & 1\\
\addlinespace
6 & 2 & 5 & 1 & 4.8762808 & 0.0247438 & 1\\
7 & 6 & 6 & 1 & 1.5328222 & 0.6934356 & 1\\
8 & 9 & 6 & 2 & 0.0238567 & 0.9952287 & 2\\
9 & 5 & 4 & 2 & 0.4190033 & 0.9161993 & 2\\
\bottomrule
\end{tabular}
\end{table}

위 Table \ref{tab:lda-unequal-cost-result}에서 보는 바와 같이 오분류 객체는 3로, 이전 장의 Table \ref{tab:lda-posterior-result}에 비해 실제범주가 1인 객체를 더 정확하게 분류함을 확인할 수 있다. 범주 1인 객체를 범주 2로 분류할 때 발생하는 비용이 범주 2인 객체를 범주 1로 분류할 때 발생하는 비용보다 다섯 배나 크기 때문에, 오분류비용을 고려한 분류규칙은 실제 범주가 2인 객체를 범주 2로 정확하게 분류할 확률이 줄어든다 할지라도, 실제 범주가 1인 객체를 범주 1로 정확하게 분류하는 확률을 높이는 방향으로 학습된다.

\hypertarget{qda}{%
\section{이차판별분석}\label{qda}}

이차판별분석은 판별함수가 변수들에 대한 이차함수로 표현되는 경우인데, 각 범주에 대한 변수벡터 \(\mathbf{x}\)가 서로 다른 분산-공분산행렬을 갖는 다변량 정규분포를 따를 때 의사결정론에 의한 분류규칙으로부터 유도된다.

\hypertarget{qda-basic-script}{%
\subsection{기본 R 스크립트}\label{qda-basic-script}}

Table \ref{tab:da-train-data-table}의 학습표본에 대해 이차판별분석을 적용하는 R 스크립트는 아래에 보이는 것과 같이 \texttt{MASS} 패키지의 \texttt{qda} 함수를 사용한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qda_fit <-}\StringTok{ }\NormalTok{MASS}\OperatorTok{::}\KeywordTok{qda}\NormalTok{(class }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, train_df)}

\KeywordTok{print}\NormalTok{(qda_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## qda(class ~ x1 + x2, data = train_df)
## 
## Prior probabilities of groups:
##         1         2 
## 0.4444444 0.5555556 
## 
## Group means:
##    x1  x2
## 1 4.0 6.0
## 2 6.6 5.4
\end{verbatim}

\hypertarget{qda-function}{%
\subsection{이차 판별함수}\label{qda-function}}

각 범주의 확률밀도함수는 아래와 같이 다변량 정규분포로 정의된다.

\begin{equation}
f_k(\mathbf{x}) = \frac{1}{(2\pi)^{p/2}|\boldsymbol\Sigma_k|^{1/2}} \exp \{ -\frac{1}{2} \left(\mathbf{x} - \boldsymbol\mu_k\right)^\top \boldsymbol\Sigma_k^{-1} \left(\mathbf{x} - \boldsymbol\mu_k\right) \}
\label{eq:qda-mv-gaussian-dist}
\end{equation}

위 식 \eqref{eq:qda-mv-gaussian-dist}이 선형판별함수에서 사용한 식 \eqref{eq:mv-gaussian-dist}과 다른 부분은 분산-공분산분포 \(\boldsymbol\Sigma_k\)가 범주 \(k\)에 대해 각각 정의된다는 점이다.

이 경우 각 범주에 대한 판별함수는 아래와 같이 정의된다.

\begin{equation}
u_k(\mathbf{x}) = - \frac{1}{2} (\mathbf{x} - \boldsymbol\mu_k)^\top \boldsymbol\Sigma^{-1} (\mathbf{x} - \boldsymbol\mu_k) - \frac{1}{2} \ln \left| \boldsymbol\Sigma_k \right| + \ln \pi_k
\label{eq:qda-discriminant-function}
\end{equation}

데이터 행렬 \(X = (\mathbf{x}_1, \mathbf{x}_2, \cdots , \mathbf{x}_N)\)의 각 객체에 대한 판별함수값을 얻는 함수를 아래와 같이 구현할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qda_discriminant_func <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(X, mu, Sigma, pi) \{}
\NormalTok{  Sigma_inv_sqrt <-}\StringTok{ }\KeywordTok{chol}\NormalTok{(}\KeywordTok{solve}\NormalTok{(Sigma))}
  \OperatorTok{-}\StringTok{ }\FloatTok{0.5} \OperatorTok{*}\StringTok{ }\KeywordTok{rowSums}\NormalTok{((}\KeywordTok{t}\NormalTok{(X }\OperatorTok{-}\StringTok{ }\NormalTok{mu) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{t}\NormalTok{(Sigma_inv_sqrt))}\OperatorTok{^}\DecValTok{2}\NormalTok{) }\OperatorTok{-}\StringTok{ }\FloatTok{0.5} \OperatorTok{*}\StringTok{ }\KeywordTok{log}\NormalTok{(}\KeywordTok{det}\NormalTok{(Sigma)) }\OperatorTok{+}\StringTok{ }\KeywordTok{log}\NormalTok{(pi)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{qda-discriminant-rule}{%
\subsection{이차판별함수에 의한 분류}\label{qda-discriminant-rule}}

분류기준은 선형판별분석과 마찬가지로 판별함수값이 큰 범주로 분류한다.

\begin{equation*}
\hat{y} = \begin{cases}
    1, & \text{if } u_1(\mathbf{x}) \ge u_2(\mathbf{x})  \\
    2, & \text{otherwise}
\end{cases}
\end{equation*}

Table \ref{tab:da-train-data-table}의 학습표본에 대해 이차판별함수값을 계산하고 범주를 추정하면 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qda_discriminant_result_df <-}\StringTok{ }\NormalTok{train_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mutate}\NormalTok{(}
  \DataTypeTok{u1 =} \KeywordTok{qda_discriminant_func}\NormalTok{(}
\NormalTok{      .[}\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{t}\NormalTok{(),}
\NormalTok{      mu_hat[}\DecValTok{1}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unlist}\NormalTok{(),}
\NormalTok{      S_within_group[[}\DecValTok{1}\NormalTok{]],}
\NormalTok{      n_obs}\OperatorTok{$}\NormalTok{pi[}\DecValTok{1}\NormalTok{]}
\NormalTok{      ),}
  \DataTypeTok{u2 =} \KeywordTok{qda_discriminant_func}\NormalTok{(}
\NormalTok{      .[}\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{t}\NormalTok{(),}
\NormalTok{      mu_hat[}\DecValTok{2}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unlist}\NormalTok{(),}
\NormalTok{      S_within_group[[}\DecValTok{2}\NormalTok{]],}
\NormalTok{      n_obs}\OperatorTok{$}\NormalTok{pi[}\DecValTok{2}\NormalTok{]}
\NormalTok{      )}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{predicted_class =} \KeywordTok{factor}\NormalTok{(}\KeywordTok{if_else}\NormalTok{(u1 }\OperatorTok{>=}\StringTok{ }\NormalTok{u2, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{  )}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  qda_discriminant_result_df,}
  \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{align =} \KeywordTok{rep}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\KeywordTok{dim}\NormalTok{(qda_discriminant_result_df)[}\DecValTok{2}\NormalTok{]),}
  \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'$x_1$'}\NormalTok{, }\StringTok{'$x_2$'}\NormalTok{,}
                \StringTok{'실제범주'}\NormalTok{, }\StringTok{'$u_1(}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$'}\NormalTok{, }\StringTok{'$u_2(}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$'}\NormalTok{,}
                \StringTok{'추정범주'}\NormalTok{),}
  \DataTypeTok{caption =} \StringTok{'학습표본에 대한 QDA 적용 결과: 판별함수값 및 추정범주'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:qda-discriminant-result}학습표본에 대한 QDA 적용 결과: 판별함수값 및 추정범주}
\centering
\begin{tabular}{rrrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$u\_1(\textbackslash{}mathbf\{x\})\$ & \$u\_2(\textbackslash{}mathbf\{x\})\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & -1.729447 & -3.950639 & 1\\
2 & 4 & 3 & 2 & -13.183993 & -2.497284 & 2\\
3 & 7 & 8 & 2 & -3.911266 & -3.145402 & 2\\
4 & 8 & 6 & 2 & -5.274902 & -1.868806 & 2\\
5 & 3 & 6 & 1 & -1.183993 & -5.764060 & 1\\
\addlinespace
6 & 2 & 5 & 1 & -1.729447 & -6.202685 & 1\\
7 & 6 & 6 & 1 & -2.002175 & -1.934273 & 2\\
8 & 9 & 6 & 2 & -7.729447 & -2.582391 & 2\\
9 & 5 & 4 & 2 & -8.274902 & -1.927726 & 2\\
\bottomrule
\end{tabular}
\end{table}

위 Table \ref{tab:qda-discriminant-result}에서 보듯이 모든 학습객체가 올바로 분류되고 있다.

또한 선형판별분석의 경우와 마찬가지로 사후확률 비교를 통한 범주 분류를 수행할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qda_posterior_result_df <-}\StringTok{ }\NormalTok{train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{f1 =}\NormalTok{ mvtnorm}\OperatorTok{::}\KeywordTok{dmvnorm}\NormalTok{(}
\NormalTok{      .[}\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)],}
\NormalTok{      mu_hat[}\DecValTok{1}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unlist}\NormalTok{(),}
\NormalTok{      S_within_group[[}\DecValTok{1}\NormalTok{]]),}
    \DataTypeTok{f2 =}\NormalTok{ mvtnorm}\OperatorTok{::}\KeywordTok{dmvnorm}\NormalTok{(}
\NormalTok{      .[}\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)],}
\NormalTok{      mu_hat[}\DecValTok{2}\NormalTok{, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unlist}\NormalTok{(),}
\NormalTok{      S_within_group[[}\DecValTok{2}\NormalTok{]]),}
    \DataTypeTok{f =}\NormalTok{ n_obs}\OperatorTok{$}\NormalTok{pi[}\DecValTok{1}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{f1 }\OperatorTok{+}\StringTok{ }\NormalTok{n_obs}\OperatorTok{$}\NormalTok{pi[}\DecValTok{2}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{f2}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{p1 =}\NormalTok{ n_obs}\OperatorTok{$}\NormalTok{pi[}\DecValTok{1}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{f1 }\OperatorTok{/}\StringTok{ }\NormalTok{f,}
    \DataTypeTok{p2 =}\NormalTok{ n_obs}\OperatorTok{$}\NormalTok{pi[}\DecValTok{2}\NormalTok{] }\OperatorTok{*}\StringTok{ }\NormalTok{f2 }\OperatorTok{/}\StringTok{ }\NormalTok{f}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{predicted_class =} \KeywordTok{factor}\NormalTok{(}\KeywordTok{if_else}\NormalTok{(p1 }\OperatorTok{>=}\StringTok{ }\NormalTok{p2, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}
\NormalTok{    id, x1, x2, class, p1, p2, predicted_class}
\NormalTok{  )}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  qda_posterior_result_df,}
  \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{align =} \KeywordTok{rep}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\KeywordTok{dim}\NormalTok{(qda_posterior_result_df)[}\DecValTok{2}\NormalTok{]),}
  \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'$x_1$'}\NormalTok{, }\StringTok{'$x_2$'}\NormalTok{,}
                \StringTok{'실제범주'}\NormalTok{, }
                \StringTok{'$P(y = 1 | }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$'}\NormalTok{, }
                \StringTok{'$P(y = 2 | }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$'}\NormalTok{,}
                \StringTok{'추정범주'}\NormalTok{),}
  \DataTypeTok{caption =} \StringTok{'학습표본에 대한 QDA 적용 결과: 사후확률 및 추정범주'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:qda-posterior-result}학습표본에 대한 QDA 적용 결과: 사후확률 및 추정범주}
\centering
\begin{tabular}{rrrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$P(y = 1 | \textbackslash{}mathbf\{x\})\$ & \$P(y = 2 | \textbackslash{}mathbf\{x\})\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & 0.9021365 & 0.0978635 & 1\\
2 & 4 & 3 & 2 & 0.0000228 & 0.9999772 & 2\\
3 & 7 & 8 & 2 & 0.3173746 & 0.6826254 & 2\\
4 & 8 & 6 & 2 & 0.0321055 & 0.9678945 & 2\\
5 & 3 & 6 & 1 & 0.9898499 & 0.0101501 & 1\\
\addlinespace
6 & 2 & 5 & 1 & 0.9887184 & 0.0112816 & 1\\
7 & 6 & 6 & 1 & 0.4830310 & 0.5169690 & 2\\
8 & 9 & 6 & 2 & 0.0057829 & 0.9942171 & 2\\
9 & 5 & 4 & 2 & 0.0017486 & 0.9982514 & 2\\
\bottomrule
\end{tabular}
\end{table}

이 또한 \texttt{MASS} 패키지의 \texttt{predict.qda} 함수를 통해 아래와 같이 동일한 결과값을 보다 간편하게 얻을 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{bind_cols}\NormalTok{(}
  \KeywordTok{predict}\NormalTok{(qda_fit, train_df)}\OperatorTok{$}\NormalTok{posterior }\OperatorTok{%>%}\StringTok{ }
\StringTok{    `}\DataTypeTok{colnames<-}\StringTok{`}\NormalTok{(}\KeywordTok{paste0}\NormalTok{(}\StringTok{"p"}\NormalTok{, }\KeywordTok{colnames}\NormalTok{(.))) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as_data_frame}\NormalTok{()}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{predicted_class =} \KeywordTok{predict}\NormalTok{(qda_fit, .)}\OperatorTok{$}\NormalTok{class}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 9 x 7
##      id    x1    x2 class        p1     p2 predicted_class
##   <int> <dbl> <dbl> <fct>     <dbl>  <dbl> <fct>          
## 1     1     5     7 1     0.902     0.0979 1              
## 2     2     4     3 2     0.0000228 1.000  2              
## 3     3     7     8 2     0.317     0.683  2              
## 4     4     8     6 2     0.0321    0.968  2              
## 5     5     3     6 1     0.990     0.0102 1              
## 6     6     2     5 1     0.989     0.0113 1              
## 7     7     6     6 1     0.483     0.517  2              
## 8     8     9     6 2     0.00578   0.994  2              
## 9     9     5     4 2     0.00175   0.998  2
\end{verbatim}

\hypertarget{da-multiclass}{%
\section{세 범주 이상의 분류}\label{da-multiclass}}

\hypertarget{mutliclass-da-basic-script}{%
\subsection{기본 R 스크립트}\label{mutliclass-da-basic-script}}

3개의 범주를 지닌 붓꽃(iris) 데이터에 대해 선형판별분석을 적용하는 R 스크립트는 아래와 같다. 본 예제에서는 각 범주별 50개 데이터 중 첫 30개 관측치만을 학습표본으로 삼아 판별함수를 유도한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris_train_df <-}\StringTok{ }\NormalTok{datasets}\OperatorTok{::}\NormalTok{iris }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{x1 =}\NormalTok{ Sepal.Length,}
         \DataTypeTok{x2 =}\NormalTok{ Sepal.Width,}
         \DataTypeTok{x3 =}\NormalTok{ Petal.Length,}
         \DataTypeTok{x4 =}\NormalTok{ Petal.Width,}
         \DataTypeTok{class =}\NormalTok{ Species) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(class) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{30}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{id =} \KeywordTok{row_number}\NormalTok{())}

\NormalTok{iris_lda_fit <-}\StringTok{ }\NormalTok{MASS}\OperatorTok{::}\KeywordTok{lda}\NormalTok{(class }\OperatorTok{~}\StringTok{ }\NormalTok{. }\OperatorTok{-}\NormalTok{id, iris_train_df)}

\KeywordTok{print}\NormalTok{(iris_lda_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## lda(class ~ . - id, data = iris_train_df)
## 
## Prior probabilities of groups:
##     setosa versicolor  virginica 
##  0.3333333  0.3333333  0.3333333 
## 
## Group means:
##                  x1       x2       x3        x4
## setosa     5.026667 3.450000 1.473333 0.2466667
## versicolor 6.070000 2.790000 4.333333 1.3533333
## virginica  6.583333 2.933333 5.603333 2.0066667
## 
## Coefficients of linear discriminants:
##           LD1        LD2
## x1  0.5711419 -1.2397647
## x2  1.8752911  3.0223980
## x3 -1.7361767  0.3159667
## x4 -3.4672646  1.3954748
## 
## Proportion of trace:
##    LD1    LD2 
## 0.9929 0.0071
\end{verbatim}

\hypertarget{mutliclass-generalized-discriminant-function}{%
\subsection{일반화된 판별함수}\label{mutliclass-generalized-discriminant-function}}

\(K (> 2)\)개의 범주가 있는 경우에 대한 판별분석은 아래와 같이 일반화된다.

\begin{itemize}
\tightlist
\item
  \(\pi_k\): 범주 \(k\)에 속할 사전확률, \(k = 1, 2, \cdots, K\)
\item
  \(C(k' \, | \, k) \ge 0\): 실제 범주 \(k\)에 속하는 데 범주 \(k'\)로 분류할 때 소요 비용 (\(C(k' \, | \, k) = 0 \text{ if } k' = k\))
\item
  \(f_k(\mathbf{x})\): 범주 \(k\)에 속하는 \(\mathbf{x}\)의 확률밀도함수
\item
  \(R_k \subset \mathbb{R}^p\): 범주 \(k\)로 분류되는 \(\mathbf{x}\)의 영역
\item
  \(P(k' \, | \, k) = \int_{\mathbf{x} \in R_{k'}} f_k(\mathbf{x}) d\mathbf{x}\): 실제범주 \(k\)에 속하는 데 범주 \(k'\)로 분류할 확률
\end{itemize}

이 때, 총 기대 오분류 비용은 아래와 같다.

\begin{equation*}
\sum_{k = 1}^{K} \pi_k \sum_{k' \neq k} C(k' \, | \, k) \int_{\mathbf{x} \in R_{k'}} f_k(\mathbf{x}) d\mathbf{x}
\end{equation*}

따라서 분류문제는 위 총 기대 오분류 비용을 최소화하는 \(R_1, \cdots, R_K\)를 찾는 것이다.

우선, 범주를 고려하지 않은 \(\mathbf{x}\)의 확률밀도함수는 아래와 같이 정의된다.

\begin{equation*}
f(\mathbf{x}) = \sum_{k=1}^{K} \pi_k f_k(\mathbf{x})
\end{equation*}

베이즈 정리에 의하여, 변수 \(\mathbf{x}\)가 주어졌을 때 범주 \(k\)에 속할 사후확률은 아래와 같다.

\begin{equation*}
P(y = k \,|\, \mathbf{x}) = \frac{\pi_k f_k(\mathbf{x})}{f(\mathbf{x})}
\end{equation*}

오분류비용이 동일한 경우에는 각 객체에 대해 위의 사후확률이 가장 큰 범주로 추정한다. 위 식에서

\begin{equation*}
P(y = k \,|\, \mathbf{x}) \propto \pi_k f_k(\mathbf{x})
\end{equation*}

이므로, 아래와 같이 범주가 추정된다.

\begin{equation*}
\hat{y} = {arg\,max}_{k} \pi_k f_k(\mathbf{x})
\end{equation*}

앞 장들에서 살펴본 것과 마찬가지로, 선형판별분석의 경우 각 범주의 확률밀도함수 \(f_k(\mathbf{x})\)가 동일 분산-공분산행렬을 가정하며, 이차판별분석의 경우 서로 다른 분산-공분산행렬을 가정한다.

아래 스크립트는 \texttt{MASS} 패키지의 \texttt{lda} 함수를 통해 각 범주에 속할 사후확률과 범주 추정값을 얻는 과정을 보여준다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris_lda_fit <-}\StringTok{ }\NormalTok{MASS}\OperatorTok{::}\KeywordTok{lda}\NormalTok{(class }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2 }\OperatorTok{+}\StringTok{ }\NormalTok{x3 }\OperatorTok{+}\StringTok{ }\NormalTok{x4, iris_train_df)}

\NormalTok{iris_lda_result <-}\StringTok{ }\NormalTok{iris_train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_cols}\NormalTok{(}
    \KeywordTok{predict}\NormalTok{(iris_lda_fit, .)}\OperatorTok{$}\NormalTok{posterior }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{as_data_frame}\NormalTok{()}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{predicted_class =} \KeywordTok{predict}\NormalTok{(iris_lda_fit, .)}\OperatorTok{$}\NormalTok{class}
\NormalTok{  )}

\KeywordTok{print}\NormalTok{(iris_lda_result)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 90 x 10
##       x1    x2    x3    x4 class    id setosa versicolor virginica
##    <dbl> <dbl> <dbl> <dbl> <fct> <int>  <dbl>      <dbl>     <dbl>
##  1   5.1   3.5   1.4   0.2 seto~     1  1       5.57e-22  6.34e-42
##  2   4.9   3     1.4   0.2 seto~     2  1       3.32e-17  5.67e-36
##  3   4.7   3.2   1.3   0.2 seto~     3  1       2.75e-19  2.14e-38
##  4   4.6   3.1   1.5   0.2 seto~     4  1       8.12e-17  5.62e-35
##  5   5     3.6   1.4   0.2 seto~     5  1       1.14e-22  1.25e-42
##  6   5.4   3.9   1.7   0.4 seto~     6  1       3.20e-21  4.38e-40
##  7   4.6   3.4   1.4   0.3 seto~     7  1       8.74e-19  4.07e-37
##  8   5     3.4   1.5   0.2 seto~     8  1       3.27e-20  1.62e-39
##  9   4.4   2.9   1.4   0.2 seto~     9  1.000   2.22e-15  3.42e-33
## 10   4.9   3.1   1.5   0.1 seto~    10  1       9.36e-19  4.85e-38
## # ... with 80 more rows, and 1 more variable: predicted_class <fct>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  iris_lda_result }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{select}\NormalTok{(id, class, predicted_class,}
\NormalTok{           setosa, versicolor, virginica) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{filter}\NormalTok{(class }\OperatorTok{!=}\StringTok{ }\NormalTok{predicted_class),}
  \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{align =} \KeywordTok{rep}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\DecValTok{6}\NormalTok{),}
  \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'실제범주'}\NormalTok{, }\StringTok{'추정범주'}\NormalTok{,}
                \StringTok{'setosa'}\NormalTok{, }\StringTok{'versicolor'}\NormalTok{, }\StringTok{'virginica'}\NormalTok{),}
  \DataTypeTok{caption =} \StringTok{'붓꽃 학습표본에 대한 LDA 적용 결과 - 오분류 객체 사후 확률'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:iris-lda}붓꽃 학습표본에 대한 LDA 적용 결과 - 오분류 객체 사후 확률}
\centering
\begin{tabular}{rrrrrr}
\toprule
객체번호 & 실제범주 & 추정범주 & setosa & versicolor & virginica\\
\midrule
51 & versicolor & virginica & 0 & 0.3088912 & 0.6911088\\
\bottomrule
\end{tabular}
\end{table}

아래 스크립트는 \texttt{MASS} 패키지의 \texttt{qda} 함수를 통해 각 범주에 속할 사후확률과 범주 추정값을 얻는 과정을 보여준다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris_qda_fit <-}\StringTok{ }\NormalTok{MASS}\OperatorTok{::}\KeywordTok{qda}\NormalTok{(class }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2 }\OperatorTok{+}\StringTok{ }\NormalTok{x3 }\OperatorTok{+}\StringTok{ }\NormalTok{x4, iris_train_df)}

\NormalTok{iris_qda_result <-}\StringTok{ }\NormalTok{iris_train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_cols}\NormalTok{(}
    \KeywordTok{predict}\NormalTok{(iris_qda_fit, .)}\OperatorTok{$}\NormalTok{posterior }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{as_data_frame}\NormalTok{()}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{predicted_class =} \KeywordTok{predict}\NormalTok{(iris_qda_fit, .)}\OperatorTok{$}\NormalTok{class}
\NormalTok{  )}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  iris_qda_result }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{select}\NormalTok{(id, class, predicted_class,}
\NormalTok{           setosa, versicolor, virginica) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{filter}\NormalTok{(class }\OperatorTok{!=}\StringTok{ }\NormalTok{predicted_class),}
  \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{align =} \KeywordTok{rep}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\DecValTok{6}\NormalTok{),}
  \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'실제범주'}\NormalTok{, }\StringTok{'추정범주'}\NormalTok{,}
                \StringTok{'setosa'}\NormalTok{, }\StringTok{'versicolor'}\NormalTok{, }\StringTok{'virginica'}\NormalTok{),}
  \DataTypeTok{caption =} \StringTok{'붓꽃 학습표본에 대한 QDA 적용 결과 - 오분류 객체 사후 확률'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:iris-qda}붓꽃 학습표본에 대한 QDA 적용 결과 - 오분류 객체 사후 확률}
\centering
\begin{tabular}{rrrrrr}
\toprule
객체번호 & 실제범주 & 추정범주 & setosa & versicolor & virginica\\
\midrule
51 & versicolor & virginica & 0 & 0.4274712 & 0.5725288\\
\bottomrule
\end{tabular}
\end{table}

위 결과에서 선형판별분석과 이차판별분석은 동일한 객체를 오분류한다. 해당 객체의 실제 범주에 대한 사후확률은 이차판별분석 결과에서 보다 높게 나타난다.

\hypertarget{tree-based-method}{%
\chapter{트리기반 기법}\label{tree-based-method}}

\hypertarget{cart-overview}{%
\section{CART 개요}\label{cart-overview}}

CART(Classification and Regression Trees)는 \citet{breiman1984classification} 에 의하여 개발된 것인데, 각 (독립)변수를 이분화(binary split)하는 과정을 반복하여 트리 형태를 형성함으로써 분류(종속변수가 범주형일 때) 또는 회귀분석(종속변수가 연속형일 때)을 수행하는 것이다. 이 때 독립변수들은 범주형 또는 연속형 모두에 적용될 수 있다. 본 장에서는 분류를 위한 목적만을 설명하도록 한다.

\hypertarget{cart-packages-install}{%
\section{필요 R package 설치}\label{cart-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.2.1\\
\hline
rpart & 4.1-15\\
\hline
rpart.plot & 3.0.7\\
\hline
\end{tabular}

\hypertarget{cart-build}{%
\section{CART 트리 생성}\label{cart-build}}

\hypertarget{cart-basic-r-script}{%
\subsection{기본 R 스크립트}\label{cart-basic-r-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{x1 =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{),}
  \DataTypeTok{x2 =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{),}
  \DataTypeTok{class =} \KeywordTok{as.factor}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:tree-train-data-table}학습표본 데이터}
\centering
\begin{tabular}{rrr}
\toprule
x1 & x2 & class\\
\midrule
1 & 4 & 1\\
2 & 6 & 1\\
2 & 5 & 1\\
2 & 4 & 2\\
2 & 3 & 2\\
\addlinespace
3 & 6 & 1\\
4 & 6 & 1\\
4 & 5 & 2\\
4 & 4 & 2\\
5 & 3 & 2\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:tree-train-data-table}와 같이 두 독립변수 \emph{x1}, \emph{x2}와 이분형 종속변수 \emph{class}의 관측값으로 이루어진 10개의 학습표본을 \emph{train\_df}라는 data frame에 저장한다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(rpart)}
\KeywordTok{library}\NormalTok{(rpart.plot)}
\NormalTok{cart.est <-}\StringTok{ }\KeywordTok{rpart}\NormalTok{(}
\NormalTok{  class }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2}
\NormalTok{  , }\DataTypeTok{data =}\NormalTok{ train_df}
\NormalTok{  , }\DataTypeTok{method =} \StringTok{"class"}
\NormalTok{  , }\DataTypeTok{parms =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{split =} \StringTok{"gini"}\NormalTok{)}
\NormalTok{  , }\DataTypeTok{control =} \KeywordTok{rpart.control}\NormalTok{(}\DataTypeTok{minsplit =} \DecValTok{2}
\NormalTok{                            , }\DataTypeTok{minbucket =} \DecValTok{1}
\NormalTok{                            , }\DataTypeTok{cp =} \DecValTok{0}
\NormalTok{                            , }\DataTypeTok{xval =} \DecValTok{0}
\NormalTok{                            , }\DataTypeTok{maxcompete =} \DecValTok{0}\NormalTok{)}
\NormalTok{  )}
\KeywordTok{rpart.plot}\NormalTok{(cart.est)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/cart-basic-1} 

}

\caption{CART 트리}\label{fig:cart-basic}
\end{figure}

\href{https://cran.r-project.org/web/packages/rpart/}{rpart} 라는 package를 기반으로, 두 변수 x1과 x2를 이용하여 이분형 종속변수 class를 분류하는 CART 트리를 생성할 수 있으며, \href{https://cran.r-project.org/web/packages/rpart.plot/}{rpart.plot} package를 이용하여 Figure \ref{fig:cart-basic}과 같이 시각화할 수 있다.

\hypertarget{cart-notation}{%
\subsection{기호 정의}\label{cart-notation}}

본 장에서 사용될 수학적 기호는 아래와 같다.

\begin{itemize}
\tightlist
\item
  \(T\): 트리
\item
  \(A(T)\): 트리 \(T\)의 최종노드의 집합
\item
  \(J\): 범주수
\item
  \(N\): 학습표본의 총 객체수
\item
  \(N_j\): 범주 \(j\)에 속한 객체 수
\item
  \(N(t)\): 노드 \(t\)에서의 객체수
\item
  \(N_j(t)\): 노드 \(t\)에서 범주 \(j\)에 속한 객체수
\item
  \(p(j,t)\): 임의의 객체가 범주 \(j\)와 노드 \(t\)에 속할 확률
\item
  \(p(t)\): 임의의 객체가 노드 \(t\)에 속할 확률
  \[p(t) = \sum_{j=1}^{J} p(j,t)\]
\item
  \(p(j|t)\): 임의의 객체가 노드 \(t\)에 속할 때 범주 \(j\)에 속할 조건부 확률
  \[p(j|t) = \frac{p(j,t)}{p(t)}, \quad \sum_{j=1}^{J} p(j|t) = 1\]
\end{itemize}

이 때, 각 확률은 학습표본에서 아래와 같이 추정할 수 있다.
\begin{align}
p(j,t) &\approx \frac{N_j(t)}{N}\\
p(t) &\approx \frac{N(t)}{N}\\
p(j|t) &\approx \frac{N_j(t)}{N(t)}
\end{align}

\hypertarget{cart-impurity}{%
\subsection{노드 및 트리의 불순도}\label{cart-impurity}}

\hypertarget{-}{%
\subsubsection{노드의 불순도}\label{-}}

CART는 지니 지수(Gini index)를 불순도 함수로 사용한다. 총 \(J\)개의 범주별 객체비율을 \(p_1, \cdots , p_J\)라 할 때 (\(\sum_{j=1}^{J} p_j = 1\)), 지니 지수는 식 \eqref{eq:gini-index}와 같다.

\begin{equation}
G(p_1, \cdots, p_J) = \sum_{j=1}^{J} p_j(1-p_j) = 1 - \sum_{j=1}^{J}p_j^2 \label{eq:gini-index}
\end{equation}

노드 \(t\)에서의 범주별 객체비율은 \(p(1|t), \cdots, p(J|t)\)이므로, 노드 \(t\)의 불순도는 식 \eqref{eq:node-impurity}와 같이 산출된다.

\begin{equation}
\begin{split}
i(t) &= 1 - \sum_{j=1}^{J} p(j|t)^2\\
&\approx 1 - \sum_{j=1}^{J} \left[\frac{N_j(t)}{N(t)}\right]^2
\end{split}
\label{eq:node-impurity}
\end{equation}

\hypertarget{-}{%
\subsubsection{트리 불순도}\label{-}}

트리 \(T\)의 불순도는 식 \eqref{eq:tree-impurity}와 같이 최종노드들의 불순도의 가중평균으로 정의된다.

\begin{equation}
I(T) = \sum_{t \in A(T)} i(t)p(t) \label{eq:tree-impurity}
\end{equation}

여기서
\[ I(t) = i(t)p(t) \]
라 하면, 다음이 성립한다.
\[ I(T) = \sum_{t \in A(T)} I(t) \]

\hypertarget{cart-split}{%
\subsection{분지기준}\label{cart-split}}

뿌리 노드에서의 분지만을 살펴보기 위해 control parameter \emph{maxdepth}의 값을 1으로 설정한다. 이 경우, CART 알고리즘은 뿌리노드에서의 양 갈래 분지만을 선택한 뒤 종료된다. 아래 스크립트를 이용하여 뿌리노드에서 최적분지된 트리를 얻는다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cart.firstsplit <-}\StringTok{ }\KeywordTok{rpart}\NormalTok{(class }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2}
\NormalTok{                  , }\DataTypeTok{data =}\NormalTok{ train_df}
\NormalTok{                  , }\DataTypeTok{method =} \StringTok{"class"}
\NormalTok{                  , }\DataTypeTok{parms =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{split =} \StringTok{"gini"}\NormalTok{)}
\NormalTok{                  , }\DataTypeTok{control =} \KeywordTok{rpart.control}\NormalTok{(}\DataTypeTok{minsplit =} \DecValTok{2}
\NormalTok{                                          , }\DataTypeTok{minbucket =} \DecValTok{1}
\NormalTok{                                          , }\DataTypeTok{maxdepth =} \DecValTok{1}
\NormalTok{                                          , }\DataTypeTok{cp =} \DecValTok{0}
\NormalTok{                                          , }\DataTypeTok{xval =} \DecValTok{0}
\NormalTok{                                          , }\DataTypeTok{maxcompete =} \DecValTok{0}
\NormalTok{                                          )}
\NormalTok{                  )}
\KeywordTok{rpart.plot}\NormalTok{(cart.firstsplit)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/firstsplit-1} 

}

\caption{뿌리노드 분지}\label{fig:firstsplit}
\end{figure}

또한 분지 결과 트리는 Table \ref{tab:firstsplit-frame}와 같이 \emph{frame}이라는 이름의 data frame에 설명된다. 각 행 앞의 번호는 노드 인덱스 \(t\)를 나타내며, 각 열에 대한 설명은 아래와 같다.

\begin{itemize}
\tightlist
\item
  var: 노드 \(t\)를 분지하는 데 이용된 변수. 값이 \textless{}leaf\textgreater{}인 경우에는 노드 \(t\)가 최종 노드임을 나타낸다.
\item
  n: 노드 내 객체 수 \(N(t)\)
\item
  wt: 가중치 적용 후 객체 수 (추후 appendix에서 설명)
\item
  dev: 오분류 객체 수
\item
  yval: 노드 \(t\)를 대표하는 범주
\item
  complexity: 노드 \(t\)에서 추가로 분지할 때 감소하는 relative error값; 본 분류트리 예제에서 error는 오분류율이며, 뿌리 노드의 relative error값을 1으로 한다.
\end{itemize}

\begin{table}[t]

\caption{\label{tab:firstsplit-frame}뿌리노드 분지 상세 (frame)}
\centering
\begin{tabular}{llrrrrrrr}
\toprule
  & var & n & wt & dev & yval & complexity & ncompete & nsurrogate\\
\midrule
1 & x2 & 10 & 10 & 5 & 1 & 0.6 & 0 & 0\\
2 & \textbackslash{}<leaf\textbackslash{}> & 3 & 3 & 0 & 1 & 0.0 & 0 & 0\\
3 & \textbackslash{}<leaf\textbackslash{}> & 7 & 7 & 2 & 2 & 0.0 & 0 & 0\\
\bottomrule
\end{tabular}
\end{table}

또한 \emph{frame}에는 트리 내 각 노드에 속한 객체와 범주에 대한 정보를 나타내는 \emph{yval2}라는 행렬이 Table \ref{tab:firstsplit-yval2}와 같이 존재한다. 실제 \emph{yval2}의 열의 개수는 전체 학습 대상 범주 수에 따라 달라지며, 본 예는 이분 분류 트리(범주개수 = 2)에 해당하는 열 구성을 보여준다. 각 행 앞의 번호는 노드 인덱스 \(t\)를 나타내며, 각 열에 대한 설명은 아래와 같다.

\begin{itemize}
\tightlist
\item
  열1: 노드 \(t\)에서의 최적 추정 범주 \(j^*\)
\item
  열2: 노드 \(t\) 내 범주 \emph{class}=1 객체 수 \(N_1(t)\)
\item
  열3: 노드 \(t\) 내 범주 \emph{class}=2 객체 수 \(N_2(t)\)
\item
  열4: 노드 \(t\) 내 범주 \emph{class}=1 관측 확률 \(p(1|t) \approx \tfrac{N_1(t)}{N(t)}\)
\item
  열5: 노드 \(t\) 내 범주 \emph{class}=2 관측 확률 \(p(2|t) \approx \tfrac{N_2(t)}{N(t)}\)
\item
  nodeprob: 노드 \(t\) 확률 \(p(t) \approx \tfrac{N(t)}{N}\)
\end{itemize}

\begin{verbatim}
## Warning: Setting row names on a tibble is deprecated.
\end{verbatim}

\begin{table}[t]

\caption{\label{tab:firstsplit-yval2}노드 내 객체 및 범주 정보 (yval2)}
\centering
\begin{tabular}{lrrrrrr}
\toprule
  & 열1 & 열2 & 열3 & 열4 & 열5 & nodeprob\\
\midrule
1 & 1 & 5 & 5 & 0.50 & 0.50 & 1.0\\
2 & 1 & 3 & 0 & 1.00 & 0.00 & 0.3\\
3 & 2 & 2 & 5 & 0.29 & 0.71 & 0.7\\
\bottomrule
\end{tabular}
\end{table}

위 CART 모델 데이터를 이용하여 트리의 불순도를 계산해보자.

우선 노드 상세 정보 행렬 \emph{yval2}의 \emph{x}번째 노드의 불순도(\(i(t)\))를 계산하는 함수 \emph{rpartNodeImpurity}를 아래와 같이 구현한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rpartNodeImpurity <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, yval2) \{}
\NormalTok{  node_vec <-}\StringTok{ }\NormalTok{yval2[x, ]}
\NormalTok{  n.columns <-}\StringTok{ }\KeywordTok{length}\NormalTok{(node_vec)}
\NormalTok{  class.prob <-}\StringTok{ }\NormalTok{node_vec[((n.columns}\OperatorTok{/}\DecValTok{2}\NormalTok{)}\OperatorTok{+}\DecValTok{1}\NormalTok{)}\OperatorTok{:}\NormalTok{(n.columns}\DecValTok{-1}\NormalTok{)]}
  \KeywordTok{return}\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\KeywordTok{sum}\NormalTok{(class.prob}\OperatorTok{^}\DecValTok{2}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

CART tree 객체의 각 leaf node에 함수 \emph{rpartNodeImpurity}를 적용하여 노드 불순도 \(i(t)\)를 계산한 뒤, 노드 확률 \(p(t)\)을 이용한 가중합을 통해 트리 불순도 \(I(T)\)를 계산하는 함수 \emph{rpartImpurity}를 아래와 같이 구현한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rpartImpurity <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(rpart.obj) \{}
\NormalTok{  leaf.nodes <-}\StringTok{ }\KeywordTok{which}\NormalTok{(rpart.obj}\OperatorTok{$}\NormalTok{frame}\OperatorTok{$}\NormalTok{var}\OperatorTok{==}\StringTok{"<leaf>"}\NormalTok{)}
\NormalTok{  node.impurity <-}\StringTok{ }\KeywordTok{sapply}\NormalTok{(leaf.nodes, }
\NormalTok{                          rpartNodeImpurity, }
                          \DataTypeTok{yval2 =}\NormalTok{ rpart.obj}\OperatorTok{$}\NormalTok{frame}\OperatorTok{$}\NormalTok{yval2)}
\NormalTok{  node.prob <-}\StringTok{ }\NormalTok{rpart.obj}\OperatorTok{$}\NormalTok{frame}\OperatorTok{$}\NormalTok{yval2[leaf.nodes, }\StringTok{'nodeprob'}\NormalTok{]}
  \KeywordTok{return}\NormalTok{(}\KeywordTok{sum}\NormalTok{(node.prob }\OperatorTok{*}\StringTok{ }\NormalTok{node.impurity))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 함수를 이용하여 계산한 트리 Figure \ref{fig:cart-basic}의 불순도는 0.29이다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rpartImpurity}\NormalTok{(cart.firstsplit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2857143
\end{verbatim}

분지를 추가할수록 불순도는 감소한다. 분지를 추가하기 위해서는 \emph{maxdepth}라는 control parameter 값을 증가시키면 된다.

\begin{itemize}
\tightlist
\item
  maxdepth: 뿌리노드부터 임의의 최종노드에 도달하는 최대 가능 분지 수 (default=30)
\end{itemize}

\emph{maxdepth} 파라미터의 값을 1부터 4까지 증가시키며 불순도의 변화를 살펴보자.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}

\NormalTok{tree.impurity <-}\StringTok{ }\KeywordTok{sapply}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{), }\ControlFlowTok{function}\NormalTok{(depth) \{}
  \KeywordTok{rpart}\NormalTok{(class }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2}
\NormalTok{        , }\DataTypeTok{data =}\NormalTok{ train_df}
\NormalTok{        , }\DataTypeTok{method =} \StringTok{"class"}
\NormalTok{        , }\DataTypeTok{parms =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{split =} \StringTok{"gini"}\NormalTok{)}
\NormalTok{        , }\DataTypeTok{control =} \KeywordTok{rpart.control}\NormalTok{(}\DataTypeTok{minsplit =} \DecValTok{2}
\NormalTok{                                  , }\DataTypeTok{minbucket =} \DecValTok{1}
\NormalTok{                                  , }\DataTypeTok{maxdepth =}\NormalTok{ depth}
\NormalTok{                                  , }\DataTypeTok{cp =} \DecValTok{0}
\NormalTok{                                  , }\DataTypeTok{xval =} \DecValTok{0}
\NormalTok{                                  , }\DataTypeTok{maxcompete =} \DecValTok{0}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rpartImpurity}\NormalTok{()}
\NormalTok{\})}

\KeywordTok{tibble}\NormalTok{(}\DataTypeTok{maxdepth=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{), }\DataTypeTok{impurity=}\NormalTok{tree.impurity) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x=}\NormalTok{maxdepth, }\DataTypeTok{y=}\NormalTok{impurity)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/impurity-trend-1} 

}

\caption{파라미터 maxdepth값에 따른 트리불순도 변화}\label{fig:impurity-trend}
\end{figure}

위 예에서, 트리의 분지가 증가함에 따라 불순도는 0.29, 0.17, 0.17, 0로 감소한다. \emph{maxdepth}값이 3일 때 불순도가 감소하지 않는 이유는, 세 번째 분지 결과가 전체적인 오분류를 감소시키지 않아 \emph{rpart} 함수가 해당 분지를 취소하기 때문이다. 여기에 작용하는 파라미터는 \emph{cp}라는 control parameter이다.

\begin{itemize}
\tightlist
\item
  cp: 노드가 분지되기 위한 최소 relative error 감소치 (default = 0.01). 값이 0일 경우 최대트리를 생성한다.
\end{itemize}

위 예제에서는 \emph{cp}값을 0으로 설정하여, 해당 분지가 트리 불순도를 감소시킨다 하더라도 전체 트리의 오분류를 감소시키는 데 기여하지 않는다면 시도하지 않도록 하였다.

\hypertarget{cart-pruning-complete}{%
\section{가지치기 및 최종 트리 선정}\label{cart-pruning-complete}}

\hypertarget{cart-pruning}{%
\subsection{가지치기}\label{cart-pruning}}

앞 장의 최대 트리 그림 \ref{fig:cart-basic}은 학습 데이터를 오분류 없이 완벽하게 분류하기 위해 복잡한 분류 구조를 형성하였다. 이러한 복잡한 분류 구조는 학습 데이터가 아닌 새로운 데이터에 대한 분류 정확도를 떨어뜨릴 수 있다. 이는 bias-variance tradeoff라 부르는 현상으로, 비단 분류트리 뿐 아니라 모든 데이터마이닝 방법에 일반적으로 적용된다.

분류 트리는 가지치기라는 방식을 통해, 분류 구조를 단순화함으로써 분류 트리가 새로운 데이터에도 정확한 분류를 제공하기를 추구한다. 가지치기란 트리 내 특정 내부노드를 기준으로 그 하위에 발생한 분지를 모두 제거하고, 해당 내부노드를 최종노드로 치환하는 방식이다.

\begin{table}[t]

\caption{\label{tab:max-frame}최대 트리 분지 상세 (frame)}
\centering
\begin{tabular}{llrrrrrrr}
\toprule
  & var & n & wt & dev & yval & complexity & ncompete & nsurrogate\\
\midrule
1 & x2 & 10 & 10 & 5 & 1 & 0.6 & 0 & 0\\
2 & \textbackslash{}<leaf\textbackslash{}> & 3 & 3 & 0 & 1 & 0.0 & 0 & 0\\
3 & x1 & 7 & 7 & 2 & 2 & 0.2 & 0 & 0\\
6 & \textbackslash{}<leaf\textbackslash{}> & 1 & 1 & 0 & 1 & 0.0 & 0 & 0\\
7 & x2 & 6 & 6 & 1 & 2 & 0.1 & 0 & 0\\
\addlinespace
14 & x1 & 2 & 2 & 1 & 1 & 0.1 & 0 & 0\\
28 & \textbackslash{}<leaf\textbackslash{}> & 1 & 1 & 0 & 1 & 0.0 & 0 & 0\\
29 & \textbackslash{}<leaf\textbackslash{}> & 1 & 1 & 0 & 2 & 0.0 & 0 & 0\\
15 & \textbackslash{}<leaf\textbackslash{}> & 4 & 4 & 0 & 2 & 0.0 & 0 & 0\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:max-frame}에서 생성 가능한 가지치기는 최종 노드(\emph{var값이 \textless{}leaf\textgreater{}})가 아닌 모든 노드(1, 3, 7, 14)에서 가능하며, 함수 \emph{snip.rpart}를 이용하여 가지치기 된 트리를 생성할 수 있다. 각 내부 노드에서 가지치기된 트리들은 아래와 같이 얻어진다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{internal.node.index <-}\StringTok{ }\KeywordTok{rownames}\NormalTok{(cart.est}\OperatorTok{$}\NormalTok{frame)[}\KeywordTok{which}\NormalTok{(cart.est}\OperatorTok{$}\NormalTok{frame}\OperatorTok{$}\NormalTok{var }\OperatorTok{!=}\StringTok{ '<leaf>'}\NormalTok{)] }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{as.numeric}\NormalTok{()}
\NormalTok{snipped <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(internal.node.index, }\ControlFlowTok{function}\NormalTok{(x)\{}\KeywordTok{snip.rpart}\NormalTok{(cart.est, x)\})}
\NormalTok{n.trees <-}\StringTok{ }\KeywordTok{length}\NormalTok{(snipped)}
\KeywordTok{par}\NormalTok{(}\DataTypeTok{mfrow=}\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\KeywordTok{invisible}\NormalTok{(}\KeywordTok{lapply}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{n.trees), }\ControlFlowTok{function}\NormalTok{(x) \{}
  \KeywordTok{rpart.plot}\NormalTok{(snipped[[x]])\}}
\NormalTok{  ))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/snipped-1} 

}

\caption{각 내부노드 기준으로 가지치기된 트리}\label{fig:snipped}
\end{figure}

위 각 가지치기 후보 노드의 오분류 비용은 함수 \emph{nodeCost}를 아래와 같이 구현하여 계산할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nodeCost <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(node, tree) \{}
\NormalTok{  node_vec <-}\StringTok{ }\NormalTok{tree}\OperatorTok{$}\NormalTok{frame}\OperatorTok{$}\NormalTok{yval2[}\KeywordTok{as.character}\NormalTok{(node) }\OperatorTok{==}\StringTok{ }\KeywordTok{row.names}\NormalTok{(tree}\OperatorTok{$}\NormalTok{frame), ]}
\NormalTok{  n.columns <-}\StringTok{ }\KeywordTok{length}\NormalTok{(node_vec)}
\NormalTok{  class.prob.max <-}\StringTok{ }\KeywordTok{max}\NormalTok{(node_vec[((n.columns}\OperatorTok{/}\DecValTok{2}\NormalTok{)}\OperatorTok{+}\DecValTok{1}\NormalTok{)}\OperatorTok{:}\NormalTok{(n.columns}\DecValTok{-1}\NormalTok{)])}
\NormalTok{  node.prob <-}\StringTok{ }\NormalTok{node_vec[n.columns]}
\NormalTok{  node.misclassification.cost <-}\StringTok{ }\NormalTok{(}\DecValTok{1}\OperatorTok{-}\NormalTok{class.prob.max)}\OperatorTok{*}\NormalTok{node.prob}
  \KeywordTok{return}\NormalTok{(node.misclassification.cost)}
\NormalTok{\}}

\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{pruning_node =}\NormalTok{ internal.node.index,}
  \DataTypeTok{node_cost =} \KeywordTok{sapply}\NormalTok{(internal.node.index, nodeCost, }\DataTypeTok{tree=}\NormalTok{cart.est)}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r}
\hline
pruning\_node & node\_cost\\
\hline
1 & 0.5\\
\hline
3 & 0.2\\
\hline
7 & 0.1\\
\hline
14 & 0.1\\
\hline
\end{tabular}

각 가지치기 노드에 해당하는 하부 트리의 오분류비용 및 복잡도를 구하기 위해 \emph{subtreeEval}라는 함수를 아래와 같이 구현한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subtreeEval <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(node, tree) \{}
\NormalTok{  snipped <-}\StringTok{ }\KeywordTok{snip.rpart}\NormalTok{(tree, node)}\OperatorTok{$}\NormalTok{frame}
\NormalTok{  leaf.nodes <-}\StringTok{ }\KeywordTok{setdiff}\NormalTok{(}\KeywordTok{rownames}\NormalTok{(tree}\OperatorTok{$}\NormalTok{frame[tree}\OperatorTok{$}\NormalTok{frame}\OperatorTok{$}\NormalTok{var}\OperatorTok{==}\StringTok{"<leaf>"}\NormalTok{,]),}
          \KeywordTok{rownames}\NormalTok{(snipped)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{as.numeric}\NormalTok{()}

  \KeywordTok{tibble}\NormalTok{(}
    \DataTypeTok{pruning_node =}\NormalTok{ node,}
    \DataTypeTok{node.cost =} \KeywordTok{nodeCost}\NormalTok{(node, tree),}
    \DataTypeTok{subtree.cost =} \KeywordTok{sapply}\NormalTok{(leaf.nodes, nodeCost, }\DataTypeTok{tree=}\NormalTok{tree) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{sum}\NormalTok{(),}
    \DataTypeTok{subtree.size =} \KeywordTok{length}\NormalTok{(leaf.nodes)}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{alpha =}\NormalTok{ (node.cost }\OperatorTok{-}\StringTok{ }\NormalTok{subtree.cost) }\OperatorTok{/}\StringTok{ }\NormalTok{(subtree.size }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

각 노드에 대하여 알파값을 다음과 같이 계산할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.cost <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(internal.node.index, subtreeEval, }\DataTypeTok{tree=}\NormalTok{cart.est) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_rows}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:first-prune-candidate-tab}내부노드 가지치기 평가 (df.cost)}
\centering
\begin{tabular}{rrrrr}
\toprule
pruning\_node & node.cost & subtree.cost & subtree.size & alpha\\
\midrule
1 & 0.5 & 0 & 5 & 0.12\\
3 & 0.2 & 0 & 4 & 0.07\\
7 & 0.1 & 0 & 3 & 0.05\\
14 & 0.1 & 0 & 2 & 0.10\\
\bottomrule
\end{tabular}
\end{table}

위 Table \ref{tab:first-prune-candidate-tab} 에서 최소 알파값에 해당하는 노드 7에서 가지치기를 한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pruned.tree}\FloatTok{.1}\NormalTok{ <-}\StringTok{ }\KeywordTok{snip.rpart}\NormalTok{(cart.est,}
\NormalTok{                            df.cost}\OperatorTok{$}\NormalTok{pruning_node[}\KeywordTok{which.min}\NormalTok{(df.cost}\OperatorTok{$}\NormalTok{alpha)])}
\KeywordTok{rpart.plot}\NormalTok{(pruned.tree}\FloatTok{.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/first-prune-result-1} 

}

\caption{1단계 가지치기 결과}\label{fig:first-prune-result}
\end{figure}

가지치기로 형성된 트리에서 다시 각 가지치기 노드의 오분류비용, 복잡도 및 알파값을 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.cost <-}\StringTok{ }\KeywordTok{rownames}\NormalTok{(pruned.tree}\FloatTok{.1}\OperatorTok{$}\NormalTok{frame)[pruned.tree}\FloatTok{.1}\OperatorTok{$}\NormalTok{frame}\OperatorTok{$}\NormalTok{var}\OperatorTok{!=}\StringTok{"<leaf>"}\NormalTok{] }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{as.numeric}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{lapply}\NormalTok{(subtreeEval, }\DataTypeTok{tree=}\NormalTok{pruned.tree}\FloatTok{.1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_rows}\NormalTok{()}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(df.cost)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|r|r|r}
\hline
pruning\_node & node.cost & subtree.cost & subtree.size & alpha\\
\hline
1 & 0.5 & 0.1 & 3 & 0.2\\
\hline
3 & 0.2 & 0.1 & 2 & 0.1\\
\hline
\end{tabular}

위 결과에서 다시 최소 알파값에 해당하는 노드 3에서 가지치기를 하면 아래와 같은 트리가 형성된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pruned.tree}\FloatTok{.2}\NormalTok{ <-}\StringTok{ }\KeywordTok{snip.rpart}\NormalTok{(pruned.tree}\FloatTok{.1}\NormalTok{,}
\NormalTok{                            df.cost}\OperatorTok{$}\NormalTok{pruning_node[}\KeywordTok{which.min}\NormalTok{(df.cost}\OperatorTok{$}\NormalTok{alpha)])}
\KeywordTok{rpart.plot}\NormalTok{(pruned.tree}\FloatTok{.2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/second-prune-result-1} 

}

\caption{2단계 가지치기 결과}\label{fig:second-prune-result}
\end{figure}

\hypertarget{cart-best-tree}{%
\subsection{최적 트리의 선정}\label{cart-best-tree}}

위 가지치기 과정에서 얻는 가지친 트리들이 최종 트리의 후보가 되며, 이 중 테스트 표본에 대한 오분류율이 가장 작은 트리를 최적 트리로 선정하게 된다.

트리를 학습할 때 사용된 학습데이터 Table \ref{tab:tree-train-data-table} 외에, Table \ref{tab:tree-test-data-table}과 같은 6개의 테스트 데이터가 있다고 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{x1 =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{),}
  \DataTypeTok{x2 =} \KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{4}\NormalTok{),}
  \DataTypeTok{class =} \KeywordTok{factor}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\DataTypeTok{levels=}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:tree-test-data-table}테스트 데이터}
\centering
\begin{tabular}{rrr}
\toprule
x1 & x2 & class\\
\midrule
1 & 5 & 1\\
0 & 5 & 1\\
3 & 4 & 2\\
4 & 3 & 2\\
2 & 7 & 1\\
\addlinespace
1 & 4 & 2\\
\bottomrule
\end{tabular}
\end{table}

테스트 데이터에 위에서 학습된 세 개의 트리, 즉 최대 트리 \emph{cart.est}와 두 개의 가지치기 트리 \emph{pruned.tree.1} \& \emph{pruned.tree.2}를 적용하여 각 트리가 각각의 테스트 데이터를 어떻게 분류하는지 살펴보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test_pred <-}\StringTok{ }\NormalTok{test_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_cols}\NormalTok{(}
    \DataTypeTok{pred_maxtree =} \KeywordTok{predict}\NormalTok{(cart.est, test_df, }\DataTypeTok{type=}\StringTok{"class"}\NormalTok{),}
    \DataTypeTok{pred_prune1 =} \KeywordTok{predict}\NormalTok{(pruned.tree}\FloatTok{.1}\NormalTok{, test_df, }\DataTypeTok{type=}\StringTok{"class"}\NormalTok{),}
    \DataTypeTok{pred_prune2 =} \KeywordTok{predict}\NormalTok{(pruned.tree}\FloatTok{.2}\NormalTok{, test_df, }\DataTypeTok{type=}\StringTok{"class"}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:tree-class-prediction-table}테스트 데이터에 대한 예측 결과}
\centering
\begin{tabular}{rrllll}
\toprule
x1 & x2 & class & pred\_maxtree & pred\_prune1 & pred\_prune2\\
\midrule
1 & 5 & 1 & 1 & 1 & 2\\
0 & 5 & 1 & 1 & 1 & 2\\
3 & 4 & 2 & 2 & 2 & 2\\
4 & 3 & 2 & 2 & 2 & 2\\
2 & 7 & 1 & 1 & 1 & 1\\
\addlinespace
1 & 4 & 2 & 1 & 1 & 2\\
\bottomrule
\end{tabular}
\end{table}

결과 Table \ref{tab:tree-class-prediction-table}에서 최대트리가 오분류한 테스트 표본은 1개, 첫번째 가지치기 트리가 오분류한 테스트 표본은 1개, 그리고 두 번째 가지치기 트리가 오분류한 테스트 표본은 2개이다.

위 결과를 토대로, 최적의 트리를 선정하는 과정은 아래와 같다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  각각의 트리에 의해 오분류된 테스트 표본의 개수를 전체 테스트 표본의 개수로 나누어 오분류율 \(R^{ts}\)를 구한다.
\item
  테스트 표본 수를 \(n_{test}\)라 할 때, 오분류의 표준편차를 아래와 같이 계산한다.
  \[SE = \sqrt{\frac{R^{ts}(1 - R^{ts})}{n_{test}}}\]
\item
  1에서 구한 오분류율에 2에서 구한 표준편차를 더하여 \(R^{ts} + SE\)를 각 트리의 평가척도로 계산한다. 후보 트리들 중 해당 평가척도가 가장 작은 트리를 최종 트리로 선정한다.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test.summary <-}\StringTok{ }\NormalTok{test_pred }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{n.test =} \KeywordTok{n}\NormalTok{(),}
            \DataTypeTok{cart.est =} \KeywordTok{sum}\NormalTok{(pred_maxtree }\OperatorTok{!=}\StringTok{ }\NormalTok{class) }\OperatorTok{/}\StringTok{ }\NormalTok{n.test,}
            \DataTypeTok{pruned.tree.1 =} \KeywordTok{sum}\NormalTok{(pred_prune1 }\OperatorTok{!=}\StringTok{ }\NormalTok{class) }\OperatorTok{/}\StringTok{ }\NormalTok{n.test,}
            \DataTypeTok{pruned.tree.2 =} \KeywordTok{sum}\NormalTok{(pred_prune2 }\OperatorTok{!=}\StringTok{ }\NormalTok{class) }\OperatorTok{/}\StringTok{ }\NormalTok{n.test) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather}\NormalTok{(}\StringTok{"tree"}\NormalTok{,}\StringTok{"R.ts"}\NormalTok{,}\OperatorTok{-}\NormalTok{n.test) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{SE =} \KeywordTok{sqrt}\NormalTok{((R.ts}\OperatorTok{*}\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{R.ts))}\OperatorTok{/}\NormalTok{n.test),}
         \DataTypeTok{score =}\NormalTok{ R.ts }\OperatorTok{+}\StringTok{ }\NormalTok{SE) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{n.test)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:misclassification-rate-table}분류 성능}
\centering
\begin{tabular}{lrrr}
\toprule
트리 & 오분류율(\$R\textasciicircum{}\{ts\}\$) & 표준편차(\$SE\$) & 척도(\$R\textasciicircum{}\{ts\} + SE\$)\\
\midrule
cart.est & 0.17 & 0.15 & 0.32\\
pruned.tree.1 & 0.17 & 0.15 & 0.32\\
pruned.tree.2 & 0.33 & 0.19 & 0.53\\
\bottomrule
\end{tabular}
\end{table}

위 결과, 최적 트리는 최대 트리 혹은 첫 번째 가지치기 트리가 된다.

위 절차를 임의의 데이터에 대해 수행하는 함수를 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rpart_learn <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(formula, train_df, test_df) \{}
  \CommentTok{# 최대 트리 생성}
\NormalTok{  max_tree <-}\StringTok{ }\KeywordTok{rpart}\NormalTok{(formula}
\NormalTok{                    , }\DataTypeTok{data =}\NormalTok{ train_df}
\NormalTok{                    , }\DataTypeTok{method =} \StringTok{"class"}
\NormalTok{                    , }\DataTypeTok{parms =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{split =} \StringTok{"gini"}\NormalTok{)}
\NormalTok{                    , }\DataTypeTok{control =} \KeywordTok{rpart.control}\NormalTok{(}\DataTypeTok{minsplit =} \DecValTok{2}
\NormalTok{                                              , }\DataTypeTok{minbucket =} \DecValTok{1}
\NormalTok{                                              , }\DataTypeTok{cp =} \DecValTok{0}
\NormalTok{                                              , }\DataTypeTok{xval =} \DecValTok{0}
\NormalTok{                                              , }\DataTypeTok{maxcompete =} \DecValTok{0}
\NormalTok{                    )}
\NormalTok{  )}
  
  \CommentTok{# 가지치기}
\NormalTok{  curr_tree <-}\StringTok{ }\KeywordTok{list}\NormalTok{()}
\NormalTok{  k <-}\StringTok{ }\DecValTok{1}
\NormalTok{  curr_tree[[k]] <-}\StringTok{ }\NormalTok{max_tree}
  \ControlFlowTok{while}\NormalTok{(}\KeywordTok{dim}\NormalTok{(curr_tree[[k]]}\OperatorTok{$}\NormalTok{frame)[}\DecValTok{1}\NormalTok{] }\OperatorTok{>}\StringTok{ }\DecValTok{1}\NormalTok{) \{}
\NormalTok{    internal.node.index <-}\StringTok{ }\KeywordTok{rownames}\NormalTok{(curr_tree[[k]]}\OperatorTok{$}\NormalTok{frame)[}\KeywordTok{which}\NormalTok{(curr_tree[[k]]}\OperatorTok{$}\NormalTok{frame}\OperatorTok{$}\NormalTok{var }\OperatorTok{!=}\StringTok{ '<leaf>'}\NormalTok{)] }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{as.numeric}\NormalTok{()}
\NormalTok{    df.cost <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(internal.node.index, subtreeEval, }\DataTypeTok{tree=}\NormalTok{curr_tree[[k]]) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{bind_rows}\NormalTok{()}
\NormalTok{    curr_tree[[k }\OperatorTok{+}\StringTok{ }\DecValTok{1}\NormalTok{]] <-}\StringTok{ }\KeywordTok{snip.rpart}\NormalTok{(curr_tree[[k]],}
\NormalTok{               df.cost}\OperatorTok{$}\NormalTok{pruning_node[}\KeywordTok{which.min}\NormalTok{(df.cost}\OperatorTok{$}\NormalTok{alpha)])}
\NormalTok{    k <-}\StringTok{ }\NormalTok{k }\OperatorTok{+}\StringTok{ }\DecValTok{1}
\NormalTok{  \}}

  \CommentTok{# 최적 가지치기 트리 선정}
\NormalTok{  n.test <-}\StringTok{ }\KeywordTok{dim}\NormalTok{(test_df)[}\DecValTok{1}\NormalTok{]}
\NormalTok{  R.ts <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(curr_tree, }\ControlFlowTok{function}\NormalTok{(x) \{}
    \KeywordTok{sum}\NormalTok{(}\KeywordTok{predict}\NormalTok{(x, test_df, }\DataTypeTok{type=}\StringTok{"class"}\NormalTok{) }\OperatorTok{!=}\StringTok{ }\NormalTok{test_df}\OperatorTok{$}\NormalTok{class) }\OperatorTok{/}\StringTok{ }\NormalTok{n.test}
\NormalTok{    \}) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unlist}\NormalTok{()}
\NormalTok{  score <-}\StringTok{ }\NormalTok{R.ts }\OperatorTok{+}\StringTok{ }\KeywordTok{sqrt}\NormalTok{((R.ts}\OperatorTok{*}\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{R.ts))}\OperatorTok{/}\NormalTok{n.test)}
  \KeywordTok{return}\NormalTok{(curr_tree[[}\KeywordTok{max}\NormalTok{(}\KeywordTok{which}\NormalTok{(score }\OperatorTok{==}\StringTok{ }\KeywordTok{min}\NormalTok{(score)))]])}
\NormalTok{\}}

\NormalTok{optimal_tree <-}\StringTok{ }\KeywordTok{rpart_learn}\NormalTok{(class }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, train_df, test_df)}
\KeywordTok{rpart.plot}\NormalTok{(optimal_tree)}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-mining-book_files/figure-latex/rpart-learn-1.png}

\hypertarget{cart-r-pkg}{%
\section{R패키지 내 분류 트리 방법}\label{cart-r-pkg}}

앞 장에서는 \emph{rpart}의 결과를 이용하여 교재 8.2 - 8.3장의 예제를 재현해보았다. 실제로 \emph{rpart} 내부의 기본 트리 방법은 교재의 예제와는 다소 다른 부분이 있다. 이 장에서는 실제 \emph{rpart} 패키지의 분류 트리 방법에 대해 알아본다.

\hypertarget{cart-r-pkg-split}{%
\subsection{트리 확장}\label{cart-r-pkg-split}}

트리 내 임의의 노드 \(t\)에 대한 불순도는 아래와 같이 정의된다.
\[i(t) = \sum_{j=1}^{J} f\left(p(j|t)\right)\]
여기에서 \(p(j|t)\)는 노드 \(t\) 내 전체 샘플 \(N(t)\) 중 범주 \(j\)의 샘플 \(N_j(t)\)의 비율로 추정된다.
\[p(j|t) \approx \frac{N_j(t)}{N(t)}\]
또한 함수 \(f\)는 concave 함수로, \(f(0) = f(1) = 0\)의 조건을 만족시켜야 한다. \emph{rpart} 에서 설정할 수 있는 함수 \(f\)의 종류에 대해서는 아래에서 좀 더 자세히 살펴보기로 한다.

트리 내 임의의 노드 \(t\)가 분지규칙 \(s\)에 따라 두 개의 노드 \(t_L\)과 \(t_R\)로 분지된다고 할 때, 불순도의 감소량은 아래와 같이 계산된다.

\begin{eqnarray}
\Delta I(s,t) &=& I(t) - I(t_L) - I(t_R)\\ &=& p(t)i(t) - p(t_L)i(t_L) - p(t_R)i(t_R) 
\end{eqnarray}

\emph{rpart}는 위 \(\Delta I(s,t)\)값이 최대가 되는 분지 기준 \(s^*\)를 찾아 노드 \(t\)를 분지하여 트리를 확장하고, 확장된 트리의 최종 노드에서 다시 최적 분지를 찾는 과정을 반복한다.

\hypertarget{-}{%
\subsubsection{분지 함수}\label{-}}

함수 \emph{rpart} 사용 시 \emph{parms} 파라미터에 \emph{split} 값으로 분지 방법을 설정할 수 있다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Gini index (parms=list(split=`gini'))
  교재의 예제에 사용된 방법으로, 우선 아래와 같은 함수 \(f\)를 사용한다.
  \[f(p) = p(1-p)\]
\item
  information index (parms=list(split=`information'))
  교재에 엔트로피 지수(Entropy index)로 설명된 지수로, 아래와 같은 함수를 사용한다.
  \[f(p) = -p\log(p)\]
\item
  user-defined function
  사용자가 임의로 함수를 정의하여 사용할 수 있다. 본 장에서는 자세한 설명은 생략한다.
\end{enumerate}

\hypertarget{cart-r-pkg-pruning}{%
\subsection{가지치기}\label{cart-r-pkg-pruning}}

임의의 노드 \(t\)에 대한 위험도(오분류 비용의 기대치)는 아래와 같이 계산된다.
\[r(t) = \sum_{j \neq \tau(t)} p(j|t)C\left(\tau(t)|j\right)\]
여기에서 함수 \(C(i|j)\)는 범주 \(j\)에 속하는 객체를 범주 \(i\)로 분류할 때의 오분류 비용이며, \(\tau(t)\)는 노드 \(t\) 내의 오분류 비용을 최소화하도록 노드 \(t\)에 지정된 범주값이다.

\emph{rpart}의 오분류 비용 \(C(i|j)\)의 기본값은
\[C(i|j) = 
\begin{cases} 1,  & \text{  if } i \neq j\\
              0,  & \text{  if } i = j
\end{cases} \]
으로 설정되어 있으며, \emph{parms} 파라미터에 \emph{loss} 값으로 오분류 비용 \(C(i|j)\)를 재설정할 수 있다. 본 장에서는 기본값을 사용하도록 하자.

\(A(T)\)를 트리 \(T\)의 최종 노드의 집합이라 정의하고, 트리의 최종 노드의 개수를 \(|T|\)라 할 때, 트리 \(T\)의 위험도 \(R(T)\)는 아래와 같이 정의된다.
\[R(T) = \sum_{t \in A(T)} p(t)r(t)\]

복잡도 계수(complexity parameter) \(\alpha \in [0, \infty)\)를 이용하여, 트리의 비용-복합도 척도를 다음과 같이 정의한다.
\[R_\alpha(T) = R(T) + \alpha|T|\]
이 때, 임의의 계수 \(\alpha\)에 대해 비용 \(R_\alpha(T)\)가 최소가 되게하는 가지치기 트리를 \(T_\alpha\)라 하면, 아래와 같은 관계들이 성립한다.

\begin{itemize}
\tightlist
\item
  \(T_0\): 최대 트리
\item
  \(T_\infty\): 뿌리 노드 트리 (분지 없음)
\item
  \(\alpha > \beta\)일 때, \(T_\alpha\)는 \(T_\beta\)와 동일하거나 혹은 \(T_\beta\)에서 가지치기된 트리이다.
\end{itemize}

\hypertarget{cart-r-pkg-param}{%
\subsection{파라미터값 결정}\label{cart-r-pkg-param}}

함수 \emph{rpart}를 사용할 때 여러가지 사용자 정의 파라미터값을 설정할 수 있으며, 그 파라미터 값에 따라 생성되는 트리의 결과가 달라진다. 대표적인 파라미터 값으로는 아래와 같은 것들이 있다.

\begin{itemize}
\tightlist
\item
  minsplit: 분지를 시도하기 위해 필요한 노드 내 최소 관측객체 수 (default=20)
\item
  cp: 노드가 분지되기 위한 최소 relative error 감소치 (default = 0.01). 값이 0일 경우 최대트리를 생성한다.
\item
  maxdepth: 뿌리노드부터 임의의 최종노드에 도달하는 최대 가능 분지 수 (default=30)
\end{itemize}

\hypertarget{svm}{%
\chapter{서포트 벡터 머신}\label{svm}}

\hypertarget{svm-overview}{%
\section{개요}\label{svm-overview}}

서포트 벡터 머신(suuport vector machine; 이하 SVM)은 기본적으로 두 범주를 갖는 객체들을 분류하는 방법이다. 물론 세 범주 이상의 경우로 확장이 가능하다.

\hypertarget{svm-packages-install}{%
\section{필요 R package 설치}\label{svm-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.2.1\\
\hline
e1071 & 1.7-1\\
\hline
Matrix & 1.2-17\\
\hline
quadprog & 1.5-7\\
\hline
\end{tabular}

\hypertarget{linear-svm-separable}{%
\section{선형 SVM - 분리 가능 경우}\label{linear-svm-separable}}

\hypertarget{linear-svm-separable-basic-script}{%
\subsection{기본 R 스크립트}\label{linear-svm-separable-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{x1 =} \KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{5}\NormalTok{),}
  \DataTypeTok{x2 =} \KeywordTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{4}\NormalTok{),}
  \DataTypeTok{class =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{-1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{-1}\NormalTok{, }\DecValTok{-1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{-1}\NormalTok{)}
\NormalTok{)}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(train_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
             \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
             \DataTypeTok{caption =} \StringTok{'선형분리가능 학습표본 데이터'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:svm-train-data-table}선형분리가능 학습표본 데이터}
\centering
\begin{tabular}{rrr}
\toprule
x1 & x2 & class\\
\midrule
5 & 7 & 1\\
4 & 3 & -1\\
7 & 8 & 1\\
8 & 6 & 1\\
3 & 6 & -1\\
\addlinespace
2 & 5 & -1\\
6 & 6 & 1\\
9 & 6 & 1\\
5 & 4 & -1\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:svm-train-data-table}와 같이 두 독립변수 \emph{x1}, \emph{x2}와 이분형 종속변수 \emph{class}의 관측값으로 이루어진 9개의 학습표본을 \emph{train\_df}라는 data frame에 저장한다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(e1071)}
\NormalTok{svm_model <-}\StringTok{ }\KeywordTok{svm}\NormalTok{(}\KeywordTok{as.factor}\NormalTok{(class) }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, }\DataTypeTok{data =}\NormalTok{ train_df, }\DataTypeTok{kernel =} \StringTok{"linear"}\NormalTok{, }\DataTypeTok{scale =} \OtherTok{FALSE}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(svm_model, }\DataTypeTok{data =}\NormalTok{ train_df, }\DataTypeTok{formula =}\NormalTok{ x2 }\OperatorTok{~}\StringTok{ }\NormalTok{x1, }\DataTypeTok{grid =} \DecValTok{200}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/linear-svm-basic-1} 

}

\caption{선형 SVM 분리 하이퍼플레인}\label{fig:linear-svm-basic}
\end{figure}

그림 \ref{fig:linear-svm-basic}에서 각 객체의 기호는 서포트 벡터 여부(``X''이면 서포트 벡터), 각 객체의 색상은 범주값(검정 = -1, 빨강 = 1)을 나타내며, 분리 하이퍼플레인은 아래와 같다.

\[
0.6666667 x_{1} + 0.6666667 x_{2} = 7
\]

\hypertarget{linear-svm-notation}{%
\subsection{기호 정의}\label{linear-svm-notation}}

본 장에서 사용될 수학적 기호는 아래와 같다.

\begin{itemize}
\tightlist
\item
  \(\mathbf{x} \in \mathbb{R}^p\): p차원 변수벡터
\item
  \(y \in \{-1, 1\}\): 범주
\item
  \(N\): 객체 수
\item
  \((\mathbf{x}_i, y_i)\): \(i\)번째 객체의 변수벡터와 범주값
\end{itemize}

\hypertarget{linear-svm-separable-hyperplane}{%
\subsection{최적 하이퍼플레인}\label{linear-svm-separable-hyperplane}}

선형 SVM은 주어진 객체들의 두 범주를 완벽하게 분리하는 하이퍼플레인 중 각 범주의 서포트 벡터들로부터의 거리가 최대가 되는 하이퍼플레인을 찾는 문제로 귀착된다.

우선 아래와 같이 하이퍼플레인을 정의한다.

\begin{equation}
\mathbf{w}^\top \mathbf{x} + b = 0 \label{eq:linear-svm-hyperplane}
\end{equation}

여기서 \(\mathbf{w} \in \mathbb{R}^p\)와 \(b \in \mathbb{R}\)이 하이퍼플레인의 계수이다.

범주값이 1인 객체들 중 하이퍼플레인에서 가장 가까운 객체에 대해 다음과 같은 조건이 만족한다고 가정하자.

\[
H_1: \mathbf{w}^\top \mathbf{x} + b = 1 
\]

또한 범주값이 -1인 객체들 중 하이퍼플레인에서 가장 가까운 객체에 대해 다음과 같은 조건이 만족한다고 가정하자.

\[
H_2: \mathbf{w}^\top \mathbf{x} + b = -1
\]

이 때 두 하이퍼플레인 \(H_1\)과 \(H_2\) 간의 거리(margin)는 \(2 / \lVert \mathbf{w} \rVert\)이다. 선형 SVM은 아래와 같이 \(H_1\)과 \(H_2\) 간의 거리를 최대로 하는 최적화 문제가 된다.

\begin{equation*}
\begin{split}
\max \text{  } & \frac{2}{\mathbf{w}^\top \mathbf{w}}\\
\text{s.t.}& \\
& \mathbf{w}^\top \mathbf{x}_i + b \ge 1 \text{ for } y_i = 1\\
& \mathbf{w}^\top \mathbf{x}_i + b \le -1 \text{ for } y_i = -1
\end{split}
\end{equation*}

이를 간략히 정리하면

\begin{equation*}
\begin{split}
\min \text{  } & \frac{\mathbf{w}^\top \mathbf{w}}{2}\\
\text{s.t.}& \\
& y_i \left( \mathbf{w}^\top \mathbf{x}_i + b \right) \ge 1
\end{split}
\end{equation*}

과 같이 정리할 수 있으며, 각 객체 \(i\)에 대한 제약조건에 라그랑지 계수(Lagrange multiplier) \(\alpha_i \ge 0\)를 도입하여 라그랑지 함수를 유도하면 식 \eqref{eq:linear-svm-primal}과 같은 최적화 문제가 된다. 이를 원문제(primal problem)라 하자.

\begin{equation}
\begin{split}
\min \text{  } & L_P = \frac{1}{2} \mathbf{w}^\top \mathbf{w} + \sum_{i = 1}^{N} \alpha_i \left[ y_i \left( \mathbf{w}^\top \mathbf{x}_i + b \right) - 1 \right]\\
\text{s.t.  } & \alpha_i \ge 0, \text{  } i = 1, \cdots, N
\end{split}
\label{eq:linear-svm-primal}
\end{equation}

원문제 식 \eqref{eq:linear-svm-primal}에 대한 울프쌍대문제(Wolfe dual problem)는 아래 식 \eqref{eq:linear-svm-dual}과 같이 도출된다. 보다 자세한 내용은 교재\citep{jun2012datamining} 참고.

\begin{equation}
\begin{split}
\max \text{  } & L_D = \sum_{i = 1}^{N} \alpha_i - \frac{1}{2} \sum_{i = 1}^{N} \sum_{j = 1}^{N} \alpha_i \alpha_j y_i y_j \mathbf{x}_i^\top \mathbf{x}_j\\
\text{s.t. } &\\
& \sum_{i = 1}^{N} \alpha_i y_i = 0\\
& \alpha_i \ge 0, \text{  } i = 1, \cdots, N
\end{split}
\label{eq:linear-svm-dual}
\end{equation}

식 \eqref{eq:linear-svm-dual}은 이차계획(quadratic programming) 문제로, 각종 소프트웨어와 알고리즘을 이용하여 구할 수 있다. 본 장에서는 \texttt{quadprog} 패키지를 이용하여 해를 구하기로 한다. 이는 실제로 \texttt{e1071}의 \texttt{svm} 함수 호출 시 사용하는 방법은 아니며, 실제 \texttt{svm} 함수가 호출하는 알고리즘은 다음 장에서 다시 설명하기로 한다.

\texttt{quadprog}의 \texttt{solve.QP} 함수는 아래와 같은 형태로 formulation된 문제\citep{goldfarb1983numerically}에 대한 최적해를 구한다.

\begin{equation}
\begin{split}
\min \text{  } & -\mathbf{d}^{\top}\boldsymbol{\alpha} + \frac{1}{2} \boldsymbol{\alpha}^{\top}\mathbf{D}\boldsymbol{\alpha}\\
\text{s.t. } & \mathbf{A}^{\top}\boldsymbol{\alpha} \ge \mathbf{b}_0
\end{split}
\label{eq:quadprog}
\end{equation}

식 \eqref{eq:quadprog}과 식 \eqref{eq:linear-svm-dual}이 동일한 문제를 나타내도록 아래와 같이 목적함수에 필요한 벡터 및 행렬을 정의한다.

\begin{eqnarray*}
\mathbf{d} &=& \mathbf{1}_{N \times 1}\\
\mathbf{D} &=& \mathbf{y}\mathbf{y}^{\top}\mathbf{X}\mathbf{X}^{\top}
\end{eqnarray*}
where
\begin{eqnarray*}
\mathbf{y} &=& \left[ \begin{array}{c c c c} y_1 & y_2 & \cdots & y_N \end{array} \right]^\top\\
\mathbf{X} &=& \left[ \begin{array}{c c c c} \mathbf{x}_1 & \mathbf{x}_2 & \cdots & \mathbf{x}_N \end{array} \right]^{\top}
\end{eqnarray*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N <-}\StringTok{ }\KeywordTok{dim}\NormalTok{(train_df)[}\DecValTok{1}\NormalTok{]}
\NormalTok{X <-}\StringTok{ }\NormalTok{train_df[}\KeywordTok{c}\NormalTok{(}\StringTok{'x1'}\NormalTok{, }\StringTok{'x2'}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{()}
\NormalTok{y <-}\StringTok{ }\NormalTok{train_df[[}\StringTok{'class'}\NormalTok{]] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{()}

\NormalTok{d <-}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, N)}
\NormalTok{D <-}\StringTok{ }\NormalTok{(y }\OperatorTok{%*%}\StringTok{ }\KeywordTok{t}\NormalTok{(y)) }\OperatorTok{*}\StringTok{ }\NormalTok{(X }\OperatorTok{%*%}\StringTok{ }\KeywordTok{t}\NormalTok{(X))}
\end{Highlighting}
\end{Shaded}

여기에서 행렬 \(\mathbf{D}\)의 determinant 값은 0으로, \citet{goldfarb1983numerically} 가 가정하는 symmetric positive definite matrix 조건에 위배되어 \texttt{solve.QP} 함수 실행 시 오류가 발생한다. 이를 방지하기 위해 아래 예에서는 \texttt{Matrix} 패키지의 \texttt{nearPD}함수를 이용하여 행렬 \(\mathbf{D}\)와 근사한 symmetric positive definite matrix를 아래와 같이 찾는다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{D_pd <-}\StringTok{ }\NormalTok{Matrix}\OperatorTok{::}\KeywordTok{nearPD}\NormalTok{(D, }\DataTypeTok{doSym =}\NormalTok{ T)}\OperatorTok{$}\NormalTok{mat }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

식 \eqref{eq:quadprog}의 제약식은 모두 inequality 형태로, 식 \eqref{eq:linear-svm-dual}의 equality constraint \(\sum_{i = 1}^{N} \alpha_i y_i = 0\)를 표현하기 위해서 두 개의 제약식 \(\sum_{i = 1}^{N} \alpha_i y_i \ge 0\)와 \(\sum_{i = 1}^{N} - \alpha_i y_i \ge 0\)를 생성한다.

\begin{equation*}
\mathbf{A}^\top = \left[ 
\begin{array}{c c c c}
y_1 & y_2 & \cdots & y_N\\
-y_1 & -y_2 & \cdots & -y_N\\
1 & 0 & \cdots & 0\\
0 & 1 & \cdots & 0\\
\cdots & \cdots & \cdots & \cdots \\
0 & 0 & \cdots & 1
\end{array}
\right],
\mathbf{b}_0 = \left[ \begin{array}{c}
0 \\ 0 \\ 0 \\ 0 \\ \cdots \\ 0
\end{array}
\right]
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A <-}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}
\NormalTok{  y,}
  \OperatorTok{-}\NormalTok{y,}
  \KeywordTok{diag}\NormalTok{(N)}
\NormalTok{)}
\NormalTok{b_zero <-}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{2} \OperatorTok{+}\StringTok{ }\NormalTok{N)}
\end{Highlighting}
\end{Shaded}

이제 위에서 구한 행렬과 벡터들을 \texttt{solve.QP} 함수에 입력하여 최적해를 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res <-}\StringTok{ }\NormalTok{quadprog}\OperatorTok{::}\KeywordTok{solve.QP}\NormalTok{(D_pd, d, A, b_zero)}
\NormalTok{alpha_sol <-}\StringTok{ }\NormalTok{res}\OperatorTok{$}\NormalTok{solution}
\NormalTok{obj_val <-}\StringTok{ }\OperatorTok{-}\NormalTok{res}\OperatorTok{$}\NormalTok{value}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:svm-separable-alpha}이차계획문제의 최적해}
\centering
\begin{tabular}{cc}
\toprule
variable & solution\\
\midrule
alpha\_1 & 0.2234\\
alpha\_2 & 0.0000\\
alpha\_3 & 0.0000\\
alpha\_4 & 0.0000\\
alpha\_5 & 0.2228\\
\addlinespace
alpha\_6 & 0.0000\\
alpha\_7 & 0.2210\\
alpha\_8 & 0.0000\\
alpha\_9 & 0.2216\\
\bottomrule
\end{tabular}
\end{table}

표 \ref{tab:svm-separable-alpha}의 결과는 교재\citep{jun2012datamining}에 나타난 최적해와는 다소 차이가 있으나, 결과적으로 목적함수값은 0.4444로 동일하다.

위의 과정으로 최적해 \(\alpha_{i}^{*}\)를 구한 뒤, 아래와 같이 분리 하이퍼플레인의 계수를 결정할 수 있다.

\begin{eqnarray*}
\mathbf{w} &=& \sum_{i = 1}^{N} \alpha_{i}^{*} y_{i} \mathbf{x}_{i}\\
b &=& \sum_{i: \alpha_{i}^{*} > 0} \frac{1 - y_{i} \mathbf{w}^{\top} \mathbf{x}_{i}}{y_{i}} \left/ \sum_{i: \alpha_{i}^{*} > 0} 1 \right. 
\end{eqnarray*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w <-}\StringTok{ }\KeywordTok{colSums}\NormalTok{(alpha_sol }\OperatorTok{*}\StringTok{ }\NormalTok{y }\OperatorTok{*}\StringTok{ }\NormalTok{X)}
\KeywordTok{print}\NormalTok{(w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        x1        x2 
## 0.6666658 0.6666657
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sv_ind <-}\StringTok{ }\KeywordTok{which}\NormalTok{(}\KeywordTok{round}\NormalTok{(alpha_sol, }\DataTypeTok{digits =} \DecValTok{4}\NormalTok{) }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{)}
\NormalTok{b <-}\StringTok{ }\KeywordTok{mean}\NormalTok{((}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{y[sv_ind] }\OperatorTok{*}\StringTok{ }\NormalTok{(X[sv_ind, ] }\OperatorTok{%*%}\StringTok{ }\NormalTok{w)) }\OperatorTok{/}\StringTok{ }\NormalTok{y[sv_ind])}
\KeywordTok{print}\NormalTok{(b)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -6.99999
\end{verbatim}

위 결과와 같이, 분리 하이퍼플레인은 교재와 동일하게 얻어진다.

\hypertarget{linear-svm-inseparable}{%
\section{선형 SVM - 분리 불가능 경우}\label{linear-svm-inseparable}}

본 장에서는 학습표본 내의 두 범주가 어떠한 선형 하이퍼플레인으로도 완전하게 분리되지 않아 식 \eqref{eq:linear-svm-primal}이 해를 갖지 못하는 경우에 대한 문제를 다룬다.

\hypertarget{linear-svm-inseparable-basic-script}{%
\subsection{기본 R 스크립트}\label{linear-svm-inseparable-basic-script}}

앞 장에서 사용한 학습표본에 아래와 같이 하나의 객체를 추가하여 전체 학습표본이 선형 하이퍼플레인으로 분리될 수 없도록 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{inseparable_train_df <-}\StringTok{ }\KeywordTok{bind_rows}\NormalTok{(train_df, }
                                  \KeywordTok{tibble}\NormalTok{(}\DataTypeTok{x1 =} \DecValTok{7}\NormalTok{, }\DataTypeTok{x2 =} \DecValTok{6}\NormalTok{, }\DataTypeTok{class =} \DecValTok{-1}\NormalTok{))}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(inseparable_train_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
             \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
             \DataTypeTok{caption =} \StringTok{'선형분리불가능 학습표본 데이터'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:svm-inseparable-train-data-table}선형분리불가능 학습표본 데이터}
\centering
\begin{tabular}{rrr}
\toprule
x1 & x2 & class\\
\midrule
5 & 7 & 1\\
4 & 3 & -1\\
7 & 8 & 1\\
8 & 6 & 1\\
3 & 6 & -1\\
\addlinespace
2 & 5 & -1\\
6 & 6 & 1\\
9 & 6 & 1\\
5 & 4 & -1\\
7 & 6 & -1\\
\bottomrule
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(e1071)}
\NormalTok{svm_model <-}\StringTok{ }\KeywordTok{svm}\NormalTok{(}\KeywordTok{as.factor}\NormalTok{(class) }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, }\DataTypeTok{data =}\NormalTok{ inseparable_train_df, }
                 \DataTypeTok{kernel =} \StringTok{"linear"}\NormalTok{, }\DataTypeTok{cost =} \DecValTok{1}\NormalTok{, }\DataTypeTok{scale =} \OtherTok{FALSE}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(svm_model, }\DataTypeTok{data =}\NormalTok{ inseparable_train_df, }\DataTypeTok{formula =}\NormalTok{ x2 }\OperatorTok{~}\StringTok{ }\NormalTok{x1, }\DataTypeTok{grid =} \DecValTok{200}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/linear-svm-basic-inseparable-1} 

}

\caption{선형 SVM 분리 불가능 경우의 하이퍼플레인}\label{fig:linear-svm-basic-inseparable}
\end{figure}

Figure \ref{fig:linear-svm-basic-inseparable}에서 보이듯, 하나의 검정 객체(범주 = -1)가 범주 1로 분류되는 영역에 존재하여 오분류가 발생한다. 이처럼 선형 하이퍼플레인으로 두 범주 학습표본의 분리가 불가능한 경우, 오분류 학습표본에 대한 페널티를 적용하여 최적 분리 하이퍼플레인을 도출하게 된다. 위 예에서의 최적 하이퍼플레인은 아래와 같다.

\[
0.6 x_{1} + 0.8 x_{2} = 7.6
\]

\hypertarget{linear-svm-inseparable-hyperplane}{%
\subsection{최적 하이퍼플레인}\label{linear-svm-inseparable-hyperplane}}

여유변수(slack variable) \(\xi_i\) 를 각 학습객체 \(i = 1, \cdots, N\)에 대해 아래와 같이 정의한다.

\begin{equation*}
\xi_i = \max \left\{ 0, 1 - y_i (\mathbf{w}^\top \mathbf{x}_i + b) \right\}
\end{equation*}

이는 객체가 자신의 범주의 서포트 벡터를 지나는 하이퍼플레인(범주 1인 경우 \(H_1\), 범주 -1인 경우 \(H_2\))으로 부터 다른 범주 방향으로 떨어진 거리를 나타낸다. 이 여유변수 \(\xi_i\)에 단위당 페널티 단가 \(C\)를 부여하여 아래와 같은 최적화 문제를 정의한다.

\begin{equation*}
\begin{split}
\min \text{  } & \frac{\mathbf{w}^\top \mathbf{w}}{2} + C \sum_{i = 1}^{N} \xi_i \\
\text{s.t.}& \\
& y_i \left( \mathbf{w}^\top \mathbf{x}_i + b \right) \ge 1 - \xi_i, \text{  } i = 1, \cdots, N \\
& \xi \ge 0, \text{  } i = 1, \cdots, N
\end{split}
\end{equation*}

이에 대한 울프쌍대문제를 앞 \ref{linear-svm-separable-hyperplane}장과 같은 과정으로 도출하면 아래 식 \eqref{eq:linear-svm-inseparable-dual}와 같다.

\begin{equation}
\begin{split}
\max \text{  } & L_D = \sum_{i = 1}^{N} \alpha_i - \frac{1}{2} \sum_{i = 1}^{N} \sum_{j = 1}^{N} \alpha_i \alpha_j y_i y_j \mathbf{x}_i^\top \mathbf{x}_j\\
\text{s.t. } &\\
& \sum_{i = 1}^{N} \alpha_i y_i = 0\\
& 0 \le \alpha_i \le C, \text{  } i = 1, \cdots, N
\end{split}
\label{eq:linear-svm-inseparable-dual}
\end{equation}

이는 분리 가능 경우의 식 \eqref{eq:linear-svm-dual}에 변수 \(\alpha_i\)에 대한 상한값 \(C\)의 제약이 추가된 문제로, 이는 \texttt{e1071} 패키지의 \texttt{svm} 함수가 기본 방법으로 사용하는 \texttt{LIBSVM} 라이브러리\citep{chang2011libsvm}의 \(C\)-support vector classification(\(C\)-SVC)이 사용하는 문제식이며, \texttt{LIBSVM} 라이브러리는 특정 알고리즘\citep{fan2005working}을 이용하여 해를 제공한다.

아래 \texttt{svm} 함수의 입력 변수에서 \texttt{type\ =\ "C-classification"}은 식 \eqref{eq:linear-svm-dual}를 최적화하겠다는 것을 나타내며, \texttt{cost\ =\ 1}은 페널티 단가 \(C\)의 값을 1로 설정하겠다는 것을 나타낸다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svm_model <-}\StringTok{ }\KeywordTok{svm}\NormalTok{(}\KeywordTok{as.factor}\NormalTok{(class) }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, }\DataTypeTok{data =}\NormalTok{ inseparable_train_df,}
                 \DataTypeTok{kernel =} \StringTok{"linear"}\NormalTok{, }\DataTypeTok{scale =} \OtherTok{FALSE}\NormalTok{,}
                 \DataTypeTok{type =} \StringTok{"C-classification"}\NormalTok{, }\DataTypeTok{cost =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

위 결과 모델 객체 \texttt{svm\_model}의 원소 중 \texttt{index}는 학습표본 중 서포트 벡터에 해당하는 인덱스 \(i\)를 나타내며, \texttt{coefs}는 각 서포트 벡터의 \(\alpha_i y_i\) 값을 나타낸다. 따라서, \texttt{coefs}를 각 서포트 벡터의 범주값 \(y_i\)로 나누면 식 \eqref{eq:linear-svm-inseparable-dual}의 최적해를 아래와 같이 볼 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N <-}\StringTok{ }\KeywordTok{dim}\NormalTok{(inseparable_train_df)[}\DecValTok{1}\NormalTok{]}
\NormalTok{X <-}\StringTok{ }\NormalTok{inseparable_train_df[}\KeywordTok{c}\NormalTok{(}\StringTok{'x1'}\NormalTok{, }\StringTok{'x2'}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{()}
\NormalTok{y <-}\StringTok{ }\NormalTok{inseparable_train_df[[}\StringTok{'class'}\NormalTok{]] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as.numeric}\NormalTok{()}

\NormalTok{sv_ind <-}\StringTok{ }\NormalTok{svm_model}\OperatorTok{$}\NormalTok{index}
\NormalTok{alpha_sol <-}\StringTok{ }\KeywordTok{vector}\NormalTok{(}\StringTok{"numeric"}\NormalTok{, N)}
\NormalTok{alpha_sol[sv_ind] <-}\StringTok{ }\KeywordTok{drop}\NormalTok{(svm_model}\OperatorTok{$}\NormalTok{coefs[, }\DecValTok{1}\NormalTok{]) }\OperatorTok{/}\StringTok{ }\NormalTok{y[sv_ind]}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:svm-inseparable-alpha}이차계획문제의 최적해: 선형 분리 불가능 경우}
\centering
\begin{tabular}{cc}
\toprule
variable & solution\\
\midrule
alpha\_1 & 0.8\\
alpha\_2 & 0.0\\
alpha\_3 & 0.0\\
alpha\_4 & 0.0\\
alpha\_5 & 0.8\\
\addlinespace
alpha\_6 & 0.0\\
alpha\_7 & 1.0\\
alpha\_8 & 0.0\\
alpha\_9 & 0.0\\
alpha\_10 & 1.0\\
\bottomrule
\end{tabular}
\end{table}

하이퍼플레인의 계수 \(\mathbf{w}\)는 분리 가능의 경우와 동일하게 구할 수 있다.

\begin{equation*}
\mathbf{w} = \sum_{i = 1}^{N} \alpha_{i}^{*} y_{i} \mathbf{x}_{i}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w <-}\StringTok{ }\KeywordTok{colSums}\NormalTok{(alpha_sol }\OperatorTok{*}\StringTok{ }\NormalTok{y }\OperatorTok{*}\StringTok{ }\NormalTok{X)}
\KeywordTok{print}\NormalTok{(w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  x1  x2 
## 0.6 0.8
\end{verbatim}

상수 \(b\)는 아래와 같이 \(0 < \alpha_{i}^{*} < C\)인 객체들을 이용해 산출할 수 있다.

\begin{equation*}
b = \sum_{i: 0 < \alpha_{i}^{*} < C} \frac{1 - y_{i} \mathbf{w}^{\top} \mathbf{x}_{i}}{y_{i}} \left/ \sum_{i: 0 < \alpha_{i}^{*} < C} 1 \right. 
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ind <-}\StringTok{ }\NormalTok{sv_ind[alpha_sol[sv_ind] }\OperatorTok{<}\StringTok{ }\NormalTok{svm_model}\OperatorTok{$}\NormalTok{cost]}
\NormalTok{b <-}\StringTok{ }\KeywordTok{mean}\NormalTok{((}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{y[ind] }\OperatorTok{*}\StringTok{ }\NormalTok{(X[ind, ] }\OperatorTok{%*%}\StringTok{ }\NormalTok{w)) }\OperatorTok{/}\StringTok{ }\NormalTok{y[ind])}
\KeywordTok{print}\NormalTok{(b)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -7.6
\end{verbatim}

위와 같은 하이퍼플레인의 계수 \(\mathbf{w}\)와 상수 \(b\)값은 \texttt{svm} 객체에 원소들을 이용하여 보다 쉽게 확인할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w <-}\StringTok{ }\KeywordTok{t}\NormalTok{(svm_model}\OperatorTok{$}\NormalTok{coefs) }\OperatorTok{%*%}\StringTok{ }\NormalTok{svm_model}\OperatorTok{$}\NormalTok{SV}
\KeywordTok{print}\NormalTok{(w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       x1  x2
## [1,] 0.6 0.8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b <-}\StringTok{ }\OperatorTok{-}\NormalTok{svm_model}\OperatorTok{$}\NormalTok{rho}
\KeywordTok{print}\NormalTok{(b)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -7.6
\end{verbatim}

선형 하이퍼플레인으로 분리 불가능한 경우, 페널티 단가 \(C\)의 값에 따라 도출되는 분리 하이퍼플레인이 달라진다. \(C\)의 값이 1, 5, 100일 때의 하이퍼플레인을 비교해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svm_models <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{100}\NormalTok{), }\ControlFlowTok{function}\NormalTok{(C)}
  \KeywordTok{svm}\NormalTok{(}\KeywordTok{as.factor}\NormalTok{(class) }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, }\DataTypeTok{data =}\NormalTok{ inseparable_train_df,}
      \DataTypeTok{kernel =} \StringTok{"linear"}\NormalTok{, }\DataTypeTok{scale =} \OtherTok{FALSE}\NormalTok{,}
      \DataTypeTok{type =} \StringTok{"C-classification"}\NormalTok{, }\DataTypeTok{cost =}\NormalTok{ C))}

\NormalTok{getHyperplane <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(model) \{}
  \KeywordTok{list}\NormalTok{(}\DataTypeTok{C =}\NormalTok{ model}\OperatorTok{$}\NormalTok{cost,}
       \DataTypeTok{w =} \KeywordTok{paste}\NormalTok{(}\KeywordTok{round}\NormalTok{(}\KeywordTok{t}\NormalTok{(model}\OperatorTok{$}\NormalTok{coefs) }\OperatorTok{%*%}\StringTok{ }\NormalTok{model}\OperatorTok{$}\NormalTok{SV, }\DataTypeTok{digits =} \DecValTok{2}\NormalTok{), }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{),}
       \DataTypeTok{b =} \OperatorTok{-}\KeywordTok{round}\NormalTok{(model}\OperatorTok{$}\NormalTok{rho, }\DataTypeTok{digits =} \DecValTok{2}\NormalTok{),}
       \DataTypeTok{sv =} \KeywordTok{paste}\NormalTok{(model}\OperatorTok{$}\NormalTok{index, }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{),}
       \DataTypeTok{misclassified =} \KeywordTok{paste}\NormalTok{(}\KeywordTok{which}\NormalTok{(model}\OperatorTok{$}\NormalTok{fitted }\OperatorTok{!=}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(inseparable_train_df}\OperatorTok{$}\NormalTok{class)), }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{))}
\NormalTok{\}}

\NormalTok{svm_summary <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(svm_models, getHyperplane) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{bind_rows}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:svm-inseparable-summary}페널티 단가 C에 따른 하이퍼플레인 계수 및 결과}
\centering
\begin{tabular}{ccccc}
\toprule
페널티 단가 \$C\$ & \$(w\_1, w\_2)\$ & \$b\$ & 서포트 벡터 객체 & 오분류 객체\\
\midrule
1 & 0.6, 0.8 & -7.6 & 1, 7, 5, 10 & 10\\
5 & 0.4, 1.2 & -9.4 & 1, 4, 7, 5, 10 & 10\\
100 & 0.4, 1.2 & -9.4 & 1, 4, 7, 5, 10 & 10\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:svm-inseparable-summary}에서 보이는 바와 같이, 페널티 단가 \(C\)의 값이 1과 5일 때 분리 하이퍼플레인이 변하는 것을 볼 수 있다. \(C\)값이 5와 100일 때의 분리 하이퍼플레인은 거의 동일하다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(svm_models[[}\DecValTok{2}\NormalTok{]], }\DataTypeTok{data =}\NormalTok{ inseparable_train_df, }\DataTypeTok{formula =}\NormalTok{ x2 }\OperatorTok{~}\StringTok{ }\NormalTok{x1, }\DataTypeTok{grid =} \DecValTok{200}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/linear-svm-inseparable-highcost-1} 

}

\caption{선형 SVM 분리 불가능 경우의 하이퍼플레인 ($C = 5$)}\label{fig:linear-svm-inseparable-highcost}
\end{figure}

Figure \ref{fig:linear-svm-inseparable-highcost}의 하이퍼플레인(\(C = 5\)인 경우)은 Figure \ref{fig:linear-svm-basic-inseparable}의 하이퍼플레인(\(C = 1\)인 경우)보다 오분류 객체에 가깝게 위치함을 확인할 수 있다.

\hypertarget{nonlinear-svm}{%
\section{비선형 SVM}\label{nonlinear-svm}}

본 장에서는 선형으로 분리 성능이 좋지 않은 경우에 대해 원 입력변수에 대해 비선형인 하이퍼플레인을 찾는 문제를 다룬다. 이는 원 입력변수에 대해 비선형인 기저함수 공간으로 객체를 이동시킨 후 해당 공간에서 선형 분리 하이퍼플레인을 찾는 과정이다.

\hypertarget{nonlinear-svm-basic-script}{%
\subsection{기본 R 스크립트}\label{nonlinear-svm-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nonlinear_train_df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{x1 =} \KeywordTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{5}\NormalTok{), }
  \DataTypeTok{x2 =} \KeywordTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{4}\NormalTok{), }
  \DataTypeTok{class =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{-1}\NormalTok{, }\DecValTok{-1}\NormalTok{, }\DecValTok{-1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{-1}\NormalTok{, }\DecValTok{-1}\NormalTok{)}
\NormalTok{)}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(nonlinear_train_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
             \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
             \DataTypeTok{caption =} \StringTok{'비선형 SVM 학습표본 데이터'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:nonlinear-svm-train-data}비선형 SVM 학습표본 데이터}
\centering
\begin{tabular}{rrr}
\toprule
x1 & x2 & class\\
\midrule
5 & 7 & 1\\
4 & 3 & -1\\
7 & 8 & -1\\
8 & 6 & -1\\
3 & 6 & 1\\
\addlinespace
2 & 5 & 1\\
6 & 6 & 1\\
9 & 6 & -1\\
5 & 4 & -1\\
\bottomrule
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(e1071)}
\NormalTok{svm_model <-}\StringTok{ }\KeywordTok{svm}\NormalTok{(}\KeywordTok{as.factor}\NormalTok{(class) }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, }\DataTypeTok{data =}\NormalTok{ nonlinear_train_df, }
                 \DataTypeTok{kernel =} \StringTok{"polynomial"}\NormalTok{, }\DataTypeTok{coef0 =} \DecValTok{1}\NormalTok{, }\DataTypeTok{gamma =} \DecValTok{1}\NormalTok{, }\DataTypeTok{degree =} \DecValTok{2}\NormalTok{,}
                 \DataTypeTok{cost =} \DecValTok{5}\NormalTok{, }\DataTypeTok{scale =} \OtherTok{FALSE}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(svm_model, }\DataTypeTok{data =}\NormalTok{ nonlinear_train_df, }\DataTypeTok{formula =}\NormalTok{ x2 }\OperatorTok{~}\StringTok{ }\NormalTok{x1, }\DataTypeTok{grid =} \DecValTok{200}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/nonlinear-svm-basic-1} 

}

\caption{비선형 SVM 하이퍼플레인}\label{fig:nonlinear-svm-basic}
\end{figure}

\hypertarget{nonlinear-svm-hyperplane}{%
\subsection{최적 하이퍼플레인}\label{nonlinear-svm-hyperplane}}

식 \eqref{eq:linear-svm-hyperplane}을 일반화한 다음과 같은 하이퍼플레인을 고려하자.

\begin{equation}
f(\mathbf{x}) = \Phi(\mathbf{x})^\top \mathbf{w} + b \label{eq:nonlinear-svm-hyperplane}
\end{equation}

여기서 벡터함수 \(\Phi: \mathbb{R}^p \rightarrow \mathbb{R}^m\)는 \(\mathbf{x}\)에 대한 새로운 특징(feature)을 추출하는 변환함수라 할 수 있는데, 통상 추출되는 특징의 차원 \(m\)이 원 변수 \(\mathbf{x}\)의 차원 \(p\)보다 높다. 이를 \(\mathbf{x}\)의 기저함수(basis function)라 부르며, 하이퍼플레인 계수 또한 \(m\)차원의 벡터가 된다 (\(\mathbf{w} \in \mathbb{R}^m\)). 이 때, 비선형 SVM 문제는 선형 SVM 문제 식 \eqref{eq:linear-svm-inseparable-dual}에서 변수를 기저변수로 치환한 형태로 아래 식 \eqref{eq:nonlinear-svm-dual}과 같이 나타낼 수 있다.

\begin{equation}
\begin{split}
\max \text{  } & L_D = \sum_{i = 1}^{N} \alpha_i - \frac{1}{2} \sum_{i = 1}^{N} \sum_{j = 1}^{N} \alpha_i \alpha_j y_i y_j \Phi(\mathbf{x}_i)^\top \Phi(\mathbf{x}_j)\\
\text{s.t. } &\\
& \sum_{i = 1}^{N} \alpha_i y_i = 0\\
& 0 \le \alpha_i \le C, \text{  } i = 1, \cdots, N
\end{split}
\label{eq:nonlinear-svm-dual}
\end{equation}

식 \eqref{eq:nonlinear-svm-dual}의 목적함수에서 기저함수의 내적 \(\Phi(\mathbf{x}_i)^\top \Phi(\mathbf{x}_j)\)을 아래와 같이 커널함수(kernel function)로 나타낼 수 있으며, 이는 두 객체 \(\mathbf{x}_i, \mathbf{x}_j\)간의 일종의 유사성 척도(similarity measure)로 해석될 수 있다.

\begin{equation*}
K(\mathbf{x}_i, \mathbf{x}_j) = \Phi(\mathbf{x}_i)^\top \Phi(\mathbf{x}_j)
\end{equation*}

널리 사용되는 커널함수로는 아래와 같은 함수들이 있다.

\begin{eqnarray*}
\text{Gaussian RBF:} & & K(\mathbf{x}_i, \mathbf{x}_j) = \exp \left( \frac{- \left\lVert \mathbf{x}_i - \mathbf{x}_j \right\rVert^2}{2 \sigma^2} \right)\\
\text{$r$-th order polynomial:} & & K(\mathbf{x}_i, \mathbf{x}_j) = \left( \mathbf{x}_i^\top \mathbf{x}_j + 1 \right)^r \\
\text{Sigmoid:} & & K(\mathbf{x}_i, \mathbf{x}_j) = \tanh \left(\kappa \mathbf{x}_i^\top \mathbf{x}_j - \delta \right)
\end{eqnarray*}

커널함수를 이용하여 분리 하이퍼플레인을 찾기 위한 식을 아래와 같이 나타낸다.

\begin{equation}
\begin{split}
\max \text{  } & L_D = \sum_{i = 1}^{N} \alpha_i - \frac{1}{2} \sum_{i = 1}^{N} \sum_{j = 1}^{N} \alpha_i \alpha_j y_i y_j k_{ij}\\
\text{s.t. } &\\
& \sum_{i = 1}^{N} \alpha_i y_i = 0\\
& 0 \le \alpha_i \le C, \text{  } i = 1, \cdots, N
\end{split}
\label{eq:nonlinear-svm-dual-kernel}
\end{equation}

이 때 \(k_{ij}\)는 \(K(\mathbf{x}_i, \mathbf{x}_j)\)를 나타낸다. 식 \eqref{eq:nonlinear-svm-dual-kernel}의 최적해 \(\boldsymbol\alpha^*\)는 선형 SVM과 마찬가지로 이차계획(quadratic programming) 소프트웨어/알고리즘을 이용하여 구할 수 있다.

Table \ref{tab:nonlinear-svm-train-data}의 학습데이터에 대해 \texttt{e1071} 패키지의 \texttt{svm} 함수를 이용하여 이차 다항 커널에 기반한 분리 하이퍼플레인을 구해보자. \texttt{svm} 함수에 파라미터값 \texttt{kernel\ =\ "polynomial"}를 설정함으로써 다항 커널을 사용할 수 있다. \texttt{svm} 함수의 다항 커널은 위에서 설명된 것보다 일반화된 형태로 아래와 같이 정의된다.

\begin{equation*}
K(\mathbf{x}_i, \mathbf{x}_j) = \left( \gamma \mathbf{x}_i^\top \mathbf{x}_j + \beta_0 \right)^r
\end{equation*}

위 커널함수의 파라미터 \(\gamma, \beta_0, r\)은 \texttt{svm} 함수에 파라미터 \texttt{gamma,\ coef0,\ degree}로 각각 정의된다. 따라서 이차 커널

\begin{equation*}
K(\mathbf{x}_i, \mathbf{x}_j) = \left( \mathbf{x}_i^\top \mathbf{x}_j + 1 \right)^2
\end{equation*}

에 기반한 SVM을 학습하기 위해서 아래와 같이 \texttt{svm} 함수를 호출한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svm_model <-}\StringTok{ }\KeywordTok{svm}\NormalTok{(}\KeywordTok{as.factor}\NormalTok{(class) }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, }\DataTypeTok{data =}\NormalTok{ nonlinear_train_df, }
                 \DataTypeTok{kernel =} \StringTok{"polynomial"}\NormalTok{, }\DataTypeTok{coef0 =} \DecValTok{1}\NormalTok{, }\DataTypeTok{gamma =} \DecValTok{1}\NormalTok{, }\DataTypeTok{degree =} \DecValTok{2}\NormalTok{,}
                 \DataTypeTok{scale =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

위 함수 호출 결과 서포트 벡터 객체는 1, 7, 2, 3, 9이다.

비선형 SVM의 분리 하이퍼플레인 또한 페널티 단가 \(C\)의 값에 따라 달라진다. 선형 SVM의 경우와 같이 \(C = 1, 5, 100\)에 대해 각각 비선형 SVM을 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svm_models <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(}
  \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{100}\NormalTok{),}
  \ControlFlowTok{function}\NormalTok{(C)}
    \KeywordTok{svm}\NormalTok{(}\KeywordTok{as.factor}\NormalTok{(class) }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, }\DataTypeTok{data =}\NormalTok{ nonlinear_train_df,}
        \DataTypeTok{kernel =} \StringTok{"polynomial"}\NormalTok{, }\DataTypeTok{coef0 =} \DecValTok{1}\NormalTok{, }\DataTypeTok{gamma =} \DecValTok{1}\NormalTok{, }\DataTypeTok{degree =} \DecValTok{2}\NormalTok{,}
        \DataTypeTok{cost =}\NormalTok{ C, }\DataTypeTok{scale =} \OtherTok{FALSE}\NormalTok{)}
\NormalTok{)}

\NormalTok{getSummary <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(model) \{}
  \KeywordTok{list}\NormalTok{(}\DataTypeTok{C =}\NormalTok{ model}\OperatorTok{$}\NormalTok{cost,}
       \DataTypeTok{sv =} \KeywordTok{paste}\NormalTok{(model}\OperatorTok{$}\NormalTok{index, }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{),}
       \DataTypeTok{misclassified =} \KeywordTok{paste}\NormalTok{(}\KeywordTok{which}\NormalTok{(model}\OperatorTok{$}\NormalTok{fitted }\OperatorTok{!=}\StringTok{ }\KeywordTok{as.factor}\NormalTok{(nonlinear_train_df}\OperatorTok{$}\NormalTok{class)), }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{))}
\NormalTok{\}}

\NormalTok{svm_summary <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(svm_models, getSummary) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{bind_rows}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:nonlinear-svm-summary}페널티 단가 C에 따른 비선형 SVM 결과}
\centering
\begin{tabular}{ccc}
\toprule
페널티 단가 \$C\$ & 서포트 벡터 객체 & 오분류 객체\\
\midrule
1 & 1, 7, 2, 3, 9 & 7\\
5 & 6, 7, 2, 3, 9 & \\
100 & 6, 7, 2, 3, 9 & \\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{svm-r-pkg}{%
\section{R패키지 내 SVM}\label{svm-r-pkg}}

\hypertarget{svm-kernel-function}{%
\subsection{커널함수}\label{svm-kernel-function}}

앞 장에서는 선형 커널과 다항 커널함수의 예를 살펴보았다. 본 장에서는 가우시안 커널 및 시그모이드 커널을 사용하는 법을 살펴보자.

가우시안 커널의 경우

\begin{equation*}
K(\mathbf{x}_i, \mathbf{x}_j) = \exp \left( -\gamma \left\lVert \mathbf{x}_i - \mathbf{x}_j \right\rVert^2 \right)
\end{equation*}

과 같이 \(\gamma\) 파라미터를 이용하여 함수를 정의하며, \texttt{svm} 함수에 \texttt{gamma} 파라미터값을 통해 설정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svm_model <-}\StringTok{ }\KeywordTok{svm}\NormalTok{(}\KeywordTok{as.factor}\NormalTok{(class) }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, }\DataTypeTok{data =}\NormalTok{ nonlinear_train_df, }
                 \DataTypeTok{kernel =} \StringTok{"radial"}\NormalTok{, }\DataTypeTok{gamma =} \DecValTok{1}\NormalTok{,}
                 \DataTypeTok{cost =} \DecValTok{5}\NormalTok{, }\DataTypeTok{scale =} \OtherTok{FALSE}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(svm_model, }\DataTypeTok{data =}\NormalTok{ nonlinear_train_df, }\DataTypeTok{formula =}\NormalTok{ x2 }\OperatorTok{~}\StringTok{ }\NormalTok{x1, }\DataTypeTok{grid =} \DecValTok{200}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/nonlinear-svm-radial-1} 

}

\caption{가우시안 커널을 이용한 비선형 SVM 하이퍼플레인}\label{fig:nonlinear-svm-radial}
\end{figure}

시그모이드 커널의 경우

\begin{equation*}
K(\mathbf{x}_i, \mathbf{x}_j) = \tanh \left(\gamma \mathbf{x}_i^\top \mathbf{x}_j + \beta_0 \right)
\end{equation*}

와 같이 두 파라미터 \(\gamma, \beta_0\)의 값에 대응하는 \texttt{svm} 함수의 파라미터 \texttt{gamma,\ coef0} 값을 통해 설정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svm_model <-}\StringTok{ }\KeywordTok{svm}\NormalTok{(}\KeywordTok{as.factor}\NormalTok{(class) }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, }\DataTypeTok{data =}\NormalTok{ nonlinear_train_df, }
                 \DataTypeTok{kernel =} \StringTok{"sigmoid"}\NormalTok{, }\DataTypeTok{gamma =} \FloatTok{0.01}\NormalTok{, }\DataTypeTok{coef0 =} \DecValTok{-1}\NormalTok{,}
                 \DataTypeTok{cost =} \DecValTok{5}\NormalTok{, }\DataTypeTok{scale =} \OtherTok{FALSE}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(svm_model, }\DataTypeTok{data =}\NormalTok{ nonlinear_train_df, }\DataTypeTok{formula =}\NormalTok{ x2 }\OperatorTok{~}\StringTok{ }\NormalTok{x1, }\DataTypeTok{grid =} \DecValTok{200}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/nonlinear-svm-sigmoid-1} 

}

\caption{시그모이드 커널을 이용한 비선형 SVM 하이퍼플레인}\label{fig:nonlinear-svm-sigmoid}
\end{figure}

커널 함수의 종류 \texttt{kernel}, 커널 함수의 파라미터 \texttt{gamma,\ coef0,\ degree}, 페널티 단가 \texttt{cost}등의 \texttt{svm} 함수 파라미터는 학습 표본과는 별도의 테스트 데이터에 대해 오분류율을 최소화하는 값을 선택하는 것이 일반적이다.

\hypertarget{svm-nu-classification}{%
\subsection{\texorpdfstring{\(\nu\)-SVC}{\textbackslash{}nu-SVC}}\label{svm-nu-classification}}

\(\nu\)-support vector classification(\(\nu\)-SVC) \citep[\citet{chang2001training}]{scholkopf2000new}은 \(C\)-SVC의 이차계획식 \eqref{eq:nonlinear-svm-dual-kernel}과 다른 형태로, 페널티 단가 \(C\) 대신 \(\nu\)라는 파라미터를 이용한 아래 최적화 문제의 해를 구한다.

\begin{equation}
\begin{split}
\min \text{  } & L_D = \sum_{i = 1}^{N} \sum_{j = 1}^{N} \alpha_i \alpha_j y_i y_j k_{ij}\\
\text{s.t. } &\\
& \sum_{i = 1}^{N} \alpha_i y_i = 0\\
& 0 \le \alpha_i \le \frac{1}{N}, \text{  } i = 1, \cdots, N\\
& \sum_{i = 1}^{N} \alpha_i = \nu
\end{split}
\label{eq:nonlinear-nu-svc-dual}
\end{equation}

이 때, 각 \(\alpha_i\)의 최대값은 \(1/N\)으로, \(\nu\)를 포함한 제약식을 무시할 때 모든 객체에 대한 \(\alpha_i\)값의 합의 이론적 최대치는 1이 되며, \(\nu \in (0, 1]\)은 전체 객체 중 서포트 벡터 객체의 개수를 제한하는 개념으로 생각할 수 있다. 식 \eqref{eq:nonlinear-nu-svc-dual}이 실제로 최적해를 가지기 위한 \(\nu\)값의 범위는

\begin{equation*}
0 < \nu \le \frac{2}{N} \min \left( \sum_i I(y_i = 1), \sum_i I(y_i = -1) \right)
\end{equation*}

으로 \citep{chang2001training}, 에를 들어 범주 1에 속하는 학습표본 객체 수가
전체의 10\% 라면, \(\nu\) 값은 최대 0.2 까지 설정할 수 있다. 또한

\texttt{svm} 함수가 호출하는 \texttt{LIBSVM} 라이브러리는 위 식 \eqref{eq:nonlinear-nu-svc-dual}을 \(N\)이 큰(학습 표본 수가 매우 많은) 경우에도 안정된 결과를 얻을 수 있도록 아래와 같이 변환한 문제를 다룬다.

\begin{equation}
\begin{split}
\min \text{  } & L_D = \sum_{i = 1}^{N} \sum_{j = 1}^{N} \bar{\alpha}_i \bar{\alpha}_j y_i y_j k_{ij}\\
\text{s.t. } &\\
& \sum_{i = 1}^{N} \bar{\alpha}_i y_i = 0\\
& 0 \le \bar{\alpha}_i \le 1, \text{  } i = 1, \cdots, N\\
& \sum_{i = 1}^{N} \bar{\alpha}_i = \nu N
\end{split}
\label{eq:libsvm-nu-svc-dual}
\end{equation}

이 때 \(\bar{\alpha}_i = \alpha_i N\)이다.

\(\nu\)-SVC은 아래와 같이 \texttt{svm} 함수를 호출할 때 \texttt{type\ =\ "nu-classification"}과 파라미터 \texttt{nu} 값을 설정함으로써 학습할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svm_model <-}\StringTok{ }\KeywordTok{svm}\NormalTok{(}\KeywordTok{as.factor}\NormalTok{(class) }\OperatorTok{~}\StringTok{ }\NormalTok{x1 }\OperatorTok{+}\StringTok{ }\NormalTok{x2, }\DataTypeTok{data =}\NormalTok{ nonlinear_train_df, }
                 \DataTypeTok{type =} \StringTok{"nu-classification"}\NormalTok{, }
                 \DataTypeTok{kernel =} \StringTok{"radial"}\NormalTok{, }\DataTypeTok{gamma =} \DecValTok{1}\NormalTok{,}
                 \DataTypeTok{nu =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{scale =} \OtherTok{FALSE}\NormalTok{)}
\KeywordTok{plot}\NormalTok{(svm_model, }\DataTypeTok{data =}\NormalTok{ nonlinear_train_df, }\DataTypeTok{formula =}\NormalTok{ x2 }\OperatorTok{~}\StringTok{ }\NormalTok{x1, }\DataTypeTok{grid =} \DecValTok{200}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/nu-svc-radial-1} 

}

\caption{가우시안 커널을 이용한 $\nu$-SVC 하이퍼플레인}\label{fig:nu-svc-radial}
\end{figure}

\hypertarget{classifier-evaluation}{%
\chapter{분류규칙의 성능 평가}\label{classifier-evaluation}}

도출된 분류규칙에 대한 평가는 범주를 아는 학습표본이 있으므로 비교적 용이하게 이루어진다. 분류정확도 또는 분류오류율이 기본이 되나, 특히 범주가 2개인 경우에는 다양한 성능평가척도가 개발되어 사용되고 있다.

\hypertarget{classifier-evaluation-packages-install}{%
\section{필요 R 패키지 설치}\label{classifier-evaluation-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.2.1\\
\hline
caret & 6.0-84\\
\hline
\end{tabular}

\hypertarget{classifier-evaluation-misclassification-rate}{%
\section{분류오류율}\label{classifier-evaluation-misclassification-rate}}

범주를 아는 데이터 \(\{(\mathbf{x}_i, y_i)\}_{i = 1, \cdots, N}\)를 학습표본이라 한다.

\begin{itemize}
\tightlist
\item
  \(\mathbf{x}_i\): \(p\)개의 독립변수로 이루어진 \(i\)번째 객체의 변수벡터 (\(\mathbf{x}_i = [x_{i1} \, x_{i2} \, \cdots \, x_{ip}]^\top\))
\item
  \(J\): 총 범주 수
\item
  \(y_i\): \(i\)번째 객체의 범주 변수; \(y_i \in \{1, 2, \cdots, J\}\)
\end{itemize}

분류규칙 \(d(\mathbf{x})\)의 성능은 주로 분류오류율(misclassification rate)을 사용하는데, 분류규칙이 추정한 범주와 실제범주가 일치하지 않는 비율을 나타낸다.

\begin{equation}
R(d) = \frac{1}{N} \sum_{i = 1}^{N} I(d(\mathbf{x}_i) \neq y_i)
\label{eq:misclassification-rate-train}
\end{equation}

여기서 함수 지시함수 \(I(x)\)는 \(x\)가 참(true)일 때 1, 거짓(false)일 때 0의 값을 갖는다.

식 \eqref{eq:misclassification-rate-train}은 학습표본에 대한 오분류율로, 이를 최소화하려할 경우 분류규칙이 해당 학습데이터에만 과적용(overfitting)되는 문제가 발생할 수 있다. 즉, 새로운 데이터에 적용할 때도 오분류율이 최소화될 것이라는 보장이 없다.

이 때문에, 통상 관측수가 상당수 있는 데이터에 대해서는 전체 데이터를 두 부분으로 나누어, 분류규칙을 만드는 데 한 부분을 사용하고, 분류오류율을 산출하는 데 다른 한 부분을 사용하는 방안이 일반적이다. 아래와 같이 범주가 알려져있지만 분류규칙 \(d(\mathbf{x})\)를 학습하는 데 사용하지 않은 \(L\)개의 테스트 표본 \(\{(\mathbf{x}_i, y_i)\}_{i = N + 1, \cdots, N + L}\)이 있다고 하자. 이 때 테스트 표본에 대한 분류오류율을 아래와 같이 계산한다.

\begin{equation}
R^{ts}(d) = \frac{1}{L} \sum_{i = N + 1}^{N + L} I(d(\mathbf{x}_i) \neq y_i)
\label{eq:misclassification-rate-test}
\end{equation}

테스트 표본으로 분리하기에 충분하지 않은 데이터의 경우에는 cross validation 기법을 사용한다.

\hypertarget{precision-sensitivity-specificity}{%
\section{정확도, 민감도 및 특이도}\label{precision-sensitivity-specificity}}

의학 분야에서 어떤 질병에 대한 진단방법을 평가할 때 오류율 이와에 정확도, 민감도 및 특이도를 분석하는 경우가 종종 있다. 실제범주가 질병이 있는 경우(\texttt{1} 또는 \texttt{+}로 표기)와 질병이 없는 경우(\texttt{0} 또는 \texttt{-}로 표기)의 두 가지로 분류된다고 하고, 진단 방법이 양성(\texttt{1} 또는 \texttt{+}) 또는 음성(\texttt{0} 또는 \texttt{-})으로 판정할 때, 아래와 같이 네 가지 경우가 발생한다. 이와 같은 표를 정오분류표(confusion matrix)라 한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{'a'}\NormalTok{, }\StringTok{'b'}\NormalTok{, }\StringTok{'c'}\NormalTok{, }\StringTok{'d'}\NormalTok{), }\DataTypeTok{nrow =} \DecValTok{2}\NormalTok{, }\DataTypeTok{byrow =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{attr}\NormalTok{(cm, }\StringTok{"dimnames"}\NormalTok{) <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}\DataTypeTok{Prediction =} \KeywordTok{c}\NormalTok{(}\StringTok{"1"}\NormalTok{, }\StringTok{"0"}\NormalTok{), }\DataTypeTok{Reference =} \KeywordTok{c}\NormalTok{(}\StringTok{"1"}\NormalTok{, }\StringTok{"0"}\NormalTok{))}
\KeywordTok{class}\NormalTok{(cm) <-}\StringTok{ "table"}
\KeywordTok{print}\NormalTok{(cm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Reference
## Prediction 1 0
##          1 a b
##          0 c d
\end{verbatim}

위 표의 문자들은 다음과 같이 정의된다.

\begin{itemize}
\tightlist
\item
  \(a\): number of true positive prediction
\item
  \(b\): number of false positive prediction
\item
  \(c\): number of false negative prediction
\item
  \(d\): number of true negative prediction
\end{itemize}

여기서 ``positive'' 또는 ``negative''는 ``양성'' 또는 ``음성''으로 추정됨을 나타내고, ``true'' 또는 ``false''는 추정의 사실 또는 거짓을 나타낸다. 이 때 분류오류율은 다음과 같이 산출된다.

\begin{equation}
\text{misclassifiction rate} = \frac{b + c}{a + b + c + d}
\label{eq:cm-misclassification-rate}
\end{equation}

정확도(accuracy)는 오류율의 반대 개념으로, 실제 범주를 제대로 추정한 전체 비율을 나타내며 아래와 같이 산출된다.

\begin{equation}
\text{accuracy} = \frac{a + d}{a + b + c + d} = 1 - \text{misclassifiction rate}
\label{eq:cm-accuracy}
\end{equation}

한편, 민감도(sensitivity)는 실제 질병이 있는 경우를 양성으로 판정하는 비율을 나타내는 것으로, 다음과 같이 산출된다.

\begin{equation}
\text{sensitivity} = \frac{a}{a + c}
\label{eq:cm-sensitivity}
\end{equation}

그리고 특이도(specificity)란 실제 질병이 없는 경우를 음성으로 판정하는 비율을 나타내는 것으로 다음과 같다.

\begin{equation}
\text{specificity} = \frac{d}{b + d}
\label{eq:cm-specificity}
\end{equation}

정확도를 민감도 및 특이도로 표현하면 다음과 같다.

\begin{equation*}
\text{accuracy} = \frac{a + c}{a + b + c + d}\text{sensitivity} + \frac{b + d}{a + b + c + d}\text{specificity}
\end{equation*}

민감도 및 특이도를 별도로 산출하여 분석하는 이유 중 하나는, 동일한 정확도를 갖는다 하더라도 민감도와 특이도는 다를 수 있기 때문이다. 경우에 따라서는 높은 민감도를 원하거나 높은 특이도를 원할 수 있다.

\hypertarget{confusion-matrix-r-package}{%
\subsection{R 패키지 내 정오분류표}\label{confusion-matrix-r-package}}

100개의 객체에 대한 실제범주와 추정범주가 아래와 같이 주어진다고 하자.

\begin{eqnarray*}
y_i &=& \begin{cases}
1 & i = 1, \cdots, 20\\
0 & i = 21, \cdots, 100
\end{cases},\\
\hat{y}_i &=& \begin{cases}
1 & i = 1, \cdots, 15, 91, \cdots, 100\\
0 & i = 16, \cdots, 90
\end{cases}
\end{eqnarray*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y <-}\StringTok{ }\KeywordTok{factor}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{20}\NormalTok{), }\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{80}\NormalTok{)), }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\NormalTok{y_hat <-}\KeywordTok{factor}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{15}\NormalTok{), }\KeywordTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{75}\NormalTok{), }\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{)), }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

해당 추정결과에 대한 정오분류표 및 각종 평가지표를 얻기 위해 \texttt{caret} 패키지의 \texttt{confusionMatrix} 함수를 이용한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm <-}\StringTok{ }\NormalTok{caret}\OperatorTok{::}\KeywordTok{confusionMatrix}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ y_hat, }\DataTypeTok{reference =}\NormalTok{ y)}
\end{Highlighting}
\end{Shaded}

우선 정오분류표는 결과 객체의 \texttt{table} component에 저장된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm}\OperatorTok{$}\NormalTok{table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Reference
## Prediction  1  0
##          1 15 10
##          0  5 70
\end{verbatim}

정확도를 비롯한 각종 전반적인 지표는 \texttt{overall}이라는 component에 벡터 형태로 저장된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm}\OperatorTok{$}\NormalTok{overall}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       Accuracy          Kappa  AccuracyLower  AccuracyUpper   AccuracyNull 
##      0.8500000      0.5714286      0.7646925      0.9135456      0.8000000 
## AccuracyPValue  McnemarPValue 
##      0.1285055      0.3016996
\end{verbatim}

또한, 민감도, 특이도를 비롯한 몇 가지 분류성능 지표들은 \texttt{byClass}라는 component에 역시 벡터 형태로 저장된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm}\OperatorTok{$}\NormalTok{byClass}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          Sensitivity          Specificity       Pos Pred Value 
##            0.7500000            0.8750000            0.6000000 
##       Neg Pred Value            Precision               Recall 
##            0.9333333            0.6000000            0.7500000 
##                   F1           Prevalence       Detection Rate 
##            0.6666667            0.2000000            0.1500000 
## Detection Prevalence    Balanced Accuracy 
##            0.2500000            0.8125000
\end{verbatim}

\hypertarget{roc-curve}{%
\section{ROC 곡선}\label{roc-curve}}

일반적으로 민감도와 특이도를 동시에 증가시키는 것은 불가능하다. 다시 말하면, 민감도를 높이면 특이도가 감소하고, 또한 반대가 성립하게 된다.

예를 들어 다음과 같이 10개의 객체로 이루어진 학습표본이 있다고 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{x, }\OperatorTok{~}\NormalTok{y,}
  \DecValTok{24}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{35}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{37}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{42}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{49}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{54}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{56}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{68}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{72}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{73}\NormalTok{, }\DecValTok{1}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{factor}\NormalTok{(y, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

분류기준이 만약 \(x < 40\)이면 범주 \texttt{0}, \(x \geq 40\)이면 범주 \texttt{1}로 추정할 때, 정오분류표는 다음과 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm40 <-}\StringTok{ }\NormalTok{caret}\OperatorTok{::}\KeywordTok{confusionMatrix}\NormalTok{(}
  \KeywordTok{factor}\NormalTok{(}\KeywordTok{as.integer}\NormalTok{(train_df}\OperatorTok{$}\NormalTok{x }\OperatorTok{>=}\StringTok{ }\DecValTok{40}\NormalTok{), }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)),}
\NormalTok{  train_df}\OperatorTok{$}\NormalTok{y}
\NormalTok{)}

\NormalTok{cm40}\OperatorTok{$}\NormalTok{table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Reference
## Prediction 1 0
##          1 5 2
##          0 1 2
\end{verbatim}

이 때 구해지는 민감도 및 특이도는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm40}\OperatorTok{$}\NormalTok{byClass[}\KeywordTok{c}\NormalTok{(}\StringTok{"Sensitivity"}\NormalTok{, }\StringTok{"Specificity"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Sensitivity Specificity 
##   0.8333333   0.5000000
\end{verbatim}

한편, 분류기준이 만약 \(x < 50\)이면 범주 \texttt{0}, \(x \geq 50\)이면 범주 \texttt{1}로 추정할 때, 정오분류표는 다음과 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm50 <-}\StringTok{ }\NormalTok{caret}\OperatorTok{::}\KeywordTok{confusionMatrix}\NormalTok{(}
  \KeywordTok{factor}\NormalTok{(}\KeywordTok{as.integer}\NormalTok{(train_df}\OperatorTok{$}\NormalTok{x }\OperatorTok{>=}\StringTok{ }\DecValTok{50}\NormalTok{), }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)),}
\NormalTok{  train_df}\OperatorTok{$}\NormalTok{y}
\NormalTok{)}

\NormalTok{cm50}\OperatorTok{$}\NormalTok{table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Reference
## Prediction 1 0
##          1 4 1
##          0 2 3
\end{verbatim}

또한, 이 때 구해지는 민감도 및 특이도는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm50}\OperatorTok{$}\NormalTok{byClass[}\KeywordTok{c}\NormalTok{(}\StringTok{"Sensitivity"}\NormalTok{, }\StringTok{"Specificity"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Sensitivity Specificity 
##   0.6666667   0.7500000
\end{verbatim}

위 \(x\)값 40을 기준으로 분류를 하는 경우와 비교하여 민감도는 감소하고 특이도는 증가함을 관찰할 수 있다.

분류를 위한 \(x\) 기준값(threshold)을 증가시켜가면서 민감도와 특이도가 어떻게 변하는 지 살펴보도록 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{univariate_binary_rule <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, y, th) \{}
\NormalTok{  cm <-}\StringTok{ }\NormalTok{caret}\OperatorTok{::}\KeywordTok{confusionMatrix}\NormalTok{(}
    \KeywordTok{factor}\NormalTok{(}\KeywordTok{as.integer}\NormalTok{(x }\OperatorTok{>=}\StringTok{ }\NormalTok{th), }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)),}
\NormalTok{    y}
\NormalTok{  )}
  
  \KeywordTok{tibble}\NormalTok{(}\DataTypeTok{threshold =}\NormalTok{ th, }
         \DataTypeTok{sensitivity =}\NormalTok{ cm}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Sensitivity"}\NormalTok{],}
         \DataTypeTok{specificity =}\NormalTok{ cm}\OperatorTok{$}\NormalTok{byClass[}\StringTok{"Specificity"}\NormalTok{])}
\NormalTok{\}}

\NormalTok{th <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\KeywordTok{sort}\NormalTok{(train_df}\OperatorTok{$}\NormalTok{x), }\OtherTok{Inf}\NormalTok{)}

\NormalTok{roc_df <-}\StringTok{ }\KeywordTok{map_dfr}\NormalTok{(th, univariate_binary_rule, }\DataTypeTok{x =}\NormalTok{ train_df}\OperatorTok{$}\NormalTok{x, }\DataTypeTok{y =}\NormalTok{ train_df}\OperatorTok{$}\NormalTok{y)}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  roc_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
  \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'분류기준값($x$)'}\NormalTok{, }\StringTok{'민감도(sensitivity)'}\NormalTok{, }\StringTok{'특이도(specificity)'}\NormalTok{),}
  \DataTypeTok{caption =} \StringTok{'분류기준별 민감도 및 특이도'}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:roc-data}분류기준별 민감도 및 특이도}
\centering
\begin{tabular}{rrr}
\toprule
분류기준값(\$x\$) & 민감도(sensitivity) & 특이도(specificity)\\
\midrule
24 & 1.0000000 & 0.00\\
35 & 1.0000000 & 0.25\\
37 & 1.0000000 & 0.50\\
42 & 0.8333333 & 0.50\\
49 & 0.8333333 & 0.75\\
\addlinespace
54 & 0.6666667 & 0.75\\
56 & 0.5000000 & 0.75\\
68 & 0.5000000 & 1.00\\
72 & 0.3333333 & 1.00\\
73 & 0.1666667 & 1.00\\
\addlinespace
Inf & 0.0000000 & 1.00\\
\bottomrule
\end{tabular}
\end{table}

민감도와 특이도를 동시에 그래프로 나타낸 것 중 ROC(receiver operating characteristic) 곡선이 널리 사용되는데, 이는 분류기의 경계치를 조정하여 가면서 (1 - 특이도)(또는 false positive rate)을 \(x\)축에, 민감도를 \(y\)축에 도식화한 것이다.

위 Table \ref{tab:roc-data}를 바탕으로 ROC 곡선을 작성해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{roc_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =} \DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{specificity, }\DataTypeTok{y =}\NormalTok{ sensitivity)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_path}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/roc-example-1} 

}

\caption{ROC 곡선}\label{fig:roc-example}
\end{figure}

\hypertarget{gain-chart}{%
\section{이익도표}\label{gain-chart}}

이익도표는 마케팅을 위하여 수익을 창출하는 목표고객(target)을 추출할 목적으로 사용되는데, 단순히 분류를 위한 여러 모형을 비교하기 위한 목적으로도 종종 사용되고 있다. 목표 마케팅의 목적에서는, 특정 범주의 고객을 목표고객으로 할 때, 이러한 목표고객의 비율이 상대적으로 높은 서브그룹을 찾고자 하는 것이다. 이를 위해, 우선 전체 데이터를 특정 범주의 사후확률의 순서로 정렬한 후, \(K\)개(주로 \(K = 10\)을 사용)의 집단으로 구분하고, 각 집단별로 다음과 같은 통계량을 산출한다.

\(k\)번째 집단 내에서 범주 \(j\)에 속한 객체의 수를 \(n_{kj}\)라 할 때, 다음과 같은 범주 \(j\)에 대한 \(k\)번째 집단의 통계량들을 산출할 수 있다. (본 장에서 \(K\)개의 집단은 동일한 크기라 가정하자. 즉, 모든 집단 \(k\)에 대해 \(\sum_{j = 1}^{J} n_{kj} = \frac{N}{K}\)가 성립한다고 하자.)

\begin{eqnarray*}
\text{$\%$ captured response} &=& \frac{n_{kj}}{\sum_{k = 1}^{K} n_{kj}} \times 100\\
\text{cumulative $\%$ captured response} &=& \frac{\sum_{l = 1}^{k} n_{lj}}{\sum_{k = 1}^{K} n_{kj}} \times 100\\
\text{$\%$ response} &=& \frac{n_{kj}}{\sum_{j = 1}^{J} n_{kj}} \times 100\\
\text{lift} &=& \frac{n_{kj}}{\frac{1}{K} \sum_{k = 1}^{K} n_{kj}}
\end{eqnarray*}

1,000개의 객체로 이루어진 어떤 데이터의 실제 범주별 빈도가 다음과 같다고 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y_freq <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{y, }\OperatorTok{~}\NormalTok{n,}
  \DecValTok{1}\NormalTok{, }\DecValTok{437}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{348}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{215}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{factor}\NormalTok{(y, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)))}

\NormalTok{y_freq}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##   y         n
##   <fct> <dbl>
## 1 1       437
## 2 2       348
## 3 3       215
\end{verbatim}

한편, 어떤 분류모형을 사용하여 각 객체의 범주 \texttt{1}(특정 범주)에 대한 사후확률을 산출한 후, 전체 객체를 사후확률의 내림차순으로 정렬한 뒤 100개 객체씩 한 집단으로 구분하였다. 각 집단에 속하는 범주 \texttt{1}의 빈도는 다음과 같았다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{freq_within_group <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{k, }\OperatorTok{~}\NormalTok{n,}
  \DecValTok{1}\NormalTok{, }\DecValTok{92}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{78}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{64}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{57}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{43}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\DecValTok{35}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\DecValTok{29}\NormalTok{,}
  \DecValTok{8}\NormalTok{, }\DecValTok{22}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\DecValTok{7}\NormalTok{,}
  \DecValTok{10}\NormalTok{, }\DecValTok{10}
\NormalTok{)}

\NormalTok{freq_within_group}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##        k     n
##    <dbl> <dbl>
##  1     1    92
##  2     2    78
##  3     3    64
##  4     4    57
##  5     5    43
##  6     6    35
##  7     7    29
##  8     8    22
##  9     9     7
## 10    10    10
\end{verbatim}

이를 바탕으로 각 집단 별 범주 \texttt{1}에 대한 통계량을 산출해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stat_df <-}\StringTok{ }\NormalTok{freq_within_group }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{cum_n =} \KeywordTok{cumsum}\NormalTok{(n)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{captured_response_pct =}\NormalTok{ n }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(n) }\OperatorTok{*}\StringTok{ }\DecValTok{100}\NormalTok{,}
    \DataTypeTok{cum_captured_response_pct =}\NormalTok{ cum_n }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(n) }\OperatorTok{*}\StringTok{ }\DecValTok{100}\NormalTok{,}
    \DataTypeTok{response_pct =}\NormalTok{ n }\OperatorTok{/}\StringTok{ }\DecValTok{100} \OperatorTok{*}\StringTok{ }\DecValTok{100}\NormalTok{,}
    \DataTypeTok{lift =}\NormalTok{ n }\OperatorTok{/}\StringTok{ }\KeywordTok{mean}\NormalTok{(n)}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{cum_n)}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
\NormalTok{  stat_df,}
  \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
  \DataTypeTok{align =} \KeywordTok{rep}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\DecValTok{6}\NormalTok{),}
  \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'집단'}\NormalTok{, }\StringTok{'범주 1의 빈도'}\NormalTok{, }\StringTok{'% captured response'}\NormalTok{, }
                \StringTok{'cum. % captured response'}\NormalTok{, }\StringTok{'% response'}\NormalTok{, }\StringTok{'lift'}\NormalTok{),}
  \DataTypeTok{caption =} \StringTok{'이익도표를 위한 통계량'}\NormalTok{,}
  \DataTypeTok{digits =} \DecValTok{2}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:gain-chart-stat}이익도표를 위한 통계량}
\centering
\begin{tabular}{rrrrrr}
\toprule
집단 & 범주 1의 빈도 & \% captured response & cum. \% captured response & \% response & lift\\
\midrule
1 & 92 & 21.05 & 21.05 & 92 & 2.11\\
2 & 78 & 17.85 & 38.90 & 78 & 1.78\\
3 & 64 & 14.65 & 53.55 & 64 & 1.46\\
4 & 57 & 13.04 & 66.59 & 57 & 1.30\\
5 & 43 & 9.84 & 76.43 & 43 & 0.98\\
\addlinespace
6 & 35 & 8.01 & 84.44 & 35 & 0.80\\
7 & 29 & 6.64 & 91.08 & 29 & 0.66\\
8 & 22 & 5.03 & 96.11 & 22 & 0.50\\
9 & 7 & 1.60 & 97.71 & 7 & 0.16\\
10 & 10 & 2.29 & 100.00 & 10 & 0.23\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:gain-chart-stat}를 바탕으로 네 가지 이익도표를 작성해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stat_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather}\NormalTok{(}\DataTypeTok{key =} \StringTok{"stat"}\NormalTok{, }\DataTypeTok{value =} \StringTok{"value"}\NormalTok{,}
\NormalTok{         captured_response_pct}\OperatorTok{:}\NormalTok{lift) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ k, }\DataTypeTok{y =}\NormalTok{ value)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\KeywordTok{vars}\NormalTok{(stat), }\DataTypeTok{nrow =} \DecValTok{2}\NormalTok{, }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{, }\DataTypeTok{scales =} \StringTok{"free_y"}\NormalTok{,}
             \DataTypeTok{labeller =} \KeywordTok{as_labeller}\NormalTok{(}
               \KeywordTok{c}\NormalTok{(}\StringTok{"captured_response_pct"}\NormalTok{ =}\StringTok{ "% captured response"}\NormalTok{,}
                 \StringTok{"cum_captured_response_pct"}\NormalTok{ =}\StringTok{ "cum. % captured response"}\NormalTok{,}
                 \StringTok{"response_pct"}\NormalTok{ =}\StringTok{ "% response"}\NormalTok{,}
                 \StringTok{"lift"}\NormalTok{ =}\StringTok{ "lift"}\NormalTok{)}
\NormalTok{             )) }\OperatorTok{+}
\StringTok{  }\KeywordTok{xlab}\NormalTok{(}\StringTok{"group"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ylab}\NormalTok{(}\StringTok{"statistics"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/gain-chart-plot-1} 

}

\caption{이익도표}\label{fig:gain-chart-plot}
\end{figure}

\hypertarget{clustering-overview}{%
\chapter{군집분석 개요}\label{clustering-overview}}

하나의 객체(object)가 여러 속성(attribute)을 갖는다 하고, 이러한 객체가 다수 있다고 하자. 군집분석이란 유사한 속성들을 갖는 객체들을 묶어 전체의 객체들을 몇 개의 그룹 또는 군집(cluster)으로 나누는 것을 말한다.

\hypertarget{clustering-overview-packages-install}{%
\section{필요 R 패키지 설치}\label{clustering-overview-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.2.1\\
\hline
stats & 3.6.0\\
\hline
corrr & 0.3.2\\
\hline
cluster & 2.0.8\\
\hline
\end{tabular}

\hypertarget{clustering-method}{%
\section{군집분석 기법}\label{clustering-method}}

전체 객체의 개수를 \(n\)이라 하고, \(i\)번째 객체를 \(O_i\)라 할 때, 전체 객체의 집합 \(S\)는 다음과 같다.

\begin{equation*}
S = \{O_1, \cdots, O_n\}
\end{equation*}

군집분석이란 집합 \(S\)를 서로 배타적인 \(K\)개의 부분집합 \(C_1, \cdots, C_K\)로 나누는 것이다. 따라서 다음이 성립한다.

\begin{equation*}
\begin{split}
C_i \cap C_j &= \emptyset, \, 1 \leq i \neq j \leq K\\
\cup_{i = 1}^{K} C_i &= S
\end{split}
\end{equation*}

이 때, \(C_j\)를 \(j\)번째 군집(또는 군집 \(j\))이라 한다. 각 객체는 한 군집에만 속하여야 하며, 한 군집에는 적어도 하나의 객체를 포함하여야 한다. 군집들을 다음과 같이 모아놓은 것을 군집결과(clustering result) 또는 군집해(clustering solution)라 한다.

\begin{equation*}
C = \{C_1, \cdots, C_K\}
\end{equation*}

군집방법(clustering method)은 무수히 많다. 다음 장들에서 아래에 분류된 방법들을 보다 자세히 다룬다.

\begin{itemize}
\tightlist
\item
  계층적 방법(hierarchical method)

  \begin{itemize}
  \tightlist
  \item
    집괴법(agglomerative method)
  \item
    분리법(divisive method)
  \end{itemize}
\item
  비계층적 방법(non-hierarchical method)
\end{itemize}

\hypertarget{object-similarity-metric}{%
\section{객체 간의 유사성 척도}\label{object-similarity-metric}}

\hypertarget{object-distance-metric}{%
\subsection{거리 관련 척도}\label{object-distance-metric}}

각 객체가 \(p\)개의 속성 또는 변수(variable)를 갖는다 하고, \(j\)번째 변수의 객체 \(i\)에 대한 관측치를 \(x_{ji}\)라 하면, 객체 \(i\)의 \(p\)차원 공간에서의 좌표는 아래와 같은 열벡터로 표현된다.

\begin{equation*}
\mathbf{x}_{i} = [x_{1i} \, x_{2i} \, \cdots \, x_{pi}]^\top
\end{equation*}

이 때, 객체 \(i\)와 객체 \(j\)의 거리를 나타내는 척도들은 아래와 같은 것들이 있다.

\begin{itemize}
\tightlist
\item
  유클리드 거리(Euclidean distance)
\end{itemize}

\begin{eqnarray*}
d(\mathbf{x}_i, \mathbf{x}_j) &=& \sqrt{\sum_{a = 1}^{p} \left(x_{ai} - x_{aj}\right)^2}\\
&=& \sqrt{(\mathbf{x}_i - \mathbf{x}_j)^\top (\mathbf{x}_i - \mathbf{x}_j)}
\end{eqnarray*}

\begin{itemize}
\tightlist
\item
  맨하탄 거리(Manhattan distance)
\end{itemize}

\begin{equation*}
d(\mathbf{x}_i, \mathbf{x}_j) = \sum_{a = 1}^{p} \left| x_{ai} - x_{aj} \right|
\end{equation*}

\begin{itemize}
\tightlist
\item
  민코프스키 거리(Minkowski distance)
\end{itemize}

\begin{equation*}
d(\mathbf{x}_i, \mathbf{x}_j) = \left( \sum_{a = 1}^{p} \left| x_{ai} - x_{aj} \right|^m \right)^\frac{1}{m}
\end{equation*}

\begin{itemize}
\tightlist
\item
  표준 유클리드 거리(standardized Euclidean distance)
\end{itemize}

\begin{eqnarray*}
d(\mathbf{x}_i, \mathbf{x}_j) &=& \sqrt{\sum_{a = 1}^{p} \left(\frac{x_{ai} - x_{aj}}{s_a}\right)^2}\\
&=& \sqrt{(\mathbf{x}_i - \mathbf{x}_j)^\top \mathbf{S}_d^{-1} (\mathbf{x}_i - \mathbf{x}_j)}
\end{eqnarray*}

여기서

\begin{eqnarray*}
\mathbf{S}_d &=& \begin{bmatrix}
s_1^2 & 0 & \dots & 0\\
0 & s_2^2 & \dots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \dots & s_p^2
\end{bmatrix}\\
s_a &=& \sqrt{\frac{\sum_{i = 1}^{n} \left(x_{ai} - \bar{x}_a \right)^2}{n - 1}}\\
\bar{x}_a &=& \frac{1}{n} \sum_{i = 1}^{n} x_{ai}
\end{eqnarray*}

\begin{itemize}
\tightlist
\item
  마할라노비스 거리(Mahalanobis distance)
\end{itemize}

\begin{equation*}
d(\mathbf{x}_i, \mathbf{x}_j) = \sqrt{(\mathbf{x}_i - \mathbf{x}_j)^\top \mathbf{S}^{-1} (\mathbf{x}_i - \mathbf{x}_j)}
\end{equation*}

여기서

\begin{eqnarray*}
\mathbf{S} &=& \begin{bmatrix}
s_1^2 & s_{12} & \dots & s_{1p}\\
s_{21} & s_2^2 & \dots & s_{2p}\\
\vdots & \vdots & \ddots & \vdots\\
s_{p1} & s_{p2} & \dots & s_p^2
\end{bmatrix}\\
s_{ab} &=& \frac{\sum_{i = 1}^{n} (x_{ai} - \bar{x}_a)(x_{bi} - \bar{x}_b)}{n - 1}\\
\bar{x}_a &=& \frac{1}{n} \sum_{i = 1}^{n} x_{ai}
\end{eqnarray*}

위와 같은 거리 척도들을 이용하여 객체들의 모든 쌍에 대한 거리를 다음과 같이 \((n \times n)\) 행렬 \(\mathbf{D}\)로 나타낼 수 있다.

\begin{equation*}
\mathbf{D} = \begin{bmatrix}
0 & d(\mathbf{x}_1, \mathbf{x}_2) & \dots & d(\mathbf{x}_1, \mathbf{x}_n)\\
d(\mathbf{x}_2, \mathbf{x}_1) & 0 & \dots & d(\mathbf{x}_2, \mathbf{x}_n)\\
\vdots & \vdots & \ddots & \vdots \\
d(\mathbf{x}_n, \mathbf{x}_1) & d(\mathbf{x}_n, \mathbf{x}_2) & \dots & 0
\end{bmatrix}
\end{equation*}

아래 표는 가정에서 PC를 사용하는 10명에 대한 나이(\(x_1\)), PC 경험연수(\(x_2\)), 주당 사용시간(\(x_3\))을 나타낸 것이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{id, }\OperatorTok{~}\NormalTok{x1, }\OperatorTok{~}\NormalTok{x2, }\OperatorTok{~}\NormalTok{x3,}
  \DecValTok{1}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{14}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{13}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{42}\NormalTok{, }\DecValTok{14}\NormalTok{, }\DecValTok{6}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{35}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{7}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{7}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{15}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\DecValTok{45}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{6}\NormalTok{,}
  \DecValTok{8}\NormalTok{, }\DecValTok{46}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\DecValTok{51}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{10}\NormalTok{, }\DecValTok{41}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}
\NormalTok{)}

\NormalTok{df }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'나이($x_1$)'}\NormalTok{, }\StringTok{'PC 경험연수($x_2$)'}\NormalTok{, }\StringTok{'주당 사용시간($x_3$)'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'PC 사용 데이터'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:pc-user}PC 사용 데이터}
\centering
\begin{tabular}{rrrr}
\toprule
객체번호 & 나이(\$x\_1\$) & PC 경험연수(\$x\_2\$) & 주당 사용시간(\$x\_3\$)\\
\midrule
1 & 20 & 6 & 14\\
2 & 28 & 8 & 13\\
3 & 42 & 14 & 6\\
4 & 35 & 12 & 7\\
5 & 30 & 15 & 7\\
\addlinespace
6 & 30 & 7 & 15\\
7 & 45 & 13 & 6\\
8 & 46 & 4 & 2\\
9 & 51 & 3 & 3\\
10 & 41 & 3 & 2\\
\bottomrule
\end{tabular}
\end{table}

R 함수 \texttt{dist}를 이용하여 다양한 거리를 계산할 수 있다.

우선 객체 2로부터 객체 4, 5까지의 유클리드 거리는 아래와 같이 계산된다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dist}\NormalTok{(df[, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{)], }\DataTypeTok{upper =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}
\NormalTok{    item1 }\OperatorTok{==}\StringTok{ }\DecValTok{2}\NormalTok{,}
\NormalTok{    item2 }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호(from)'}\NormalTok{, }\StringTok{'객체번호(to)'}\NormalTok{, }\StringTok{'거리'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'유클리드 거리'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:euclidean-dist}유클리드 거리}
\centering
\begin{tabular}{rrr}
\toprule
객체번호(from) & 객체번호(to) & 거리\\
\midrule
2 & 4 & 10.049876\\
2 & 5 & 9.433981\\
\bottomrule
\end{tabular}
\end{table}

위 표에서 나타나는 바와 같이, 객체 2를 기준으로 할 때, 객체 4가 객체 5보다 멀리 떨어져있다고 할 수 있다.

표준화된 거리를 계산하기 위해서는 데이터를 함수 \texttt{scale}을 이용하여 데이터를 표준화한 뒤 \texttt{dist}함수를 적용한다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dist}\NormalTok{(}\KeywordTok{scale}\NormalTok{(df[, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{)]), }\DataTypeTok{upper =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}
\NormalTok{    item1 }\OperatorTok{==}\StringTok{ }\DecValTok{2}\NormalTok{,}
\NormalTok{    item2 }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호(from)'}\NormalTok{, }\StringTok{'객체번호(to)'}\NormalTok{, }\StringTok{'거리'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'표준 유클리드 거리'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:std-euclidean-dist}표준 유클리드 거리}
\centering
\begin{tabular}{rrr}
\toprule
객체번호(from) & 객체번호(to) & 거리\\
\midrule
2 & 4 & 1.663576\\
2 & 5 & 1.954486\\
\bottomrule
\end{tabular}
\end{table}

표준화된 거리로는 객체 5가 객체 4보다 객체 2에서 멀리 떨어짐을 알 수 있다.

유클리드 거리 외에 민코프스키 거리, 마할라노비스 거리 등은 \texttt{dist}함수의 파라미터 \texttt{method} 및 \texttt{p}값을 설정하여 계산할 수 있다.

\hypertarget{object-correlation-metric}{%
\subsection{상관계수 관련 척도}\label{object-correlation-metric}}

또 다른 유사성 척도로 다음과 같은 객체 간의 상관계수를 사용할 수 있다.

\begin{equation}
sim(\mathbf{x}_i, \mathbf{x}_j) = r_{ij} = \frac{\sum_{a = 1}^{p} (x_{ai} - m_{i})(x_{aj} - m_{j})}{\sqrt{\sum_{a = 1}^{p} (x_{ai} - m_{i})^2} \sqrt{\sum_{a = 1}^{p} (x_{aj} - m_{j})^2}}
\label{eq:object-correlation}
\end{equation}

여기서 \(m_i\)는 객체 \(i\)의 평균값으로 다음과 같다.

\begin{equation*}
m_{i} = \frac{1}{p} \sum_{a = 1}^{p} x_{ai}
\end{equation*}

식 \eqref{eq:object-correlation}은 -1에서 1 사이의 값을 가지며, 값이 클수록 두 객체의 유사성이 크다고 할 수 있다. 여기서도 데이터를 변수별로 표준화한 후 상관계수를 산출함을 추천한다.

아래는 Table \ref{tab:pc-user}의 객체 1과 객체 6, 8간의 상관계수를 계산한 것이다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t}\NormalTok{(}\KeywordTok{scale}\NormalTok{(df[, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{)])) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\NormalTok{corrr}\OperatorTok{::}\KeywordTok{correlate}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\NormalTok{corrr}\OperatorTok{::}\KeywordTok{stretch}\NormalTok{(}\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{x =} \KeywordTok{as.integer}\NormalTok{(}\KeywordTok{gsub}\NormalTok{(}\StringTok{"V"}\NormalTok{, }\StringTok{""}\NormalTok{, x)),}
    \DataTypeTok{y =} \KeywordTok{as.integer}\NormalTok{(}\KeywordTok{gsub}\NormalTok{(}\StringTok{"V"}\NormalTok{, }\StringTok{""}\NormalTok{, y))}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}
\NormalTok{    x }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{,}
\NormalTok{    y }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{)}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호(from)'}\NormalTok{, }\StringTok{'객체번호(to)'}\NormalTok{, }\StringTok{'상관계수'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'객체 간 상관계수'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Correlation method: 'pearson'
## Missing treated using: 'pairwise.complete.obs'
\end{verbatim}

\begin{table}[t]

\caption{\label{tab:std-correlation-similarity}객체 간 상관계수}
\centering
\begin{tabular}{rrr}
\toprule
객체번호(from) & 객체번호(to) & 상관계수\\
\midrule
1 & 6 & 0.9718362\\
1 & 8 & -0.8348917\\
\bottomrule
\end{tabular}
\end{table}

한편, 상관계수로부터 거리 개념의 비유사성 척도를 원하면 다음의 척도를 사용할 수 있다.

\begin{equation*}
d(\mathbf{x}_i, \mathbf{x}_j) = 1 - r_{ij}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{t}\NormalTok{(}\KeywordTok{scale}\NormalTok{(df[, }\KeywordTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{)])) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\NormalTok{corrr}\OperatorTok{::}\KeywordTok{correlate}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\NormalTok{corrr}\OperatorTok{::}\KeywordTok{stretch}\NormalTok{(}\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{x =} \KeywordTok{as.integer}\NormalTok{(}\KeywordTok{gsub}\NormalTok{(}\StringTok{"V"}\NormalTok{, }\StringTok{""}\NormalTok{, x)),}
    \DataTypeTok{y =} \KeywordTok{as.integer}\NormalTok{(}\KeywordTok{gsub}\NormalTok{(}\StringTok{"V"}\NormalTok{, }\StringTok{""}\NormalTok{, y)),}
    \DataTypeTok{d =} \DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{r}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{r) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}
\NormalTok{    x }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{,}
\NormalTok{    y }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{)}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호(from)'}\NormalTok{, }\StringTok{'객체번호(to)'}\NormalTok{, }\StringTok{'거리'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'상관계수 기반 비유사성 척도'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Correlation method: 'pearson'
## Missing treated using: 'pairwise.complete.obs'
\end{verbatim}

\begin{table}[t]

\caption{\label{tab:std-correlation-dissimilarity}상관계수 기반 비유사성 척도}
\centering
\begin{tabular}{rrr}
\toprule
객체번호(from) & 객체번호(to) & 거리\\
\midrule
1 & 6 & 0.0281638\\
1 & 8 & 1.8348917\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{category-similarity-metric}{%
\section{범주형 객체의 유사성 척도}\label{category-similarity-metric}}

객체의 변수(속성)들 중 일부 또는 전체가 범주형인 경우에는 유사성 척도를 다소 다르게 정의할 필요가 있다. 범주형 변수는 다시 이분형(binary), 서열형(ordinal), 명목형(nominal)으로 구분된다. 이분형은 서열형 또는 명목형에 속할 수도 있으나, 통상적으로 별도로 구분하고 있다.

\hypertarget{binary-similarity-metric}{%
\subsection{이분형 변수의 경우}\label{binary-similarity-metric}}

이분형 변수란 변수가 취하는 값이 두 개인 것을 의미하며, 통상 0과 1을 부여한다. 이 경우 사용되는 유사성 척도는 다양하나, 단순매칭(simple matching)과 자카드(Jaccard) 척도가 주로 사용된다.

\begin{itemize}
\tightlist
\item
  단순매칭
\end{itemize}

객체 \(\mathbf{x}_i\)와 \(\mathbf{x}_j\)에 대하여 \(k\)번째 변수가 이분형일 때, 해당 변수값에 대한 유사성을 아래와 같이 계산한다.

\begin{equation*}
sim(x_{ki}, x_{kj}) = \begin{cases}
1 & \text{if } x_{ki} = x_{kj}\\
0 & \text{if } x_{ki} \neq x_{kj}
\end{cases}
\end{equation*}

객체의 \(p\)개의 모든 변수가 이분형일 때, 두 객체의 유사성은 아래와 같이 변수별 유사성의 평균으로 계산한다.

\begin{equation*}
sim(\mathbf{x}_i, \mathbf{x}_j) = \frac{1}{p} \sum_{k = 1}^{p} sim(x_{ki}, x_{kj})
\end{equation*}

\begin{itemize}
\tightlist
\item
  자카드(Jaccard) 척도
\end{itemize}

자카드 척도에서는 변수값을 특정 속성이 나타나는(presence) 경우에 1, 나타나지 않는(absence) 경우 0으로 표현할 때, 두 객체에서 모두 나타나는 경우에만 유사한 것으로 평가한다. 결국, 이 척도에서는 두 객체에서 특정 속성이 0인 경우에는 전반적 유사성 척도 산출에 포함되지 않고 무시된다.

\begin{equation*}
sim(x_{ki}, x_{kj}) = \begin{cases}
1 & \text{if } x_{ki} = x_{kj} = 1\\
\text{ignored} & \text{if } x_{ki} = x_{kj} = 0\\
0 & \text{if } x_{ki} \neq x_{kj}
\end{cases}
\end{equation*}

따라서, 객체의 \(p\)개의 모든 변수가 이분형일 때, 두 객체의 유사성은 아래와 같이 계산한다.

\begin{equation*}
sim(\mathbf{x}_i, \mathbf{x}_j) = \frac{\sum_{k: x_{ki} + x_{kj} > 0} sim(x_{ki}, x_{kj})}{\sum_{k: x_{ki} + x_{kj} > 0} 1}
\end{equation*}

다음은 3명에 대한 건강 관련 문진에 대한 답을 나타낸 자료이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{id, }\OperatorTok{~}\NormalTok{x1, }\OperatorTok{~}\NormalTok{x2, }\OperatorTok{~}\NormalTok{x3, }\OperatorTok{~}\NormalTok{x4, }\OperatorTok{~}\NormalTok{x5,}
  \DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}
\NormalTok{)}

\NormalTok{df }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'운동여부($x_1$)'}\NormalTok{, }\StringTok{'음주여부($x_2$)'}\NormalTok{, }\StringTok{'흡연여부($x_3$)'}\NormalTok{, }\StringTok{'가족력여부($x_4$)'}\NormalTok{, }\StringTok{'고혈압여부($x_5$)'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'건강 문진'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:health-question-df}건강 문진}
\centering
\begin{tabular}{rrrrrr}
\toprule
객체번호 & 운동여부(\$x\_1\$) & 음주여부(\$x\_2\$) & 흡연여부(\$x\_3\$) & 가족력여부(\$x\_4\$) & 고혈압여부(\$x\_5\$)\\
\midrule
1 & 1 & 1 & 1 & 0 & 1\\
2 & 1 & 0 & 1 & 0 & 0\\
3 & 0 & 1 & 0 & 1 & 0\\
\bottomrule
\end{tabular}
\end{table}

객체 1과 2의 단순매칭에 의한 유사성은 다음과 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{similarity_simplematching <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(vec_}\DecValTok{1}\NormalTok{, vec_}\DecValTok{2}\NormalTok{) \{}
  \KeywordTok{sum}\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\KeywordTok{abs}\NormalTok{(vec_}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{vec_}\DecValTok{2}\NormalTok{)) }\OperatorTok{/}\StringTok{ }\KeywordTok{length}\NormalTok{(vec_}\DecValTok{1}\NormalTok{)}
\NormalTok{\}}

\NormalTok{df_pairs <-}\StringTok{ }\NormalTok{df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(id) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{expand}\NormalTok{(}\DataTypeTok{id_1 =}\NormalTok{ id, }\DataTypeTok{id_2 =}\NormalTok{ id) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(id_}\DecValTok{1} \OperatorTok{!=}\StringTok{ }\NormalTok{id_}\DecValTok{2}\NormalTok{)}

\NormalTok{df_pairs}\OperatorTok{$}\NormalTok{similarity <-}\StringTok{ }\NormalTok{df_pairs }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(df, }\DataTypeTok{by=}\KeywordTok{c}\NormalTok{(}\StringTok{"id_1"}\NormalTok{ =}\StringTok{ "id"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(df, }\DataTypeTok{by=}\KeywordTok{c}\NormalTok{(}\StringTok{"id_2"}\NormalTok{ =}\StringTok{ "id"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rowwise}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{do}\NormalTok{(}\DataTypeTok{similarity =} \KeywordTok{similarity_simplematching}\NormalTok{(}
\NormalTok{    .[}\KeywordTok{c}\NormalTok{(}\StringTok{"x1.x"}\NormalTok{, }\StringTok{"x2.x"}\NormalTok{, }\StringTok{"x3.x"}\NormalTok{, }\StringTok{"x4.x"}\NormalTok{, }\StringTok{"x5.x"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unlist}\NormalTok{(),}
\NormalTok{    .[}\KeywordTok{c}\NormalTok{(}\StringTok{"x1.y"}\NormalTok{, }\StringTok{"x2.y"}\NormalTok{, }\StringTok{"x3.y"}\NormalTok{, }\StringTok{"x4.y"}\NormalTok{, }\StringTok{"x5.y"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unlist}\NormalTok{())) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{unlist}\NormalTok{()}

\NormalTok{df_pairs }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}
\NormalTok{    id_}\DecValTok{1} \OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{,}
\NormalTok{    id_}\DecValTok{2} \OperatorTok{==}\StringTok{ }\DecValTok{2}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호(from)'}\NormalTok{, }\StringTok{'객체번호(to)'}\NormalTok{, }\StringTok{'유사도'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'단순매칭 유사성 척도'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:binary-simplematching}단순매칭 유사성 척도}
\centering
\begin{tabular}{rrr}
\toprule
객체번호(from) & 객체번호(to) & 유사도\\
\midrule
1 & 2 & 0.6\\
\bottomrule
\end{tabular}
\end{table}

한편 자카드 유사성은 아래와 같이 함수 \texttt{dist}를 이용하여 구할 수 있다. 함수 \texttt{dist}는 거리 척도 함수로, 자카드 기반 거리의 경우 \(d(\mathbf{x}_i, \mathbf{x}_j) = 1 - sim(\mathbf{x}_i, \mathbf{x}_j)\)를 계산한다. 따라서, 거리값에 기반하여 자카드 유사성을 구하고 싶은 경우, \(sim(\mathbf{x}_i, \mathbf{x}_j) = 1 - d(\mathbf{x}_i, \mathbf{x}_j)\)를 계산하면 된다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dist}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{method =} \StringTok{"binary"}\NormalTok{, }\DataTypeTok{upper =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{similarity =} \DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{distance) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{distance) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}
\NormalTok{    item1 }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{,}
\NormalTok{    item2 }\OperatorTok{==}\StringTok{ }\DecValTok{2}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호(from)'}\NormalTok{, }\StringTok{'객체번호(to)'}\NormalTok{, }\StringTok{'유사도'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'자카드 유사성 척도'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:binary-jaccard}자카드 유사성 척도}
\centering
\begin{tabular}{rrr}
\toprule
객체번호(from) & 객체번호(to) & 유사도\\
\midrule
1 & 2 & 0.5\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{ordinal-similarity-metric}{%
\subsection{서열형 변수의 경우}\label{ordinal-similarity-metric}}

객체의 \(k\)번째 변수가 서열형이고 \(1, 2, \cdots, M_k\) 중 한 값을 갖는다고 할 때, 거리척도로는 우선 아래와 같은 직접적 방법이 있다.

\begin{equation*}
d(x_{ki}, x_{kj}) = \frac{|x_{ki} - x_{kj}|}{M_k - 1}
\end{equation*}

위에서 분모는 해당 변수가 취할 수 있는 범위(range)를 나타내며, 따라서 위의 값은 0에서 1 사이 값을 갖는다. 이 방법을 사용할 경우, 객체의 모든 변수가 서열형이면 두 객 체의 거리는 다음과 같다.

\begin{equation*}
d(\mathbf{x}_i, \mathbf{x}_j) = \sum_{k = 1}^{p} d(x_{ki}, x_{kj}) = \sum_{k = 1}^{p} \frac{|x_{ki} - x_{kj}|}{M_k - 1}
\end{equation*}

또 다른 방법은 우선 각 변수를 0에서 1 사이의 값으로 변환한 후, 연속형 변수의 경우와 같이 거리척도를 산출하는 것이다. 이 경우 객체 \(i\)의 \(k\)번째 변수는 다음과 같이 변환한다.

\begin{equation*}
x_{ki}' = \frac{x_{ki} - 1}{M_k - 1}
\end{equation*}

\hypertarget{nominal-similarity-metric}{%
\subsection{명목형 변수의 경우}\label{nominal-similarity-metric}}

두 객체에 대한 \(k\)번째 변수가 명목형인 경우, 이분형 변수의 경우와 같이 두 변수가 일치하면 1, 그렇지 않으면 0으로 유사성을 평가한다. 즉,

\begin{equation*}
sim(x_{ki}, x_{kj}) = \begin{cases}
1 & \text{if } x_{ki} = x_{kj}\\
0 & \text{if } x_{ki} \neq x_{kj}
\end{cases}
\end{equation*}

\(p\)개의 모든 변수가 명목형인 경우, 두 객체 간유사성은 다음과 같다.

\begin{equation*}
sim(\mathbf{x}_i, \mathbf{x}_j) = \frac{1}{p} \sum_{k: x_{ki} = x_{kj}} 1
\end{equation*}

\hypertarget{mixed-similarity-metric}{%
\subsection{혼합형의 경우}\label{mixed-similarity-metric}}

두 객체의 유사성 또는 비유사성을 산출하는 데 각 변수의 형태가 연속형, 이분형, 서열형, 명목형 등으로 다른 경우에는, 각 변수의 형태에 따라 위에서 언급한 바와 같이 각기 다른 방법으로 유사성 또는 비유사성을 평가한 후, 최종적으로 합 또는 평균으로 도출하게 된다. 따라서 편의상 각 변수에 대하여 0에서 1 사이의 값을 갖는 척도를 사용하고 있다. 위에서 언급한 이분형, 서열형, 명목형인 경우에는 이미 0에서 1 사이의 유사성 척도가 제시되었다.

연속형의 경우, 0에서 1 사이의 값을 갖는 거리(비유사성)의 척도로는 아래와 같이 각 변수의 범위를 활용하는 방법을 사용한다.

\begin{equation*}
d(x_{ki}, x_{kj}) = \frac{|x_{ki} - x_{kj}|}{R_k}
\end{equation*}

여기서 \(R_k\)는 \(k\)번째 변수의 범위(=최대값 - 최소값)를 의미한다. 유사성 척도를 원할 경우에는 다음과 같이 산출할 수 있다.

\begin{equation*}
sim(x_{ki}, x_{kj}) = 1 - d(x_{ki}, x_{kj})
\end{equation*}

결국, 여러 형태의 변수가 혼합되어 있는 경우, 각 변수에 대한 유사성 척도가 산출되어 있을 때, 두 객체의 유사성은 다음과 같이 계산한다.

\begin{equation*}
sim(\mathbf{x}_i, \mathbf{x}_j) = \frac{1}{p} \sum_{k = 1}^{p} sim(x_{ki}, x_{kj})
\end{equation*}

또는 각 변수의 거리가 산출도니 경우, 두 객체의 거리는 다음과 같다.

\begin{equation*}
d(\mathbf{x}_i, \mathbf{x}_j) = \frac{1}{p} \sum_{k = 1}^{p} d(x_{ki}, x_{kj})
\end{equation*}

위에 설명한 혼합형 거리 척도는 \citet{gower1971general} 에 기반하며, R에서는 \texttt{cluster} 패키지의 \texttt{daisy} 함수를 이용하여 구할 수 있다. \texttt{daisy} 함수는 연속형 및 서열형 변수의 경우 입력 데이터에 기반하여 range를 계산하므로, 입력 데이터의 최소값, 최대값이 아닌 이론적 최소값, 최대값에 의하여 range를 계산하고 싶은 경우에는 명시적으로 각 변수의 최소값과 최대값을 나타내는 데이터를 입력 데이터에 추가하여야 한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{id, }\OperatorTok{~}\NormalTok{x1, }\OperatorTok{~}\NormalTok{x2, }\OperatorTok{~}\NormalTok{x3, }\OperatorTok{~}\NormalTok{x4, }\OperatorTok{~}\NormalTok{x5,}
  \DecValTok{1}\NormalTok{, }\StringTok{"남"}\NormalTok{, }\DecValTok{46}\NormalTok{, }\StringTok{"공무원"}\NormalTok{, }\DecValTok{35000}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\StringTok{"여"}\NormalTok{, }\DecValTok{28}\NormalTok{, }\StringTok{"은행원"}\NormalTok{, }\DecValTok{51000}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\StringTok{"여"}\NormalTok{, }\DecValTok{32}\NormalTok{, }\StringTok{"주부"}\NormalTok{, }\DecValTok{46000}\NormalTok{, }\DecValTok{4}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{x1 =} \KeywordTok{factor}\NormalTok{(x1, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\StringTok{"남"}\NormalTok{, }\StringTok{"여"}\NormalTok{)),}
    \DataTypeTok{x3 =} \KeywordTok{factor}\NormalTok{(x3),}
    \DataTypeTok{x5 =} \KeywordTok{factor}\NormalTok{(x5, }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{), }\DataTypeTok{ordered =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{  )}

\NormalTok{n_obs <-}\StringTok{ }\KeywordTok{nrow}\NormalTok{(df)}

\NormalTok{range_df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
    \DataTypeTok{x2 =} \KeywordTok{c}\NormalTok{(}\DecValTok{25}\NormalTok{, }\DecValTok{70}\NormalTok{),}
    \DataTypeTok{x4 =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{150000}\NormalTok{),}
    \DataTypeTok{x5 =} \KeywordTok{factor}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{), }\DataTypeTok{levels =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{5}\NormalTok{), }\DataTypeTok{ordered =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{  )}

\NormalTok{df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_rows}\NormalTok{(range_df) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{id) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{cluster}\OperatorTok{::}\KeywordTok{daisy}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{as.dist}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}
\NormalTok{    item1 }\OperatorTok{<=}\StringTok{ }\NormalTok{n_obs,}
\NormalTok{    item2 }\OperatorTok{<=}\StringTok{ }\NormalTok{n_obs}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호(from)'}\NormalTok{, }\StringTok{'객체번호(to)'}\NormalTok{, }\StringTok{'거리'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'혼합형 Gower 거리'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:mixed-gower}혼합형 Gower 거리}
\centering
\begin{tabular}{rrr}
\toprule
객체번호(from) & 객체번호(to) & 거리\\
\midrule
2 & 1 & 0.5513333\\
3 & 1 & 0.5768889\\
3 & 2 & 0.2744444\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{hierarchical-clustering}{%
\chapter{계층적 군집방법}\label{hierarchical-clustering}}

계층적 군집방법에는 집괴법과 분리법이 있으나 주로 집괴법이 사용된다. 본 장에서는 집괴법으로는 연결법을 소개하고, 분리법으로는 다이아나(DIANA)를 소개한다.

\hypertarget{hierarchical-clustering-packages-install}{%
\section{필요 R 패키지 설치}\label{hierarchical-clustering-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.2.1\\
\hline
stats & 3.6.0\\
\hline
cluster & 2.0.8\\
\hline
\end{tabular}

\hypertarget{distance-between-clusters}{%
\section{군집 간 거리척도 및 연결법}\label{distance-between-clusters}}

계층적 군집방법에서는 유사한 객체들을 군집으로 묶고, 다시 유사한 군집을 새로운 군집으로 묶는 등 단계적 절차를 사용한다. 이를 위해서는 군집 간의 유사성 척도 혹은 비유사성 척도가 필요하다.

\begin{itemize}
\tightlist
\item
  \(C_i\): \(i\)번째 군집(군집 \(i\))
\item
  \(|C_i|\): 군집 \(i\)의 객체수
\item
  \(\mathbf{c}_i = \left( \bar{x}_1^{(i)}, \bar{x}_2^{(i)}, \cdots, \bar{x}_p^{(i)} \right)\): 군집 \(i\)의 중심좌표(centroid) (\(\bar{x}_a^{(i)} = \frac{1}{|C_i|} \sum_{j \in C_i} x_{aj}\))
\item
  \(d(u, v) = d(\mathbf{x}_u, \mathbf{x}_v)\): 객체 \(u\)와 객체 \(v\)의 거리(또는 비유사성 척도)
\item
  \(D(C_i, C_j)\): 군집 \(i\)와 군집 \(j\)의 거리(또는 비유사성 척도)
\end{itemize}

군집과 군집 간의 거리척도를 평가하는 방법에 따라 다양한 연결법(linkage method)이 존재한다. 아래에 대표적인 연결법과 군집 간 거리척도를 소개한다.

\begin{table}[t]

\caption{\label{tab:linkage-method}연결법 종류}
\centering
\begin{tabular}{cc}
\toprule
연결법 & 군집거리 \$D(C\_i, C\_j)\$\\
\midrule
단일연결법(single linkage method) & \$\textbackslash{}min\_\{u \textbackslash{}in C\_i, \textbackslash{}, v \textbackslash{}in C\_j\} d(u, v)\$\\
완전연결법(complete linkage method) & \$\textbackslash{}max\_\{u \textbackslash{}in C\_i, \textbackslash{}, v \textbackslash{}in C\_j\} d(u, v)\$\\
평균연결법(average linkage method) & \$\textbackslash{}frac\{1\}\{|C\_i||C\_j|\} \textbackslash{}sum\_\{u \textbackslash{}in C\_i, \textbackslash{}, v \textbackslash{}in C\_j\} d(u, v)\$\\
중심연결법(centroid linkage method) & \$d(\textbackslash{}mathbf\{c\}\_i, \textbackslash{}mathbf\{c\}\_j)\$\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{linkage-method}{%
\section{연결법의 군집 알고리즘}\label{linkage-method}}

\hypertarget{linkage-method-basic-script}{%
\subsection{기본 R 스크립트}\label{linkage-method-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{id =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{),}
  \DataTypeTok{x1 =} \KeywordTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{14}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{),}
  \DataTypeTok{x2 =} \KeywordTok{c}\NormalTok{(}\DecValTok{14}\NormalTok{,}\DecValTok{13}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{)}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(train_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
             \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
             \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'PC 경력(년, $x_1$)'}\NormalTok{, }\StringTok{'사용시간(시간, $x_2$)'}\NormalTok{),}
             \DataTypeTok{caption =} \StringTok{'PC 사용자 데이터'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:pc-user-data}PC 사용자 데이터}
\centering
\begin{tabular}{rrr}
\toprule
객체번호 & PC 경력(년, \$x\_1\$) & 사용시간(시간, \$x\_2\$)\\
\midrule
1 & 6 & 14\\
2 & 8 & 13\\
3 & 14 & 6\\
4 & 11 & 8\\
5 & 15 & 7\\
\addlinespace
6 & 7 & 15\\
7 & 13 & 6\\
8 & 5 & 4\\
9 & 3 & 3\\
10 & 3 & 2\\
\bottomrule
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{theme_set}\NormalTok{(}\KeywordTok{theme_gray}\NormalTok{(}\DataTypeTok{base_family=}\StringTok{'NanumGothic'}\NormalTok{))}
\KeywordTok{ggplot}\NormalTok{(train_df, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x1, }\DataTypeTok{y =}\NormalTok{ x2)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_text}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =}\NormalTok{ id)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{xlab}\NormalTok{(}\StringTok{"PC 경력"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ylab}\NormalTok{(}\StringTok{"사용시간"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/pc-user-data-plot-1} 

}

\caption{PC 사용자 데이터}\label{fig:pc-user-data-plot}
\end{figure}

Table \ref{tab:pc-user-data}는 10명의 사람(객체)에 대한 PC 사용경력과 주당 PC 사용시간을 나타낸 것이다. 각 객체가 두 변수로 이루어져 있으며, Figure \ref{fig:pc-user-data-plot}에서 보는 바와 같이 세 개의 군집(\{1, 2, 6\}, \{3, 4, 5, 7\}, \{8, 9, 10\})으로 이루어져 있다고 볼 수 있다.

본 장에서 평균연결법에 의한 군집화 과정을 살펴보기로 하자. 우선 R 패키지를 이용해서 간단하게 군집해를 구하는 과정은 아래와 같다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{stats} 패키지의 함수 \texttt{dist}를 이용하여 객체간 거리를 계산한다.
\item
  1에서 얻은 거리 행렬을 \texttt{stats} 패키지의 \texttt{hclust} 함수에 입력하여 데이터 군집을 분석한다. 이 때, 파라미터 \texttt{method}의 값을 ``average''로 설정하면 평균연결법을 이용한다.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dist}\NormalTok{(train_df[, }\DecValTok{-1}\NormalTok{]) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{hclust}\NormalTok{(}\DataTypeTok{method =} \StringTok{"average"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{plot}\NormalTok{(}
    \DataTypeTok{main =} \OtherTok{NULL}\NormalTok{,}
    \DataTypeTok{ylab =} \StringTok{"distance"}\NormalTok{,}
    \DataTypeTok{xlab =} \StringTok{"observation"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/pc-user-average-linkage-1} 

}

\caption{PC 사용자 데이터에 대한 평균연결법 덴드로그램}\label{fig:pc-user-average-linkage}
\end{figure}

\hypertarget{linkage-method-algorithm}{%
\subsection{연결법 군집 알고리즘}\label{linkage-method-algorithm}}

각 연결법들은 군집간 유사성 척도 평가 방법이 다를 뿐, 군집화를 위한 알고리즘은 동일하게 아래와 같이 진행된다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{-1}
\tightlist
\item
  단계0: 초기화

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    연결법을 선정한다.
  \item
    각 객체를 하나의 군집으로 간주한다.
  \item
    \(k \leftarrow n\)
  \end{enumerate}
\item
  단계1: 군집

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    현재의 군집결과에 있는 모든 군집 간의 쌍에 대하여 \(D(C_i, C_j)\)를 산출하여, 이 중 최소가 되는 군집 \(i\)와 \(j\)를 묶어 하나의 군집으로 만든 후 군집결과를 수정한다.
  \item
    \(k \leftarrow k - 1\)
  \end{enumerate}
\item
  단계2: \(k = 1\)이면 Stop, 그렇지 않으면 단계 1을 반복한다.
\end{enumerate}

단계1은 객체 수 \(n\)만큼 반복된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration <-}\StringTok{ }\KeywordTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\DataTypeTok{length =} \KeywordTok{nrow}\NormalTok{(train_df))}
\end{Highlighting}
\end{Shaded}

임의의 군집해에 대하여, 단계1을 수행하는 함수를 아래와 같이 구현해보자. 아래 함수 \texttt{merge\_cluster}는 아래와 같은 두 개의 입력변수를 사용한다.

\begin{itemize}
\tightlist
\item
  \texttt{df}: 객체 데이터 프레임. 열 이름이 \texttt{id}인 열은 객체번호를 나타내어, 객체간 거리 계산에 포함하지 않는다.
\item
  \texttt{cluster\_label}: 두 개의 열로 이루어진 데이터 프레임. 열 \texttt{id}는 객체번호를 나타내며, 열 \texttt{cluster}는 군집 이름을 나타낸다. 하나의 객체는 하나의 군집에만 속할 수 있으나, 하나의 군집은 여러 개의 객체를 포함할 수 있다.
\end{itemize}

함수 수행 결과, 아래와 같은 세 개의 원소를 지닌 리스트를 리턴한다.

\begin{itemize}
\tightlist
\item
  \texttt{cluster\_dist}: 군집 간 거리를 나타낸 데이터 프레임. 평균연결법에 기반한 거리.
\item
  \texttt{closest\_clusters}: 입력된 군집해 내에서 가장 가까운 두 군집을 나타낸 데이터 프레임. 두 열 \texttt{item1}과 \texttt{item2}는 각각 군집 이름을 나타내며, \texttt{distance}는 해당 두 군집간의 거리를 나타낸다.
\item
  \texttt{new\_cluster\_label}: \texttt{closest\_clusters}에 포함된 두 군집을 하나로 묶어 새로운 군집을 만든 후 얻어진 군집해.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{merge_cluster <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, cluster_label) \{}
  \CommentTok{# 군집간 거리 계산한다. - 유클리드 거리 및 평균연결법 기반}
\NormalTok{  cluster_dist <-}\StringTok{ }\KeywordTok{dist}\NormalTok{(}\KeywordTok{subset}\NormalTok{(df, }\DataTypeTok{select =} \OperatorTok{-}\NormalTok{id), }\DataTypeTok{upper =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{inner_join}\NormalTok{(}
\NormalTok{      cluster_label }\OperatorTok{%>%}\StringTok{ }\KeywordTok{rename}\NormalTok{(}
        \DataTypeTok{item1 =}\NormalTok{ id, }\DataTypeTok{cluster1 =}\NormalTok{ cluster}
\NormalTok{        ),}
      \DataTypeTok{by =} \StringTok{"item1"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{inner_join}\NormalTok{(}
\NormalTok{      cluster_label }\OperatorTok{%>%}\StringTok{ }\KeywordTok{rename}\NormalTok{(}
        \DataTypeTok{item2 =}\NormalTok{ id, }\DataTypeTok{cluster2 =}\NormalTok{ cluster}
\NormalTok{        ),}
      \DataTypeTok{by =} \StringTok{"item2"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(cluster1 }\OperatorTok{!=}\StringTok{ }\NormalTok{cluster2) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(cluster1, cluster2) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{distance =} \KeywordTok{mean}\NormalTok{(distance)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{ungroup}\NormalTok{()}
  
  \CommentTok{# 서로 가장 가깝게 위치하는 두 군집을 찾는다.}
\NormalTok{  closest_clusters <-}\StringTok{ }\NormalTok{cluster_dist }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{arrange}\NormalTok{(distance) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{)}
  
  \CommentTok{# 군집해를 업데이트한다.}
\NormalTok{  cluster_label[}
\NormalTok{    cluster_label}\OperatorTok{$}\NormalTok{cluster }\OperatorTok{%in%}\StringTok{ }\NormalTok{(}
\NormalTok{      closest_clusters[, }\KeywordTok{c}\NormalTok{(}\StringTok{"cluster1"}\NormalTok{, }\StringTok{"cluster2"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unlist}\NormalTok{()}
\NormalTok{    ),}
    \StringTok{"cluster"}
\NormalTok{  ] <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(}
\NormalTok{    closest_clusters[, }\KeywordTok{c}\NormalTok{(}\StringTok{"cluster1"}\NormalTok{, }\StringTok{"cluster2"}\NormalTok{)] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unlist}\NormalTok{(),}
    \DataTypeTok{collapse =} \StringTok{","}
\NormalTok{    )}
  
  \KeywordTok{list}\NormalTok{(}\DataTypeTok{cluster_dist =}\NormalTok{ cluster_dist, }
       \DataTypeTok{closest_clusters =}\NormalTok{ closest_clusters, }
       \DataTypeTok{new_cluster_label =}\NormalTok{ cluster_label)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

우선 단계 0에서 얻어지는 군집해에 대한 데이터를 아래와 같이 생성한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{init_cluster <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{id =}\NormalTok{ train_df}\OperatorTok{$}\NormalTok{id,}
  \DataTypeTok{cluster =} \KeywordTok{as.character}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(train_df))}
\NormalTok{)}

\KeywordTok{print}\NormalTok{(}\KeywordTok{unique}\NormalTok{(init_cluster}\OperatorTok{$}\NormalTok{cluster))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "1"  "2"  "3"  "4"  "5"  "6"  "7"  "8"  "9"  "10"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{k <-}\StringTok{ }\KeywordTok{length}\NormalTok{(}\KeywordTok{unique}\NormalTok{(init_cluster}\OperatorTok{$}\NormalTok{cluster))}

\KeywordTok{print}\NormalTok{(k)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10
\end{verbatim}

위와 같이, 초기 군집해에서 군집 수는 전체 객체수와 같은 10개이다.

위 초기해로부터 단계1을 아래와 같이 수행해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration[[}\DecValTok{1}\NormalTok{]] <-}\StringTok{ }\KeywordTok{merge_cluster}\NormalTok{(train_df, init_cluster)}
\end{Highlighting}
\end{Shaded}

찾아진 가장 가까운 두 군집은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration[[}\DecValTok{1}\NormalTok{]]}\OperatorTok{$}\NormalTok{closest_cluster}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
##   cluster1 cluster2 distance
##   <chr>    <chr>       <dbl>
## 1 10       9               1
\end{verbatim}

위 두 군집을 하나로 묶은 새로운 군집해는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration[[}\DecValTok{1}\NormalTok{]]}\OperatorTok{$}\NormalTok{new_cluster_label}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##       id cluster
##    <int> <chr>  
##  1     1 1      
##  2     2 2      
##  3     3 3      
##  4     4 4      
##  5     5 5      
##  6     6 6      
##  7     7 7      
##  8     8 8      
##  9     9 10,9   
## 10    10 10,9
\end{verbatim}

위 새로운 군집해의 군집 수는 9이다. 이는 아직 1보다 크므로, 새로 얻어진 군집해로부터 단계 1을 반복한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration[[}\DecValTok{2}\NormalTok{]] <-}\StringTok{ }\KeywordTok{merge_cluster}\NormalTok{(}
\NormalTok{  train_df,}
\NormalTok{  iteration[[}\DecValTok{1}\NormalTok{]]}\OperatorTok{$}\NormalTok{new_cluster_label}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

이번에 찾아진 가장 가까운 두 군집은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration[[}\DecValTok{2}\NormalTok{]]}\OperatorTok{$}\NormalTok{closest_cluster}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
##   cluster1 cluster2 distance
##   <chr>    <chr>       <dbl>
## 1 3        7               1
\end{verbatim}

위 두 군집을 하나로 묶은 새로운 군집해는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration[[}\DecValTok{2}\NormalTok{]]}\OperatorTok{$}\NormalTok{new_cluster_label}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##       id cluster
##    <int> <chr>  
##  1     1 1      
##  2     2 2      
##  3     3 3,7    
##  4     4 4      
##  5     5 5      
##  6     6 6      
##  7     7 3,7    
##  8     8 8      
##  9     9 10,9   
## 10    10 10,9
\end{verbatim}

위 군집해에 기반하여 단계 1을 다시 반복해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration[[}\DecValTok{3}\NormalTok{]] <-}\StringTok{ }\KeywordTok{merge_cluster}\NormalTok{(}
\NormalTok{  train_df,}
\NormalTok{  iteration[[}\DecValTok{2}\NormalTok{]]}\OperatorTok{$}\NormalTok{new_cluster_label}
\NormalTok{)}

\KeywordTok{print}\NormalTok{(iteration[[}\DecValTok{3}\NormalTok{]]}\OperatorTok{$}\NormalTok{closest_cluster)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
##   cluster1 cluster2 distance
##   <chr>    <chr>       <dbl>
## 1 1        6            1.41
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{print}\NormalTok{(iteration[[}\DecValTok{3}\NormalTok{]]}\OperatorTok{$}\NormalTok{new_cluster_label)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##       id cluster
##    <int> <chr>  
##  1     1 1,6    
##  2     2 2      
##  3     3 3,7    
##  4     4 4      
##  5     5 5      
##  6     6 1,6    
##  7     7 3,7    
##  8     8 8      
##  9     9 10,9   
## 10    10 10,9
\end{verbatim}

위와 같은 과정을 전체 객체가 하나의 군집으로 묶일 때까지 아래와 같이 반복하며 군집결과를 출력해보자.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#단계0}
\NormalTok{init_cluster <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{id =}\NormalTok{ train_df}\OperatorTok{$}\NormalTok{id,}
  \DataTypeTok{cluster =} \KeywordTok{as.character}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(train_df))}
\NormalTok{)}

\NormalTok{i <-}\StringTok{ }\NormalTok{0L}
\NormalTok{current_clusters <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(init_cluster}\OperatorTok{$}\NormalTok{cluster)}
\NormalTok{k <-}\StringTok{ }\KeywordTok{length}\NormalTok{(current_clusters)}

\NormalTok{print_clusters <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(i, k, clusters) \{}
  \KeywordTok{cat}\NormalTok{(}\StringTok{"Iteration: "}\NormalTok{, i, }\StringTok{", k = "}\NormalTok{, k, }\StringTok{", clusters = "}\NormalTok{, }\KeywordTok{paste0}\NormalTok{(}\StringTok{"\{"}\NormalTok{, clusters, }\StringTok{"\}"}\NormalTok{), }\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{\}}

\KeywordTok{print_clusters}\NormalTok{(i, k, current_clusters)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Iteration:  0 , k =  10 , clusters =  {1} {2} {3} {4} {5} {6} {7} {8} {9} {10}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#단계1}
\NormalTok{iteration <-}\StringTok{ }\KeywordTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\DataTypeTok{length =} \KeywordTok{nrow}\NormalTok{(train_df) }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)}
\ControlFlowTok{while}\NormalTok{(k }\OperatorTok{>}\StringTok{ }\DecValTok{1}\NormalTok{) \{}
\NormalTok{  i <-}\StringTok{ }\NormalTok{i }\OperatorTok{+}\StringTok{ }\DecValTok{1}
  \ControlFlowTok{if}\NormalTok{(i }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{) \{}
\NormalTok{    iteration[[i]] <-}\StringTok{ }\KeywordTok{merge_cluster}\NormalTok{(}
\NormalTok{      train_df,}
\NormalTok{      init_cluster}
\NormalTok{    )}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    iteration[[i]] <-}\StringTok{ }\KeywordTok{merge_cluster}\NormalTok{(}
\NormalTok{      train_df,}
\NormalTok{      iteration[[i}\DecValTok{-1}\NormalTok{]]}\OperatorTok{$}\NormalTok{new_cluster_label}
\NormalTok{    )}
\NormalTok{  \}}

\NormalTok{  current_clusters <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(iteration[[i]]}\OperatorTok{$}\NormalTok{new_cluster_label}\OperatorTok{$}\NormalTok{cluster)}
\NormalTok{  k <-}\StringTok{ }\KeywordTok{length}\NormalTok{(current_clusters)}
  
  \KeywordTok{print_clusters}\NormalTok{(i, k, current_clusters)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Iteration:  1 , k =  9 , clusters =  {1} {2} {3} {4} {5} {6} {7} {8} {10,9} 
## Iteration:  2 , k =  8 , clusters =  {1} {2} {3,7} {4} {5} {6} {8} {10,9} 
## Iteration:  3 , k =  7 , clusters =  {1,6} {2} {3,7} {4} {5} {8} {10,9} 
## Iteration:  4 , k =  6 , clusters =  {1,6} {2} {3,7,5} {4} {8} {10,9} 
## Iteration:  5 , k =  5 , clusters =  {1,6,2} {3,7,5} {4} {8} {10,9} 
## Iteration:  6 , k =  4 , clusters =  {1,6,2} {3,7,5} {4} {10,9,8} 
## Iteration:  7 , k =  3 , clusters =  {1,6,2} {3,7,5,4} {10,9,8} 
## Iteration:  8 , k =  2 , clusters =  {1,6,2,3,7,5,4} {10,9,8} 
## Iteration:  9 , k =  1 , clusters =  {1,6,2,3,7,5,4,10,9,8}
\end{verbatim}

\hypertarget{hclust}{%
\subsection{R 패키지 내 연결법}\label{hclust}}

R에서는 \texttt{stats} 패키지의 \texttt{hclust} 함수를 이용하여 군집해를 구할 수 있다.

우선, 객체간 거리 행렬을 함수 \texttt{dist}를 이용하여 구한다. 아래는 유클리드 거리를 구하는 예이며, 상황에 따라 다른 거리 척도를 이용할 수도 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{distance_matrix <-}\StringTok{ }\KeywordTok{dist}\NormalTok{(train_df[, }\DecValTok{-1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

객체간 거리를 구한 후, 함수 \texttt{hclust}를 이용하여 군집분석을 수행한다. 기본설정은 완전연결법이며, 파라미터 \texttt{method}의 값을 설정함으로써 단일연결법, 평균연결법, 중심연결법을 수행할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster_solution <-}\StringTok{ }\KeywordTok{hclust}\NormalTok{(distance_matrix, }\DataTypeTok{method =} \StringTok{"average"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

결과 객체 \texttt{cluster\_solution}는 아래와 같은 컴포넌트(components)를 지닌 리스트(list) 객체이다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{names}\NormalTok{(cluster_solution)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "merge"       "height"      "order"       "labels"      "method"     
## [6] "call"        "dist.method"
\end{verbatim}

이 중, \texttt{merge}는 2개의 열과 \(n - 1\)개의 행으로 이루어진 행렬로, 연결법 알고리즘의 단계1 iteration에서 묶어지는 두 군집을 기록한 것이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster_solution}\OperatorTok{$}\NormalTok{merge}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       [,1] [,2]
##  [1,]   -3   -7
##  [2,]   -9  -10
##  [3,]   -1   -6
##  [4,]   -5    1
##  [5,]   -2    3
##  [6,]   -8    2
##  [7,]   -4    4
##  [8,]    5    7
##  [9,]    6    8
\end{verbatim}

위에서 각 행은 iteration을 나타내며, 두 열은 묶어지는 두 군집을 나타낸다. 값이 0보다 작은 경우에는 번호가 원 객체 번호를 나타내며, 값이 0보다 큰 경우에는 해당 번호의 iteration에서 묶어진 군집을 나타낸다. 예를 들어, 위 결과의 6번째 행 (-8, 2) 은 객체 8과 두 번째 iteration에서 얻어진 군집 (객체 9와 10이 묶여진 군집)이 묶여 하나의 군집(객체 8, 9, 10)을 이루게 됨을 나타낸다.

\texttt{height}는 각 iteration에서 묶이는 두 군집간의 거리를 나타내며, 위 Figure \ref{fig:pc-user-average-linkage}의 덴드로그램에서 세로선의 높이를 나타낸다. Iteration이 증가함에 따라 묶이는 두 군집간의 거리도 증가한다. 일반적으로 이 거리값이 크게 증가하는 iteration에서 두 군집을 묶지 않고 최종 군집해를 도출한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster_solution}\OperatorTok{$}\NormalTok{height}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1.000000  1.000000  1.414214  1.825141  2.236068  2.532248  3.519028
## [8]  9.635217 10.881878
\end{verbatim}

위 결과의 경우 iteration 8에서 거리값이 크게 증가한다. 이는 위 Figure \ref{fig:pc-user-average-linkage}의 덴드로그램에서 3개의 군집에서 2개의 군집으로 묶이는 과정에서 세로선의 높이가 현격히 증가하는 지점이다. 따라서, iteration 7에서 얻어진 3개의 군집이 적절한 군집해라 판단할 수 있겠다.

\hypertarget{ward-method}{%
\section{워드 방법}\label{ward-method}}

워드방법(Ward's method) 역시 각 객체를 하나의 군집으로 간주함을 시작으로 군집들을 묶어 단계적으로 그 수를 하나가 돌 때까지 줄여나가는 것인데, 군집의 제곱합을 활용한다.

\hypertarget{ward-method-basic-script}{%
\subsection{기본 R 스크립트}\label{ward-method-basic-script}}

아래 Table \ref{tab:driver-data}는 8명의 운전자에 대한 운전경력과 교통위반 횟수를 나타낸 것이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{id =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{8}\NormalTok{),}
  \DataTypeTok{x1 =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{17}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{18}\NormalTok{),}
  \DataTypeTok{x2 =} \KeywordTok{c}\NormalTok{(}\DecValTok{15}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{17}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{6}\NormalTok{)}
\NormalTok{)}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(train_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
             \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
             \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'운전경력($x_1$)'}\NormalTok{, }\StringTok{'위반횟수($x_2$)'}\NormalTok{),}
             \DataTypeTok{caption =} \StringTok{'운전경력에 따른 교통위반 횟수'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:driver-data}운전경력에 따른 교통위반 횟수}
\centering
\begin{tabular}{rrr}
\toprule
객체번호 & 운전경력(\$x\_1\$) & 위반횟수(\$x\_2\$)\\
\midrule
1 & 4 & 15\\
2 & 20 & 13\\
3 & 3 & 13\\
4 & 19 & 4\\
5 & 17 & 17\\
\addlinespace
6 & 8 & 11\\
7 & 19 & 12\\
8 & 18 & 6\\
\bottomrule
\end{tabular}
\end{table}

앞 절의 연결법에서 사용했던 \texttt{hclust} 함수를 이용하여 워드 방법에 의한 군집해도 구할 수 있으며, 이 때 파라미터 \texttt{method}의 값으로 ``ward.D2''를 사용한다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{dist}\NormalTok{(train_df[, }\DecValTok{-1}\NormalTok{]) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{hclust}\NormalTok{(}\DataTypeTok{method =} \StringTok{"ward.D2"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{plot}\NormalTok{(}
    \DataTypeTok{main =} \OtherTok{NULL}\NormalTok{,}
    \DataTypeTok{xlab =} \StringTok{"observation"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/ward-dendrogram-1} 

}

\caption{운전자 데이터에 대한 워드 방법 덴드로그램}\label{fig:ward-dendrogram}
\end{figure}

\hypertarget{ward-method-algorithm}{%
\subsection{워드 군집 알고리즘}\label{ward-method-algorithm}}

군집결과가 \(\mathbf{C} = \{ C_1, C_2, \cdots, C_k \}\)일 때, 군집 \(C_i\) 내의 제곱합(within sum of squares)은 다음과 같이 산출된다.

\begin{equation*}
SS(C_i) = \sum_{u \in C_i} \left(\mathbf{x}_u - \mathbf{c}_i\right)^\top\left(\mathbf{x}_u - \mathbf{c}_i\right)
\end{equation*}

이 때, 전체 군집 내 제곱합을 \(SSW\)라 할 때, 이는 다음과 같다.

\begin{equation*}
SSW = \sum_{i = 1}^{k} SS(C_i)
\end{equation*}

다음으로, 현 군집의 각 쌍을 묶는다고 할 때의 새로운 \(SSW\)를 산출한 후, 이 값이 가장 작게 되는 군집 쌍을 묶는다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  단계0

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    각 객체를 하나의 군집으로 간주한다.
  \item
    \(k \leftarrow n\)
  \end{enumerate}
\item
  단계1

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    현재의 군집 결과에 있는 모든 군집간의 쌍에 대하여 묶을 경우 전체제곱합(SSW)을 산출하고, 이 중 최소가 되는 군집 \(i\)와 군집 \(j\)를 묶어 하나의 군집으로 만든 후, 군집 결과를 수정한다.
  \item
    \(k \leftarrow k - 1\)
  \end{enumerate}
\item
  단계2: \(k = 1\)이면 Stop, 그렇지 않으면 단계1을 반복한다.
\end{enumerate}

워드 군집 알고리즘을 R script로 구현해보자. 우선, 객체 데이터 \(SSW\)를 계산하는 사용자 정의 함수 \texttt{calculate\_ssw}를 아래와 같이 두 입력변수 \texttt{df} 및 \texttt{cluster\_label}를 이용하여 구현하자.

\begin{itemize}
\tightlist
\item
  \texttt{df}: 객체 데이터 프레임. 열 이름이 \texttt{id}인 열은 객체번호를 나타내어, 객체간 거리 계산에 포함하지 않는다.
\item
  \texttt{cluster\_label}: 두 개의 열로 이루어진 데이터 프레임. 열 \texttt{id}는 객체번호를 나타내며, 열 \texttt{cluster}는 군집 이름을 나타낸다. 하나의 객체는 하나의 군집에만 속할 수 있으나, 하나의 군집은 여러 개의 객체를 포함할 수 있다.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# SSW 계산}
\NormalTok{calculate_ssw <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, cluster_label) \{}
\NormalTok{  df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{inner_join}\NormalTok{(cluster_label, }\DataTypeTok{by =} \StringTok{"id"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(cluster) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{id) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{summarize_all}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{sum}\NormalTok{((x }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(x))}\OperatorTok{^}\DecValTok{2}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{ss =} \KeywordTok{rowSums}\NormalTok{(}\KeywordTok{subset}\NormalTok{(., }\DataTypeTok{select =} \OperatorTok{-}\NormalTok{cluster))) }\OperatorTok{%>%}
\StringTok{    `}\DataTypeTok{[[}\StringTok{`}\NormalTok{(}\StringTok{"ss"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{sum}\NormalTok{()}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

워드 군집 알고리즘은 현재 군집해 내의 모든 군집쌍에 대하여 두 군집을 하나의 군집으로 묶을 경우의 \(SSW\)를 계산해야 한다. 따라서, 우선 고려할 모든 군집해를 생성하는 사용자 정의 함수 \texttt{generate\_clusters}를 아래와 같이 구현한다.

아래 사용자 정의 함수 \texttt{generate\_clusters}는 임의의 군집해 \texttt{cluster\_label}을 입력변수로 사용하며, 해당 입력변수에 대한 설명은 위 함수 \texttt{calculate\_ssw}에서와 같다. 함수 수행 결과, 가능한 각각의 군집쌍 결합의 결과물인 군집해 데이터 프레임을 리스트(list) 형태로 출력한다.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 임의의 군집해로부터 가능한 다음단계 군집해 생성}
\NormalTok{generate_clusters <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(cluster_label) \{}
\NormalTok{  unique_clusters <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(cluster_label}\OperatorTok{$}\NormalTok{cluster)}
  
\NormalTok{  potential_pairs <-}\StringTok{ }\KeywordTok{crossing}\NormalTok{(}\DataTypeTok{cluster1 =}\NormalTok{ unique_clusters, }
           \DataTypeTok{cluster2 =}\NormalTok{ unique_clusters) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(cluster1 }\OperatorTok{<}\StringTok{ }\NormalTok{cluster2) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{cluster =} \KeywordTok{paste}\NormalTok{(cluster1, cluster2, }\DataTypeTok{sep =} \StringTok{","}\NormalTok{))}
  
\NormalTok{  candidate_solutions <-}\StringTok{ }\NormalTok{potential_pairs }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{rowwise}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{do}\NormalTok{(}\DataTypeTok{candidate_solution =} \KeywordTok{merge_cluster}\NormalTok{(cluster_label, .)) }\OperatorTok{%>%}
\StringTok{    `}\DataTypeTok{[[}\StringTok{`}\NormalTok{(}\StringTok{"candidate_solution"}\NormalTok{)}
  
\NormalTok{  candidate_solutions}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위에서 보이는 바와 같이, 함수 \texttt{generate\_clusters}는 또 다른 사용자 정의함수 \texttt{merge\_cluster}를 호출한다. 이 함수는 두 입력변수 \texttt{cluster\_label} 및 \texttt{cluster\_merge}를 사용하는데, \texttt{cluster\_label}에 대한 설명은 위 다른 사용자 정의 함수에서와 동일하며, \texttt{cluster\_merge}에 대한 설명은 아래와 같다.

\begin{itemize}
\tightlist
\item
  \texttt{cluster\_merge}: 3차원 character 벡터. 첫 두 element는 현재 \texttt{cluster\_label}에 존재하는 군집 중 하나의 군집으로 묶일 두 군집의 이름을 나타내며, 세 번째 element는 그 결과 나타나는 군집 이름을 나타낸다.
\end{itemize}

함수 수행 결과, 입력된 \texttt{cluster\_label}에서 군집이름이 \texttt{cluster\_merge{[}1{]}} 혹은 \texttt{cluster\_merge{[}2{]}}에 해당하는 객체들은, 출력된 군집해에서는 군집이름 \texttt{cluster\_merge{[}3{]}}을 지닌다.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 임의의 군집 결합 규칙 cluster_merge에 따른 군집해}
\NormalTok{merge_cluster <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(cluster_label, cluster_merge) \{}
\NormalTok{  idx <-}\StringTok{ }\NormalTok{cluster_label}\OperatorTok{$}\NormalTok{cluster }\OperatorTok{%in%}\StringTok{ }\NormalTok{cluster_merge[}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{]}
\NormalTok{  cluster_label[idx, }\StringTok{"cluster"}\NormalTok{] <-}\StringTok{ }\NormalTok{cluster_merge[}\DecValTok{3}\NormalTok{]}
\NormalTok{  cluster_label}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

마지막으로, 현재 군집해로부터 가장 최적의 다음단계 군집해를 얻는 사용자 함수 \texttt{best\_merge\_cluster}를 아래와 같이 구현해보자.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{generate\_clusters}를 실행하여 다음 단계에 가능한 모든 군집해를 구한다.
\item
  1의 각 군집해에 함수 \texttt{calculate\_ssw}를 적용하여 \(SSW\)값을 구한다.
\item
  \(SSW\)값이 최소인 군집해를 최적 군집해로 선정한다.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 최적 군집 결합}
\NormalTok{best_merge_cluster <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, cluster_label) \{}
\NormalTok{  candidate_solutions <-}\StringTok{ }\KeywordTok{generate_clusters}\NormalTok{(cluster_label)}
\NormalTok{  ssw <-}\StringTok{ }\KeywordTok{sapply}\NormalTok{(candidate_solutions, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{calculate_ssw}\NormalTok{(df, x))}
  \KeywordTok{list}\NormalTok{(}
    \DataTypeTok{new_cluster_label =}\NormalTok{ candidate_solutions[[}\KeywordTok{which.min}\NormalTok{(ssw)]],}
    \DataTypeTok{new_ssw =} \KeywordTok{min}\NormalTok{(ssw)}
\NormalTok{  )}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 사용자 함수들을 이용하여 Table \ref{tab:driver-data}에 대한 워드 군집 분석을 수행해보자.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#단계0}
\NormalTok{init_cluster <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{id =}\NormalTok{ train_df}\OperatorTok{$}\NormalTok{id,}
  \DataTypeTok{cluster =} \KeywordTok{as.character}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(train_df))}
\NormalTok{)}
\NormalTok{i <-}\StringTok{ }\NormalTok{0L}
\NormalTok{current_clusters <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(init_cluster}\OperatorTok{$}\NormalTok{cluster)}
\NormalTok{k <-}\StringTok{ }\KeywordTok{length}\NormalTok{(current_clusters)}
\NormalTok{ssw <-}\StringTok{ }\KeywordTok{calculate_ssw}\NormalTok{(train_df, init_cluster)}

\NormalTok{print_clusters <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(i, k, clusters, ssw) \{}
  \KeywordTok{cat}\NormalTok{(}\StringTok{"Iteration: "}\NormalTok{, i, }\StringTok{", k = "}\NormalTok{, k, }\StringTok{", clusters = "}\NormalTok{, }\KeywordTok{paste0}\NormalTok{(}\StringTok{"\{"}\NormalTok{, clusters, }\StringTok{"\}"}\NormalTok{), }\StringTok{", SSW ="}\NormalTok{, ssw, }\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{\}}

\KeywordTok{print_clusters}\NormalTok{(i, k, current_clusters, ssw)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Iteration:  0 , k =  8 , clusters =  {1} {2} {3} {4} {5} {6} {7} {8} , SSW = 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#단계1}
\NormalTok{iteration <-}\StringTok{ }\KeywordTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\DataTypeTok{length =} \KeywordTok{nrow}\NormalTok{(train_df) }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)}
\ControlFlowTok{while}\NormalTok{(k }\OperatorTok{>}\StringTok{ }\DecValTok{1}\NormalTok{) \{}
\NormalTok{  i <-}\StringTok{ }\NormalTok{i }\OperatorTok{+}\StringTok{ }\DecValTok{1}
  \ControlFlowTok{if}\NormalTok{(i }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{) \{}
\NormalTok{    iteration[[i]] <-}\StringTok{ }\KeywordTok{best_merge_cluster}\NormalTok{(}
\NormalTok{      train_df,}
\NormalTok{      init_cluster}
\NormalTok{    )}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    iteration[[i]] <-}\StringTok{ }\KeywordTok{best_merge_cluster}\NormalTok{(}
\NormalTok{      train_df,}
\NormalTok{      iteration[[i}\DecValTok{-1}\NormalTok{]]}\OperatorTok{$}\NormalTok{new_cluster_label}
\NormalTok{    )}
\NormalTok{  \}}

\NormalTok{  current_clusters <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(iteration[[i]]}\OperatorTok{$}\NormalTok{new_cluster_label}\OperatorTok{$}\NormalTok{cluster)}
\NormalTok{  k <-}\StringTok{ }\KeywordTok{length}\NormalTok{(current_clusters)}
\NormalTok{  ssw <-}\StringTok{ }\NormalTok{iteration[[i]]}\OperatorTok{$}\NormalTok{new_ssw}
  
  \KeywordTok{print_clusters}\NormalTok{(i, k, current_clusters, ssw)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Iteration:  1 , k =  7 , clusters =  {1} {2,7} {3} {4} {5} {6} {8} , SSW = 1 
## Iteration:  2 , k =  6 , clusters =  {1,3} {2,7} {4} {5} {6} {8} , SSW = 3.5 
## Iteration:  3 , k =  5 , clusters =  {1,3} {2,7} {4,8} {5} {6} , SSW = 6 
## Iteration:  4 , k =  4 , clusters =  {1,3} {2,7,5} {4,8} {6} , SSW = 23.66667 
## Iteration:  5 , k =  3 , clusters =  {1,3,6} {2,7,5} {4,8} , SSW = 43.16667 
## Iteration:  6 , k =  2 , clusters =  {1,3,6} {2,7,5,4,8} , SSW = 140.4 
## Iteration:  7 , k =  1 , clusters =  {1,3,6,2,7,5,4,8} , SSW = 499.875
\end{verbatim}

\hypertarget{ward-rpackages}{%
\subsection{R 패키지 내 워드 방법}\label{ward-rpackages}}

R 패키지로 구현된 워드 군집은 위에서 구현한 \(SSW\)와는 다소 다른 metric을 이용하여 군집해를 구한다. 따라서, 우선 워드 방법이 제안된 논문들을 살펴볼 필요가 있다.

우선 원 논문 \citet{ward1963hierarchical} 는 \(ESS\)(error sum of squares)를 아래와 같이 정의하였으며, 이는 위에서 사용한 \(SSW\)와 일치한다.

\begin{equation*}
\begin{split}
ESS(\{C_1, \cdots, C_k \}) &= \sum_{i = 1}^{k} ESS(C_i)\\
&= \sum_{i = 1}^{k} \sum_{u \in C_i} \mathbf{x}_u^\top \mathbf{x}_u - |C_i| \mathbf{c}_i^\top \mathbf{c}_i\\
&= SSW
\end{split}
\end{equation*}

위 식에서 임의의 두 군집 \(C_i\), \(C_j\)를 하나의 군집으로 묶을 때 \(SSW\)의 변화는 아래와 같다. \(C_i\)와 \(C_j\) 외의 군집은 \(SSW\)의 변화에 영향을 미치지 않으므로, \(SSW\) 변화량은 아래와 같이 군집 \(C_i\)와 \(C_j\)에 속하는 객체만을 이용하여 구할 수 있으며, 결과적으로 \(C_i\)와 \(C_j\)의 군집 크기 \(|C_i|\)와 \(|C_j|\)및 군집 중심벡터 \(\mathbf{c}_i\)와 \(\mathbf{c}_j\)를 이용하여 구할 수 있다.

\begin{equation}
\begin{split}
\Delta SSW =& ESS(C_i \cup C_j) - ESS(C_i) - ESS(C_j)\\
=& \sum_{u \in C_i \cup C_j} \mathbf{x}_u^\top \mathbf{x}_u - (|C_i| + |C_j|)\left[\frac{|C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j}{|C_i| + |C_j|}\right]^\top \left[\frac{|C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j}{|C_i| + |C_j|}\right]\\
& - \left( \sum_{u \in C_i} \mathbf{x}_u^\top \mathbf{x}_u - |C_i| \mathbf{c}_i^\top \mathbf{c}_i \right) - \left( \sum_{u \in C_j} \mathbf{x}_u^\top \mathbf{x}_u - |C_j| \mathbf{c}_j^\top \mathbf{c}_j \right)\\
=& -\frac{1}{|C_i| + |C_j|} \left( |C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j \right)^\top \left( |C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j \right) + |C_i| \mathbf{c}_i^\top \mathbf{c}_i + |C_j| \mathbf{c}_j^\top \mathbf{c}_j\\
=& \frac{|C_i||C_j|}{|C_i| + |C_j|} \left(\mathbf{c}_i - \mathbf{c}_j\right)^\top \left(\mathbf{c}_i - \mathbf{c}_j\right)
\end{split}
\label{eq:ward-minimand}
\end{equation}

따라서 워드 방법은 각 iteration에서 식 \eqref{eq:ward-minimand}를 최소화하는 두 군집 \(C_i\), \(C_j\)를 선택하여 두 군집을 하나로 묶는 방법이다.

한편, \(SS(C_i)\)는 아래와 같이 군집 \(C_i\)내 객체들 간의 제곱 유클리드 거리로 나타낼 수 있다.

\begin{equation}
\begin{split}
D^2(C_i) =& \sum_{u, v \in C_i} (\mathbf{x}_u - \mathbf{x}_v)^\top (\mathbf{x}_u - \mathbf{x}_v)\\
=& \sum_{u, v \in C_i} \left((\mathbf{x}_u - \mathbf{c}_i) - (\mathbf{x}_v - \mathbf{c}_i)\right)^\top \left((\mathbf{x}_u - \mathbf{c}_i) - (\mathbf{x}_v - \mathbf{c}_i)\right)\\
=& 2 \sum_{u \in C_i} (\mathbf{x}_u - \mathbf{c}_i)^\top (\mathbf{x}_u - \mathbf{c}_i) - 2 \sum_{u, v \in C_i} (\mathbf{x}_u - \mathbf{c}_i)^\top (\mathbf{x}_v - \mathbf{c}_i)\\
=& 2 \sum_{u \in C_i} (\mathbf{x}_u - \mathbf{c}_i)^\top (\mathbf{x}_u - \mathbf{c}_i)\\
=& 2 SS(C_i)
\end{split}
\label{eq:squared-euclidean-within-cluster}
\end{equation}

위 식 \eqref{eq:squared-euclidean-within-cluster}을 달리 표현하면, 객체간의 제곱 유클리드 거리를 표현한 행렬에서 군집 \(i\)에 속한 객체들에 해당하는 부분행렬(submatrix)를 뽑아 행렬의 원소값을 모두 더하면, 그 값이 \(2 SS(C_i)\)와 같다. 이를 통해 각 군집의 중심벡터를 계산하지 않고도 각 iteration에서 SSW를 최소화하는 군집 결합을 찾을 수 있다.

R 패키지 \texttt{stats} 내의 \texttt{hclust} 함수는 워드 방법으로 \texttt{method} 파라미터의 값을 ``ward.D'' 혹은 ``ward.D2''로 설정할 수 있다. 이 두 방법의 차이는 입력 거리행렬을 제곱 유클리드 거리로 사용하는지 일반 유클리드 거리로 사용하는지의 차이로, 아래에서 R 스크립트 예제와 함께 설명하기로 한다.

우선 \texttt{method}값을 ``ward.D2''로 설정하는 경우, \texttt{dist} 함수의 결과를 입력 거리행렬로 그대로 사용하면 된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res_ward.D2 <-}\StringTok{ }\KeywordTok{dist}\NormalTok{(train_df[, }\DecValTok{-1}\NormalTok{]) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{hclust}\NormalTok{(}\DataTypeTok{method =} \StringTok{"ward.D2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

이 때, 결과 데이터 \texttt{res\_ward.D2}에서 워드 방법의 criterion을 나타내는 \texttt{height} 원소(component)가 표현하는 값은 위에서 계산하였던 \(SSW\)와 다르다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res_ward.D2}\OperatorTok{$}\NormalTok{height}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1.414214  2.236068  2.236068  5.944185  6.244998 13.945131 26.813243
\end{verbatim}

이는 \texttt{height}에서 표현하는 값은 전체 \(SSW\)가 아니라, 두 군집 \(i\)와 \(j\)를 하나로 묶을 때 추가로 증가하는 \(SSW\) 수치의 변환으로, 아래와 같이 계산되기 때문이다.

\begin{equation}
height = \sqrt{D^2(C_i \cup C_j) - \left(D^2(C_i) + D^2(C_j)\right)}
\label{eq:hclust-height}
\end{equation}

따라서, 군집 \(i\)와 \(j\)를 하나로 묶을 때 증가하는 \(SSW\)의 수치 \(\Delta SSW\)는 아래와 같이 표현된다.

\begin{equation}
\Delta SSW = \frac{1}{2} height^2
\end{equation}

각 iteration에서 발생하는 \(\Delta SSW\)의 누적합이 위 \ref{ward-method-algorithm}절에서 보였던 \(SSW\) 결과와 동일함을 아래와 같이 확인해보자.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{iteration =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(train_df) }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)),}
  \DataTypeTok{height =}\NormalTok{ res_ward.D2}\OperatorTok{$}\NormalTok{height}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{delta_ssw =}\NormalTok{ height }\OperatorTok{^}\StringTok{ }\DecValTok{2} \OperatorTok{/}\StringTok{ }\DecValTok{2}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{ssw =} \KeywordTok{cumsum}\NormalTok{(delta_ssw)}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'iteration'}\NormalTok{, }\StringTok{'$height$'}\NormalTok{, }\StringTok{'$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{Delta SSW = }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{frac\{1\}\{2\} height ^ 2$'}\NormalTok{, }\StringTok{'$SSW = }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{sum }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{Delta SSW$'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'hclust 함수 ward.D2 방법의 height와 SSW 관계'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:ward-D2-height-ssw}hclust 함수 ward.D2 방법의 height와 SSW 관계}
\centering
\begin{tabular}{rrrr}
\toprule
iteration & \$height\$ & \$\textbackslash{}Delta SSW = \textbackslash{}frac\{1\}\{2\} height \textasciicircum{} 2\$ & \$SSW = \textbackslash{}sum \textbackslash{}Delta SSW\$\\
\midrule
1 & 1.414214 & 1.00000 & 1.00000\\
2 & 2.236068 & 2.50000 & 3.50000\\
3 & 2.236068 & 2.50000 & 6.00000\\
4 & 5.944185 & 17.66667 & 23.66667\\
5 & 6.244998 & 19.50000 & 43.16667\\
\addlinespace
6 & 13.945131 & 97.23333 & 140.40000\\
7 & 26.813243 & 359.47500 & 499.87500\\
\bottomrule
\end{tabular}
\end{table}

우선 \texttt{method}값을 ``ward.D''로 설정하는 경우, \texttt{dist} 함수의 결과를 입력 거리행렬로 그대로 사용하면 아래와 같이 위 ``ward.D2''와는 다른 \texttt{height}값을 출력하며, 이는 워드 방법의 criterion을 정확히 반영하지 못한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res_ward.D <-}\StringTok{ }\KeywordTok{dist}\NormalTok{(train_df[, }\DecValTok{-1}\NormalTok{]) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{hclust}\NormalTok{(}\DataTypeTok{method =} \StringTok{"ward.D"}\NormalTok{)}

\NormalTok{res_ward.D}\OperatorTok{$}\NormalTok{height}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1.414214  2.236068  2.236068  6.452039  6.615990 17.358484 39.311447
\end{verbatim}

이는 ``ward.D2''는 워드 방법 수행 전 입력된 유클리드 거리행렬을 내부적으로 제곱하는 반면, ``ward.D'' 방법은 제곱 유클리드 거리행렬이 입력되는 것을 가정하기 때문이다.

\citet{lance1967general} 은 군집 \(i\)와 \(j\)를 하나로 묶을 때, 새로 생성된 군집과 다른 군집들간의 거리는 원 두 군집들과 다른 군집들간의 거리로 아래와 같이 표현됨을 보였다. 이를 Lance-Williams update 공식이라 한다.

\begin{equation}
D(C_i \cup C_j, C_{h \notin \{i, j\}}) = \alpha_i D(C_i, C_h) + \alpha_j D(C_j, C_h) + \beta D(C_i, C_j) + \gamma |D(C_i, C_h) - D(C_j, C_h)|
\label{eq:lance-williams-update}
\end{equation}

이후 \citet{wishart1969256} 에서 워드 방법을 위 Lance-Williams update 공식으로 표현하였다.

\begin{equation}
\begin{split}
\alpha_i =& \frac{|C_i| + |C_h|}{|C_i| + |C_j| + |C_h|}\\
\alpha_j =& \frac{|C_j| + |C_h|}{|C_i| + |C_j| + |C_h|}\\
\beta =& - \frac{|C_h|}{|C_i| + |C_j| + |C_h|}\\
\gamma =& 0
\end{split}
\label{eq:wishart}
\end{equation}

이 때, 식 \eqref{eq:wishart}가 기반한 식 \eqref{eq:lance-williams-update}에서의 거리함수 \(D\)는 제곱 유클리드 거리를 사용한다.

``ward.D'' 방법은 제곱 유클리드 거리의 입력을 가정하며, 위의 경우와 같이 제곱 유클리드 거리가 아닌 일반 유클리드 거리행렬을 입력하였을 때, 오류 메시지를 출력하는 대신, 입력된 거리행렬이 제곱 유클리드 거리를 나타낸다 가정하고 Lance-Williams update를 수행한다. 따라서, 이 경우 \texttt{height}는 워드 방법의 criterion을 정확히 표현하지 못한다.

제곱 유클리드 거리를 ``ward.D'' 방법의 입력 거리행렬로 설정하고, 구해진 \texttt{height}를 출력해보자

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res_ward.D <-}\StringTok{ }\KeywordTok{dist}\NormalTok{(train_df[, }\DecValTok{-1}\NormalTok{])}\OperatorTok{^}\DecValTok{2} \OperatorTok{%>%}
\StringTok{  }\KeywordTok{hclust}\NormalTok{(}\DataTypeTok{method =} \StringTok{"ward.D"}\NormalTok{)}

\NormalTok{res_ward.D}\OperatorTok{$}\NormalTok{height}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]   2.00000   5.00000   5.00000  35.33333  39.00000 194.46667 718.95000
\end{verbatim}

위 \texttt{height}값은 ``ward.D2'' 방법에서 출력된 값보다 크다. 위 값의 제곱근(square root)를 구하면 ``ward.D2''에서의 \texttt{height}값과 동일한 값을 얻을 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sqrt}\NormalTok{(res_ward.D}\OperatorTok{$}\NormalTok{height)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1.414214  2.236068  2.236068  5.944185  6.244998 13.945131 26.813243
\end{verbatim}

제곱 유클리드 거리행렬을 입력한 ``ward.D'' 방법의 결과로 출력된 criterion \texttt{height}는 \(2 \Delta SSW\)의 값에 해당하는 수치이며, 각 iteration 당 \(\sum_i D(C_i)\)의 값의 변화량이라고 볼 수 있다. (식 \eqref{eq:squared-euclidean-within-cluster} 참조)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{iteration =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(train_df) }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)),}
  \DataTypeTok{height =}\NormalTok{ res_ward.D}\OperatorTok{$}\NormalTok{height}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{delta_ssw =}\NormalTok{ height }\OperatorTok{/}\StringTok{ }\DecValTok{2}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{ssw =} \KeywordTok{cumsum}\NormalTok{(delta_ssw)}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'iteration'}\NormalTok{, }\StringTok{'$height$'}\NormalTok{, }\StringTok{'$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{Delta SSW = }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{frac\{1\}\{2\} height$'}\NormalTok{, }\StringTok{'$SSW = }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{sum }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{Delta SSW$'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'hclust 함수 ward.D 방법의 height와 SSW 관계'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:ward-D-height-ssw}hclust 함수 ward.D 방법의 height와 SSW 관계}
\centering
\begin{tabular}{rrrr}
\toprule
iteration & \$height\$ & \$\textbackslash{}Delta SSW = \textbackslash{}frac\{1\}\{2\} height\$ & \$SSW = \textbackslash{}sum \textbackslash{}Delta SSW\$\\
\midrule
1 & 2.00000 & 1.00000 & 1.00000\\
2 & 5.00000 & 2.50000 & 3.50000\\
3 & 5.00000 & 2.50000 & 6.00000\\
4 & 35.33333 & 17.66667 & 23.66667\\
5 & 39.00000 & 19.50000 & 43.16667\\
\addlinespace
6 & 194.46667 & 97.23333 & 140.40000\\
7 & 718.95000 & 359.47500 & 499.87500\\
\bottomrule
\end{tabular}
\end{table}

즉, ``ward.D2''와 ``ward.D''의 가장 큰 차이는 입력될 거리행렬이 유클리드 거리(ward.D2)인지 제곱 유클리드 거리(ward.D)인지의 차이이다.

참고로, \texttt{cluster} 패키지의 \texttt{agnes}함수도 워드 방법을 지원하며, 이 경우 파라미터 \texttt{method}의 값을 ``ward''로 설정한 결과가 \texttt{hclust}함수의 ``ward.D2''의 경우와 동일하다. 본 절에서는 해당 함수의 자세한 사용법은 생략한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res_agnes_ward <-}\StringTok{ }\NormalTok{cluster}\OperatorTok{::}\KeywordTok{agnes}\NormalTok{(train_df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{method =} \StringTok{"ward"}\NormalTok{)}

\KeywordTok{sort}\NormalTok{(res_agnes_ward}\OperatorTok{$}\NormalTok{height)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1.414214  2.236068  2.236068  5.944185  6.244998 13.945131 26.813243
\end{verbatim}

\hypertarget{diana}{%
\section{분리적 방법 - 다이아나}\label{diana}}

다이아나는 분리적 방법의 하나로, \citet{kaufman1990finding} 에 의하여 제안된 것이다. 이는 전체의 객체를 하나의 군집으로 시작하여 매번 이분화하는 등 모든 군집이 단독 객체로 구성될 때까지 진행하는 방법이다. 이 때, 비유사성 척도로는 평균거리를 사용한다.

\hypertarget{diana-basic-script}{%
\subsection{기본 R 스크립트}\label{diana-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{id =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{7}\NormalTok{),}
  \DataTypeTok{x1 =} \KeywordTok{c}\NormalTok{(}\DecValTok{30}\NormalTok{, }\DecValTok{45}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{40}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{42}\NormalTok{),}
  \DataTypeTok{x2 =} \KeywordTok{c}\NormalTok{(}\DecValTok{15}\NormalTok{, }\DecValTok{22}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{24}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\NormalTok{)}

\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(train_df, }\DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
             \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
             \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'객체번호'}\NormalTok{, }\StringTok{'$x_1$'}\NormalTok{, }\StringTok{'$x_2$'}\NormalTok{),}
             \DataTypeTok{caption =} \StringTok{'DIANA 군집 대상 객체 데이터'}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:diana-data}DIANA 군집 대상 객체 데이터}
\centering
\begin{tabular}{rrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$\\
\midrule
1 & 30 & 15\\
2 & 45 & 22\\
3 & 25 & 12\\
4 & 40 & 24\\
5 & 50 & 25\\
\addlinespace
6 & 20 & 10\\
7 & 42 & 9\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:diana-data}와 같이 두 변수 \(x_1\), \(x_2\)로 이루어진 7개의 객체 데이터에 대해 DIANA 방법에 의해 군집해를 아래와 같이 \texttt{cluster} 패키지의 \texttt{diana} 함수를 이용하여 간단히 구할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res_diana <-}\StringTok{ }\NormalTok{cluster}\OperatorTok{::}\KeywordTok{diana}\NormalTok{(train_df[, }\DecValTok{-1}\NormalTok{])}
\NormalTok{cluster}\OperatorTok{::}\KeywordTok{pltree}\NormalTok{(res_diana,}
                \DataTypeTok{main =} \OtherTok{NULL}\NormalTok{,}
                \DataTypeTok{xlab =} \StringTok{"observation"}
\NormalTok{                )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/diana-result-plot-1} 

}

\caption{DIANA 방법에 의한 군집 덴드로그램}\label{fig:diana-result-plot}
\end{figure}

\hypertarget{diana-algorithm}{%
\subsection{다이아나 알고리즘}\label{diana-algorithm}}

가장 처음 이분화가 이루어질 때, 우선 타 객체와의 평균거리가 가장 큰 객체가 분파되어 새로운 군집을 형성한다. 그리고 다른 객체에 대하여, 군집에 남아있을 때의 평균거리와 새로운 군집으로 분리될 때의 평균거리를 산출하여, 현 군집에 잔류 또는 새로운 군집으로의 합류를 결정한다.

여기서 객체 \(i\)와 군집 \(C\)간의 평균거리는 다음과 같이 산출된다.

\begin{equation*}
\bar{d}(i, C) = \begin{cases}
\frac{1}{|C| - 1} \sum_{j \in C} d(i, j) & \text{ if } i \in C\\
\frac{1}{|C|} \sum_{j \in C} d(i, j) & \text{ if } i \notin C
\end{cases}
\end{equation*}

본 방법의 알고리즘은 다음과 같다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  단계0: \(n\)개의 객체를 하나의 군집으로 간주한다. (\(k = 1\))
\item
  단계1: 객체 간 거리가 가장 큰 두 객체를 포함한 군집을 이분화 대상으로 선정한다. (이를 \(A\)라 하고, \(B \leftarrow \emptyset\)로 둔다.)
\item
  단계2: 다음 과정을 통하여 군집 \(A\)를 이분화한다.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    단계2-1: \(i \leftarrow \arg\,\max_{i'} \bar{d}(i', A)\)
  \item
    단계2-2: \(A \leftarrow A - \{i\}\), \(B \leftarrow B \cup \{i\}\)
  \item
    단계2-3: \(i \leftarrow \arg\,\max_{i' \in A} e(i') = \bar{d}(i', A) - \bar{d}(i', B)\)
  \item
    단계2-4: \(e(i) > 0\)이면 단계2-2로, \(e(i) \le 0\)이면 단계3으로
  \end{enumerate}
\item
  단계3

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    \(k \leftarrow k + 1\)
  \item
    \(k < n\)이면 단계1로, \(k = n\)이면 Stop.
  \end{enumerate}
\end{enumerate}

DIANA 알고리즘을 R script로 구현해보자.

우선, 단계1의 군집을 찾는 함수 \texttt{max\_distance\_cluster}를 구현하자. 이 함수는 아래 두 개의 데이터 프레임을 입력받는다.

\begin{itemize}
\tightlist
\item
  입력

  \begin{itemize}
  \tightlist
  \item
    \texttt{df}: 관측 데이터. 각 열의 설명은 아래와 같다.

    \begin{itemize}
    \tightlist
    \item
      \texttt{id}: 객체번호
    \item
      나머지 열: 숫자형 변수
    \end{itemize}
  \item
    \texttt{cluster\_label}: 각 객체의 현재 소속 군집을 나타내는 데이터 프레임

    \begin{itemize}
    \tightlist
    \item
      \texttt{id}: 객체번호
    \item
      \texttt{cluster}: 군집명
    \end{itemize}
  \end{itemize}
\item
  함수값

  \begin{itemize}
  \tightlist
  \item
    \texttt{cluster}: 객체간 거리가 가장 큰 두 객체를 포함한 군집명
  \item
    \texttt{distance}: 군집 내 객체간 최대 거리
  \end{itemize}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{max_distance_cluster <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, cluster_label) \{}
\NormalTok{  unique_cluster <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(cluster_label}\OperatorTok{$}\NormalTok{cluster)}
  
\NormalTok{  cluster_df <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(unique_cluster, }\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{    cluster_label }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{filter}\NormalTok{(cluster }\OperatorTok{==}\StringTok{ }\NormalTok{x) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{inner_join}\NormalTok{(df, }\DataTypeTok{by =} \StringTok{"id"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{cluster, }\OperatorTok{-}\NormalTok{id)}
\NormalTok{    \})}
  
\NormalTok{  max_distance <-}\StringTok{ }\KeywordTok{sapply}\NormalTok{(cluster_df, }
                         \ControlFlowTok{function}\NormalTok{(x) \{}
                           \ControlFlowTok{if}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(x) }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{) }\KeywordTok{return}\NormalTok{(}\DecValTok{0}\NormalTok{)}
                           \KeywordTok{max}\NormalTok{(}\KeywordTok{dist}\NormalTok{(x))}
\NormalTok{                         \}}
\NormalTok{                         )}

  \KeywordTok{list}\NormalTok{(}
    \DataTypeTok{cluster =}\NormalTok{ unique_cluster[}\KeywordTok{which.max}\NormalTok{(max_distance)],}
    \DataTypeTok{distance =} \KeywordTok{max}\NormalTok{(max_distance)}
\NormalTok{  )}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

단계 2-1에서 군집 내 평균거리가 가장 큰 객체를 찾는 함수 \texttt{max\_within\_distance}를 아래와 같이 구현해보자. 이 때 입력변수인 \texttt{cluster\_df}는 해당 군집의 객체 데이터로, 객체 번호를 나타내는 열 \texttt{id}와 객체의 각 숫자형 변수를 표현하는 열들로 구성된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{max_within_distance <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(cluster_df) \{}
\NormalTok{  idx <-}\StringTok{ }\KeywordTok{dist}\NormalTok{(}\KeywordTok{subset}\NormalTok{(cluster_df, }\DataTypeTok{select =} \OperatorTok{-}\NormalTok{id), }\DataTypeTok{upper =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{mean_distance =} \KeywordTok{mean}\NormalTok{(distance)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{arrange}\NormalTok{(}\OperatorTok{-}\NormalTok{mean_distance) }\OperatorTok{%>%}
\StringTok{    }\NormalTok{.[[}\StringTok{"item1"}\NormalTok{]] }\OperatorTok{%>%}
\StringTok{    }\NormalTok{.[}\DecValTok{1}\NormalTok{]}
  
\NormalTok{  cluster_df}\OperatorTok{$}\NormalTok{id[idx]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

이후 단계2-3에서 정의한 \(e(i') = \bar{d}(i', A) - \bar{d}(i', B)\)를 계산하는 함수 \texttt{e\_score}를 아래와 같이 구현한다.

\begin{itemize}
\tightlist
\item
  \texttt{object}: 객체 번호(\texttt{id})
\item
  \texttt{A}(\texttt{B}): 군집 \(A\)(\(B\))의 객체 데이터. 행은 객체를 나타내며, \texttt{id} 열은 객체 번호, 이외의 열들은 변수를 나타낸다.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e_score <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(object, A, B) \{}
\NormalTok{  d_from_A <-}\StringTok{ }\NormalTok{proxy}\OperatorTok{::}\KeywordTok{dist}\NormalTok{(}\KeywordTok{subset}\NormalTok{(A, id }\OperatorTok{==}\StringTok{ }\NormalTok{object, }\OperatorTok{-}\NormalTok{id), }
                          \KeywordTok{subset}\NormalTok{(A, id }\OperatorTok{!=}\StringTok{ }\NormalTok{object, }\OperatorTok{-}\NormalTok{id)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{mean}\NormalTok{()}
\NormalTok{  d_from_B <-}\StringTok{ }\NormalTok{proxy}\OperatorTok{::}\KeywordTok{dist}\NormalTok{(}\KeywordTok{subset}\NormalTok{(A, id }\OperatorTok{==}\StringTok{ }\NormalTok{object, }\OperatorTok{-}\NormalTok{id), }
\NormalTok{                          B }\OperatorTok{%>%}\StringTok{ }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{id)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{mean}\NormalTok{()}
  \KeywordTok{return}\NormalTok{(d_from_A }\OperatorTok{-}\StringTok{ }\NormalTok{d_from_B)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 두 함수 \texttt{max\_within\_distance}와 \texttt{e\_score}를 이용하여, 주어진 데이터 프레임을 두 군집으로 나누는 함수 \texttt{split\_cluster}를 구현해보자.

\begin{itemize}
\tightlist
\item
  입력: 객체 데이터를 나타내는 데이터 프레임 \texttt{cluster\_df}. 행은 객체를 나타내며, 객체 번호를 나타내는 열 \texttt{id}와 객체의 각 숫자형 변수를 표현하는 열들로 구성된다.
\item
  함수값: 아래 두 개의 component를 지닌 리스트.

  \begin{itemize}
  \tightlist
  \item
    \texttt{idx\_A}: 객체 데이터에서 행렬 \(A\)에 속하는 객체 번호
  \item
    \texttt{idx\_B}: 객체 데이터에서 행렬 \(B\)에 속하는 객체 번호
  \end{itemize}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{split_cluster <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(cluster_df) \{}
\NormalTok{  n <-}\StringTok{ }\KeywordTok{nrow}\NormalTok{(cluster_df)}
  
\NormalTok{  idx_A <-}\StringTok{ }\NormalTok{cluster_df}\OperatorTok{$}\NormalTok{id}
\NormalTok{  idx_B <-}\StringTok{ }\OtherTok{NULL}
  
  \CommentTok{# 단계2-1}
\NormalTok{  max_object <-}\StringTok{ }\KeywordTok{max_within_distance}\NormalTok{(cluster_df)}
\NormalTok{  e_i <-}\StringTok{ }\OtherTok{Inf}

  \ControlFlowTok{while}\NormalTok{(e_i }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{) \{}
    \CommentTok{# 단계2-2}
\NormalTok{    idx_B <-}\StringTok{ }\KeywordTok{c}\NormalTok{(idx_B, max_object)}
\NormalTok{    idx_A <-}\StringTok{ }\KeywordTok{setdiff}\NormalTok{(idx_A, max_object)}
    
\NormalTok{    A <-}\StringTok{ }\NormalTok{cluster_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(id }\OperatorTok{%in%}\StringTok{ }\NormalTok{idx_A)}
\NormalTok{    B <-}\StringTok{ }\NormalTok{cluster_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(id }\OperatorTok{%in%}\StringTok{ }\NormalTok{idx_B)}

    \CommentTok{# 단계2-3}
    \ControlFlowTok{if}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(A) }\OperatorTok{>}\StringTok{ }\DecValTok{1}\NormalTok{) \{}
\NormalTok{      e_is <-}\StringTok{ }\KeywordTok{sapply}\NormalTok{(A}\OperatorTok{$}\NormalTok{id, }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{e_score}\NormalTok{(x, A, B))}
\NormalTok{      max_object <-}\StringTok{ }\NormalTok{A}\OperatorTok{$}\NormalTok{id[}\KeywordTok{which.max}\NormalTok{(e_is)]}
\NormalTok{      e_i <-}\StringTok{ }\KeywordTok{max}\NormalTok{(e_is)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{      e_i <-}\StringTok{ }\OperatorTok{-}\OtherTok{Inf}
\NormalTok{    \}}
\NormalTok{  \}}
  
  \KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{idx_A =}\NormalTok{ idx_A, }\DataTypeTok{idx_B =}\NormalTok{ idx_B))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

단계1 함수 \texttt{max\_distance\_cluster}와 단계2 함수 \texttt{split\_cluster}를 반복적으로 수행하며 각각의 객체가 군집에 될 때까지 군집을 분리해간다.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 단계0}
\NormalTok{current_cluster <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{id =}\NormalTok{ train_df}\OperatorTok{$}\NormalTok{id}
\NormalTok{)}
\NormalTok{current_cluster}\OperatorTok{$}\NormalTok{cluster <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(current_cluster), }\DataTypeTok{collapse =} \StringTok{","}\NormalTok{)}
\NormalTok{i <-}\StringTok{ }\NormalTok{0L}
\NormalTok{k <-}\StringTok{ }\NormalTok{1L}

\ControlFlowTok{while}\NormalTok{(k }\OperatorTok{<}\StringTok{ }\KeywordTok{nrow}\NormalTok{(train_df)) \{}
\NormalTok{  i <-}\StringTok{ }\NormalTok{i }\OperatorTok{+}\StringTok{ }\NormalTok{1L}
  
  \CommentTok{# 단계1}
\NormalTok{  max_cluster <-}\StringTok{ }\KeywordTok{max_distance_cluster}\NormalTok{(train_df, current_cluster)}

  \CommentTok{# 단계2}
\NormalTok{  new_split <-}\StringTok{ }\NormalTok{current_cluster }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(cluster }\OperatorTok{==}\StringTok{ }\NormalTok{max_cluster}\OperatorTok{$}\NormalTok{cluster) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{inner_join}\NormalTok{(train_df, }\DataTypeTok{by =} \StringTok{"id"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{cluster) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{split_cluster}\NormalTok{()}

  \CommentTok{# 군집해 업데이트}
\NormalTok{  current_cluster[}
\NormalTok{    current_cluster}\OperatorTok{$}\NormalTok{id }\OperatorTok{%in%}\StringTok{ }\NormalTok{new_split}\OperatorTok{$}\NormalTok{idx_A, }
    \StringTok{"cluster"}\NormalTok{] <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(new_split}\OperatorTok{$}\NormalTok{idx_A, }\DataTypeTok{collapse =} \StringTok{","}\NormalTok{)}
\NormalTok{  current_cluster[}
\NormalTok{    current_cluster}\OperatorTok{$}\NormalTok{id }\OperatorTok{%in%}\StringTok{ }\NormalTok{new_split}\OperatorTok{$}\NormalTok{idx_B, }
    \StringTok{"cluster"}\NormalTok{] <-}\StringTok{ }\KeywordTok{paste}\NormalTok{(new_split}\OperatorTok{$}\NormalTok{idx_B, }\DataTypeTok{collapse =} \StringTok{","}\NormalTok{)}
  
  \CommentTok{# 군집해 출력}
\NormalTok{  k <-}\StringTok{ }\KeywordTok{length}\NormalTok{(}\KeywordTok{unique}\NormalTok{(current_cluster}\OperatorTok{$}\NormalTok{cluster))}
  \KeywordTok{cat}\NormalTok{(}\StringTok{"Iteration: "}\NormalTok{, i, }\StringTok{", k = "}\NormalTok{, k, }\StringTok{", clusters = "}\NormalTok{, }
      \KeywordTok{paste0}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{unique}\NormalTok{(current_cluster}\OperatorTok{$}\NormalTok{cluster), }\StringTok{"\}"}\NormalTok{),}
      \StringTok{", height = "}\NormalTok{, max_cluster}\OperatorTok{$}\NormalTok{distance, }\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Iteration:  1 , k =  2 , clusters =  {6,3,1} {2,4,5,7} , height =  33.54102 
## Iteration:  2 , k =  3 , clusters =  {6,3,1} {2,4,5} {7} , height =  17.88854 
## Iteration:  3 , k =  4 , clusters =  {1} {2,4,5} {3,6} {7} , height =  11.18034 
## Iteration:  4 , k =  5 , clusters =  {1} {2,4} {3,6} {5} {7} , height =  10.04988 
## Iteration:  5 , k =  6 , clusters =  {1} {2} {3,6} {4} {5} {7} , height =  5.385165 
## Iteration:  6 , k =  7 , clusters =  {1} {2} {3} {4} {5} {6} {7} , height =  5.385165
\end{verbatim}

위 출력 결과에서 \texttt{height}는 해당 iteration에서 분리된 군집의 분리 전 지름(diameter)으로, 함수 \texttt{max\_distance\_cluster}에서 계산한 군집 내 객체간 최대 거리를 나타내며, 이는 R 패키지 \texttt{cluster}의 \texttt{diana} 함수 수행 시 함수값으로 출력되는 \texttt{height}값이다. Iteration이 진행됨에 따라 \texttt{height}의 값이 감소하는 것을 확인할 수 있다.

\hypertarget{hierarchical-cluster-number}{%
\section{군집수의 결정}\label{hierarchical-cluster-number}}

최적의 군집수를 결정하는 객관적인 방법은 존재하지 않는다. 계층적 군집방법에서는 덴드로그램을 참조하여 군집 간의 거리가 급격히 증가하는 계층에서 수평으로 절단하여, 그 이하의 그룹들을 하나의 군집으로 형성하는 방안을 널리 사용하고 있다. 이외에 군집수를 결정하는 데 통계량으로 다음과 같은 통계량들이 부수적으로 사용된다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  새 군집의 RMS 표준편차(root-mean-square standard deviation of the new cluster; RMSSTD)
\end{enumerate}

\begin{equation*}
RMSSTD(C_i, C_j) = \sqrt{\frac{SS(C_i \cup C_j)}{p(|C_i| + |C_j| - 1)}}
\end{equation*}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Semipartial R-squared(SPR)
\end{enumerate}

\begin{equation*}
SPR(C_i, C_j) = \frac{SS(C_i \cup C_j) - (SS(C_i) + SS(C_j))}{SST}
\end{equation*}

where

\begin{equation*}
SST = \sum_{i = 1}^{n} \sum_{j = 1}^{p} \left( x_{ji} - \frac{1}{n} \sum_{a = 1}^{n} x_{ja} \right)^2
\end{equation*}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  R-squared(\(R^2\))
\end{enumerate}

\begin{equation*}
1 - \frac{\sum_{i = 1}^{k} SS(C_i)}{SST}
\end{equation*}

위 \ref{ward-method-algorithm}절에서 워드 군집 알고리즘으로 구현한 군집 과정에 대해 위 통계량을 계산해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train_df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{id =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{8}\NormalTok{),}
  \DataTypeTok{x1 =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{17}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{18}\NormalTok{),}
  \DataTypeTok{x2 =} \KeywordTok{c}\NormalTok{(}\DecValTok{15}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{17}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{6}\NormalTok{)}
\NormalTok{)}

\NormalTok{sst <-}\StringTok{ }\NormalTok{train_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{id) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{sapply}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{sum}\NormalTok{((x }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(x))}\OperatorTok{^}\DecValTok{2}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{sum}\NormalTok{()}

\CommentTok{#단계0}
\NormalTok{init_cluster <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{id =}\NormalTok{ train_df}\OperatorTok{$}\NormalTok{id,}
  \DataTypeTok{cluster =} \KeywordTok{as.character}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\KeywordTok{nrow}\NormalTok{(train_df))}
\NormalTok{)}
\NormalTok{i <-}\StringTok{ }\NormalTok{0L}
\NormalTok{current_clusters <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(init_cluster}\OperatorTok{$}\NormalTok{cluster)}
\NormalTok{k <-}\StringTok{ }\KeywordTok{length}\NormalTok{(current_clusters)}
\NormalTok{ssw <-}\StringTok{ }\KeywordTok{calculate_ssw}\NormalTok{(train_df, init_cluster)}
\NormalTok{old_ssw <-}\StringTok{ }\OtherTok{NA_real_}

\CommentTok{#단계1}
\NormalTok{iteration <-}\StringTok{ }\KeywordTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\DataTypeTok{length =} \KeywordTok{nrow}\NormalTok{(train_df) }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)}
\ControlFlowTok{while}\NormalTok{(k }\OperatorTok{>}\StringTok{ }\DecValTok{1}\NormalTok{) \{}
\NormalTok{  i <-}\StringTok{ }\NormalTok{i }\OperatorTok{+}\StringTok{ }\DecValTok{1}
\NormalTok{  old_ssw <-}\StringTok{ }\NormalTok{ssw}
  
  \ControlFlowTok{if}\NormalTok{(i }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{) \{}
\NormalTok{    old_cluster <-}\StringTok{ }\NormalTok{init_cluster}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    old_cluster <-}\StringTok{ }\NormalTok{iteration[[i}\DecValTok{-1}\NormalTok{]]}\OperatorTok{$}\NormalTok{new_cluster_label}
\NormalTok{  \}}
  
\NormalTok{  iteration[[i]] <-}\StringTok{ }\KeywordTok{best_merge_cluster}\NormalTok{(}
\NormalTok{    train_df,}
\NormalTok{    old_cluster}
\NormalTok{  )}
  
\NormalTok{  merged <-}\StringTok{ }\NormalTok{old_cluster }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{anti_join}\NormalTok{(iteration[[i]]}\OperatorTok{$}\NormalTok{new_cluster_label, }\DataTypeTok{by =} \StringTok{"cluster"}\NormalTok{)}
  
\NormalTok{  current_clusters <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(iteration[[i]]}\OperatorTok{$}\NormalTok{new_cluster_label}\OperatorTok{$}\NormalTok{cluster)}
\NormalTok{  k <-}\StringTok{ }\KeywordTok{length}\NormalTok{(current_clusters)}
\NormalTok{  ssw <-}\StringTok{ }\NormalTok{iteration[[i]]}\OperatorTok{$}\NormalTok{new_ssw}
  
\NormalTok{  iteration[[i]]}\OperatorTok{$}\NormalTok{rmsstd <-}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}
\NormalTok{    merged }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{inner_join}\NormalTok{(train_df, }\DataTypeTok{by =} \StringTok{"id"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{id, }\OperatorTok{-}\NormalTok{cluster) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{sapply}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{sum}\NormalTok{((x }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(x))}\OperatorTok{^}\DecValTok{2}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{sum}\NormalTok{() }\OperatorTok{/}\StringTok{ }\NormalTok{(}\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{(}\KeywordTok{nrow}\NormalTok{(merged) }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{))}
\NormalTok{  )}
  
\NormalTok{  iteration[[i]]}\OperatorTok{$}\NormalTok{iter <-}\StringTok{ }\NormalTok{i}
\NormalTok{  iteration[[i]]}\OperatorTok{$}\NormalTok{merge <-}\StringTok{ }\KeywordTok{paste0}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{unique}\NormalTok{(merged}\OperatorTok{$}\NormalTok{cluster), }\StringTok{"\}"}\NormalTok{, }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{)}
\NormalTok{  iteration[[i]]}\OperatorTok{$}\NormalTok{sol <-}\StringTok{ }\KeywordTok{paste0}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{unique}\NormalTok{(current_clusters), }\StringTok{"\}"}\NormalTok{, }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{)}
\NormalTok{  iteration[[i]]}\OperatorTok{$}\NormalTok{spr <-}\StringTok{ }\NormalTok{(ssw }\OperatorTok{-}\StringTok{ }\NormalTok{old_ssw) }\OperatorTok{/}\StringTok{ }\NormalTok{sst}
\NormalTok{  iteration[[i]]}\OperatorTok{$}\NormalTok{r_sq <-}\StringTok{ }\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{ssw }\OperatorTok{/}\StringTok{ }\NormalTok{sst}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster_statistic <-}\StringTok{ }\KeywordTok{lapply}\NormalTok{(iteration, }\ControlFlowTok{function}\NormalTok{(x) x[}
  \KeywordTok{c}\NormalTok{(}\StringTok{"iter"}\NormalTok{, }\StringTok{"merge"}\NormalTok{, }\StringTok{"sol"}\NormalTok{, }\StringTok{"rmsstd"}\NormalTok{, }\StringTok{"spr"}\NormalTok{, }\StringTok{"r_sq"}\NormalTok{)]) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_rows}\NormalTok{(}
    \KeywordTok{tibble}\NormalTok{(}
      \DataTypeTok{iter =} \DecValTok{0}\NormalTok{,}
      \DataTypeTok{sol =} \KeywordTok{paste0}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{unique}\NormalTok{(init_cluster}\OperatorTok{$}\NormalTok{cluster), }\StringTok{"\}"}\NormalTok{, }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{),}
      \DataTypeTok{r_sq =} \DecValTok{1}
\NormalTok{    )}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(iter)}

\NormalTok{cluster_statistic }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'Iteration'}\NormalTok{, }\StringTok{'통합대상군집'}\NormalTok{, }\StringTok{'통합 후 군집'}\NormalTok{,}
                  \StringTok{'$RMSSTD$'}\NormalTok{, }\StringTok{'$SPR$'}\NormalTok{, }\StringTok{'$R^2$'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'군집 과정에 따른 여러 통계량'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:cluster-statistic}군집 과정에 따른 여러 통계량}
\centering
\begin{tabular}{rllrrr}
\toprule
Iteration & 통합대상군집 & 통합 후 군집 & \$RMSSTD\$ & \$SPR\$ & \$R\textasciicircum{}2\$\\
\midrule
0 & NA & \{1\}, \{2\}, \{3\}, \{4\}, \{5\}, \{6\}, \{7\}, \{8\} & NA & NA & 1.0000000\\
1 & \{2\}, \{7\} & \{1\}, \{2,7\}, \{3\}, \{4\}, \{5\}, \{6\}, \{8\} & 0.7071068 & 0.0020005 & 0.9979995\\
2 & \{1\}, \{3\} & \{1,3\}, \{2,7\}, \{4\}, \{5\}, \{6\}, \{8\} & 1.1180340 & 0.0050013 & 0.9929982\\
3 & \{4\}, \{8\} & \{1,3\}, \{2,7\}, \{4,8\}, \{5\}, \{6\} & 1.1180340 & 0.0050013 & 0.9879970\\
4 & \{2,7\}, \{5\} & \{1,3\}, \{2,7,5\}, \{4,8\}, \{6\} & 2.1602469 & 0.0353422 & 0.9526548\\
\addlinespace
5 & \{1,3\}, \{6\} & \{1,3,6\}, \{2,7,5\}, \{4,8\} & 2.3452079 & 0.0390098 & 0.9136451\\
6 & \{2,7,5\}, \{4,8\} & \{1,3,6\}, \{2,7,5,4,8\} & 3.8470768 & 0.1945153 & 0.7191298\\
7 & \{1,3,6\}, \{2,7,5,4,8\} & \{1,3,6,2,7,5,4,8\} & 5.9753960 & 0.7191298 & 0.0000000\\
\bottomrule
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster_statistic }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{rmsstd =} \KeywordTok{if_else}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(rmsstd), }\DecValTok{0}\NormalTok{, rmsstd),}
    \DataTypeTok{spr =} \KeywordTok{if_else}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(spr), }\DecValTok{0}\NormalTok{, spr)}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ iter)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ rmsstd, }\DataTypeTok{color =} \StringTok{"RMSSTD"}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ spr }\OperatorTok{*}\StringTok{ }\DecValTok{6}\NormalTok{, }\DataTypeTok{color =} \StringTok{"SPR"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ r_sq }\OperatorTok{*}\StringTok{ }\DecValTok{6}\NormalTok{, }\DataTypeTok{color =} \StringTok{"R2"}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{scale_y_continuous}\NormalTok{(}\DataTypeTok{sec.axis =} \KeywordTok{sec_axis}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{. }\OperatorTok{/}\StringTok{ }\DecValTok{6}\NormalTok{, }\DataTypeTok{name =} \StringTok{"SPR, R2"}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ylab}\NormalTok{(}\StringTok{"RMSSTD"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Iteration"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/cluster-statistic-1} 

}

\caption{군집 과정에 따른 통계량 추이}\label{fig:cluster-statistic}
\end{figure}

그림 \ref{fig:cluster-statistic}에서 보듯이 Iteration 6부터 3가지 통계량 모두 급격하게 변화하는 것을 알 수 있다. 따라서 군집수는 Iteration 5까지 3개가 가장 적당하다고 하겠다.

\hypertarget{nonhierarchical-clustering}{%
\chapter{비계층적 군집방법}\label{nonhierarchical-clustering}}

비계층적 군집방법(Nonhierarchical clustering)은 분할방법(Partitioning method)이라고도 하는데, 군집의 수 \(K\)를 사전에 지정하고 대상 객체들을 적절한 군집에 배정하는 방법이다. 즉, 이 방법은 \(n\)개의 객체를 \(K\)개의 군집에 할당하는 최적화 문제로 간주할 수 있다. 본 장에서는 분할방법의 대표적인 K-means 알고리즘, K-medoids 군집방법, 퍼지 K-means 알고리즘, 그리고 모형기반 군집방법에 대하여 주로 알아본다.

\hypertarget{nonhierarchical-clustering-packages-install}{%
\section{필요 R package 설치}\label{nonhierarchical-clustering-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.2.1\\
\hline
stats & 3.6.0\\
\hline
cluster & 2.0.8\\
\hline
flexclust & 1.4-0\\
\hline
mclust & 5.4.3\\
\hline
mvtnorm & 1.0-10\\
\hline
\end{tabular}

\hypertarget{kmeans}{%
\section{K-means 알고리즘}\label{kmeans}}

K-means 알고리즘은 비계층적 군집방법 중 가장 널리 사용되는 것으로 \(K\)개 군집의 중심좌표를 고려하여 각 객체를 가까운 군집에 배정하는 반복적 알고리즘이다.

\hypertarget{kmeans-basic-script}{%
\subsection{기본 R 스크립트}\label{kmeans-basic-script}}

10명에 대한 PC의 사용경력(\(x_1\))과 주당 사용시간(\(x_2\))이 다음과 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{id, }\OperatorTok{~}\NormalTok{x1, }\OperatorTok{~}\NormalTok{x2,}
  \DecValTok{1}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{14}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{13}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{14}\NormalTok{, }\DecValTok{6}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{8}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{7}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{15}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{6}\NormalTok{,}
  \DecValTok{8}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{10}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}
\NormalTok{)}

\NormalTok{df }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}
      \StringTok{'객체번호'}\NormalTok{, }
      \StringTok{'사용경력($x_1$)'}\NormalTok{, }\StringTok{'사용시간($x_2$)'}
\NormalTok{      ),}
    \DataTypeTok{caption =} \StringTok{'PC 사용 데이터'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:kmeans-train-data}PC 사용 데이터}
\centering
\begin{tabular}{rrr}
\toprule
객체번호 & 사용경력(\$x\_1\$) & 사용시간(\$x\_2\$)\\
\midrule
1 & 6 & 14\\
2 & 8 & 13\\
3 & 14 & 6\\
4 & 11 & 8\\
5 & 15 & 7\\
\addlinespace
6 & 7 & 15\\
7 & 13 & 6\\
8 & 5 & 4\\
9 & 3 & 3\\
10 & 3 & 2\\
\bottomrule
\end{tabular}
\end{table}

아래와 같이 \texttt{stats} 패키지의 \texttt{kmeans} 함수를 이용하여 K-means 알고리즘 수행 결과를 얻을 수 있다. 아래 스크립트는 군집 수가 \(K = 3\)라 가정하여 수행한 예이다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{kmeans_solution <-}\StringTok{ }\KeywordTok{kmeans}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{centers =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

위 스크립트 실행 결과 도출된 군집 중심좌표는 위에서 얻어진 \texttt{kmeans} 클래스 객체의 \texttt{centers}값에 저장된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kmeans_solution}\OperatorTok{$}\NormalTok{centers}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          x1    x2
## 1 13.250000  6.75
## 2  3.666667  3.00
## 3  7.000000 14.00
\end{verbatim}

또한 각 학습 데이터가 속한 군집은 \texttt{cluster}값에 저장된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kmeans_solution}\OperatorTok{$}\NormalTok{cluster}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 3 3 1 1 1 3 1 2 2 2
\end{verbatim}

객체의 군집결과는 아래와 같이 도식화하여 보일 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{cluster =} \KeywordTok{as.factor}\NormalTok{(kmeans_solution}\OperatorTok{$}\NormalTok{cluster)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ x1, }\DataTypeTok{y =}\NormalTok{ x2)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_text}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =}\NormalTok{ id, }\DataTypeTok{color =}\NormalTok{ cluster))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/kmeans-cluster-1} 

}

\caption{K-means 수행 결과}\label{fig:kmeans-cluster}
\end{figure}

\hypertarget{kmeans-algorithm}{%
\subsection{알고리즘}\label{kmeans-algorithm}}

K-means 알고리즘의 구체적 절차는 아래와 같다. Table \ref{tab:kmeans-train-data}에 대한 각 단계의 결과를 함께 살펴보자.

\textbf{{[}단계 0{]} (초기 객체 선정)} 어떤 규칙에 의하여 \(K\)개의 객체의 좌표를 초기 군집의 중심좌표(centroid)로 선정한다. 군집 \(j\)의 중심좌표를 \(\mathbf{c}_j = \left(\bar{x}^{(j)}_1, \cdots, \bar{x}^{(j)}_p\right)^\top\)라 하자. 초기 군집 중심좌표 \(\mathbf{c}_1, \cdots, \mathbf{c}_K\)를 선정하는 방법은 예를 들어 다음과 같은 규칙이 사용된다.

\begin{itemize}
\tightlist
\item
  무작위 방법: 대상 객체 중 무작위로 \(K\)개를 선정한다.
\item
  외각 객체 선정: 전체 객체의 중심좌표에서 가장 멀리 위치하는 \(K\)개의 객체를 선정한다.
\end{itemize}

{[}단계 0{]} 무작위 방법을 이용하여 Table \ref{tab:kmeans-train-data}으로부터 3개의 객체를 초기 군집 중심좌표로 선정하자.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}

\NormalTok{init_cluster <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, }\DataTypeTok{k =} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  k <-}\StringTok{ }\KeywordTok{min}\NormalTok{(k, }\KeywordTok{nrow}\NormalTok{(df))}
  
\NormalTok{  df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{sample_n}\NormalTok{(k)}
\NormalTok{\}}

\NormalTok{cluster_df <-}\StringTok{ }\KeywordTok{init_cluster}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], }\DecValTok{3}\NormalTok{)}

\NormalTok{cluster_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##      x1    x2
##   <dbl> <dbl>
## 1    14     6
## 2     3     2
## 3     8    13
\end{verbatim}

\textbf{{[}단계 1{]} (객체의 군집 배정)} 각 객체에 대하여 \(K\)개의 군집 중심좌표(centroid)와의 거리(주로 유클리드 거리 사용)를 산출한 후 가장 가까운 군집에 그 객체를 배정한다.

\begin{equation*}
a_{ij} = \begin{cases}
1 & \text{if } j = \arg\,\max_k d(\mathbf{x}_i, \mathbf{c}_k)\\
0 & \text{otherwise}
\end{cases}, \, i = 1, \cdots, n, \, j = 1, \cdots, K
\end{equation*}

각 객체에 대하여 3개의 군집 중심좌표와의 거리를 산출해보면 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{flexclust}\OperatorTok{::}\KeywordTok{dist2}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], cluster_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            [,1]      [,2]      [,3]
##  [1,] 11.313708 12.369317  2.236068
##  [2,]  9.219544 12.083046  0.000000
##  [3,]  0.000000 11.704700  9.219544
##  [4,]  3.605551 10.000000  5.830952
##  [5,]  1.414214 13.000000  9.219544
##  [6,] 11.401754 13.601471  2.236068
##  [7,]  1.000000 10.770330  8.602325
##  [8,]  9.219544  2.828427  9.486833
##  [9,] 11.401754  1.000000 11.180340
## [10,] 11.704700  0.000000 12.083046
\end{verbatim}

이에 각 객체들에 대해 거리가 가장 가까운 군집에 그 객체를 배정한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{assign_cluster <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, cluster_df) \{}
\NormalTok{  cluster_ind <-}\StringTok{ }\NormalTok{flexclust}\OperatorTok{::}\KeywordTok{dist2}\NormalTok{(df, cluster_df) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{apply}\NormalTok{(}\DecValTok{1}\NormalTok{, which.min)}
  
  \KeywordTok{map}\NormalTok{(}\KeywordTok{unique}\NormalTok{(cluster_ind), }\OperatorTok{~}\KeywordTok{which}\NormalTok{(cluster_ind }\OperatorTok{==}\StringTok{ }\NormalTok{.))}
\NormalTok{\}}

\NormalTok{cluster_objects <-}\StringTok{ }\KeywordTok{assign_cluster}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], cluster_df)}

\NormalTok{cluster_objects}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] 1 2 6
## 
## [[2]]
## [1] 3 4 5 7
## 
## [[3]]
## [1]  8  9 10
\end{verbatim}

\textbf{{[}단계 2{]} (군집 중심좌표의 산출)} 새로운 군집에 대한 중심좌표를 산출한다.

\begin{equation*}
\bar{x}^{(j)}_l = \frac{\sum_{i} a_{ij} x_{li}}{\sum_{i} a_{ij}}, \, l = 1, \cdots, p, \, j = 1, \cdots, K
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{find_center <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, cluster) \{}
  \KeywordTok{map_dfr}\NormalTok{(cluster, }\OperatorTok{~}\NormalTok{df[., ] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{summarize_all}\NormalTok{(mean)) }
\NormalTok{\}}

\NormalTok{new_cluster_df <-}\StringTok{ }\KeywordTok{find_center}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], cluster_objects)}

\NormalTok{new_cluster_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##      x1    x2
##   <dbl> <dbl>
## 1  7    14   
## 2 13.2   6.75
## 3  3.67  3
\end{verbatim}

\textbf{{[}단계 3{]} (수렴 조건 점검)} 새로 산출된 중심좌표값과 이전 좌표값을 비교하여 수렴 조건 내에 들면 마치며, 그렇지 않으면 단계 1을 반복한다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{identical}\NormalTok{(cluster_df, new_cluster_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

위의 경우, 군집 중심좌표가 다르므로 다음 iteration을 진행한다.

\hypertarget{kmeans-user-defined-functions}{%
\subsection{R 스크립트 구현}\label{kmeans-user-defined-functions}}

위의 과정을 군집해가 수렴할 때까지 반복하도록 아래와 같이 R 스크립트를 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{init_cluster <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, }\DataTypeTok{k =} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  k <-}\StringTok{ }\KeywordTok{min}\NormalTok{(k, }\KeywordTok{nrow}\NormalTok{(df))}
  
\NormalTok{  df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{sample_n}\NormalTok{(k)}
\NormalTok{\}}

\NormalTok{assign_cluster <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, cluster_df) \{}
\NormalTok{  cluster_ind <-}\StringTok{ }\NormalTok{flexclust}\OperatorTok{::}\KeywordTok{dist2}\NormalTok{(df, cluster_df) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{apply}\NormalTok{(}\DecValTok{1}\NormalTok{, which.min)}
  
  \KeywordTok{map}\NormalTok{(}\KeywordTok{unique}\NormalTok{(cluster_ind), }\OperatorTok{~}\KeywordTok{which}\NormalTok{(cluster_ind }\OperatorTok{==}\StringTok{ }\NormalTok{.))}
\NormalTok{\}}

\NormalTok{find_center <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, cluster) \{}
  \KeywordTok{map_dfr}\NormalTok{(cluster, }\OperatorTok{~}\NormalTok{df[., ] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{summarize_all}\NormalTok{(mean)) }
\NormalTok{\}}

\NormalTok{kmeans_cluster <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, }\DataTypeTok{k =} \DecValTok{1}\NormalTok{, }\DataTypeTok{verbose =} \OtherTok{FALSE}\NormalTok{) \{}
\NormalTok{  k <-}\StringTok{ }\KeywordTok{min}\NormalTok{(k, }\KeywordTok{nrow}\NormalTok{(df))}
  
\NormalTok{  i <-}\StringTok{ }\NormalTok{0L}
  
  \CommentTok{## 단계 0}
\NormalTok{  cluster_df <-}\StringTok{ }\KeywordTok{init_cluster}\NormalTok{(df, k)}
  
  \ControlFlowTok{while}\NormalTok{(}\OtherTok{TRUE}\NormalTok{) \{}
\NormalTok{    i <-}\StringTok{ }\NormalTok{i }\OperatorTok{+}\StringTok{ }\NormalTok{1L}
    
    \CommentTok{## 단계 1}
\NormalTok{    cluster_objects <-}\StringTok{ }\KeywordTok{assign_cluster}\NormalTok{(df, cluster_df)}
    \ControlFlowTok{if}\NormalTok{ (verbose) \{ }\CommentTok{# 군집해 출력}
      \KeywordTok{cat}\NormalTok{(}\StringTok{"Iteration"}\NormalTok{, i, }\StringTok{":"}\NormalTok{, }
          \KeywordTok{map}\NormalTok{(cluster_objects, }\OperatorTok{~}\StringTok{ }\KeywordTok{str_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{str_c}\NormalTok{(., }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{            }\KeywordTok{str_c}\NormalTok{(}\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{),}
          \StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}
\NormalTok{      )}
\NormalTok{    \}}
    
    \CommentTok{## 단계 2}
\NormalTok{    new_cluster_df <-}\StringTok{ }\KeywordTok{find_center}\NormalTok{(df, cluster_objects)}

    \CommentTok{## 단계 3}
    \ControlFlowTok{if}\NormalTok{(}\KeywordTok{identical}\NormalTok{(cluster_df, new_cluster_df)) }\ControlFlowTok{break}
    
\NormalTok{    cluster_df <-}\StringTok{ }\NormalTok{new_cluster_df}
\NormalTok{  \}}
  
\NormalTok{  res <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}
    \DataTypeTok{cluster_centers =}\NormalTok{ cluster_df,}
    \DataTypeTok{assgined_objects =}\NormalTok{ cluster_objects,}
    \DataTypeTok{n_iteration =}\NormalTok{ i}
\NormalTok{  )}
  
  \KeywordTok{return}\NormalTok{ (res)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}

\NormalTok{kmeans_solution <-}\StringTok{ }\KeywordTok{kmeans_cluster}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{k =} \DecValTok{3}\NormalTok{, }\DataTypeTok{verbose =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Iteration 1 : {1, 2, 6}, {3, 4, 5, 7}, {8, 9, 10} 
## Iteration 2 : {1, 2, 6}, {3, 4, 5, 7}, {8, 9, 10}
\end{verbatim}

위와 같이 2번째 Iteration에서 군집해가 수렴하였으며, 최종 군집해는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kmeans_solution}\OperatorTok{$}\NormalTok{assgined_objects}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] 1 2 6
## 
## [[2]]
## [1] 3 4 5 7
## 
## [[3]]
## [1]  8  9 10
\end{verbatim}

\hypertarget{kmedoids}{%
\section{K-medoids 군집방법}\label{kmedoids}}

K-means 알고리즘에서는 각 군집의 중심좌표(centroid)를 군집 중심으로 고려하고 있는 반면, K-medoids 군집방법에서는 각 군집의 대표객체를 군집 중심으로 고려한다.

K-medoids 군집방법의 알고리즘으로 잘 알려진 것에는 다음과 같은 것들이 있다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  PAM(Partitioning Around Medoids)
\item
  CLARA(Clustering LARge Applications)
\item
  CLARANS(Clustering Large Applications based on RANdomized Search)
\item
  K-means-like 알고리즘
\end{enumerate}

\hypertarget{pam}{%
\subsection{PAM 알고리즘}\label{pam}}

PAM 알고리즘은 \citet{kaufman1990finding} 에 의하여 발표된 것으로, 초기 대표객체를 선정하는 방법인 \textbf{BUILD}와 더 나은 군집해를 찾아나가는 과정인 \textbf{SWAP}의 두 부분으로 구성되어 있다.

\hypertarget{pam-basic-script}{%
\subsubsection{기본 R 스크립트}\label{pam-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{id, }\OperatorTok{~}\NormalTok{x1, }\OperatorTok{~}\NormalTok{x2,}
  \DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{8}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{6}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{14}\NormalTok{, }\DecValTok{6}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{7}
\NormalTok{)}

\NormalTok{df }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}
      \StringTok{'객체번호'}\NormalTok{, }
      \StringTok{'사용경력($x_1$)'}\NormalTok{, }\StringTok{'사용시간($x_2$)'}
\NormalTok{      ),}
    \DataTypeTok{caption =} \StringTok{'PC 사용자 데이터'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:pam-train-data}PC 사용자 데이터}
\centering
\begin{tabular}{rrr}
\toprule
객체번호 & 사용경력(\$x\_1\$) & 사용시간(\$x\_2\$)\\
\midrule
1 & 3 & 3\\
2 & 5 & 4\\
3 & 11 & 8\\
4 & 13 & 6\\
5 & 14 & 6\\
\addlinespace
6 & 15 & 7\\
\bottomrule
\end{tabular}
\end{table}

PAM 알고리즘은 \texttt{cluster} 패키지 내의 함수 \texttt{pam}을 이용하여 아래와 같이 간단하게 실행할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pam_solution <-}\StringTok{ }\NormalTok{cluster}\OperatorTok{::}\KeywordTok{pam}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{k =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

얻어진 \texttt{pam} 객체의 원소 \texttt{id.med}는 몇 번째 객체가 군집의 대표객체로 선정되었는지를 나타낸다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pam_solution}\OperatorTok{$}\NormalTok{id.med}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2 5
\end{verbatim}

또한 \texttt{pam} 객체의 원소 \texttt{clustering}은 각 객체가 어떠한 군집에 할당되었는지를 보여준다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pam_solution}\OperatorTok{$}\NormalTok{clustering}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 1 2 2 2 2
\end{verbatim}

\hypertarget{pam-algorithm}{%
\subsubsection{PAM 알고리즘}\label{pam-algorithm}}

PAM 알고리즘의 각 단계를 Table \ref{tab:pam-train-data}의 예제 데이터에 적용하여 살펴보기로 하자.

\hypertarget{pam-build}{%
\paragraph{BUILD}\label{pam-build}}

BUILD는 다음 절차들을 거쳐서 \(K\)개의 초기 대표객체를 구하는 과정이다.

\textbf{{[}단계 0{]}} 우선 각 객체별로 다른 객체 간의 거리를 구한 후, 그 합이 가장 작은 객체 하나를 대표객체로 선정한다. 선정된 대표객체집합을 \(M\)이라 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pairwise_distance_df <-}\StringTok{ }\KeywordTok{dist}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{upper =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{()}

\NormalTok{M_idx <-}\StringTok{ }\NormalTok{pairwise_distance_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{sum_distance =} \KeywordTok{sum}\NormalTok{(distance)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{top_n}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, sum_distance) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{.}\OperatorTok{$}\NormalTok{item1}

\NormalTok{M <-}\StringTok{ }\NormalTok{df[M_idx, ]}

\NormalTok{M}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
##      id    x1    x2
##   <dbl> <dbl> <dbl>
## 1     4    13     6
\end{verbatim}

\textbf{{[}단계 1{]}} 대표객체로 선정되지 않은 객체 \(j\)에 대하여, 이전에 대표객체로 선정된 객체들 중 객체 \(j\)에 가장 가까운 거리 \(D_j\)를 구한다. 즉,

\begin{equation*}
D_j = \min_{k \in M} d(j, k), \, j \notin M
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{D_j <-}\StringTok{ }\NormalTok{pairwise_distance_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}
    \OperatorTok{!}\NormalTok{item1 }\OperatorTok{%in%}\StringTok{ }\NormalTok{M}\OperatorTok{$}\NormalTok{id,}
\NormalTok{    item2 }\OperatorTok{%in%}\StringTok{ }\NormalTok{M}\OperatorTok{$}\NormalTok{id}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{top_n}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, distance) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{D_j =}\NormalTok{ distance) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{item2)}

\NormalTok{D_j}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 2
##   item1   D_j
##   <int> <dbl>
## 1     1 10.4 
## 2     2  8.25
## 3     3  2.83
## 4     5  1   
## 5     6  2.24
\end{verbatim}

그리고 대표객체로 선정되지 않은 두 객체 \(i\), \(j\)에 대하여 다음을 산출한다.

\begin{equation*}
C_{ji} = \max \left(D_j - d(j, i), 0\right)
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d_ji <-}\StringTok{ }\NormalTok{pairwise_distance_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}
    \OperatorTok{!}\NormalTok{item1 }\OperatorTok{%in%}\StringTok{ }\NormalTok{M}\OperatorTok{$}\NormalTok{id,}
    \OperatorTok{!}\NormalTok{item2 }\OperatorTok{%in%}\StringTok{ }\NormalTok{M}\OperatorTok{$}\NormalTok{id}
\NormalTok{  )}

\NormalTok{C_ji <-}\StringTok{ }\NormalTok{D_j }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(d_ji, }\DataTypeTok{by =} \StringTok{"item1"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{C_ji =} \KeywordTok{pmax}\NormalTok{(D_j }\OperatorTok{-}\StringTok{ }\NormalTok{distance, }\DecValTok{0}\NormalTok{))}

\NormalTok{C_ji}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 20 x 5
##    item1   D_j item2 distance  C_ji
##    <int> <dbl> <int>    <dbl> <dbl>
##  1     1 10.4      2     2.24 8.20 
##  2     1 10.4      3     9.43 1.01 
##  3     1 10.4      5    11.4  0    
##  4     1 10.4      6    12.6  0    
##  5     2  8.25     1     2.24 6.01 
##  6     2  8.25     3     7.21 1.04 
##  7     2  8.25     5     9.22 0    
##  8     2  8.25     6    10.4  0    
##  9     3  2.83     1     9.43 0    
## 10     3  2.83     2     7.21 0    
## 11     3  2.83     5     3.61 0    
## 12     3  2.83     6     4.12 0    
## 13     5  1        1    11.4  0    
## 14     5  1        2     9.22 0    
## 15     5  1        3     3.61 0    
## 16     5  1        6     1.41 0    
## 17     6  2.24     1    12.6  0    
## 18     6  2.24     2    10.4  0    
## 19     6  2.24     3     4.12 0    
## 20     6  2.24     5     1.41 0.822
\end{verbatim}

이는 객체 \(i\)가 추가로 대표객체가 된다고 할 때, 객체 \(j\)의 입장에서 거리 감소량이다.

\textbf{{[}단계 2{]}} 다음과 같이 거리감소량이 가장 큰 객체 \(m\)을 대표객체에 포함시키고,

\begin{equation*}
m = \arg\,\max_{i \notin M} \sum_{j \notin M} C_{ji}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m <-}\StringTok{ }\NormalTok{C_ji }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(item2) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{sum_C_ji =} \KeywordTok{sum}\NormalTok{(C_ji)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{top_n}\NormalTok{(}\DecValTok{1}\NormalTok{, sum_C_ji) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{.}\OperatorTok{$}\NormalTok{item2}

\NormalTok{m}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2
\end{verbatim}

대표객체집합을 수정한다.

\begin{equation*}
M \leftarrow M \cup \{m\}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M <-}\StringTok{ }\NormalTok{M }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_rows}\NormalTok{(df[m, ])}
\end{Highlighting}
\end{Shaded}

\textbf{{[}단계 3{]}} \(K\)개의 대표객체가 선정되었으면 Stop, 그렇지 않은 경우에는 {[}단계 1{]}로 되돌아간다.

\hypertarget{pam-swap}{%
\paragraph{SWAP}\label{pam-swap}}

SWAP은 대표객체로 선정되어 있는 객체 \(i\)와 선정되지 않은 객체 \(h\)를 교환할 때 목적함수의 변화량을 산출해 더 나은 목적함수값을 찾아가는 과정이다.

\textbf{{[}단계 1{]}} 객체 \(i\)와 객체 \(h\)를 교환할 때 목적함수의 변화량을 산출하기 위하여 우선, 대표객체로 선정되지 않은 임의의 객체 \(j \neq h\)에서의 변화량을 다음과 같이 산출한다.

\begin{eqnarray*}
C_{jih} &=& \text{($i$와 $h$를 교환 후 객체 $j$와 대표객체와의 거리)}\\
 & & - \text{(교환 전 객체 $j$와 대표객체와의 거리)},\\
 & & \, (j \notin M, i \in M, h \notin M)
\end{eqnarray*}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 교환 전 각 객체와 대표 객체와의 거리}
\NormalTok{D_j <-}\StringTok{ }\NormalTok{pairwise_distance_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(}
    \OperatorTok{!}\NormalTok{item1 }\OperatorTok{%in%}\StringTok{ }\NormalTok{M}\OperatorTok{$}\NormalTok{id,}
\NormalTok{    item2 }\OperatorTok{%in%}\StringTok{ }\NormalTok{M}\OperatorTok{$}\NormalTok{id}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{top_n}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, distance) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{j =}\NormalTok{ item1) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{item2)}

\NormalTok{D_j}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 2
##       j distance
##   <int>    <dbl>
## 1     1     2.24
## 2     3     2.83
## 3     5     1   
## 4     6     2.24
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 교환할 객체}
\NormalTok{swap_ids <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{i =} \KeywordTok{rep}\NormalTok{(M}\OperatorTok{$}\NormalTok{id, }\DataTypeTok{each =} \KeywordTok{nrow}\NormalTok{(df) }\OperatorTok{-}\StringTok{ }\KeywordTok{nrow}\NormalTok{(M)),}
  \DataTypeTok{h =} \KeywordTok{rep}\NormalTok{(}\KeywordTok{setdiff}\NormalTok{(df}\OperatorTok{$}\NormalTok{id, M}\OperatorTok{$}\NormalTok{id), }\KeywordTok{nrow}\NormalTok{(M))}
\NormalTok{)}

\CommentTok{# 교환 후 각 객체와 대표 객체와의 거리}
\NormalTok{update_distance <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(i, h, distance_df, center_ids) \{}
\NormalTok{  new_center_ids <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\KeywordTok{setdiff}\NormalTok{(center_ids, i), h)}

\NormalTok{  res <-}\StringTok{ }\NormalTok{distance_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(}
      \OperatorTok{!}\NormalTok{item1 }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(center_ids, h),}
\NormalTok{      item2 }\OperatorTok{%in%}\StringTok{ }\NormalTok{new_center_ids}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{top_n}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, distance) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{j =}\NormalTok{ item1) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{item2) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}
      \DataTypeTok{i =}\NormalTok{ i,}
      \DataTypeTok{h =}\NormalTok{ h}
\NormalTok{    )}
  
  \KeywordTok{return}\NormalTok{(res)}
\NormalTok{\}}

\NormalTok{D_jih <-}\StringTok{ }\KeywordTok{pmap_dfr}\NormalTok{(}
\NormalTok{  swap_ids, }
\NormalTok{  update_distance,}
  \DataTypeTok{distance_df =}\NormalTok{ pairwise_distance_df,}
  \DataTypeTok{center_ids =}\NormalTok{ M}\OperatorTok{$}\NormalTok{id}
\NormalTok{  )}

\NormalTok{D_jih}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 24 x 4
##        j distance     i     h
##    <int>    <dbl> <dbl> <dbl>
##  1     3     7.21     4     1
##  2     5     9.22     4     1
##  3     6    10.4      4     1
##  4     1     2.24     4     3
##  5     5     3.61     4     3
##  6     6     4.12     4     3
##  7     1     2.24     4     5
##  8     3     3.61     4     5
##  9     6     1.41     4     5
## 10     1     2.24     4     6
## # ... with 14 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 거리의 변화량}
\NormalTok{C_jih <-}\StringTok{ }\NormalTok{D_j }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(D_jih, }\DataTypeTok{by =} \StringTok{"j"}\NormalTok{, }\DataTypeTok{suffix =} \KeywordTok{c}\NormalTok{(}\StringTok{""}\NormalTok{, }\StringTok{"_new"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{diff_distance =}\NormalTok{ distance_new }\OperatorTok{-}\StringTok{ }\NormalTok{distance)}

\NormalTok{C_jih}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 24 x 6
##        j distance distance_new     i     h diff_distance
##    <int>    <dbl>        <dbl> <dbl> <dbl>         <dbl>
##  1     1     2.24         2.24     4     3         0    
##  2     1     2.24         2.24     4     5         0    
##  3     1     2.24         2.24     4     6         0    
##  4     1     2.24         9.43     2     3         7.20 
##  5     1     2.24        10.4      2     5         8.20 
##  6     1     2.24        10.4      2     6         8.20 
##  7     3     2.83         7.21     4     1         4.38 
##  8     3     2.83         3.61     4     5         0.777
##  9     3     2.83         4.12     4     6         1.29 
## 10     3     2.83         2.83     2     1         0    
## # ... with 14 more rows
\end{verbatim}

\textbf{{[}단계 2{]}} 대표객체 \(i\)를 \(h\)로 교환하는 경우 총 변화량은 다음과 같다.

\begin{equation*}
T_{ih} = \sum_{j} C_{jih}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{T_ih <-}\StringTok{ }\NormalTok{C_jih }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(i, h) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{total_diff_distance =} \KeywordTok{sum}\NormalTok{(diff_distance))}

\NormalTok{T_ih}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 8 x 3
## # Groups:   i [2]
##       i     h total_diff_distance
##   <dbl> <dbl>               <dbl>
## 1     2     1              0     
## 2     2     3              7.20  
## 3     2     5              7.38  
## 4     2     6              8.20  
## 5     4     1             20.8   
## 6     4     3              4.49  
## 7     4     5             -0.0447
## 8     4     6              1.71
\end{verbatim}

이 때 \(\min_{i, h} T_{ih}\)에 대응하는 객체 \(i^*\)와 \(h^*\)를 찾아 \(T_{i^*h^*} < 0\)이면 교환한 후에 다시 {[}단계 1{]}으로 돌아가고, \(T_{i^*h^*} \geq 0\)이면 교환하지 않고 stop.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{swap_ih <-}\StringTok{ }\NormalTok{T_ih }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(total_diff_distance }\OperatorTok{<}\StringTok{ }\DecValTok{0}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{top_n}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, total_diff_distance)}

\NormalTok{swap_ih}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
## # Groups:   i [1]
##       i     h total_diff_distance
##   <dbl> <dbl>               <dbl>
## 1     4     5             -0.0447
\end{verbatim}

본 예제의 경우 객체 4 대신 객체 5가 새로운 대표객체로 선택되고, 다시 {[}단계 1{]}로 넘어간다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M <-}\StringTok{ }\NormalTok{M }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{anti_join}\NormalTok{(df[swap_ih}\OperatorTok{$}\NormalTok{i, ]) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_rows}\NormalTok{(df[swap_ih}\OperatorTok{$}\NormalTok{h, ])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining, by = c("id", "x1", "x2")
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 3
##      id    x1    x2
##   <dbl> <dbl> <dbl>
## 1     2     5     4
## 2     5    14     6
\end{verbatim}

SWAP 과정이 종료된 후, 최종 군집해는 각 객체를 가장 가까운 대표객체가 속한 군집에 할당함으로써 얻어진다.

\hypertarget{pam-user-defined-functions}{%
\subsubsection{R 스크립트 구현}\label{pam-user-defined-functions}}

일련의 과정을 함수로 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 각 객체로부터 가장 가까운 대표객체까지의 거리}
\NormalTok{distance_from_medoids <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(distance_df, medoids_ids) \{}
\NormalTok{  distance_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(}
      \OperatorTok{!}\NormalTok{item1 }\OperatorTok{%in%}\StringTok{ }\NormalTok{medoids_ids,}
\NormalTok{      item2 }\OperatorTok{%in%}\StringTok{ }\NormalTok{medoids_ids}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{arrange}\NormalTok{(distance) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{j =}\NormalTok{ item1) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{item2)}
\NormalTok{\}}

\CommentTok{# k개의 초기 대표객체를 선정}
\NormalTok{build_medoids <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(distance_df, }\DataTypeTok{k =}\NormalTok{ 1L) \{}
\NormalTok{  k  <-}\StringTok{ }\KeywordTok{min}\NormalTok{(k, }\KeywordTok{length}\NormalTok{(}\KeywordTok{unique}\NormalTok{(distance_df}\OperatorTok{$}\NormalTok{item1)))}

  \CommentTok{# 첫 번째 대표객체 선정}
\NormalTok{  medoids_ids <-}\StringTok{ }\NormalTok{distance_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{sum_distance =} \KeywordTok{sum}\NormalTok{(distance)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{arrange}\NormalTok{(sum_distance) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\NormalTok{.}\OperatorTok{$}\NormalTok{item1}
  
  \ControlFlowTok{while}\NormalTok{ (}\KeywordTok{length}\NormalTok{(medoids_ids) }\OperatorTok{<}\StringTok{ }\NormalTok{k) \{}
\NormalTok{    D_j <-}\StringTok{ }\KeywordTok{distance_from_medoids}\NormalTok{(distance_df, medoids_ids)}

\NormalTok{    d_ji <-}\StringTok{ }\NormalTok{distance_df }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{filter}\NormalTok{(}
        \OperatorTok{!}\NormalTok{item1 }\OperatorTok{%in%}\StringTok{ }\NormalTok{medoids_ids,}
        \OperatorTok{!}\NormalTok{item2 }\OperatorTok{%in%}\StringTok{ }\NormalTok{medoids_ids}
\NormalTok{      ) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{j =}\NormalTok{ item1, }\DataTypeTok{i =}\NormalTok{ item2)}

    \CommentTok{# 거리 감소량}
\NormalTok{    C_ji <-}\StringTok{ }\NormalTok{D_j }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{inner_join}\NormalTok{(d_ji, }\DataTypeTok{by =} \StringTok{"j"}\NormalTok{,}
                 \DataTypeTok{suffix =} \KeywordTok{c}\NormalTok{(}\StringTok{""}\NormalTok{, }\StringTok{"_new"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{diff_distance =} \KeywordTok{pmax}\NormalTok{(distance }\OperatorTok{-}\StringTok{ }\NormalTok{distance_new, }\DecValTok{0}\NormalTok{))}
    
    \CommentTok{# 거리 감소량이 가장 큰 객체 선택}
\NormalTok{    m <-}\StringTok{ }\NormalTok{C_ji }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{group_by}\NormalTok{(i) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{total_diff_distance =} \KeywordTok{sum}\NormalTok{(diff_distance)) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(total_diff_distance)) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{      }\NormalTok{.}\OperatorTok{$}\NormalTok{i}
    
    \CommentTok{# 대표객체에 추가}
\NormalTok{    medoids_ids <-}\StringTok{ }\KeywordTok{c}\NormalTok{(medoids_ids, m)}
\NormalTok{  \}}
  
  \KeywordTok{return}\NormalTok{(medoids_ids)}
\NormalTok{\}}

\CommentTok{# 교환 후 각 객체와 대표 객체와의 거리}
\NormalTok{update_distance <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(i, h, distance_df, medoids_ids) \{}
\NormalTok{  new_medoids_ids <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\KeywordTok{setdiff}\NormalTok{(medoids_ids, i), h)}

\NormalTok{  res <-}\StringTok{ }\KeywordTok{distance_from_medoids}\NormalTok{(distance_df, new_medoids_ids) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(j }\OperatorTok{!=}\StringTok{ }\NormalTok{h) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}
      \DataTypeTok{i =}\NormalTok{ i,}
      \DataTypeTok{h =}\NormalTok{ h}
\NormalTok{    )}

  \KeywordTok{return}\NormalTok{(res)}
\NormalTok{\}}

\CommentTok{# 교환할 medoid 선택}
\NormalTok{swap_medoids <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(distance_df, medoids_ids) \{}
\NormalTok{  observation_ids <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(distance_df}\OperatorTok{$}\NormalTok{item1)}
  
  \CommentTok{# 교환 전 각 객체와 대표 객체와의 거리}
\NormalTok{  D_j <-}\StringTok{ }\KeywordTok{distance_from_medoids}\NormalTok{(distance_df, medoids_ids)}
  
  \CommentTok{# 교환할 객체}
\NormalTok{  swap_ids <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
    \DataTypeTok{i =} \KeywordTok{rep}\NormalTok{(medoids_ids, }
            \DataTypeTok{each =} \KeywordTok{length}\NormalTok{(observation_ids) }\OperatorTok{-}\StringTok{ }\KeywordTok{length}\NormalTok{(medoids_ids)),}
    \DataTypeTok{h =} \KeywordTok{rep}\NormalTok{(}\KeywordTok{setdiff}\NormalTok{(observation_ids, medoids_ids), }
            \KeywordTok{length}\NormalTok{(medoids_ids))}
\NormalTok{  )}
  
\NormalTok{  D_jih <-}\StringTok{ }\KeywordTok{pmap_dfr}\NormalTok{(}
\NormalTok{    swap_ids, }
\NormalTok{    update_distance,}
    \DataTypeTok{distance_df =}\NormalTok{ distance_df,}
    \DataTypeTok{medoids_ids =}\NormalTok{ medoids_ids}
\NormalTok{  )}
  
  \CommentTok{# 거리의 변화량}
\NormalTok{  C_jih <-}\StringTok{ }\NormalTok{D_j }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{inner_join}\NormalTok{(D_jih, }\DataTypeTok{by =} \StringTok{"j"}\NormalTok{, }\DataTypeTok{suffix =} \KeywordTok{c}\NormalTok{(}\StringTok{""}\NormalTok{, }\StringTok{"_new"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{diff_distance =}\NormalTok{ distance_new }\OperatorTok{-}\StringTok{ }\NormalTok{distance)}
  
\NormalTok{  T_ih <-}\StringTok{ }\NormalTok{C_jih }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(i, h) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{total_diff_distance =} \KeywordTok{sum}\NormalTok{(diff_distance))}
  
\NormalTok{  swap_ih <-}\StringTok{ }\NormalTok{T_ih }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(total_diff_distance }\OperatorTok{<}\StringTok{ }\DecValTok{0}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{arrange}\NormalTok{(total_diff_distance) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{)}
  
  \KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{remove =}\NormalTok{ swap_ih}\OperatorTok{$}\NormalTok{i, }\DataTypeTok{add =}\NormalTok{ swap_ih}\OperatorTok{$}\NormalTok{h))}
\NormalTok{\}}

\CommentTok{# 전체 PAM 알고리즘}
\NormalTok{pam_medoids <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(distance_df, }\DataTypeTok{k =}\NormalTok{ 1L) \{}
  \CommentTok{# BUILD}
\NormalTok{  medoids_ids <-}\StringTok{ }\KeywordTok{build_medoids}\NormalTok{(distance_df, k)}
\NormalTok{  k <-}\StringTok{ }\KeywordTok{length}\NormalTok{(medoids_ids)}
  
  \CommentTok{# SWAP}
  \ControlFlowTok{while}\NormalTok{ (}\OtherTok{TRUE}\NormalTok{) \{}
\NormalTok{    swap_medoids <-}\StringTok{ }\KeywordTok{swap_medoids}\NormalTok{(distance_df, medoids_ids)}
    \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is_empty}\NormalTok{(swap_medoids}\OperatorTok{$}\NormalTok{remove)) \{}
      \ControlFlowTok{break}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{      medoids_ids <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}
        \KeywordTok{setdiff}\NormalTok{(medoids_ids, swap_medoids}\OperatorTok{$}\NormalTok{remove),}
\NormalTok{        swap_medoids}\OperatorTok{$}\NormalTok{add}
\NormalTok{      )}
\NormalTok{    \}}
\NormalTok{  \}}
  
  \KeywordTok{return}\NormalTok{ (medoids_ids)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 구현한 함수를 이용하여 아래와 같이 PAM을 실행해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pairwise_distance_df <-}\StringTok{ }\KeywordTok{dist}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{upper =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{()}

\NormalTok{medoids_ids <-}\StringTok{ }\KeywordTok{pam_medoids}\NormalTok{(pairwise_distance_df, }\DataTypeTok{k =} \DecValTok{2}\NormalTok{)}

\NormalTok{df[medoids_ids, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 3
##      id    x1    x2
##   <dbl> <dbl> <dbl>
## 1     2     5     4
## 2     5    14     6
\end{verbatim}

위와 같이 2개의 대표객체 2, 5가 선정된다.

최종 군집해는 각 객체를 가장 가까운 대표객체가 속한 군집에 할당함으로써 얻어진다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{assign_cluster <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(distance_df, medoids_ids) \{}
\NormalTok{  distance_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(}
      \OperatorTok{!}\NormalTok{item1 }\OperatorTok{%in%}\StringTok{ }\NormalTok{medoids_ids,}
\NormalTok{      item2 }\OperatorTok{%in%}\StringTok{ }\NormalTok{medoids_ids}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{arrange}\NormalTok{(distance) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{bind_rows}\NormalTok{(}
      \KeywordTok{tibble}\NormalTok{(}
        \DataTypeTok{item1 =}\NormalTok{ medoids_ids,}
        \DataTypeTok{item2 =}\NormalTok{ medoids_ids,}
        \DataTypeTok{distance =} \DecValTok{0}
\NormalTok{      )}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ item1) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{arrange}\NormalTok{(object) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(item2) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{cluster =} \KeywordTok{str_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{str_c}\NormalTok{(object, }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{item2)}
\NormalTok{\}}

\KeywordTok{assign_cluster}\NormalTok{(pairwise_distance_df, medoids_ids)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   object distance cluster     
##    <int>    <dbl> <chr>       
## 1      1     2.24 {1, 2}      
## 2      2     0    {1, 2}      
## 3      3     3.61 {3, 4, 5, 6}
## 4      4     1    {3, 4, 5, 6}
## 5      5     0    {3, 4, 5, 6}
## 6      6     1.41 {3, 4, 5, 6}
\end{verbatim}

\hypertarget{clara}{%
\subsection{CLARA 알고리즘}\label{clara}}

PAM 알고리즘은 SWAP 부분에서 모든 가능한 경우를 고려하기 때문에, 전체 객체 수가 많은 경우 계산 시간이 매우 길다는 단점이 있다. 이를 보완하기 위해 CLARA는 적절한 수의 객체를 샘플링한 후 이들에 대해 PAM 알고리즘을 적용하여 중심객체를 선정하는 방법이다. 이러한 샘플링을 여러 번 한 후, 이 중 가장 좋은 결과를 택하는 것인데, 반복수는 5번으로 충분한 것으로 분석되고 있다.

자세한 내용은 교재 \citep{jun2012datamining} 참조

\hypertarget{clara-basic-script}{%
\subsubsection{기본 R 스크립트}\label{clara-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clara_solution <-}\StringTok{ }\NormalTok{cluster}\OperatorTok{::}\KeywordTok{clara}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{k =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

얻어진 \texttt{clara} 객체의 원소 \texttt{i.med}는 몇 번째 객체가 군집의 대표객체로 선정되었는지를 나타낸다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clara_solution}\OperatorTok{$}\NormalTok{i.med}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2 5
\end{verbatim}

또한 \texttt{clara} 객체의 원소 \texttt{clustering}은 각 객체가 어떠한 군집에 할당되었는지를 보여준다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clara_solution}\OperatorTok{$}\NormalTok{clustering}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 1 2 2 2 2
\end{verbatim}

\hypertarget{clarans}{%
\subsection{CLARANS 알고리즘}\label{clarans}}

교재 \citep{jun2012datamining} 참조

\hypertarget{kmeans-like}{%
\subsection{K-means-like 알고리즘}\label{kmeans-like}}

본 알고리즘은 PAM 알고리즘의 단점을 보완하고자 \citet{park2009simple} 에 의해 제안된 것으로, 대표객체를 반복적으로 수정하는데 K-means 알고리즘의 작동 원리를 모방한 K-medoids 군집 방법이다. 따라서 간단하며 계산 시간이 빠른 것이 장점이라 하겠다. 이 알고리즘은 다음과 같이 3단계로 구성되어 있다. 알고리즘의 각 단계를 Table \ref{tab:pam-train-data}의 예제 데이터에 적용하여 살펴보기로 하자.

\textbf{{[}단계 1{]}} (초기 대표객체 선정) \(K\)개의 초기 대표객체를 선정하며, 각 객체를 가장 가까운 대표객체에 배정하여 초기 군집해를 얻는다.

객체들 간의 거리 \(d(i, j), \, i, j = 1, \cdots, n\)를 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pairwise_distance_df <-}\StringTok{ }\KeywordTok{dist}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{upper =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

각 객체 \(j = 1, \cdots, n\)에 대하여 다음을 산출한다.

\begin{equation*}
v_j = \sum_{i = 1}^{n} \frac{d(i, j)}{\sum_{k = 1}^{n} d(i, k)}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{v_j <-}\StringTok{ }\NormalTok{pairwise_distance_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(item2) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{prop =}\NormalTok{ distance }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(distance)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{sum_prop =} \KeywordTok{sum}\NormalTok{(prop)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{j =}\NormalTok{ item1)}

\NormalTok{v_j}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##       j sum_prop
##   <int>    <dbl>
## 1     1    1.67 
## 2     2    1.33 
## 3     3    0.781
## 4     4    0.661
## 5     5    0.713
## 6     6    0.849
\end{verbatim}

이후 \(v_j\)값들을 오름차순으로 정렬하여 가장 작은 \(K\)개의 값을 초기 대표객체로 선정한다. 본 예에서는 \(K = 2\)로 가정하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{medoids_ids <-}\StringTok{ }\NormalTok{v_j }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(sum_prop) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{.}\OperatorTok{$}\NormalTok{j}

\NormalTok{medoids_ids}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4 5
\end{verbatim}

이후 객체를 배정하여 군집해를 얻는다. 위에서 정의했던 \texttt{assign\_cluster} 함수를 재사용하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster_solution <-}\StringTok{ }\KeywordTok{assign_cluster}\NormalTok{(}
\NormalTok{  pairwise_distance_df, }
\NormalTok{  medoids_ids}
\NormalTok{  )}

\NormalTok{cluster_solution}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   object distance cluster     
##    <int>    <dbl> <chr>       
## 1      1    10.4  {1, 2, 3, 4}
## 2      2     8.25 {1, 2, 3, 4}
## 3      3     2.83 {1, 2, 3, 4}
## 4      4     0    {1, 2, 3, 4}
## 5      5     0    {5, 6}      
## 6      6     1.41 {5, 6}
\end{verbatim}

\textbf{{[}단계 2{]}} (대표객체의 수정) 현재의 군집에 배정된 객체들의 대표객체를 구하여 새로운 대표객체로 삼는다. 새로운 대표객체는 같은 군집에 배정된 다른 객체들로부터의 거리의 합이 최소가 되는 객체이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{find_medoids <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(distance_df, ids) \{}
\NormalTok{  distance_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(}
\NormalTok{      item1 }\OperatorTok{%in%}\StringTok{ }\NormalTok{ids, }
\NormalTok{      item2 }\OperatorTok{%in%}\StringTok{ }\NormalTok{ids}
\NormalTok{      ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{total_distance =} \KeywordTok{sum}\NormalTok{(distance)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{arrange}\NormalTok{(total_distance) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\NormalTok{.}\OperatorTok{$}\NormalTok{item1}
\NormalTok{\}}

\NormalTok{cluster_objects <-}\StringTok{ }\NormalTok{cluster_solution }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{split}\NormalTok{(.}\OperatorTok{$}\NormalTok{cluster) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{map}\NormalTok{(}\OperatorTok{~}\NormalTok{.}\OperatorTok{$}\NormalTok{object)}

\NormalTok{medoids_ids <-}\StringTok{ }\KeywordTok{map_int}\NormalTok{(}
\NormalTok{  cluster_objects, }
\NormalTok{  find_medoids,}
  \DataTypeTok{distance_df =}\NormalTok{ pairwise_distance_df}
\NormalTok{)}

\NormalTok{medoids_ids}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## {1, 2, 3, 4}       {5, 6} 
##            2            5
\end{verbatim}

\textbf{{[}단계 3{]}} (객체의 배정) 각 객체를 가장 가까운 대표객체에 배정하여 군집해를 얻는다. 군집해가 이전과 동일하면 Stop하고, 그렇지 않으면 {[}단계 2{]}를 반복한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new_cluster_solution <-}\StringTok{ }\KeywordTok{assign_cluster}\NormalTok{(}
\NormalTok{  pairwise_distance_df, }
\NormalTok{  medoids_ids}
\NormalTok{  )}

\NormalTok{is_converge <-}\StringTok{ }\KeywordTok{near}\NormalTok{(}
  \DecValTok{1}\NormalTok{, }
  \CommentTok{# clusteval::cluster_similarity(}
  \CommentTok{#   as.factor(cluster_solution$cluster),}
  \CommentTok{#   as.factor(new_cluster_solution$cluster),}
  \CommentTok{#   similarity = "rand"}
  \CommentTok{# )}
\NormalTok{  flexclust}\OperatorTok{::}\KeywordTok{randIndex}\NormalTok{(}
    \KeywordTok{as.factor}\NormalTok{(cluster_solution}\OperatorTok{$}\NormalTok{cluster),}
    \KeywordTok{as.factor}\NormalTok{(new_cluster_solution}\OperatorTok{$}\NormalTok{cluster)}
\NormalTok{  )}
\NormalTok{)}

\KeywordTok{print}\NormalTok{(is_converge)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   ARI 
## FALSE
\end{verbatim}

위의 경우 첫 번째 iteration에서 군집해가 수정되었으므로 다음 iteration을 수행한다.

\hypertarget{kmeans-like-user-defined-functions}{%
\subsubsection{R 스크립트 구현}\label{kmeans-like-user-defined-functions}}

위 일련의 과정들을 수행하는 R 함수 스크립트를 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{init_medoids <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(distance_df, }\DataTypeTok{k =} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  object_ids <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(distance_df}\OperatorTok{$}\NormalTok{item1)}
\NormalTok{  k <-}\StringTok{ }\KeywordTok{min}\NormalTok{(k, }\KeywordTok{length}\NormalTok{(object_ids))}
  
\NormalTok{  v_j <-}\StringTok{ }\NormalTok{distance_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(item2) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{prop =}\NormalTok{ distance }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(distance)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{sum_prop =} \KeywordTok{sum}\NormalTok{(prop)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{j =}\NormalTok{ item1)}
  
\NormalTok{  medoids_ids <-}\StringTok{ }\NormalTok{v_j }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{arrange}\NormalTok{(sum_prop) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{k) }\OperatorTok{%>%}
\StringTok{    }\NormalTok{.}\OperatorTok{$}\NormalTok{j}
  
  \KeywordTok{return}\NormalTok{(medoids_ids)}
\NormalTok{\}}

\NormalTok{assign_cluster <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(distance_df, medoids_ids) \{}
\NormalTok{  distance_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(}
      \OperatorTok{!}\NormalTok{item1 }\OperatorTok{%in%}\StringTok{ }\NormalTok{medoids_ids,}
\NormalTok{      item2 }\OperatorTok{%in%}\StringTok{ }\NormalTok{medoids_ids}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{arrange}\NormalTok{(distance) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{bind_rows}\NormalTok{(}
      \KeywordTok{tibble}\NormalTok{(}
        \DataTypeTok{item1 =}\NormalTok{ medoids_ids,}
        \DataTypeTok{item2 =}\NormalTok{ medoids_ids,}
        \DataTypeTok{distance =} \DecValTok{0}
\NormalTok{      )}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{object =}\NormalTok{ item1) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{arrange}\NormalTok{(object) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(item2) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{cluster =} \KeywordTok{str_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{str_c}\NormalTok{(object, }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{item2)}
\NormalTok{\}}

\NormalTok{find_medoids <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(distance_df, ids) \{}
\NormalTok{  distance_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(}
\NormalTok{      item1 }\OperatorTok{%in%}\StringTok{ }\NormalTok{ids, }
\NormalTok{      item2 }\OperatorTok{%in%}\StringTok{ }\NormalTok{ids}
\NormalTok{      ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{total_distance =} \KeywordTok{sum}\NormalTok{(distance)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{arrange}\NormalTok{(total_distance) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\NormalTok{.}\OperatorTok{$}\NormalTok{item1}
\NormalTok{\}}

\NormalTok{kmeans_like_kmedoids <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(distance_df, }\DataTypeTok{k =} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  medoids_ids <-}\StringTok{ }\KeywordTok{init_medoids}\NormalTok{(distance_df, k)}
  
  \ControlFlowTok{while}\NormalTok{ (}\OtherTok{TRUE}\NormalTok{) \{}
\NormalTok{    cluster_solution <-}\StringTok{ }\KeywordTok{assign_cluster}\NormalTok{(distance_df, medoids_ids)}
    
\NormalTok{    cluster_objects <-}\StringTok{ }\NormalTok{cluster_solution }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{split}\NormalTok{(.}\OperatorTok{$}\NormalTok{cluster) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{map}\NormalTok{(}\OperatorTok{~}\NormalTok{.}\OperatorTok{$}\NormalTok{object)}
    
\NormalTok{    medoids_ids <-}\StringTok{ }\KeywordTok{map_int}\NormalTok{(}
\NormalTok{      cluster_objects, }
\NormalTok{      find_medoids,}
      \DataTypeTok{distance_df =}\NormalTok{ distance_df}
\NormalTok{    )}
    
\NormalTok{    new_cluster_solution <-}\StringTok{ }\KeywordTok{assign_cluster}\NormalTok{(distance_df, medoids_ids)}
    
\NormalTok{    is_converge <-}\StringTok{ }\KeywordTok{near}\NormalTok{(}
      \DecValTok{1}\NormalTok{, }
\NormalTok{      flexclust}\OperatorTok{::}\KeywordTok{randIndex}\NormalTok{(}
        \KeywordTok{as.factor}\NormalTok{(cluster_solution}\OperatorTok{$}\NormalTok{cluster),}
        \KeywordTok{as.factor}\NormalTok{(new_cluster_solution}\OperatorTok{$}\NormalTok{cluster)}
\NormalTok{      )}
\NormalTok{    )}
    
    \ControlFlowTok{if}\NormalTok{ (is_converge) }\ControlFlowTok{break}
\NormalTok{  \}}
  
  \KeywordTok{return}\NormalTok{(medoids_ids)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위에서 정의한 함수 \texttt{kmeans\_like\_kmedoids}를 Table \ref{tab:pam-train-data}의 데이터에 적용한 군집결과 및 군집 대표객체는 아래와 같이 얻어진다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pairwise_distance_df <-}\StringTok{ }\KeywordTok{dist}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{upper =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{()}

\NormalTok{medoids_ids <-}\StringTok{ }\KeywordTok{kmeans_like_kmedoids}\NormalTok{(pairwise_distance_df, }\DataTypeTok{k =} \DecValTok{2}\NormalTok{)}

\NormalTok{medoids_ids}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       {1, 2} {3, 4, 5, 6} 
##            1            5
\end{verbatim}

\hypertarget{fuzzy-kmeans}{%
\section{퍼지 K-means 알고리즘}\label{fuzzy-kmeans}}

이 방법은 K-means 알고리즘과 유사하나, 하나의 객체가 여러 군집에 속할 가능성을 허용하는 확률 또는 이를 확장한 퍼지(fuzzy) 개념을 도입한 것이다. 객체 \(i\)가 군집 \(j\)에 속할 확률 \(P_{ij}\)를 구하는 문제이다.

\hypertarget{fuzzy-kmeans-basic-script}{%
\subsection{기본 R 스크립트}\label{fuzzy-kmeans-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{id =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{),}
  \DataTypeTok{x1 =} \KeywordTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{14}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{),}
  \DataTypeTok{x2 =} \KeywordTok{c}\NormalTok{(}\DecValTok{14}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{)}

\NormalTok{df }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}
      \StringTok{'객체번호'}\NormalTok{, }
      \StringTok{'사용경력($x_1$)'}\NormalTok{, }
      \StringTok{'사용시간($x_2$)'}
\NormalTok{      ),}
    \DataTypeTok{caption =} \StringTok{'PC 사용자 데이터'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:fuzzy-kmeans-data}PC 사용자 데이터}
\centering
\begin{tabular}{rrr}
\toprule
객체번호 & 사용경력(\$x\_1\$) & 사용시간(\$x\_2\$)\\
\midrule
1 & 6 & 14\\
2 & 8 & 13\\
3 & 14 & 6\\
4 & 11 & 8\\
5 & 15 & 7\\
\addlinespace
6 & 7 & 15\\
7 & 13 & 6\\
8 & 5 & 4\\
9 & 3 & 3\\
10 & 3 & 2\\
\bottomrule
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster}\OperatorTok{::}\KeywordTok{fanny}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{k =} \DecValTok{3}\NormalTok{, }\DataTypeTok{metric =} \StringTok{"SqEuclidean"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Fuzzy Clustering object of class 'fanny' :                      
## m.ship.expon.        2
## objective     18.37061
## tolerance        1e-15
## iterations          12
## converged            1
## maxit              500
## n                   10
## Membership coefficients (in %, rounded):
##       [,1] [,2] [,3]
##  [1,]   98    1    1
##  [2,]   96    3    2
##  [3,]    1   99    1
##  [4,]   12   80    8
##  [5,]    2   96    2
##  [6,]   98    1    1
##  [7,]    1   99    1
##  [8,]    3    3   94
##  [9,]    0    0   99
## [10,]    1    1   98
## Fuzzyness coefficients:
## dunn_coeff normalized 
##  0.9225653  0.8838480 
## Closest hard clustering:
##  [1] 1 1 2 2 2 1 2 3 3 3
## 
## Available components:
##  [1] "membership"  "coeff"       "memb.exp"    "clustering"  "k.crisp"    
##  [6] "objective"   "convergence" "diss"        "call"        "silinfo"    
## [11] "data"
\end{verbatim}

\hypertarget{fuzzy-kmeans-algorithm}{%
\subsection{알고리즘}\label{fuzzy-kmeans-algorithm}}

\textbf{{[}단계 0{]}} 초기 \(K\)개의 군집을 임의로 결정한다.

\begin{equation*}
P_{ij} = \begin{cases}
1 & \text{ if object $i$ belongs to cluster $j$}\\
0 & \text{ otherwise}
\end{cases}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{init_cluster <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, }\DataTypeTok{k =} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  k <-}\StringTok{ }\KeywordTok{min}\NormalTok{(k, }\KeywordTok{nrow}\NormalTok{(df))}
  
  \ControlFlowTok{while}\NormalTok{ (}\OtherTok{TRUE}\NormalTok{) \{}
\NormalTok{    cluster_ind <-}\StringTok{ }\KeywordTok{sample.int}\NormalTok{(k, }\DataTypeTok{size =} \KeywordTok{nrow}\NormalTok{(df), }\DataTypeTok{replace =} \OtherTok{TRUE}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{length}\NormalTok{(}\KeywordTok{unique}\NormalTok{(cluster_ind)) }\OperatorTok{==}\StringTok{ }\NormalTok{k) }\ControlFlowTok{break}
\NormalTok{  \}}
  
  \KeywordTok{map_dfc}\NormalTok{(}\KeywordTok{unique}\NormalTok{(cluster_ind), }\OperatorTok{~}\StringTok{ }\KeywordTok{as.double}\NormalTok{(cluster_ind }\OperatorTok{==}\StringTok{ }\NormalTok{.))}
\NormalTok{\}}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{4000}\NormalTok{)}

\NormalTok{cluster_membership <-}\StringTok{ }\KeywordTok{init_cluster}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{k =} \DecValTok{3}\NormalTok{)}

\NormalTok{cluster_membership}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 3
##       V1    V2    V3
##    <dbl> <dbl> <dbl>
##  1     1     0     0
##  2     1     0     0
##  3     0     1     0
##  4     1     0     0
##  5     0     0     1
##  6     0     1     0
##  7     0     0     1
##  8     0     1     0
##  9     1     0     0
## 10     1     0     0
\end{verbatim}

\textbf{{[}단계 1{]}} 각 군집의 중심좌표를 산출한다.

\begin{equation*}
\mathbf{c}_j = \frac{\sum_{i = 1}^{n} P_{ij}^{m} \mathbf{x}_i}{\sum_{i = 1}^{n} P_{ij}^{m}}
\end{equation*}

여기에서 상수 \(m\)은 1보다 큰 값을 사용한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{find_center <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, p, m) \{}
\NormalTok{  wt <-}\StringTok{ }\NormalTok{p }\OperatorTok{^}\StringTok{ }\NormalTok{m}
\NormalTok{  df }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{summarize_all}\NormalTok{(weighted.mean, }\DataTypeTok{w =}\NormalTok{ wt)}
\NormalTok{\}}

\NormalTok{cluster_df <-}\StringTok{ }\KeywordTok{map_dfr}\NormalTok{(cluster_membership, find_center, }\DataTypeTok{df =}\NormalTok{ df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{m =} \DecValTok{2}\NormalTok{)}

\NormalTok{cluster_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##      x1    x2
##   <dbl> <dbl>
## 1  6.2   8   
## 2  8.67  8.33
## 3 14     6.5
\end{verbatim}

\textbf{{[}단계 2{]}} 군집 membership 계수 \(P_{ij}\)를 업데이트한다.

\begin{equation*}
P_{ij} = \frac{d(\mathbf{x}_i, \mathbf{c}_j)^{-\frac{1}{m - 1}}}{\sum_{a = 1}^{K} d(\mathbf{x}_i, \mathbf{c}_a)^{-\frac{1}{m - 1}}}
\end{equation*}

여기에서 거리함수 \(d()\)는 제곱 유클리드 거리를 사용한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{update_membership <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, cluster_df, m) \{}
\NormalTok{  distance_mat <-}\StringTok{ }\NormalTok{flexclust}\OperatorTok{::}\KeywordTok{dist2}\NormalTok{(df, cluster_df)  }\OperatorTok{^}\StringTok{ }\DecValTok{2}
  
\NormalTok{  p <-}\StringTok{ }\NormalTok{distance_mat }\OperatorTok{^}\StringTok{ }\NormalTok{(}\OperatorTok{-}\DecValTok{1} \OperatorTok{/}\StringTok{ }\NormalTok{(m }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{    `}\DataTypeTok{/}\StringTok{`}\NormalTok{(}\KeywordTok{rowSums}\NormalTok{(.)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{as_tibble}\NormalTok{(}\DataTypeTok{.name_repair =} \StringTok{"minimal"}\NormalTok{)}
  
\NormalTok{  p}
\NormalTok{\}}

\KeywordTok{update_membership}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], cluster_df, }\DataTypeTok{m =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 3
##         ``      ``    ``
##      <dbl>   <dbl> <dbl>
##  1 0.451   0.414   0.135
##  2 0.380   0.483   0.137
##  3 0.00381 0.00730 0.989
##  4 0.139   0.576   0.285
##  5 0.0152  0.0285  0.956
##  6 0.406   0.427   0.166
##  7 0.0231  0.0479  0.929
##  8 0.574   0.311   0.115
##  9 0.542   0.315   0.143
## 10 0.508   0.325   0.166
\end{verbatim}

\hypertarget{fuzzy-kmeans-script-implement}{%
\subsection{R 스크립트 구현}\label{fuzzy-kmeans-script-implement}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fuzzy_kmeans <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, }\DataTypeTok{k =} \DecValTok{1}\NormalTok{, }\DataTypeTok{m =} \DecValTok{2}\NormalTok{, }\DataTypeTok{max_iter =}\NormalTok{ 1000L, }\DataTypeTok{tol =} \FloatTok{1e-9}\NormalTok{) \{}
\NormalTok{  k <-}\StringTok{ }\KeywordTok{min}\NormalTok{(k, }\KeywordTok{nrow}\NormalTok{(df))}
\NormalTok{  i <-}\StringTok{ }\NormalTok{0L}
  
\NormalTok{  cluster_membership <-}\StringTok{ }\KeywordTok{init_cluster}\NormalTok{(df, k)}
  
  \ControlFlowTok{while}\NormalTok{ (i }\OperatorTok{<}\StringTok{ }\NormalTok{max_iter) \{}
\NormalTok{    i <-}\StringTok{ }\NormalTok{i }\OperatorTok{+}\StringTok{ }\NormalTok{1L}
    
\NormalTok{    cluster_df <-}\StringTok{ }\KeywordTok{map_dfr}\NormalTok{(cluster_membership, find_center, }\DataTypeTok{df =}\NormalTok{ df, }\DataTypeTok{m =}\NormalTok{ m)}
    
\NormalTok{    new_cluster_membership <-}\StringTok{ }\KeywordTok{update_membership}\NormalTok{(df, cluster_df, m)}
    
    \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{max}\NormalTok{(}\KeywordTok{abs}\NormalTok{(cluster_membership }\OperatorTok{-}\StringTok{ }\NormalTok{new_cluster_membership)) }\OperatorTok{<}\StringTok{ }\NormalTok{tol) }\ControlFlowTok{break}
    
\NormalTok{    cluster_membership <-}\StringTok{ }\NormalTok{new_cluster_membership}
\NormalTok{  \}}
  
\NormalTok{  res <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}
    \DataTypeTok{n_iteration =}\NormalTok{ i,}
    \DataTypeTok{center =}\NormalTok{ cluster_df,}
    \DataTypeTok{membership =}\NormalTok{ cluster_membership }\OperatorTok{%>%}\StringTok{ }\KeywordTok{as.matrix}\NormalTok{()}
\NormalTok{  )}
  
  \KeywordTok{return}\NormalTok{ (res)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{4000}\NormalTok{)}

\NormalTok{fuzzy_kmeans_solution <-}\StringTok{ }\KeywordTok{fuzzy_kmeans}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{k =} \DecValTok{3}\NormalTok{, }\DataTypeTok{m =} \DecValTok{2}\NormalTok{)}

\NormalTok{fuzzy_kmeans_solution}\OperatorTok{$}\NormalTok{n_iteration}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fuzzy_kmeans_solution}\OperatorTok{$}\NormalTok{center}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##      x1    x2
##   <dbl> <dbl>
## 1  3.64  2.98
## 2  7.00 14.0 
## 3 13.4   6.63
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fuzzy_kmeans_solution}\OperatorTok{$}\NormalTok{membership}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                          
##  [1,] 0.007809655 0.983147737 0.009042608
##  [2,] 0.015726915 0.957515486 0.026757600
##  [3,] 0.006068358 0.006268614 0.987663029
##  [4,] 0.078772454 0.120672309 0.800555237
##  [5,] 0.017165082 0.022105992 0.960728926
##  [6,] 0.006532987 0.984345339 0.009121674
##  [7,] 0.005945712 0.005766360 0.988287928
##  [8,] 0.939278603 0.026072757 0.034648640
##  [9,] 0.993661877 0.002989486 0.003348637
## [10,] 0.981125198 0.008481303 0.010393499
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fuzzy_kmeans_solution}\OperatorTok{$}\NormalTok{membership }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{apply}\NormalTok{(}\DecValTok{1}\NormalTok{, which.max)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 2 2 3 3 3 2 3 1 1 1
\end{verbatim}

\hypertarget{model-based-clustering}{%
\section{모형기반 군집방법}\label{model-based-clustering}}

모형기반 군집방법(model-based clustering)에서는 각 객체가 혼합분포(mixture)를 따른다고 가정하여 객체의 군집배정변수를 통계적으로 추정하는 것이다.

\hypertarget{model-based-clustering-basic-script}{%
\subsection{기본 R script}\label{model-based-clustering-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{id =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{7}\NormalTok{),}
  \DataTypeTok{x1 =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{12}\NormalTok{),}
  \DataTypeTok{x2 =} \KeywordTok{c}\NormalTok{(}\DecValTok{12}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{)}

\NormalTok{df }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}
      \StringTok{'객체번호'}\NormalTok{, }
      \StringTok{'$x_1$'}\NormalTok{, }
      \StringTok{'$x_2$'}
\NormalTok{      ),}
    \DataTypeTok{caption =} \StringTok{'모형기반 군집 학습 데이터'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:model-based-clustering-data}모형기반 군집 학습 데이터}
\centering
\begin{tabular}{rrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$\\
\midrule
1 & 4 & 12\\
2 & 6 & 13\\
3 & 6 & 15\\
4 & 10 & 4\\
5 & 11 & 3\\
\addlinespace
6 & 12 & 2\\
7 & 12 & 5\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:model-based-clustering-data}의 7개의 객체를 두 개의 군집에 배정하는 간단한 R 스크립트는 아래와 같다. 여기에서 \texttt{mclust::meVII}는 각 군집의 분산-공분산 행렬은 서로 다르되, 각 변수의 분산이 동일하며 공분산은 0이라 가정한다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1024}\NormalTok{)}

\CommentTok{# 군집 개수}
\NormalTok{K <-}\StringTok{ }\DecValTok{2}

\CommentTok{# z_ik 값 초기화}
\NormalTok{init_z <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{runif}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(df) }\OperatorTok{*}\StringTok{ }\NormalTok{K), }\DataTypeTok{ncol =}\NormalTok{ K) }\OperatorTok{%>%}
\StringTok{  `}\DataTypeTok{/}\StringTok{`}\NormalTok{(}\KeywordTok{apply}\NormalTok{(., }\DecValTok{1}\NormalTok{, sum))}

\CommentTok{# EM 알고리즘 - 분산-공분산 행렬: unequal volume (V), spherical(II) }
\NormalTok{sol <-}\StringTok{ }\NormalTok{mclust}\OperatorTok{::}\KeywordTok{meVII}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{z =}\NormalTok{ init_z)}

\CommentTok{# 군집 사후확률}
\NormalTok{sol}\OperatorTok{$}\NormalTok{z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              [,1]         [,2]
## [1,] 7.596402e-28 1.000000e+00
## [2,] 8.254183e-27 1.000000e+00
## [3,] 9.463816e-36 1.000000e+00
## [4,] 1.000000e+00 6.832084e-20
## [5,] 1.000000e+00 1.473491e-25
## [6,] 1.000000e+00 4.876251e-31
## [7,] 1.000000e+00 1.480388e-20
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 혼합분포}
\NormalTok{sol}\OperatorTok{$}\NormalTok{parameters}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $pro
## [1] 0.5714286 0.4285714
## 
## $mean
##     [,1]      [,2]
## x1 11.25  5.333333
## x2  3.50 13.333333
## 
## $variance
## $variance$modelName
## [1] "VII"
## 
## $variance$d
## [1] 2
## 
## $variance$G
## [1] 2
## 
## $variance$sigma
## , , 1
## 
##         x1      x2
## x1 0.96875 0.00000
## x2 0.00000 0.96875
## 
## , , 2
## 
##          x1       x2
## x1 1.222222 0.000000
## x2 0.000000 1.222222
## 
## 
## $variance$sigmasq
## [1] 0.968750 1.222222
## 
## $variance$scale
## [1] 0.968750 1.222222
## 
## 
## $Vinv
## NULL
\end{verbatim}

\hypertarget{model-based-clustering-em}{%
\subsection{EM 알고리즘}\label{model-based-clustering-em}}

우선, 필요한 기호를 다음과 같이 정의하자.

\begin{itemize}
\tightlist
\item
  \(f_k(\mathbf{x} \, | \, \theta_k)\): 군집 \(k\)에 속하는 객체 \(\mathbf{x}\)의 확률밀도함수(\(\theta_k\)는 관련 파라미터)
\item
  \(\tau_k\): 임의의 객체가 군집 \(k\)에 속할 사전확률 (\(\tau_k \geq 0, \, \sum_{k = 1}^{K} \tau = 1\))
\end{itemize}

이 때, 임의의 객체 \(\mathbf{x}\)는 다음과 같은 혼합 확률밀도함수를 갖는다.

\begin{equation*}
f(\mathbf{x} \, | \, \boldsymbol\theta) = \sum_{k = 1}^{K} \tau_k f_k(\mathbf{x} \, | \, \theta_k)
\end{equation*}

본 장에서는 \(f_k\)가 다변량 정규분포를 나타낸다고 가정하자.

추가로, 각 객체가 속하는 군집에 대한 지시변수 \(z_{ik}\)를 아래와 같이 정의하자.

\begin{equation*}
z_{ik} = \begin{cases}
1 & \text{ if object $i$ belongs to cluster $k$} \\
0 & \text{ otherwise}
\end{cases}
\end{equation*}

이 \(z_{ik}\) 변수는 실제값이 관측되지 않는 변수이므로, 최우추정법을 이용하여 그 기대값, 즉 객체 \(i\)가 군집 \(k\)에 속할 확률을 추정한다. 보다 자세한 설명은 교재 \citep{jun2012datamining} 참조.

앞의 \ref{model-based-clustering-basic-script}장에서 수행했던 예제를 단계별로 살펴보기로 하자.

\textbf{{[}단계 0{]}} \(\hat{z}_{ik}\)를 초기화한다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1024}\NormalTok{)}

\CommentTok{# 군집 개수}
\NormalTok{K <-}\StringTok{ }\DecValTok{2}

\CommentTok{# z_ik 추정값 초기화}
\NormalTok{z_hat <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{runif}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(df) }\OperatorTok{*}\StringTok{ }\NormalTok{K), }\DataTypeTok{ncol =}\NormalTok{ K) }\OperatorTok{%>%}
\StringTok{  `}\DataTypeTok{/}\StringTok{`}\NormalTok{(}\KeywordTok{apply}\NormalTok{(., }\DecValTok{1}\NormalTok{, sum)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{as_tibble}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  `}\DataTypeTok{names<-}\StringTok{`}\NormalTok{(}\KeywordTok{str_c}\NormalTok{(}\StringTok{"C"}\NormalTok{, }\DecValTok{1}\OperatorTok{:}\NormalTok{K))}

\NormalTok{z_hat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 7 x 2
##       C1     C2
##    <dbl>  <dbl>
## 1 0.406  0.594 
## 2 0.623  0.377 
## 3 0.372  0.628 
## 4 0.956  0.0444
## 5 0.0214 0.979 
## 6 0.681  0.319 
## 7 0.264  0.736
\end{verbatim}

\textbf{{[}단계 1{]}} (M-step) \(\hat{z}_{ik}\)를 바탕으로 파라미터를 추정한다.

우선 \(\tau_k\)와 \(\boldsymbol\mu_k\)를 다음과 같이 추정한다.

\begin{equation*}
\hat{\tau}_k = \frac{\sum_{i = 1}^{n} \hat{z}_{ik}}{n}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tau_hat <-}\StringTok{ }\KeywordTok{map}\NormalTok{(z_hat, mean)}
\NormalTok{tau_hat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $C1
## [1] 0.4746762
## 
## $C2
## [1] 0.5253238
\end{verbatim}

\begin{equation*}
\hat{\boldsymbol\mu}_k = \frac{\sum_{i = 1}^{n} \hat{z}_{ik} \mathbf{x}_i}{\sum_{i = 1}^{n} \hat{z}_{ik}}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mu_hat <-}\StringTok{ }\KeywordTok{map}\NormalTok{(z_hat, }\OperatorTok{~}\KeywordTok{colSums}\NormalTok{(.}\OperatorTok{*}\NormalTok{df[, }\DecValTok{-1}\NormalTok{]) }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(.))}
\NormalTok{mu_hat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $C1
##       x1       x2 
## 8.644042 7.559792 
## 
## $C2
##       x1       x2 
## 8.777757 7.853884
\end{verbatim}

분산-공분산 행렬 \(\boldsymbol\Sigma_k\)의 추정은 분산-공분산 구조를 어떻게 가정하느냐에 따라 다르다. 우선, 일반적으로 분산-공분산 행렬 \(\boldsymbol\Sigma_k\)는 아래와 같이 decompose할 수 있다 \citep{banfield1993model}.

\begin{equation*}
\boldsymbol\Sigma_k = \lambda_k \mathbf{D}_k \mathbf{A}_k \mathbf{D}_k^\top
\end{equation*}

여기에서

\begin{itemize}
\tightlist
\item
  \(\lambda_k = \det{\boldsymbol\Sigma_k}^{1 / 2}\); 군집 \(k\)이 크기와 관련
\item
  \(\mathbf{D}_k\): matrix of eigenvectors of \(\boldsymbol\Sigma_k\); 군집 \(k\)의 방향(orientation)과 관련
\item
  \(\mathbf{A}_k\): diagonal matrix s.t. \(\det{\mathbf{A}_k} = 1\); 군집 \(k\)의 형태와 관련
\end{itemize}

이다. \(\lambda_k\), \(\mathbf{D}_k\) 및 \(\mathbf{A}_k\)에 적용되는 제약조건에 따라 분산-공분산 모형을 정의할 수 있다. 아래는 본 장에서 다룰 세 가지 모형이다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{model, }\OperatorTok{~}\NormalTok{sigma,}
  \StringTok{"VII"}\NormalTok{, }\StringTok{"$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{lambda_k }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{I\}$"}\NormalTok{,}
  \StringTok{"VEI"}\NormalTok{, }\StringTok{"$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{lambda_k }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{A\}$"}\NormalTok{,}
  \StringTok{"VEE"}\NormalTok{, }\StringTok{"$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{lambda_k }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{D\} }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{A\} }\CharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{D\}^}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{top$"}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'c'}\NormalTok{, }\StringTok{'c'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}
      \StringTok{'분산-공분산 모형'}\NormalTok{, }
      \StringTok{'$}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{boldsymbol}\CharTok{\textbackslash{}\textbackslash{}}\StringTok{Sigma_k$'}
\NormalTok{      ),}
    \DataTypeTok{caption =} \StringTok{'Within-group 분산-공분산 모형'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:within-group-cov-models}Within-group 분산-공분산 모형}
\centering
\begin{tabular}{cc}
\toprule
분산-공분산 모형 & \$\textbackslash{}boldsymbol\textbackslash{}Sigma\_k\$\\
\midrule
VII & \$\textbackslash{}lambda\_k \textbackslash{}mathbf\{I\}\$\\
VEI & \$\textbackslash{}lambda\_k \textbackslash{}mathbf\{A\}\$\\
VEE & \$\textbackslash{}lambda\_k \textbackslash{}mathbf\{D\} \textbackslash{}mathbf\{A\} \textbackslash{}mathbf\{D\}\textasciicircum{}\textbackslash{}top\$\\
\bottomrule
\end{tabular}
\end{table}

즉,

\begin{itemize}
\tightlist
\item
  ``VII''

  \begin{itemize}
  \tightlist
  \item
    for all \(k\),\(\mathbf{D}_k = \mathbf{I}\)
  \item
    for all \(k\), \(\mathbf{A}_k = \mathbf{I}\)
  \end{itemize}
\item
  ``VEI''

  \begin{itemize}
  \tightlist
  \item
    for all \(k\), \(\mathbf{D}_k = \mathbf{I}\)
  \item
    for all \(k\), \(\mathbf{A}_k = \mathbf{A}\)
  \end{itemize}
\item
  ``VEE''

  \begin{itemize}
  \tightlist
  \item
    for all \(k\), \(\mathbf{D}_k = \mathbf{D}\)
  \item
    for all \(k\), \(\mathbf{A}_k = \mathbf{A}\)
  \end{itemize}
\end{itemize}

\citet{celeux1995gaussian} 에 각 분산-공분산 모형에 대한 추정값을 얻는 반복적 알고리즘이 소개되어 있으며, 이는 교재 \citep{jun2012datamining}에도 설명되어 있다.

우선, 각 군집 \(k\) 내에서의 scatter matrix를 아래와 같이 계산한다.

\begin{equation*}
\mathbf{W}_k = \sum_{i = 1}^{n} \hat{z}_{ik} (\mathbf{x}_i - \hat{\boldsymbol\mu}_k)(\mathbf{x}_i - \hat{\boldsymbol\mu}_k)^\top
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p <-}\StringTok{ }\KeywordTok{ncol}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{])}
\NormalTok{W <-}\StringTok{ }\KeywordTok{map}\NormalTok{(mu_hat, }
    \OperatorTok{~}\KeywordTok{pmap_dfc}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{mu =}\NormalTok{ .),}
             \ControlFlowTok{function}\NormalTok{(x, mu) x }\OperatorTok{-}\StringTok{ }\NormalTok{mu)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{map}\NormalTok{(as.matrix, }\DataTypeTok{nrow =}\NormalTok{ p, }\DataTypeTok{ncol =}\NormalTok{ p) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{map2}\NormalTok{(z_hat, }\OperatorTok{~}\StringTok{ }\KeywordTok{t}\NormalTok{(.x) }\OperatorTok{%*%}\StringTok{ }\NormalTok{(.y }\OperatorTok{*}\StringTok{ }\NormalTok{.x))}

\NormalTok{W}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $C1
##           x1        x2
## x1  28.22794 -44.46516
## x2 -44.46516  82.36848
## 
## $C2
##           x1        x2
## x1  37.16942 -53.17491
## x2 -53.17491  92.90912
\end{verbatim}

이후 분산-공분산 모형에 따라 아래와 같이 각 군집의 분산-공분산 행렬을 추정한다.

{[}VII의 경우{]} 반복 업데이트의 과정 없이 closed-form으로 해가 존재한다.

\begin{equation*}
\lambda_k = \frac{Tr(\mathbf{W}_k)}{p \sum_{i = 1}^{n} \hat{z}_{ik}}
\end{equation*}

\begin{equation*}
\boldsymbol\Sigma_k = \lambda_k \mathbf{I}
\end{equation*}

이 때 \(p\)는 관측값의 차원수이다 (\(\mathbf{x} \in \mathbb{R}^p\)).

{[}VEI의 경우{]}

VEI-0. 행렬 \(\mathbf{B} = \mathbf{I}\)로 초기화한다.

VEI-1. \(\lambda_k\)값을 아래와 같이 계산한다.

\begin{equation*}
\lambda_k = \frac{Tr(\mathbf{W}_k \mathbf{B}^{-1})}{p \sum_{i = 1}^{n} \hat{z}_{ik}}
\end{equation*}

VEI-2. 행렬 \(\mathbf{B}\)를 아래와 같이 업데이트한다.

\begin{equation*}
\mathbf{B} = \frac{diag\left( \sum_{k = 1}^{K} \frac{\mathbf{W}_k}{\lambda_k} \right)}{\left( \det diag\left( \sum_{k = 1}^{K} \frac{\mathbf{W}_k}{\lambda_k} \right) \right)^{1 / p}}
\end{equation*}

VEI-3. 결과가 수렴하면 종료, 그렇지 않으면 VEI-1로 돌아간다. 최종 수렴한 결과를 통해 각 군집의 분산-공분산 행렬을 아래와 같이 얻는다.

\begin{equation*}
\boldsymbol\Sigma_k = \lambda_k \mathbf{B}
\end{equation*}

{[}VEE의 경우{]}

VEE-0. 행렬 \(\mathbf{C} = \mathbf{I}\)로 초기화한다.

VEE-1. \(\lambda_k\)값을 아래와 같이 계산한다.

\begin{equation*}
\lambda_k = \frac{Tr(\mathbf{W}_k \mathbf{C}^{-1})}{p \sum_{i = 1}^{n} \hat{z}_{ik}}
\end{equation*}

VEE-2. 행렬 \(\mathbf{C}\)를 아래와 같이 업데이트한다.

\begin{equation*}
\mathbf{C} = \frac{\sum_{k = 1}^{K} \frac{\mathbf{W}_k}{\lambda_k}}{\left( \det \sum_{k = 1}^{K} \frac{\mathbf{W}_k}{\lambda_k} \right)^{1 / p}}
\end{equation*}

VEE-3. 결과가 수렴하면 종료, 그렇지 않으면 VEE-1로 돌아간다. 최종 수렴한 결과를 통해 각 군집의 분산-공분산 행렬을 아래와 같이 얻는다.

\begin{equation*}
\boldsymbol\Sigma_k = \lambda_k \mathbf{C}
\end{equation*}

위 각 분산-공분산 모형을 추정 과정에 대한 설명은, 보다 일반화된 분산-공분산 구조 \(\lambda_k \mathbf{D}_k \mathbf{A}_k \mathbf{D}_k^\top\)을 추정하는 과정을 각 모형에 추가되는 제약에 따라 조금 더 단순하게 표현한 것이다. 보다 자세한 내용은 \citet{celeux1995gaussian} 참조.

아래와 같이 군집 내 분산-공분산 행렬을 추정하는 함수 \texttt{estimate\_mixture\_cov}를 구현해보자. 해당 함수는 3개의 입력변수를 사용한다.

\begin{itemize}
\tightlist
\item
  \texttt{modelName}: 분산-공분산 모형 이름. ``VII'', ``VEI'', ``VEE'' 중 하나를 선택한다.
\item
  \texttt{W}: \texttt{K}개의 scatter matrix (\(\mathbf{W}_1, \cdots, \mathbf{W}_K\))를 원소로 지니는 리스트 (\texttt{list})
\item
  \texttt{z}: \(z_{ik}\) 값을 지닌 데이터 프레임 (\texttt{data.frame}). \(n\)개의 행과 \(K\)개의 열로 이루어진다. 즉, 행은 각 관측객체를 나타내며, 열은 각 군집을 나타낸다.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{estimate_mixture_cov <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(modelName, W, z) \{}
\NormalTok{  K <-}\StringTok{ }\KeywordTok{ncol}\NormalTok{(z)}
\NormalTok{  p <-}\StringTok{ }\KeywordTok{ncol}\NormalTok{(W[[}\DecValTok{1}\NormalTok{]])}

  \CommentTok{# 초기화}
\NormalTok{  D <-}\StringTok{ }\KeywordTok{map}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{K, }\OperatorTok{~}\StringTok{ }\KeywordTok{diag}\NormalTok{(}\DecValTok{1}\NormalTok{, p))}
\NormalTok{  A <-}\StringTok{ }\KeywordTok{map}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{K, }\OperatorTok{~}\StringTok{ }\KeywordTok{diag}\NormalTok{(}\DecValTok{1}\NormalTok{, p))}
  
\NormalTok{  get_lambda <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(W, z, D, A, p) \{}
    \KeywordTok{pmap}\NormalTok{(}
      \KeywordTok{list}\NormalTok{(W, z, D, A),}
      \ControlFlowTok{function}\NormalTok{(W, z, D, A, p)}
        \KeywordTok{sum}\NormalTok{(}\KeywordTok{diag}\NormalTok{(W }\OperatorTok{%*%}\StringTok{ }\NormalTok{D }\OperatorTok{%*%}\StringTok{ }\KeywordTok{solve}\NormalTok{(A) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{t}\NormalTok{(D))) }\OperatorTok{/}\StringTok{ }\NormalTok{(}\KeywordTok{sum}\NormalTok{(z) }\OperatorTok{*}\StringTok{ }\NormalTok{p),}
      \DataTypeTok{p =}\NormalTok{ p}
\NormalTok{      )}
\NormalTok{  \}}
  
\NormalTok{  objective_value <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(W, z, lambda, D, A, p) \{}
    \KeywordTok{pmap_dbl}\NormalTok{(}
      \KeywordTok{list}\NormalTok{(W, z, lambda, D, A),}
      \ControlFlowTok{function}\NormalTok{(W, z, lambda, D, A, p)}
        \KeywordTok{sum}\NormalTok{(}\KeywordTok{diag}\NormalTok{(W }\OperatorTok{%*%}\StringTok{ }\NormalTok{D }\OperatorTok{%*%}\StringTok{ }\KeywordTok{solve}\NormalTok{(A) }\OperatorTok{%*%}\StringTok{ }\KeywordTok{t}\NormalTok{(D))) }\OperatorTok{/}\StringTok{ }\NormalTok{lambda }\OperatorTok{+}
\StringTok{        }\NormalTok{p }\OperatorTok{*}\StringTok{ }\KeywordTok{sum}\NormalTok{(z) }\OperatorTok{*}\StringTok{ }\KeywordTok{log}\NormalTok{(lambda),}
      \DataTypeTok{p =}\NormalTok{ p}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{sum}\NormalTok{()}
\NormalTok{  \}}
  
\NormalTok{  i <-}\StringTok{ }\NormalTok{0L}
\NormalTok{  obj <-}\StringTok{ }\OtherTok{Inf}
  
  \ControlFlowTok{while}\NormalTok{(}\OtherTok{TRUE}\NormalTok{) \{}
\NormalTok{    i <-}\StringTok{ }\NormalTok{i }\OperatorTok{+}\StringTok{ }\NormalTok{1L}
    
\NormalTok{    lambda <-}\StringTok{ }\KeywordTok{get_lambda}\NormalTok{(W, z, D, A, p)}
\NormalTok{    new_obj <-}\StringTok{ }\KeywordTok{objective_value}\NormalTok{(W, z, lambda, D, A, p)}
    
    \ControlFlowTok{if}\NormalTok{ (obj }\OperatorTok{-}\StringTok{ }\NormalTok{new_obj }\OperatorTok{<}\StringTok{ }\FloatTok{1e-9}\NormalTok{) }\ControlFlowTok{break}
    
    \ControlFlowTok{if}\NormalTok{ (modelName }\OperatorTok{==}\StringTok{ "VII"}\NormalTok{) \{}
      
\NormalTok{    \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (modelName }\OperatorTok{==}\StringTok{ "VEI"}\NormalTok{) \{}
\NormalTok{      B <-}\StringTok{ }\KeywordTok{map2}\NormalTok{(W, lambda, }\OperatorTok{~}\StringTok{ }\KeywordTok{diag}\NormalTok{(.x) }\OperatorTok{/}\StringTok{ }\NormalTok{.y) }\OperatorTok{%>%}\StringTok{ }
\StringTok{        }\KeywordTok{reduce}\NormalTok{(}\StringTok{`}\DataTypeTok{+}\StringTok{`}\NormalTok{) }\OperatorTok{%>%}
\StringTok{        }\KeywordTok{diag}\NormalTok{() }\OperatorTok{%>%}
\StringTok{        `}\DataTypeTok{/}\StringTok{`}\NormalTok{(}\KeywordTok{det}\NormalTok{(.) }\OperatorTok{^}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{/}\StringTok{ }\NormalTok{p))}
\NormalTok{      A <-}\StringTok{ }\KeywordTok{map}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{K, }\OperatorTok{~}\StringTok{ }\NormalTok{B)}
\NormalTok{    \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (modelName }\OperatorTok{==}\StringTok{ "VEE"}\NormalTok{) \{}
\NormalTok{      C <-}\StringTok{ }\KeywordTok{map2}\NormalTok{(W, lambda, }\OperatorTok{~}\StringTok{ }\NormalTok{.x }\OperatorTok{/}\StringTok{ }\NormalTok{.y) }\OperatorTok{%>%}\StringTok{ }
\StringTok{        }\KeywordTok{reduce}\NormalTok{(}\StringTok{`}\DataTypeTok{+}\StringTok{`}\NormalTok{) }\OperatorTok{%>%}
\StringTok{        `}\DataTypeTok{/}\StringTok{`}\NormalTok{(}\KeywordTok{det}\NormalTok{(.) }\OperatorTok{^}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{/}\StringTok{ }\NormalTok{p))}
      
\NormalTok{      s <-}\StringTok{ }\KeywordTok{svd}\NormalTok{(C)}
\NormalTok{      A <-}\StringTok{ }\KeywordTok{map}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{K, }\OperatorTok{~}\StringTok{ }\KeywordTok{diag}\NormalTok{(s}\OperatorTok{$}\NormalTok{d))}
\NormalTok{      D <-}\StringTok{ }\KeywordTok{map}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{K, }\OperatorTok{~}\StringTok{ }\NormalTok{s}\OperatorTok{$}\NormalTok{u)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
      \KeywordTok{stop}\NormalTok{(}\StringTok{"Model "}\NormalTok{, modelName, }\StringTok{" is not supported yet."}\NormalTok{)}
\NormalTok{    \}}
    
\NormalTok{    obj <-}\StringTok{ }\NormalTok{new_obj}
\NormalTok{  \}}

\NormalTok{  Sigma <-}\StringTok{ }\KeywordTok{pmap}\NormalTok{(}
    \KeywordTok{list}\NormalTok{(lambda, D, A),}
    \ControlFlowTok{function}\NormalTok{(lambda, D, A) lambda }\OperatorTok{*}\StringTok{ }\NormalTok{(D }\OperatorTok{%*%}\StringTok{ }\NormalTok{A }\OperatorTok{%*%}\StringTok{ }\KeywordTok{t}\NormalTok{(D))}
\NormalTok{    )}

  \KeywordTok{return}\NormalTok{ (}\KeywordTok{list}\NormalTok{(}
    \DataTypeTok{volume =}\NormalTok{ lambda,}
    \DataTypeTok{shape =}\NormalTok{ A,}
    \DataTypeTok{orientation =}\NormalTok{ D,}
    \DataTypeTok{Sigma =}\NormalTok{ Sigma}
\NormalTok{  ))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

초기값으로 주어진 \(\hat{z}_{ik}\) 를 이용하여 ``VII'' 구조의 분산-공분산 행렬을 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{estimate_mixture_cov}\NormalTok{(}\StringTok{"VII"}\NormalTok{, W, z_hat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $volume
## $volume$C1
## [1] 16.64239
## 
## $volume$C2
## [1] 17.68685
## 
## 
## $shape
## $shape[[1]]
##      [,1] [,2]
## [1,]    1    0
## [2,]    0    1
## 
## $shape[[2]]
##      [,1] [,2]
## [1,]    1    0
## [2,]    0    1
## 
## 
## $orientation
## $orientation[[1]]
##      [,1] [,2]
## [1,]    1    0
## [2,]    0    1
## 
## $orientation[[2]]
##      [,1] [,2]
## [1,]    1    0
## [2,]    0    1
## 
## 
## $Sigma
## $Sigma$C1
##          [,1]     [,2]
## [1,] 16.64239  0.00000
## [2,]  0.00000 16.64239
## 
## $Sigma$C2
##          [,1]     [,2]
## [1,] 17.68685  0.00000
## [2,]  0.00000 17.68685
\end{verbatim}

위 \texttt{estimate\_mixture\_cov} 함수에서 ``VII''보다 일반화된 ``VEI''와 ``VEE'' 분산-공분산 모형에 대한 추정도 구현되어 있다.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# estimate_mixture_cov("VEI", W, z_hat)}
\CommentTok{# estimate_mixture_cov("VEE", W, z_hat)}
\end{Highlighting}
\end{Shaded}

위 일련의 파리미터 추정을 하나의 함수 \texttt{GMM\_Mstep}으로 아래와 같이 구성해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{GMM_Mstep <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, z, }\DataTypeTok{modelName =} \StringTok{"VII"}\NormalTok{) \{}
\NormalTok{  tau <-}\StringTok{ }\KeywordTok{map}\NormalTok{(z, mean)}
\NormalTok{  mu <-}\StringTok{ }\KeywordTok{map}\NormalTok{(z, }\OperatorTok{~}\KeywordTok{colSums}\NormalTok{(. }\OperatorTok{*}\StringTok{ }\NormalTok{df) }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(.))}
  
\NormalTok{  p <-}\StringTok{ }\KeywordTok{ncol}\NormalTok{(df)}
\NormalTok{  W <-}\StringTok{ }\KeywordTok{map}\NormalTok{(mu, }\OperatorTok{~}\KeywordTok{pmap_dfc}\NormalTok{(}
    \KeywordTok{list}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ df, }\DataTypeTok{mu =}\NormalTok{ .), }\ControlFlowTok{function}\NormalTok{(x, mu) x }\OperatorTok{-}\StringTok{ }\NormalTok{mu)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{map}\NormalTok{(as.matrix, }\DataTypeTok{nrow =}\NormalTok{ p, }\DataTypeTok{ncol =}\NormalTok{ p) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{map2}\NormalTok{(z, }\OperatorTok{~}\StringTok{ }\KeywordTok{t}\NormalTok{(.x) }\OperatorTok{%*%}\StringTok{ }\NormalTok{(.y }\OperatorTok{*}\StringTok{ }\NormalTok{.x))}
  
\NormalTok{  var_cov <-}\StringTok{ }\KeywordTok{estimate_mixture_cov}\NormalTok{(modelName, W, z)}
  
\NormalTok{  res <-}\StringTok{ }\KeywordTok{list}\NormalTok{(}
    \DataTypeTok{tau =}\NormalTok{ tau,}
    \DataTypeTok{mu =}\NormalTok{ mu,}
    \DataTypeTok{Sigma =}\NormalTok{ var_cov}\OperatorTok{$}\NormalTok{Sigma}
\NormalTok{  )}
  
  \KeywordTok{return}\NormalTok{ (res)}
\NormalTok{\}}

\NormalTok{Mstep_res <-}\StringTok{ }\KeywordTok{GMM_Mstep}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], z_hat)}

\NormalTok{Mstep_res}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $tau
## $tau$C1
## [1] 0.4746762
## 
## $tau$C2
## [1] 0.5253238
## 
## 
## $mu
## $mu$C1
##       x1       x2 
## 8.644042 7.559792 
## 
## $mu$C2
##       x1       x2 
## 8.777757 7.853884 
## 
## 
## $Sigma
## $Sigma$C1
##          [,1]     [,2]
## [1,] 16.64239  0.00000
## [2,]  0.00000 16.64239
## 
## $Sigma$C2
##          [,1]     [,2]
## [1,] 17.68685  0.00000
## [2,]  0.00000 17.68685
\end{verbatim}

\textbf{{[}단계 2{]}} (E-step) M-step에서의 파라미터 추정치를 바탕으로 \(\hat{z}_{ik}\)를 산출한다.

\begin{equation*}
\hat{z}_{ik} = \frac{\hat{\tau}_k f_k(\mathbf{x}_i \, | \, \hat{\boldsymbol{\mu}}_k, \hat{\boldsymbol{\Sigma}}_k)}{\sum_{l = 1}^{K} \hat{\tau}_l f_l(\mathbf{x}_i \, | \, \hat{\boldsymbol{\mu}}_l, \hat{\boldsymbol{\Sigma}}_l)}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{GMM_Estep <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, tau, mu, Sigma) \{}
  \KeywordTok{pmap_dfc}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{tau =}\NormalTok{ tau, }\DataTypeTok{mu =}\NormalTok{ mu, }\DataTypeTok{Sigma =}\NormalTok{ Sigma),}
       \ControlFlowTok{function}\NormalTok{(df, tau, mu, Sigma) }
\NormalTok{         tau }\OperatorTok{*}\StringTok{ }\NormalTok{mvtnorm}\OperatorTok{::}\KeywordTok{dmvnorm}\NormalTok{(df, }\DataTypeTok{mean =}\NormalTok{ mu, }\DataTypeTok{sigma =}\NormalTok{ Sigma),}
       \DataTypeTok{df =}\NormalTok{ df) }\OperatorTok{%>%}
\StringTok{    `}\DataTypeTok{/}\StringTok{`}\NormalTok{(}\KeywordTok{rowSums}\NormalTok{(.))}
\NormalTok{\}}

\NormalTok{new_z_hat <-}\StringTok{ }\KeywordTok{GMM_Estep}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], Mstep_res}\OperatorTok{$}\NormalTok{tau, Mstep_res}\OperatorTok{$}\NormalTok{mu, Mstep_res}\OperatorTok{$}\NormalTok{Sigma)}

\NormalTok{new_z_hat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          C1        C2
## 1 0.4626878 0.5373122
## 2 0.4568716 0.5431284
## 3 0.4373551 0.5626449
## 4 0.4964082 0.5035918
## 5 0.4934276 0.5065724
## 6 0.4886741 0.5113259
## 7 0.4870085 0.5129915
\end{verbatim}

\textbf{{[}단계 3{]}} 수렴조건을 만족하면 stop, 그렇지 않으면 {[}단계 1{]}을 반복한다. 일반적으로는 우도함수값의 변화량을 수렴조건으로 사용하나, 본 장에서는 간단하게 \(z_{ik}\)값의 변화량을 기준으로 수렴을 판단하도록 하자.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{max}\NormalTok{(}\KeywordTok{abs}\NormalTok{(z_hat }\OperatorTok{-}\StringTok{ }\NormalTok{new_z_hat)) }\OperatorTok{<}\StringTok{ }\FloatTok{1e-9}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

위 수식의 값이 \texttt{TRUE}이면 수렴, \texttt{FALSE}이면 {[}단계 1{]}을 반복한다.

\hypertarget{model-based-clustering-script-implement}{%
\subsection{R 스크립트 구현}\label{model-based-clustering-script-implement}}

위 일련의 과정들을 포함하는 하나의 함수 \texttt{GMM\_EM}을 아래와 같이 구현해보자. 앞에서 정의했던 함수 \texttt{GMM\_Mstep} 및 \texttt{GMM\_Estep}을 재사용한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{GMM_EM <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(df, K, }\DataTypeTok{modelName =} \StringTok{"VII"}\NormalTok{, }\DataTypeTok{tol =} \FloatTok{1e-9}\NormalTok{) \{}
\NormalTok{  K <-}\StringTok{ }\KeywordTok{min}\NormalTok{(K, }\KeywordTok{nrow}\NormalTok{(df))}
  
\NormalTok{  i <-}\StringTok{ }\NormalTok{0L  }
  
  \CommentTok{# [단계 0] z_ik 추정값 초기화}
\NormalTok{  z_hat <-}\StringTok{ }\KeywordTok{matrix}\NormalTok{(}\KeywordTok{runif}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(df) }\OperatorTok{*}\StringTok{ }\NormalTok{K), }\DataTypeTok{ncol =}\NormalTok{ K) }\OperatorTok{%>%}
\StringTok{    `}\DataTypeTok{/}\StringTok{`}\NormalTok{(}\KeywordTok{apply}\NormalTok{(., }\DecValTok{1}\NormalTok{, sum)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{as_tibble}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    `}\DataTypeTok{names<-}\StringTok{`}\NormalTok{(}\KeywordTok{str_c}\NormalTok{(}\StringTok{"C"}\NormalTok{, }\DecValTok{1}\OperatorTok{:}\NormalTok{K))}
  
  \ControlFlowTok{while}\NormalTok{ (}\OtherTok{TRUE}\NormalTok{) \{}
\NormalTok{    i <-}\StringTok{ }\NormalTok{i }\OperatorTok{+}\StringTok{ }\NormalTok{1L}
    
    \CommentTok{# [단계 1] M-step}
\NormalTok{    Mstep_res <-}\StringTok{ }\KeywordTok{GMM_Mstep}\NormalTok{(df, z_hat, modelName)}
    
    \CommentTok{# [단계 2] E-step}
\NormalTok{    new_z_hat <-}\StringTok{ }\KeywordTok{GMM_Estep}\NormalTok{(df, Mstep_res}\OperatorTok{$}\NormalTok{tau, Mstep_res}\OperatorTok{$}\NormalTok{mu, Mstep_res}\OperatorTok{$}\NormalTok{Sigma)}
    
    \CommentTok{# [단계 3] 수렴조건 확인}
    \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{max}\NormalTok{(}\KeywordTok{abs}\NormalTok{(z_hat }\OperatorTok{-}\StringTok{ }\NormalTok{new_z_hat)) }\OperatorTok{<}\StringTok{ }\NormalTok{tol) }\ControlFlowTok{break}
    
\NormalTok{    z_hat <-}\StringTok{ }\NormalTok{new_z_hat}
\NormalTok{  \}}
  
  \KeywordTok{return}\NormalTok{ (}\KeywordTok{list}\NormalTok{(}\DataTypeTok{z =}\NormalTok{ z_hat, }
               \DataTypeTok{parameters =}\NormalTok{ Mstep_res,}
               \DataTypeTok{n_iteration =}\NormalTok{ i))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 함수를 학습데이터 Table \ref{tab:model-based-clustering-data}에 적용한 결과는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{VII_res <-}\StringTok{ }\KeywordTok{GMM_EM}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], }\DecValTok{2}\NormalTok{, }\StringTok{"VII"}\NormalTok{)}

\CommentTok{# 군집 멤버쉽}
\NormalTok{VII_res}\OperatorTok{$}\NormalTok{z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             C1           C2
## 1 1.000000e+00 6.786307e-28
## 2 1.000000e+00 8.771316e-27
## 3 1.000000e+00 8.895007e-36
## 4 5.251505e-17 1.000000e+00
## 5 7.046079e-22 1.000000e+00
## 6 1.843399e-26 1.000000e+00
## 7 1.544788e-17 1.000000e+00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 혼합분포}
\NormalTok{VII_res}\OperatorTok{$}\NormalTok{parameters}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $tau
## $tau$C1
## [1] 0.4285714
## 
## $tau$C2
## [1] 0.5714286
## 
## 
## $mu
## $mu$C1
##        x1        x2 
##  5.333333 13.333333 
## 
## $mu$C2
##    x1    x2 
## 11.25  3.50 
## 
## 
## $Sigma
## $Sigma$C1
##          [,1]     [,2]
## [1,] 1.222222 0.000000
## [2,] 0.000000 1.222222
## 
## $Sigma$C2
##         [,1]    [,2]
## [1,] 0.96875 0.00000
## [2,] 0.00000 0.96875
\end{verbatim}

\hypertarget{r-packages-model-based-clustering}{%
\subsection{R 패키지 내 모형기반 군집분석}\label{r-packages-model-based-clustering}}

R 패키지 \texttt{mclust}를 통해, 위에서 살펴본 VII, VEI, VEE 외에 보다 다양한 분산-공분산 모형을 가정한 군집분석을 수행할 수 있다 \citep{scrucca2016mclust}. 다음은 ``EEI'' 구조에 대한 수행 예이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res_mclust_EEI <-}\StringTok{ }\NormalTok{mclust}\OperatorTok{::}\KeywordTok{meEEI}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], z_hat)}
\end{Highlighting}
\end{Shaded}

위 수행 결과 객체는 리스트 형태이며, 그 원소 중 \texttt{z}는 \(\hat{z}_{ik}\)값을, \texttt{parameters}는 혼합분포 파라미터 추정값 (\(\hat{\tau}_k\), \(\hat{\boldsymbol\mu}_k\), \(\hat{\boldsymbol\Sigma}_k\))을 나타낸다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res_mclust_EEI}\OperatorTok{$}\NormalTok{z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              [,1]         [,2]
## [1,] 6.198742e-26 1.000000e+00
## [2,] 2.193775e-22 1.000000e+00
## [3,] 1.432979e-28 1.000000e+00
## [4,] 1.000000e+00 3.497777e-20
## [5,] 1.000000e+00 1.350932e-26
## [6,] 1.000000e+00 5.217649e-33
## [7,] 1.000000e+00 9.883335e-24
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res_mclust_EEI}\OperatorTok{$}\NormalTok{parameters}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $pro
## [1] 0.5714286 0.4285714
## 
## $mean
##     [,1]      [,2]
## x1 11.25  5.333333
## x2  3.50 13.333333
## 
## $variance
## $variance$modelName
## [1] "EEI"
## 
## $variance$d
## [1] 2
## 
## $variance$G
## [1] 2
## 
## $variance$sigma
## , , 1
## 
##           x1       x2
## x1 0.7738095 0.000000
## x2 0.0000000 1.380952
## 
## , , 2
## 
##           x1       x2
## x1 0.7738095 0.000000
## x2 0.0000000 1.380952
## 
## 
## $variance$Sigma
##           x1       x2
## x1 0.7738095 0.000000
## x2 0.0000000 1.380952
## 
## $variance$scale
## [1] 1.033728
## 
## $variance$shape
## [1] 0.7485618 1.3358950
## 
## 
## $Vinv
## NULL
\end{verbatim}

\texttt{mclust} 패키지 내의 함수 \texttt{densityMclust}는 Bayesian information criterion (BIC)을 기준으로 최적의 혼합분포를 찾는 함수이다. 즉, 내부적으로 여러가지 분산-공분산 모형과 군집 수의 조합에 대한 군집분석을 수행한 뒤, 각 조합의 최종결과에서 얻어진 BIC 값을 기준으로 최적의 조합을 선정한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res_mclust_opt <-}\StringTok{ }\NormalTok{mclust}\OperatorTok{::}\KeywordTok{densityMclust}\NormalTok{(df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{verbose =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

함수 수행결과 객체의 \texttt{BIC} 원소가 나타내는 결과는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res_mclust_opt}\OperatorTok{$}\NormalTok{BIC}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Bayesian Information Criterion (BIC): 
##         EII       VII       EEI       VEI       EVI       VVI       EEE
## 1 -85.40006 -85.40006 -85.70851 -85.70851 -85.70851 -85.70851 -75.27433
## 2 -62.00992 -63.86240 -63.37677 -65.22485 -65.32204 -67.17013 -64.66516
## 3 -65.47796        NA -66.01911        NA        NA        NA -67.87781
## 4 -69.04346        NA -70.17240        NA        NA        NA -67.31282
## 5 -72.02226        NA -73.96817        NA        NA        NA        NA
## 6 -62.27998        NA -64.22589        NA        NA        NA        NA
## 7        NA        NA        NA        NA        NA        NA        NA
##         EVE       VEE       VVE       EEV       VEV       EVV       VVV
## 1 -75.27433 -75.27433 -75.27433 -75.27433 -75.27433 -75.27433 -75.27433
## 2 -65.06811 -66.60332 -66.92481 -65.42506 -67.34154 -66.55375 -68.44666
## 3        NA        NA        NA -71.48895        NA        NA        NA
## 4        NA        NA        NA        NA        NA        NA        NA
## 5        NA        NA        NA        NA        NA        NA        NA
## 6        NA        NA        NA        NA        NA        NA        NA
## 7        NA        NA        NA        NA        NA        NA        NA
## 
## Top 3 models based on the BIC criterion: 
##     EII,2     EII,6     EEI,2 
## -62.00992 -62.27998 -63.37677
\end{verbatim}

수행 결과 가장 큰 BIC 값을 지닌 최적의 조합은 EII 분산-공분산 모형으로 2개의 군집을 가정했을 때 얻어진다.

\texttt{densityMclust} 함수 수행 결과 얻어진 혼합분포를 plotting해보자.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{plot}\NormalTok{(res_mclust_opt, }\DataTypeTok{what =} \StringTok{"density"}\NormalTok{,}
     \DataTypeTok{data =}\NormalTok{ df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{points.cex =} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/mclust-opt-result-plot-1} 

}

\caption{mclust::densityMclust 수행 결과 얻어진 혼합분포}\label{fig:mclust-opt-result-plot}
\end{figure}

\hypertarget{cluster-solution-evaluation}{%
\chapter{군집해의 평가 및 해석}\label{cluster-solution-evaluation}}

군집분석 수행 시에는 분류분석과 달리 각 객체가 속하는 군집에 대하여 알려진 학습표본이 없기 때문에 어떤 군집해의 성능을 평가하기가 곤란하다. 각 객체가 이차원 또는 삼차원의 변수로 이루어진 경우에는 각 객체를 좌표축에 나타내어 도식화함으로써 어느 정도 군집해의 타당성을 정성적으로 평가가 가능할 것이나, 이보다 높은 차원의 경우에는 도식화가 불가능하다. 따라서 응용분야에 따라 전문가의 견해가 군집해의 평가에 필요할 수도 있다.

\hypertarget{cluster-solution-evaluation-packages-install}{%
\section{필요 R package 설치}\label{cluster-solution-evaluation-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.2.1\\
\hline
cluster & 2.0.8\\
\hline
flexclust & 1.4-0\\
\hline
clValid & 0.6-6\\
\hline
\end{tabular}

\hypertarget{cluster-solution-evaluation-metric}{%
\section{군집해의 평가}\label{cluster-solution-evaluation-metric}}

군집해의 정량적인 평가척도에 대한 연구는 지속적으로 이루어지고 있으며, 크게 외부평가지수(external index)와 내부평가지수(internal index)로 구분되고 있다.

\hypertarget{cluster-evaluation-external-index}{%
\subsection{외부평가지수}\label{cluster-evaluation-external-index}}

이미 잘 알려진 군집해가 있다고 가정할 때, 새로 제안된 군집해를 기존에 알려진 군집해와 비교하는 평가척도이다.

\(n\)개의 객체에 대하여 알려진 기준 군집해를 다음과 같다고 하자.

\begin{equation*}
\mathbf{U} = \{ U_1, U_2, \cdots, U_r \}
\end{equation*}

즉, 기준 군집해 \(\mathbf{U}\)는 \(r\)개의 군집으로 구성되며, \(k\)번째 군집을 \(U_k\)로 나타낸다.

유사하게, 비교 대상의 군집해를 다음과 같이 \(s\)개의 군집으로 구성된 \(\mathbf{V}\)로 나타내자.

\begin{equation*}
\mathbf{V} = \{ V_1, V_2, \cdots, V_s \}
\end{equation*}

\hypertarget{cluster-external-index-basic-script}{%
\subsubsection{기본 R 스크립트}\label{cluster-external-index-basic-script}}

다음의 두 군집해 간의 유사도를 랜드지수 및 수정랜드지수를 이용하여 표현할 수 있다.

\begin{eqnarray*}
U &=& \{ \{1, 2, 3, 4\}, \{5, 6, 7\}, \{8, 9, 10\} \}\\
V &=& \{ \{1, 2, 5, 8\}, \{3, 6, 9\}, \{4, 7, 10\} \}
\end{eqnarray*}

랜드지수 및 수정랜드지수는 \texttt{flexclust} 패키지의 \texttt{randIndex} 함수를 호출하여 계산할 수 있으며, 랜드지수를 계산할 때는 \texttt{correct\ =\ FALSE}, 수정랜드지수를 계산할 때는 \texttt{correct\ =\ TRUE}로 파라미터 값을 지정하여야 한다. 파라미터값을 지정하지 않을 때는 기본값으로 수정랜드지수를 계산한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sol_}\DecValTok{1}\NormalTok{ <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{sol_}\DecValTok{2}\NormalTok{ <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\KeywordTok{map}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\OtherTok{FALSE}\NormalTok{, }\OtherTok{TRUE}\NormalTok{), }
    \OperatorTok{~}\StringTok{ }\NormalTok{flexclust}\OperatorTok{::}\KeywordTok{randIndex}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sol_}\DecValTok{1}\NormalTok{, }\DataTypeTok{y =}\NormalTok{ sol_}\DecValTok{2}\NormalTok{, }\DataTypeTok{correct =}\NormalTok{ .x))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
##        RI 
## 0.5111111 
## 
## [[2]]
##   ARI 
## -0.25
\end{verbatim}

\hypertarget{cluster-external-rand-index}{%
\subsubsection{랜드지수}\label{cluster-external-rand-index}}

두 군집해 \(U, V\) 내 에서 각 객체가 속한 군집을 나타내기 위한membership 변수를 아래와 같이 정의하자.

\begin{equation*}
u_{ik} = \begin{cases}
1 & \text{ if object $i$ belongs to cluster $U_k$, i.e. } i \in U_k \\
0 & \text{ otherwise}
\end{cases}, \, i = 1, \cdots, n, \, k = 1, \cdots, r
\end{equation*}

\begin{equation*}
v_{ik} = \begin{cases}
1 & \text{ if object $i$ belongs to cluster $V_k$, i.e. } i \in V_k \\
0 & \text{ otherwise}
\end{cases}, \, i = 1, \cdots, n, \, k = 1, \cdots, s
\end{equation*}

랜드지수를 산출하기 위해, 우선 다음과 같은 네 가지 값을 정의한다.

\begin{eqnarray*}
a &=& \sum_{i = 1}^{n - 1} \sum_{j = i + 1}^{n} \sum_{k = 1}^{r} \sum_{l = 1}^{s} u_{ik} u_{jk} v_{il} v_{jl}\\
b &=& \sum_{i = 1}^{n - 1} \sum_{j = i + 1}^{n} \sum_{k = 1}^{r} \sum_{l = 1}^{s} u_{ik} u_{jk} v_{il} (1 - v_{jl})\\
c &=& \sum_{i = 1}^{n - 1} \sum_{j = i + 1}^{n} \sum_{k = 1}^{r} \sum_{l = 1}^{s} u_{ik} (1 - u_{jk}) v_{il} v_{jl}\\
d &=& \sum_{i = 1}^{n - 1} \sum_{j = i + 1}^{n} \sum_{k = 1}^{r} \sum_{l = 1}^{s} u_{ik} (1 - u_{jk}) v_{il} (1 - v_{jl})
\end{eqnarray*}

이 때, \citet{rand1971objective} 가 제안한 랜드지수(Rand index)는 다음과 같이 정의된다.

\begin{equation}
RI = \frac{a + d}{a + b + c + d} \label{eq:rand-index}
\end{equation}

여기서, \(a + b + c + d\)는 객체 쌍의 전체 수를 의미하므로 다음과 같다.

\begin{equation*}
a + b + c + d = {n \choose 2}
\end{equation*}

식 \eqref{eq:rand-index}는 0에서 1 사이의 값을 갖게 되며, 0에 가까울수록 두 군집해가 일치하지 않음을, 1에 가까울수록 두 군집해가 일치함을 나타낸다. 또한 랜드지수는 랜덤하게 작성한 두 군집해 간의 유사도의 기대값이 0보다 크다.

\citet{hubert1985comparing} 는 수정랜드지수(adjusted Rand index)를 아래와 같이 제안하였다.

\begin{equation}
RI_{adj} = \frac{2 (ad - bc)}{(a + b)(b + d) + (a + c)(c + d)} \label{eq:adj-rand-index}
\end{equation}

식 \eqref{eq:adj-rand-index}는 랜덤한 군집해 간의 비교의 경우 0에 가까운 값을 갖는다.

아래 구현한 \texttt{rand\_index} 함수는 임의의 두 군집해 \texttt{u}와 \texttt{v}에 대한 랜드지수 및 수정랜드지수를 계산하는 함수이다.

\begin{itemize}
\tightlist
\item
  \texttt{u}, \texttt{v}: 서로 비교할 두 개의 군집해 벡터. 각 원소값은 각 객체가 속한 군집을 나타낸다.
\item
  다음과 같은 두 개의 component를 지닌 list를 리턴한다.

  \begin{itemize}
  \tightlist
  \item
    \texttt{ri}: 랜드지수
  \item
    \texttt{adj\_ri}: 수정랜드지수
  \end{itemize}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rand_index <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(u, v) \{}
  \ControlFlowTok{if}\NormalTok{ (}\OperatorTok{!}\KeywordTok{is_vector}\NormalTok{(u) }\OperatorTok{||}\StringTok{ }\OperatorTok{!}\KeywordTok{is_vector}\NormalTok{(v)) \{}
    \KeywordTok{stop}\NormalTok{(}\StringTok{"Input needs to be vector"}\NormalTok{)}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{length}\NormalTok{(u) }\OperatorTok{!=}\StringTok{ }\KeywordTok{length}\NormalTok{(v)) \{}
    \KeywordTok{stop}\NormalTok{(}\StringTok{"Vectors u and v must have the same length."}\NormalTok{)}
\NormalTok{  \}}
  
\NormalTok{  U <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
    \DataTypeTok{i =} \KeywordTok{seq_along}\NormalTok{(u),}
    \DataTypeTok{cluster =}\NormalTok{ u}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{inner_join}\NormalTok{(}
      \KeywordTok{rename}\NormalTok{(., }\DataTypeTok{j =}\NormalTok{ i),}
      \DataTypeTok{by =} \StringTok{"cluster"}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{cluster) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(i }\OperatorTok{<}\StringTok{ }\NormalTok{j) }
  
\NormalTok{  V <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
    \DataTypeTok{i =} \KeywordTok{seq_along}\NormalTok{(v),}
    \DataTypeTok{cluster =}\NormalTok{ v}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{inner_join}\NormalTok{(}
      \KeywordTok{rename}\NormalTok{(., }\DataTypeTok{j =}\NormalTok{ i),}
      \DataTypeTok{by =} \StringTok{"cluster"}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{cluster) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(i }\OperatorTok{<}\StringTok{ }\NormalTok{j) }
  
\NormalTok{  a <-}\StringTok{ }\KeywordTok{nrow}\NormalTok{(}\KeywordTok{inner_join}\NormalTok{(U, V, }\DataTypeTok{by =} \KeywordTok{c}\NormalTok{(}\StringTok{"i"}\NormalTok{, }\StringTok{"j"}\NormalTok{)))}
\NormalTok{  b <-}\StringTok{ }\KeywordTok{nrow}\NormalTok{(}\KeywordTok{anti_join}\NormalTok{(U, V, }\DataTypeTok{by =} \KeywordTok{c}\NormalTok{(}\StringTok{"i"}\NormalTok{, }\StringTok{"j"}\NormalTok{)))}
\NormalTok{  c <-}\StringTok{ }\KeywordTok{nrow}\NormalTok{(}\KeywordTok{anti_join}\NormalTok{(V, U, }\DataTypeTok{by =} \KeywordTok{c}\NormalTok{(}\StringTok{"i"}\NormalTok{, }\StringTok{"j"}\NormalTok{)))}
\NormalTok{  d <-}\StringTok{ }\KeywordTok{choose}\NormalTok{(}\KeywordTok{length}\NormalTok{(u), }\DecValTok{2}\NormalTok{) }\OperatorTok{-}\StringTok{ }\NormalTok{(a }\OperatorTok{+}\StringTok{ }\NormalTok{b }\OperatorTok{+}\StringTok{ }\NormalTok{c)}
  
\NormalTok{  ri <-}\StringTok{ }\NormalTok{(a }\OperatorTok{+}\StringTok{ }\NormalTok{d) }\OperatorTok{/}\StringTok{ }\NormalTok{(a }\OperatorTok{+}\StringTok{ }\NormalTok{b }\OperatorTok{+}\StringTok{ }\NormalTok{c }\OperatorTok{+}\StringTok{ }\NormalTok{d)}
\NormalTok{  adj_ri <-}\StringTok{ }\DecValTok{2} \OperatorTok{*}\StringTok{ }\NormalTok{(a }\OperatorTok{*}\StringTok{ }\NormalTok{d }\OperatorTok{-}\StringTok{ }\NormalTok{b }\OperatorTok{*}\StringTok{ }\NormalTok{c) }\OperatorTok{/}\StringTok{ }
\StringTok{    }\NormalTok{((a }\OperatorTok{+}\StringTok{ }\NormalTok{b) }\OperatorTok{*}\StringTok{ }\NormalTok{(b }\OperatorTok{+}\StringTok{ }\NormalTok{d) }\OperatorTok{+}\StringTok{ }\NormalTok{(a }\OperatorTok{+}\StringTok{ }\NormalTok{c) }\OperatorTok{*}\StringTok{ }\NormalTok{(c }\OperatorTok{+}\StringTok{ }\NormalTok{d))}

  \KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}\DataTypeTok{ri =}\NormalTok{ ri, }\DataTypeTok{adj_ri =}\NormalTok{ adj_ri))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

50개의 객체에 대해 랜덤하게 할당된 군집해(\texttt{K\ =\ 3}) 두 개를 비교하여 랜드지수와 수정랜드지수를 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{random_rand_index <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(n, r, s) \{}
\NormalTok{  u <-}\StringTok{ }\KeywordTok{sample.int}\NormalTok{(r, }\DataTypeTok{size =}\NormalTok{ n, }\DataTypeTok{replace =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{  v <-}\StringTok{ }\KeywordTok{sample.int}\NormalTok{(s, }\DataTypeTok{size =}\NormalTok{ n, }\DataTypeTok{replace =} \OtherTok{TRUE}\NormalTok{)}
  \KeywordTok{rand_index}\NormalTok{(u, v)}
\NormalTok{\}}

\KeywordTok{set.seed}\NormalTok{(}\DecValTok{500}\NormalTok{)}

\KeywordTok{rerun}\NormalTok{(}\DecValTok{200}\NormalTok{, }\KeywordTok{random_rand_index}\NormalTok{(}\DecValTok{50}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_rows}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{gather}\NormalTok{(}\DataTypeTok{key =} \StringTok{"metric"}\NormalTok{, }\DataTypeTok{value =} \StringTok{"value"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ value, }\DataTypeTok{fill =}\NormalTok{ metric)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \FloatTok{0.05}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{limits =} \KeywordTok{c}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_fill_discrete}\NormalTok{(}
    \DataTypeTok{name =} \StringTok{"index"}\NormalTok{,}
    \DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\StringTok{"ri"}\NormalTok{, }\StringTok{"adj_ri"}\NormalTok{),}
    \DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Rand Index"}\NormalTok{, }\StringTok{"adjusted Rand Index"}\NormalTok{)}
\NormalTok{  ) }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}
    \DataTypeTok{title =} \StringTok{"Distribution of index values from 200 random assignments"}\NormalTok{,}
    \DataTypeTok{x =} \StringTok{"index value"}\NormalTok{,}
    \DataTypeTok{y =} \StringTok{"frequency"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Removed 4 rows containing missing values (geom_bar).
\end{verbatim}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/rand-index-random-1} 

}

\caption{랜덤한 군집해 간 비교: 랜드지수 및 수정랜드지수}\label{fig:rand-index-random}
\end{figure}

Figure \ref{fig:rand-index-random}에 보이듯이, 랜덤한 군집해 간 비교에서 랜드지수는 0보다 큰 값을 나타내는 반면, 수정랜드지수는 0을 중심으로 분포되어 있다.

다음의 두 군집해에 대하여 랜드지수와 수정랜드지수를 구해보자.

\begin{eqnarray*}
U &=& \{(1, 2, 3, 4), (5, 6, 7), (8, 9, 10) \}\\
V &=& \{(1, 2, 5, 8), (3, 6, 9), (4, 7, 10) \}
\end{eqnarray*}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rand_index}\NormalTok{(}
  \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{),}
  \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $ri
## [1] 0.5111111
## 
## $adj_ri
## [1] -0.25
\end{verbatim}

\hypertarget{cluster-evaluation-internal-index}{%
\subsection{내부평가지수}\label{cluster-evaluation-internal-index}}

군집해에 대한 내부평가지수는 외부 정보의 도움 없이 입력 데이터만으로 군집해를 평가하는 척도로써, 주로 밀집성(compactness), 연결성(connectedness), 분리성(spatial separation) 등 세 가지 관점에서 평가한다.

우선 \(K\)개의 군집으로 이루어진 군집해 \(C\)가 다음과 같다고 하자.

\begin{equation*}
C = \{ C_1, C_2, \cdots, C_K \}
\end{equation*}

\hypertarget{cluster-evaluation-internal-index-basic-script}{%
\subsubsection{기본 R 스크립트}\label{cluster-evaluation-internal-index-basic-script}}

아래와 같이 두 개의 변수 \(x_1\) 및 \(x_2\)로 표현되는 객체 데이터에 대해 군집을 찾고자 한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{id, }\OperatorTok{~}\NormalTok{x1, }\OperatorTok{~}\NormalTok{x2,}
  \DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{15}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{13}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{13}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{17}\NormalTok{, }\DecValTok{17}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{11}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{12}\NormalTok{,}
  \DecValTok{8}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{6}
\NormalTok{)}

\NormalTok{df }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{, }\StringTok{'r'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}
      \StringTok{'객체번호'}\NormalTok{, }
      \StringTok{'$x_1$'}\NormalTok{, }\StringTok{'$x_2$'}
\NormalTok{      ),}
    \DataTypeTok{caption =} \StringTok{'군집 대상 데이터'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:cluster-eval-data}군집 대상 데이터}
\centering
\begin{tabular}{rrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$\\
\midrule
1 & 4 & 15\\
2 & 20 & 13\\
3 & 3 & 13\\
4 & 19 & 4\\
5 & 17 & 17\\
\addlinespace
6 & 8 & 11\\
7 & 19 & 12\\
8 & 18 & 6\\
\bottomrule
\end{tabular}
\end{table}

위 데이터에 대해 다음과 같은 두 개의 다른 군집해를 얻었다고 하자.

\begin{equation}
\begin{split}
U =& \{ \{1, 3, 6\}, \{2, 5, 7\}, \{4, 8\} \}\\
V =& \{ \{1, 3, 6\}, \{2, 4, 5, 7, 8\} \}
\end{split}
\label{eq:cluster-eval-two-solutions}
\end{equation}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sol_}\DecValTok{1}\NormalTok{ <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{sol_}\DecValTok{2}\NormalTok{ <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

본 장에서는 4가지 내부 평가지수를 다룬다. 아래는 R 패키지들에 속한 각각의 함수를 실행하여 그 결과를 리스트 형태로 리턴하는 사용자 정의 함수 \texttt{cluster\_eval}를 구현한 것이다. 해당 함수에서 호출하는 R 패키지 함수들은 아래와 같다.

\begin{itemize}
\tightlist
\item
  Dunn index \citep{dunn1973fuzzy}: \texttt{clValid::dunn}
\item
  CH index \citep{calinski1974dendrite}: \texttt{fpc::calinhara}
\item
  Connectivity \citep{handl2005exploiting}: \texttt{clValid::connectivity}
\item
  Silhouettes \citep{rousseeuw1987silhouettes}: \texttt{cluster::silhouette}
\end{itemize}

각각의 평가지수에 대한 자세한 설명은 다음 장에서 하기로 한다.

아래 구현한 사용자 정의함수는 아래와 같은 입력 파라미터를 요구한다.

\begin{itemize}
\tightlist
\item
  \texttt{cluster}: 군집 해를 나타내는 길이 \(n\), 최대값 \(K\)의 정수형 벡터
\item
  \texttt{df}: 군집 데이터
\item
  \texttt{dist\_method}: 거리 척도; Dunn, Connectivity, Silhouettes 지수 측정에 사용된다.
\item
  \texttt{nn}: 최근 객체 수 (\textgreater{}= 2); Connectivity 측정에 사용된다.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster_eval <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(cluster, df, }\DataTypeTok{dist_method =} \StringTok{"euclidean"}\NormalTok{, }\DataTypeTok{nn =} \DecValTok{2}\NormalTok{) \{}
\NormalTok{  dunn_index <-}\StringTok{ }\NormalTok{clValid}\OperatorTok{::}\KeywordTok{dunn}\NormalTok{(}
    \DataTypeTok{Data =}\NormalTok{ df, }
    \DataTypeTok{clusters =}\NormalTok{ cluster, }
    \DataTypeTok{method =}\NormalTok{ dist_method}
\NormalTok{  )}
  
\NormalTok{  ch_index <-}\StringTok{ }\NormalTok{fpc}\OperatorTok{::}\KeywordTok{calinhara}\NormalTok{(}
    \DataTypeTok{x =}\NormalTok{ df, }
    \DataTypeTok{clustering =}\NormalTok{ cluster}
\NormalTok{  )}
  
\NormalTok{  connectivity <-}\StringTok{ }\NormalTok{clValid}\OperatorTok{::}\KeywordTok{connectivity}\NormalTok{(}
    \DataTypeTok{Data =}\NormalTok{ df, }
    \DataTypeTok{clusters =}\NormalTok{ cluster, }
    \DataTypeTok{neighbSize =}\NormalTok{ nn}
\NormalTok{  )}
  
\NormalTok{  asw <-}\StringTok{ }\NormalTok{cluster}\OperatorTok{::}\KeywordTok{silhouette}\NormalTok{(}
    \DataTypeTok{x =}\NormalTok{ cluster, }
    \DataTypeTok{dist =} \KeywordTok{dist}\NormalTok{(df, }\DataTypeTok{method =}\NormalTok{ dist_method)}
\NormalTok{  )[, }\StringTok{"sil_width"}\NormalTok{] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mean}\NormalTok{()}
  
  \KeywordTok{return}\NormalTok{(}\KeywordTok{list}\NormalTok{(}
    \DataTypeTok{dunn_index =}\NormalTok{ dunn_index,}
    \DataTypeTok{ch_index =}\NormalTok{ ch_index,}
    \DataTypeTok{connectivity =}\NormalTok{ connectivity,}
    \DataTypeTok{asw =}\NormalTok{ asw}
\NormalTok{  ))}
\NormalTok{\}}

\KeywordTok{map_dfr}\NormalTok{(}\KeywordTok{list}\NormalTok{(sol_}\DecValTok{1}\NormalTok{, sol_}\DecValTok{2}\NormalTok{), cluster_eval, }\DataTypeTok{df =}\NormalTok{ df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{.id =} \StringTok{"solution"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 5
##   solution dunn_index ch_index connectivity   asw
##   <chr>         <dbl>    <dbl>        <dbl> <dbl>
## 1 1             1.08      26.5            1 0.651
## 2 2             0.822     15.4            0 0.586
\end{verbatim}

\hypertarget{cluster-evaluation-internal-index-explanation}{%
\subsubsection{대표 내부평가지수}\label{cluster-evaluation-internal-index-explanation}}

\citet{dunn1973fuzzy} 은 아래와 같은 지수를 제안하였다.

\begin{equation}
DI = \frac{\min_{\mathbf{x} \in C_i, \, \mathbf{y} \in C_j \, 1 \leq i \neq j \leq K} d(\mathbf{x}, \mathbf{y})}{\max_{\mathbf{x} \in C_i, \mathbf{y} \in C_i, \, 1 \leq i \leq K} d(\mathbf{x}, \mathbf{y})} \label{eq:cluster-dunn-index}
\end{equation}

여기서 분자는 군집 간의 분리성(클수록 분리성이 큼), 분모는 군집의 밀집성(작을수록 밀집성이 높음)을 반영하는 것이라 볼 수 있다. 따라서 분리성과 밀집성이 높을 때 식 \eqref{eq:cluster-dunn-index}는 큰 값을 갖게 되며 해당 군집해가 상대적으로 좋게 평가된다.

군집해로부터 식 \eqref{eq:cluster-dunn-index}를 계산하는 함수 \texttt{dunn\_index}를 아래와 같이 구현해보자. 입력 파라미터는 아래와 같다.

\begin{itemize}
\tightlist
\item
  \texttt{cluster}: 각 객체가 속한 군집을 나타내는 길이 \(n\)의 벡터
\item
  \texttt{df}: 객체 데이터를 나타내는 \(n\)행의 프레임
\item
  \texttt{dist\_method}: \texttt{base::dist} 함수의 \texttt{method} 파라미터값으로 사용할 거리 척도
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dunn_index <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(cluster, df, }\DataTypeTok{dist_method =} \StringTok{"euclidean"}\NormalTok{) \{}
  \CommentTok{# 객체 수}
\NormalTok{  n <-}\StringTok{ }\KeywordTok{nrow}\NormalTok{(df)}
  
  \CommentTok{# 각 객체의 군집해}
\NormalTok{  cluster_df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
    \DataTypeTok{id =} \DecValTok{1}\OperatorTok{:}\NormalTok{n,}
    \DataTypeTok{cluster =}\NormalTok{ cluster}
\NormalTok{  )}
  
  \CommentTok{# 각 객체 간 거리 데이터 프레임}
  \CommentTok{# 위 군집해 데이터 프레임과 `inner_join` 을 통해}
  \CommentTok{# 두 객체가 동일 군집에 속하는지 서로 다른 군집에 속하는 지 표현}
\NormalTok{  dist_df <-}\StringTok{ }\KeywordTok{dist}\NormalTok{(df, }\DataTypeTok{method =}\NormalTok{ dist_method, }\DataTypeTok{upper =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{inner_join}\NormalTok{(}
\NormalTok{      cluster_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{item1 =}\NormalTok{ id, }\DataTypeTok{item1_cluster =}\NormalTok{ cluster),}
      \DataTypeTok{by =} \StringTok{"item1"}
\NormalTok{      ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{inner_join}\NormalTok{(}
\NormalTok{      cluster_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{item2 =}\NormalTok{ id, }\DataTypeTok{item2_cluster =}\NormalTok{ cluster),}
      \DataTypeTok{by =} \StringTok{"item2"}
\NormalTok{    )}
  
  \CommentTok{# 서로 다른 군집에 속한 객체 쌍 중}
  \CommentTok{# 가장 가까운 객체 간의 거리}
\NormalTok{  numerator <-}\StringTok{ }\NormalTok{dist_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(item1_cluster }\OperatorTok{!=}\StringTok{ }\NormalTok{item2_cluster) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{top_n}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, distance) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\NormalTok{.}\OperatorTok{$}\NormalTok{distance}
  
  \CommentTok{# 서로 같은 군집에 속한 객체 쌍 중}
  \CommentTok{# 가장 먼 객체 간의 거리}
\NormalTok{  denominator <-}\StringTok{ }\NormalTok{dist_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(item1_cluster }\OperatorTok{==}\StringTok{ }\NormalTok{item2_cluster) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{top_n}\NormalTok{(}\DecValTok{1}\NormalTok{, distance) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\NormalTok{.}\OperatorTok{$}\NormalTok{distance}
  
\NormalTok{  res <-}\StringTok{ }\NormalTok{numerator }\OperatorTok{/}\StringTok{ }\NormalTok{denominator}
  
  \KeywordTok{return}\NormalTok{(res)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{map_dbl}\NormalTok{(}\KeywordTok{list}\NormalTok{(sol_}\DecValTok{1}\NormalTok{, sol_}\DecValTok{2}\NormalTok{), dunn_index, }\DataTypeTok{df =}\NormalTok{ df[, }\DecValTok{-1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.075291 0.822375
\end{verbatim}

\citet{calinski1974dendrite} 는 다음과 같은 지수를 제안하였다.

\begin{equation}
CH = \frac{\frac{1}{K - 1} \sum_{k = 1}^{K} n_k (\mathbf{c}_k - \mathbf{c})^\top (\mathbf{c}_k - \mathbf{c})}{\frac{1}{n - K} \sum_{k = 1}^{K} \sum_{i \in C_k} (\mathbf{x}_i - \mathbf{c}_k)^\top (\mathbf{x}_i - \mathbf{c}_k)} \label{eq:cluster-ch-index}
\end{equation}

여기에서 \(\mathbf{c}_k\)는 군집 \(k\)의 중심좌표(centroid), \(\mathbf{c}\)는 전체 객체들의 중심좌표, \(n_k\)는 군집 \(C_k\)내의 객체 수, \(n\)은 전체 객체 수를 나타낸다. 식 \eqref{eq:cluster-ch-index} 또한 분자는 분리성, 분모는 밀집성을 평가하며, 값이 클수록 좋은 군집해로 평가된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ch_index <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(cluster, df) \{}
  \CommentTok{# 전체 데이터 중심}
\NormalTok{  centroid <-}\StringTok{ }\NormalTok{df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{summarize_all}\NormalTok{(mean)}
  
\NormalTok{  cluster_df <-}\StringTok{ }\NormalTok{df }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{cluster =}\NormalTok{ cluster) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(cluster) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{nest}\NormalTok{()}
  
  \CommentTok{# 군집 중심}
\NormalTok{  cluster_centroid_df <-}\StringTok{ }\KeywordTok{map_dfr}\NormalTok{(cluster_df}\OperatorTok{$}\NormalTok{data, }\OperatorTok{~}\StringTok{ }\KeywordTok{summarize_all}\NormalTok{(., mean))}
  
  \CommentTok{# 각 군집 중심과 전체 데이터 중심 간 제곱 유클리드 거리}
\NormalTok{  centroid_dist <-}\StringTok{ }\NormalTok{flexclust}\OperatorTok{::}\KeywordTok{dist2}\NormalTok{(}
\NormalTok{    cluster_centroid_df, }
\NormalTok{    centroid}
\NormalTok{    )}\OperatorTok{^}\DecValTok{2}
  
  \CommentTok{# 각 군집 크기}
\NormalTok{  cluster_size <-}\StringTok{ }\KeywordTok{map_dbl}\NormalTok{(cluster_df}\OperatorTok{$}\NormalTok{data, nrow)}
  
\NormalTok{  numerator <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(centroid_dist }\OperatorTok{*}\StringTok{ }\NormalTok{cluster_size) }\OperatorTok{/}\StringTok{ }\NormalTok{(}\KeywordTok{nrow}\NormalTok{(cluster_df) }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)}
  
\NormalTok{  denominator <-}\StringTok{ }\KeywordTok{map_dbl}\NormalTok{(}
\NormalTok{    cluster_df}\OperatorTok{$}\NormalTok{data,}
    \CommentTok{# 각 군집 내의 객체와 군집 중심 간 제곱 유클리드 거리의 합}
    \OperatorTok{~}\StringTok{ }\NormalTok{flexclust}\OperatorTok{::}\KeywordTok{dist2}\NormalTok{(., }\KeywordTok{summarize_all}\NormalTok{(., mean))}\OperatorTok{^}\DecValTok{2} \OperatorTok{%>%}\StringTok{ }\KeywordTok{sum}\NormalTok{()}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{sum}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    `}\DataTypeTok{/}\StringTok{`}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(df) }\OperatorTok{-}\StringTok{ }\KeywordTok{nrow}\NormalTok{(cluster_df))}

\NormalTok{  res <-}\StringTok{ }\NormalTok{numerator }\OperatorTok{/}\StringTok{ }\NormalTok{denominator}
  
  \KeywordTok{return}\NormalTok{(res)}
\NormalTok{\}}

\KeywordTok{map_dbl}\NormalTok{(}\KeywordTok{list}\NormalTok{(sol_}\DecValTok{1}\NormalTok{, sol_}\DecValTok{2}\NormalTok{), ch_index, }\DataTypeTok{df =}\NormalTok{ df[, }\DecValTok{-1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 26.45029 15.36218
\end{verbatim}

\citet{handl2005exploiting} 은 연결성을 반영한 아래와 같은 지수를 제시하고 있다.

\begin{equation}
Conn = \sum_{i = 1}^{n} \sum_{j = 1}^{L} v_{i, nn_{i}(j)} \label{eq:cluster-connectivity}
\end{equation}

이 때, \(nn_{i}(j)\)는 객체 \(i\)의 \(j\)번째 최근 객체(nearest neighbor)를 나타내며, \(L\)은 연결성 척도 측정을 위한 사용자 지정 파라미터값이다. 또한 변수 \(v_{i, nn_i(j)}\)는 아래와 같이 정의된다.

\begin{equation*}
v_{i, nn_i(j)} = \begin{cases}
0 & \text{ if } \exists C_k : i, nn_i(j) \in C_k \\
1 / j & \text{ otherwise} 
\end{cases}
\end{equation*}

즉, 식 \eqref{eq:cluster-connectivity}는 각 객체가 \(j (\leq L)\)번째 최근 객체와 다른 객체에 속하면 \(1 / j\)의 벌점을 부여하는 방식으로, 작은 값일수록 좋은 군집으로 평가될 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{connectivity <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(cluster, df, }\DataTypeTok{dist_method =} \StringTok{"euclidean"}\NormalTok{, }\DataTypeTok{n_neighbor =} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  n <-}\StringTok{ }\KeywordTok{nrow}\NormalTok{(df)}
  
\NormalTok{  cluster_df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
    \DataTypeTok{id =} \DecValTok{1}\OperatorTok{:}\NormalTok{n,}
    \DataTypeTok{cluster =}\NormalTok{ cluster}
\NormalTok{  )}

  \CommentTok{# 객체간 거리}
\NormalTok{  distance_df <-}\StringTok{ }\KeywordTok{dist}\NormalTok{(df, }\DataTypeTok{method =}\NormalTok{ dist_method, }\DataTypeTok{upper =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{()}
  
  \CommentTok{# 최근 객체}
\NormalTok{  nn_df <-}\StringTok{ }\NormalTok{distance_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(item1) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{nearest =} \KeywordTok{rank}\NormalTok{(distance, }\DataTypeTok{ties.method =} \StringTok{"random"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(nearest }\OperatorTok{<=}\StringTok{ }\NormalTok{n_neighbor) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{inner_join}\NormalTok{(}
\NormalTok{      cluster_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{item1 =}\NormalTok{ id, }\DataTypeTok{item1_cluster =}\NormalTok{ cluster),}
      \DataTypeTok{by =} \StringTok{"item1"}
\NormalTok{      ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{inner_join}\NormalTok{(}
\NormalTok{      cluster_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{item2 =}\NormalTok{ id, }\DataTypeTok{item2_cluster =}\NormalTok{ cluster),}
      \DataTypeTok{by =} \StringTok{"item2"}
\NormalTok{    )}
  
  \CommentTok{# 연결성 계산}
\NormalTok{  nn_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(item1_cluster }\OperatorTok{!=}\StringTok{ }\NormalTok{item2_cluster) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{v =} \DecValTok{1} \OperatorTok{/}\StringTok{ }\NormalTok{nearest) }\OperatorTok{%>%}
\StringTok{    }\NormalTok{.}\OperatorTok{$}\NormalTok{v }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{sum}\NormalTok{()}
  
\NormalTok{\}}

\KeywordTok{map_dbl}\NormalTok{(}\KeywordTok{list}\NormalTok{(sol_}\DecValTok{1}\NormalTok{, sol_}\DecValTok{2}\NormalTok{), connectivity, }\DataTypeTok{df =}\NormalTok{ df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{n_neighbor =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{map_dbl}\NormalTok{(}\KeywordTok{list}\NormalTok{(sol_}\DecValTok{1}\NormalTok{, sol_}\DecValTok{2}\NormalTok{), connectivity, }\DataTypeTok{df =}\NormalTok{ df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{n_neighbor =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 0
\end{verbatim}

\citet{rousseeuw1987silhouettes} 은 실루엣(silhouettes)이라는 내부평가지수를 제안하였다. 우선 다음과 같은 기호를 정의하자.

\begin{itemize}
\tightlist
\item
  \(a(i)\): 객체 \(i\)와 동일 군집에 속한 다른 객체들과의 평균 거리
\item
  \(d(i, C_k)\): 객체 \(i\)와 다른 군집 \(C_k\)에 속한 모든 객체들과의 평균 거리, \(i \notin C_k\)
\item
  \(b(i) = \min_{k: i \notin C_k} d(i, C_k)\)
\end{itemize}

객체의 군집 멤버쉽 변수 \(z_{ik}\)를

\begin{equation*}
z_{ik} = \begin{cases}
1 & \text{ if } i \in C_k\\
0 & \text{ otherwise }
\end{cases}
\end{equation*}

라 정의하면, 위 \(a(i)\)와 \(b(i)\)를 아래와 같이 수식화할 수 있다.

\begin{eqnarray*}
a(i) &=& \sum_{k = 1}^{K} z_{ik} \frac{\sum_{j \neq i} z_{jk} d(\mathbf{x}_i, \mathbf{x}_j)}{\sum_{j \neq i} z_{jk}}\\
b(i) &=& \max_{k: z_{ik} \neq 1} \frac{\sum_{j \neq i} z_{jk} d(\mathbf{x}_i, \mathbf{x}_j)}{\sum_{j \neq i} z_{jk}}
\end{eqnarray*}

이 때 객체 \(i\)에 대한 실루엣은 아래와 같이 정의된다.

\begin{equation}
s(i) = \frac{b(i) - a(i)}{\max \{ a(i), b(i) \}} \label{eq:cluster-silhouette}
\end{equation}

식 \eqref{eq:cluster-silhouette}은 -1과 1 사이의 값을 갖는데, 1에 가까울수록 객체 \(i\)가 비슷한 객체들과 군집된 것으로, -1에 가까울수록 먼 객체들과 군집된 것으로 판단할 수 있다.

객체 \(i\)가 어떠한 다른 객체와도 같은 군집에 속하지 않는 경우가 발생할 수 있다 (\(i \in C_k, \, \left| C_k \right| = 1\)). 이 경우 \(a(i)\)가 정의되지 않으므로 \(s(i)\)값이 식 \eqref{eq:cluster-silhouette}에 의해서 정의되지 않는다. 이러한 경우에는 \(s(i) = 0\)이라고 실루엣을 정의한다.

\begin{equation}
s(i) = \begin{cases}
\frac{b(i) - a(i)}{\max \{ a(i), b(i) \}} & \text{ if $a(i)$ is defined}\\
0 & \text{ otherwise }
\end{cases}
\label{eq:cluster-silhouette-single}
\end{equation}

이후 군집해의 평가지표로써 평균실루엣(overall average silhouette width; ASW)을 다음과 같이 정의하여 사용한다.

\begin{equation}
ASW = \frac{1}{n} \sum_{i = 1}^{n} s(i) \label{eq:cluster-average-silhouette}
\end{equation}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{asw <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(cluster, df, }\DataTypeTok{dist_method =} \StringTok{"euclidean"}\NormalTok{) \{}
\NormalTok{  n <-}\StringTok{ }\KeywordTok{nrow}\NormalTok{(df)}
  
\NormalTok{  cluster_df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
    \DataTypeTok{id =} \DecValTok{1}\OperatorTok{:}\NormalTok{n,}
    \DataTypeTok{cluster =}\NormalTok{ cluster}
\NormalTok{  )}
  
\NormalTok{  dist_df <-}\StringTok{ }\KeywordTok{dist}\NormalTok{(df, }\DataTypeTok{method =}\NormalTok{ dist_method, }\DataTypeTok{upper =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\NormalTok{broom}\OperatorTok{::}\KeywordTok{tidy}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{inner_join}\NormalTok{(}
\NormalTok{      cluster_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{item1 =}\NormalTok{ id, }\DataTypeTok{item1_cluster =}\NormalTok{ cluster),}
      \DataTypeTok{by =} \StringTok{"item1"}
\NormalTok{      ) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{inner_join}\NormalTok{(}
\NormalTok{      cluster_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{item2 =}\NormalTok{ id, }\DataTypeTok{item2_cluster =}\NormalTok{ cluster),}
      \DataTypeTok{by =} \StringTok{"item2"}
\NormalTok{    )}
  
\NormalTok{  dist_df <-}\StringTok{ }\NormalTok{dist_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{group_by}\NormalTok{(item1, item1_cluster, item2_cluster) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{summarize}\NormalTok{(}
      \DataTypeTok{avg_distance =} \KeywordTok{mean}\NormalTok{(distance)}
\NormalTok{    )}
  
\NormalTok{  a <-}\StringTok{ }\NormalTok{dist_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(item1_cluster }\OperatorTok{==}\StringTok{ }\NormalTok{item2_cluster) }\OperatorTok{%>%}
\StringTok{    }\NormalTok{.}\OperatorTok{$}\NormalTok{avg_distance}
  
\NormalTok{  b <-}\StringTok{ }\NormalTok{dist_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{filter}\NormalTok{(item1_cluster }\OperatorTok{!=}\StringTok{ }\NormalTok{item2_cluster) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{top_n}\NormalTok{(}\OperatorTok{-}\DecValTok{1}\NormalTok{, avg_distance) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\NormalTok{.}\OperatorTok{$}\NormalTok{avg_distance}
  
\NormalTok{  s <-}\StringTok{ }\KeywordTok{map2_dbl}\NormalTok{(a, b, }\OperatorTok{~}\StringTok{ }\NormalTok{(.y }\OperatorTok{-}\StringTok{ }\NormalTok{.x) }\OperatorTok{/}\StringTok{ }\KeywordTok{max}\NormalTok{(.x, .y))}
  
  \KeywordTok{mean}\NormalTok{(s)}
\NormalTok{\}}

\KeywordTok{map_dbl}\NormalTok{(}\KeywordTok{list}\NormalTok{(sol_}\DecValTok{1}\NormalTok{, sol_}\DecValTok{2}\NormalTok{), asw, }\DataTypeTok{df =}\NormalTok{ df[, }\DecValTok{-1}\NormalTok{], }\DataTypeTok{dist_method =} \StringTok{"euclidean"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6507364 0.5864226
\end{verbatim}

\hypertarget{cluster-solution-interpretation}{%
\section{군집해의 해석}\label{cluster-solution-interpretation}}

군집분석의 주목적을 달성하기 위해서는 군집해를 얻은 후 이에 대한 해석이 가능하여야 할 것이다. 즉, 각 군집의 특성을 파악할 수 있어야 실제 문제에 적용할 수 있을 것이다. 이를 위해서는 특정 응용분야의 전문가 지식을 요하는 경우가 많다. 그러나 첫 출발은 각 군집의 중심좌표, 즉 군집 별 변수별 평균치를 산출하는 것이다. 대부분의 경우 변수별 평균치로 군집들을 비교함으로써 군집의 특성을 파악할 수 있다. 다변량을 처리할 수 있는 그래프 역시 도움이 되며, 특히 다변량인 경우 요인분석(factor analysis)를 활용하기도 한다. 최종적으로 각 군집에 대한 특성이 파악되면 명명(naming)하는 것이 추천된다.

\hypertarget{association-rule}{%
\chapter{연관규칙}\label{association-rule}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

연관규칙(association rule)이란 간단히 말하면 항목들 간의 조건-결과 식으로 표현되는 유용한 패턴을 말한다. 연관규칙 탐사는 기업의 활동, 특히 마케팅에서 가장 널리 사용되고 있다.

\hypertarget{association-packages-install}{%
\section{필요 R package 설치}\label{association-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.2.1\\
\hline
arules & 1.6-3\\
\hline
\end{tabular}

\hypertarget{association-rule-definition-metric}{%
\section{연관규칙의 정의 및 성능척도}\label{association-rule-definition-metric}}

데이터베이스가 총 \(n\)개의 트랜잭션 데이터로 구성되며, 전체 \(m\)개의 항목을 포함한다 하자. 전체 항목집합 \(I\)를 다음과 같이 정의하자.

\begin{equation*}
I = \{ i_1, \cdots, i_m \}
\end{equation*}

이 때, 각 트랜잭션 \(Z_j\)는 \(I\)의 부분집합이 된다.

\begin{equation*}
Z_j \subseteq I, \, j = 1, \cdots, n
\end{equation*}

연관규칙 \(R\)은 조건부 \(X\)와 결과부 \(Y\)로 구성되어 (\(X, Y \subseteq I\), \(X \cap Y = \emptyset\)) ``\(X\)가 일어나면 \(Y\)도 일어난다''는 의미로 아래와 같이 표현된다.

\begin{equation}
R: X \Rightarrow Y \label{eq:association-rule}
\end{equation}

식 \eqref{eq:association-rule}의 연관규칙 \(R\)에 대한 성능척도로 지지도(support), 신뢰도(confidence) 및 개선도(lift)가 널리 사용된다.

\hypertarget{association-rule-support}{%
\subsection{지지도}\label{association-rule-support}}

지지도는 전체 트랜잭션 중 관심있는 항목집합을 포함하는 트랜잭션의 비율을 나타낸다.

항목 \(X \subseteq I\)에 대한 지지도는 아래와 같이 계산된다.

\begin{equation*}
supp(X) = \frac{1}{n} \sum_{j = 1}^{n} \mathbb{I}(X \subseteq Z_j)
\end{equation*}

이 때, \(\mathbb{I}(a)\)는 지시함수로 \(a\)가 참일 때 1, 거짓일 때 0의 함수값을 가진다.

식 \eqref{eq:association-rule}의 연관규칙 \(R\)에 대한 지지도는 아래와 같이 정의된다.

\begin{equation*}
supp(R) = supp(X \cup Y)
\end{equation*}

다음과 같은 5개의 트랜잭션을 고려해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{transaction_df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{transaction_id, }\OperatorTok{~}\NormalTok{item,}
  \DecValTok{1}\NormalTok{, }\StringTok{"b"}\NormalTok{,}
  \DecValTok{1}\NormalTok{, }\StringTok{"c"}\NormalTok{,}
  \DecValTok{1}\NormalTok{, }\StringTok{"g"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\StringTok{"a"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\StringTok{"b"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\StringTok{"d"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\StringTok{"e"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\StringTok{"f"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\StringTok{"a"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\StringTok{"b"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\StringTok{"c"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\StringTok{"g"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\StringTok{"b"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\StringTok{"c"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\StringTok{"e"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\StringTok{"f"}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\StringTok{"b"}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\StringTok{"c"}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\StringTok{"e"}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\StringTok{"f"}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\StringTok{"g"}
\NormalTok{)}

\NormalTok{transaction_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(transaction_id) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{items =} \KeywordTok{str_c}\NormalTok{(item, }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'c'}\NormalTok{, }\StringTok{'c'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'트랜잭션'}\NormalTok{, }\StringTok{'항목'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'트랜잭션 데이터'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:transaction-data}트랜잭션 데이터}
\centering
\begin{tabular}{cc}
\toprule
트랜잭션 & 항목\\
\midrule
1 & b, c, g\\
2 & a, b, d, e, f\\
3 & a, b, c, g\\
4 & b, c, e, f\\
5 & b, c, e, f, g\\
\bottomrule
\end{tabular}
\end{table}

이 때, 전체 항목집합 \(I\)는 \(\{a, b, c, d, e, f, g\}\) 이다. 다음과 같은 규칙을 적용해보자.

\begin{equation*}
R: \{b, c\} \Rightarrow \{g\}
\end{equation*}

이 때, 조건부 \(X = \{b, c\}\)에 대한 지지도는 아래와 같이 산출된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{support <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(group_df, item, set) \{}
  \ControlFlowTok{if}\NormalTok{(}\KeywordTok{is_empty}\NormalTok{(set)) }\KeywordTok{return}\NormalTok{(}\DecValTok{1}\NormalTok{)}
  
\NormalTok{  group_df }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{unique}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{sum}\NormalTok{(}\OperatorTok{!!}\NormalTok{rlang}\OperatorTok{::}\KeywordTok{sym}\NormalTok{(item) }\OperatorTok{%in%}\StringTok{ }\NormalTok{set)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{is_support =}\NormalTok{ (n }\OperatorTok{==}\StringTok{ }\KeywordTok{length}\NormalTok{(set))) }\OperatorTok{%>%}
\StringTok{    }\NormalTok{\{}\KeywordTok{mean}\NormalTok{(.}\OperatorTok{$}\NormalTok{is_support)\}}
\NormalTok{\}}

\NormalTok{X <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{)}
\NormalTok{group_transaction_df <-}\StringTok{ }\NormalTok{transaction_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{group_by}\NormalTok{(transaction_id)}

\KeywordTok{support}\NormalTok{(group_transaction_df, }\DataTypeTok{item =} \StringTok{"item"}\NormalTok{, }\DataTypeTok{set =}\NormalTok{ X)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8
\end{verbatim}

또한, 규칙 \(R\)에 대한 지지도는 아래와 같이 산출할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"g"}\NormalTok{)}
\KeywordTok{support}\NormalTok{(group_transaction_df, }\DataTypeTok{item =} \StringTok{"item"}\NormalTok{, }\DataTypeTok{set =} \KeywordTok{union}\NormalTok{(X, Y))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6
\end{verbatim}

\hypertarget{association-rule-confidence}{%
\subsection{신뢰도}\label{association-rule-confidence}}

연관규칙 \(R\)의 가치를 평가할 때, 통상 다음과 같이 정의되는 신뢰도를 사용한다.

\begin{equation*}
conf(R) = \frac{supp(R)}{supp(X)} = \frac{supp(X \cup Y)}{supp(X)}
\end{equation*}

이 신뢰도는 조건부 확률의 개념으로, 집합 \(X\)(조건부)가 발생할 때 집합 \(Y\)(결과부)도 동시에 발생할 확률을 의미한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rule_confidence <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(group_df, item, x, y) \{}
  \KeywordTok{support}\NormalTok{(group_df, item, }\KeywordTok{union}\NormalTok{(x, y)) }\OperatorTok{/}\StringTok{ }\KeywordTok{support}\NormalTok{(group_df, item, x)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rule_confidence}\NormalTok{(group_transaction_df, }\DataTypeTok{item =} \StringTok{"item"}\NormalTok{, }\DataTypeTok{x =}\NormalTok{ X, }\DataTypeTok{y =}\NormalTok{ Y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.75
\end{verbatim}

\hypertarget{association-rule-lift}{%
\subsection{개선도}\label{association-rule-lift}}

결과가 단독으로 발생할 가능성에 비추어 조건과 연계하여 결과가 발생할 가능성의 빈도 비율로 정의한다.

\begin{equation*}
lift(R) = \frac{conf(R)}{supp(Y)} = \frac{supp(X \cup Y)}{supp(X)supp(Y)}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rule_lift <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(group_df, item, x, y) \{}
  \KeywordTok{rule_confidence}\NormalTok{(group_df, item, x, y) }\OperatorTok{/}\StringTok{ }\KeywordTok{support}\NormalTok{(group_df, item, y)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{rule_lift}\NormalTok{(group_transaction_df, }\DataTypeTok{item =} \StringTok{"item"}\NormalTok{, }\DataTypeTok{x =}\NormalTok{ X, }\DataTypeTok{y =}\NormalTok{ Y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.25
\end{verbatim}

즉, 항목 \(b\), \(c\)가 발생할 때 \(g\)가 발생하는 빈도가 25\% 높아진다.

\hypertarget{association-rule-exploration}{%
\section{연관규칙의 탐사}\label{association-rule-exploration}}

연관규칙의 탐사는 결국 신뢰도 또는 개선도가 높은 규칙 \(R\)을 트랜잭션 데이터로부터 도출하는 과정이다. 알고리즘으로 가장 널리 사용되는 것이 Apriori 알고리즘\citep{agrawal1994fast}이다.

\hypertarget{apriori-large-itemsets}{%
\subsection{빈발항목집합 생성}\label{apriori-large-itemsets}}

빈발항목집합(large itemsets)이란 미리 결정한 최소 지지도 \(s_{\text{min}}\) 이상의 지지도를 같는 모든 항목집합들을 뜻한다.

빈발항목집합 생성 과정은 아래와 같다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(k\)개의 항목을 지닌 빈발항목집합 후보군 \(C_{k}\) 중 최소지지도 \(s_{\text{min}}\) 이상의 지지도를 같는 모든 항목집합들을 빈발항목집합 \(L_{k}\)라 한다.
\item
  빈발항목집합들 \(L_{k}\)내의 각 쌍에 대해 합집합을 구하여 그 합집합의 크기(항목의 수)가 \(k + 1\)인 항목집합들을 빈발항목집합 후보군 \(C_{k + 1}\)라 한다.
\end{enumerate}

\(k\)를 1부터 증가시키면서 더 이상 빈발항목집합을 찾을 수 없을 때까지 위 과정을 반복한다. 이 때, 빈발항목집합 후보군을 생성하는 함수 \texttt{apriori\_gen}을 아래와 같이 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{apriori_gen <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(L) \{}
  \ControlFlowTok{if}\NormalTok{(}\KeywordTok{length}\NormalTok{(L) }\OperatorTok{<}\StringTok{ }\DecValTok{2}\NormalTok{) }\KeywordTok{return}\NormalTok{(}\OtherTok{NULL}\NormalTok{)}
  
\NormalTok{  n_sets <-}\StringTok{ }\KeywordTok{length}\NormalTok{(L)}
\NormalTok{  n_item <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(}\KeywordTok{map_dbl}\NormalTok{(L, length))}

  \ControlFlowTok{if}\NormalTok{(}\KeywordTok{length}\NormalTok{(n_item) }\OperatorTok{>}\StringTok{ }\DecValTok{1}\NormalTok{) }\KeywordTok{stop}\NormalTok{(}\StringTok{"All itemsets must be the same length."}\NormalTok{)}
  
\NormalTok{  C <-}\StringTok{ }\KeywordTok{combn}\NormalTok{(L, }\DataTypeTok{m =} \DecValTok{2}\NormalTok{, }\DataTypeTok{simplify =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{t}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    `}\DataTypeTok{colnames<-}\StringTok{`}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"set1"}\NormalTok{, }\StringTok{"set2"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{as_tibble}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{pmap}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(set1, set2) \{}
      \ControlFlowTok{if}\NormalTok{(}\KeywordTok{length}\NormalTok{(}\KeywordTok{intersect}\NormalTok{(set1, set2)) }\OperatorTok{!=}\StringTok{ }\NormalTok{n_item }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{) }\KeywordTok{return}\NormalTok{(}\OtherTok{NULL}\NormalTok{)}
      \KeywordTok{sort}\NormalTok{(}\KeywordTok{union}\NormalTok{(set1, set2))}
\NormalTok{      \}) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{compact}\NormalTok{() }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{unique}\NormalTok{()}

\NormalTok{  C  }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 함수를 이용하여, Table \ref{tab:transaction-data}에서 최소 지지도 \(s_{\text{min}} = 0.4\)를 기준으로 빈발항목집합을 찾아보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s_min <-}\StringTok{ }\FloatTok{0.4}
\NormalTok{group_transaction_df <-}\StringTok{ }\NormalTok{transaction_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{group_by}\NormalTok{(transaction_id)}

\NormalTok{candidate_itemsets <-}\StringTok{ }\KeywordTok{as.list}\NormalTok{(}\KeywordTok{sort}\NormalTok{(}\KeywordTok{unique}\NormalTok{(transaction_df}\OperatorTok{$}\NormalTok{item)))}
\NormalTok{large_itemsets <-}\StringTok{ }\KeywordTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\DataTypeTok{length =} \KeywordTok{length}\NormalTok{(candidate_itemsets))}

\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \KeywordTok{seq_along}\NormalTok{(large_itemsets)) \{}
\NormalTok{  itemset_support <-}\StringTok{ }\KeywordTok{map_dbl}\NormalTok{(candidate_itemsets, }
\NormalTok{                             support, }
                             \DataTypeTok{group_df =}\NormalTok{ group_transaction_df, }
                             \DataTypeTok{item =} \StringTok{"item"}\NormalTok{)}

\NormalTok{  large_itemsets[[i]] <-}\StringTok{ }\NormalTok{candidate_itemsets[itemset_support }\OperatorTok{>=}\StringTok{ }\NormalTok{s_min]}
  
\NormalTok{  candidate_itemsets <-}\StringTok{ }\KeywordTok{apriori_gen}\NormalTok{(large_itemsets[[i]])}
  
  \ControlFlowTok{if}\NormalTok{(}\KeywordTok{is.null}\NormalTok{(candidate_itemsets)) }\ControlFlowTok{break}
\NormalTok{\}}

\NormalTok{large_itemsets <-}\StringTok{ }\KeywordTok{compact}\NormalTok{(large_itemsets)}
\end{Highlighting}
\end{Shaded}

찾아진 빈발항목집합들은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{map}\NormalTok{(large_itemsets,}
    \OperatorTok{~}\KeywordTok{map_chr}\NormalTok{(.x, }\OperatorTok{~}\KeywordTok{str_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{str_c}\NormalTok{(.x, }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] "{a}" "{b}" "{c}" "{e}" "{f}" "{g}"
## 
## [[2]]
## [1] "{a, b}" "{b, c}" "{b, e}" "{b, f}" "{b, g}" "{c, e}" "{c, f}" "{c, g}"
## [9] "{e, f}"
## 
## [[3]]
## [1] "{b, c, e}" "{b, c, f}" "{b, c, g}" "{b, e, f}" "{c, e, f}"
## 
## [[4]]
## [1] "{b, c, e, f}"
\end{verbatim}

\hypertarget{apriori-rule-exploration}{%
\subsection{규칙의 탐사}\label{apriori-rule-exploration}}

도출된 빈발항목집합 각각(\(L\))을 조건부(\(X\))와 결과부(\(Y = L \backslash A\))로 나눌 때 미리 결정된 최소 신뢰도 \(c_{\text{min}}\) 이상의 신뢰도를 지닌 규칙 \(R\)을 찾는다.

\begin{equation*}
R: X \Rightarrow L \backslash X
\end{equation*}

우선, 빈발항목집합 \(L\)으로부터 가능한 규칙들을 생성하는 함수 \texttt{generate\_rules}를 아래와 같이 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{generate_rules <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(L, }\DataTypeTok{n_min_item =} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  n_item <-}\StringTok{ }\KeywordTok{length}\NormalTok{(L)}
  \ControlFlowTok{if}\NormalTok{(n_item }\OperatorTok{<}\StringTok{ }\NormalTok{n_min_item) }\KeywordTok{return}\NormalTok{(}\OtherTok{NULL}\NormalTok{) }\CommentTok{# 항목 최소개수 제한}
  
\NormalTok{  X <-}\StringTok{ }\KeywordTok{map}\NormalTok{(}\KeywordTok{seq_len}\NormalTok{(n_item), }\OperatorTok{~}\KeywordTok{combn}\NormalTok{(L, }\DataTypeTok{m =}\NormalTok{ .x }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{, list)) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{flatten}\NormalTok{()}
\NormalTok{  Y <-}\StringTok{ }\KeywordTok{map}\NormalTok{(X, }\OperatorTok{~}\KeywordTok{setdiff}\NormalTok{(L, .x))}
  
  \KeywordTok{tibble}\NormalTok{(}\DataTypeTok{X =}\NormalTok{ X, }\DataTypeTok{Y =}\NormalTok{ Y)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

앞 장에서 추출한 모든 빈발항목집합들로부터 규칙을 생성해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rule_list <-}\StringTok{ }\KeywordTok{map_dfr}\NormalTok{(}
\NormalTok{  large_itemsets }\OperatorTok{%>%}\StringTok{ }\KeywordTok{flatten}\NormalTok{(),}
\NormalTok{  generate_rules}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

각각의 규칙에 대하여 신뢰도를 계산하여, 그 값이 최소 신뢰도 \(c_{\text{min}}\) 이상인 규칙만을 \texttt{conf\_rule\_list}라는 데이터 프레임으로 저장하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rule_list}\OperatorTok{$}\NormalTok{confidence <-}\StringTok{ }\KeywordTok{pmap_dbl}\NormalTok{(rule_list, }\ControlFlowTok{function}\NormalTok{(X, Y) }
  \KeywordTok{rule_confidence}\NormalTok{(group_transaction_df, }\DataTypeTok{item =} \StringTok{"item"}\NormalTok{, }\DataTypeTok{x =}\NormalTok{ X, }\DataTypeTok{y =}\NormalTok{ Y)}
\NormalTok{  )}

\NormalTok{c_min <-}\StringTok{ }\FloatTok{0.7}
\NormalTok{conf_rule_list <-}\StringTok{ }\NormalTok{rule_list }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(confidence }\OperatorTok{>=}\StringTok{ }\NormalTok{c_min)}
\end{Highlighting}
\end{Shaded}

이 결과 최종적으로 도출된 규칙들은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{conf_rule_list }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rowwise}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{X =} \KeywordTok{str_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{str_c}\NormalTok{(}\KeywordTok{unlist}\NormalTok{(X), }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{),}
    \DataTypeTok{Y =} \KeywordTok{str_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{str_c}\NormalTok{(}\KeywordTok{unlist}\NormalTok{(Y), }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'c'}\NormalTok{, }\StringTok{'c'}\NormalTok{, }\StringTok{'c'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'조건부 $X$'}\NormalTok{, }\StringTok{'결과부 $Y$'}\NormalTok{, }\StringTok{'신뢰도'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'최종 연관규칙'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:confident-rules}최종 연관규칙}
\centering
\begin{tabular}{ccc}
\toprule
조건부 \$X\$ & 결과부 \$Y\$ & 신뢰도\\
\midrule
\{\} & \{b\} & 1.00\\
\{\} & \{c\} & 0.80\\
\{a\} & \{b\} & 1.00\\
\{\} & \{b, c\} & 0.80\\
\{b\} & \{c\} & 0.80\\
\addlinespace
\{c\} & \{b\} & 1.00\\
\{e\} & \{b\} & 1.00\\
\{f\} & \{b\} & 1.00\\
\{g\} & \{b\} & 1.00\\
\{c\} & \{g\} & 0.75\\
\addlinespace
\{g\} & \{c\} & 1.00\\
\{e\} & \{f\} & 1.00\\
\{f\} & \{e\} & 1.00\\
\{c, e\} & \{b\} & 1.00\\
\{c, f\} & \{b\} & 1.00\\
\addlinespace
\{c\} & \{b, g\} & 0.75\\
\{g\} & \{b, c\} & 1.00\\
\{b, c\} & \{g\} & 0.75\\
\{b, g\} & \{c\} & 1.00\\
\{c, g\} & \{b\} & 1.00\\
\addlinespace
\{e\} & \{b, f\} & 1.00\\
\{f\} & \{b, e\} & 1.00\\
\{b, e\} & \{f\} & 1.00\\
\{b, f\} & \{e\} & 1.00\\
\{e, f\} & \{b\} & 1.00\\
\addlinespace
\{c, e\} & \{f\} & 1.00\\
\{c, f\} & \{e\} & 1.00\\
\{c, e\} & \{b, f\} & 1.00\\
\{c, f\} & \{b, e\} & 1.00\\
\{b, c, e\} & \{f\} & 1.00\\
\addlinespace
\{b, c, f\} & \{e\} & 1.00\\
\{c, e, f\} & \{b\} & 1.00\\
\bottomrule
\end{tabular}
\end{table}

항목의 수가 많은 경우, 생성 가능한 규칙의 수가 매우 많아, 보다 효율적인 탐사의 수행이 필요할 수 있다. 자세한 방법에 대해서는 교재 \citep{jun2012datamining} 참조.

\hypertarget{apriori-r-package}{%
\subsection{R 패키지 내 Apriori}\label{apriori-r-package}}

R 패키지 \texttt{arules}의 \texttt{apriori} 함수를 이용하여 위에서 살펴본 연관규칙 탐사를 수행할 수 있다.

우선, \ref{association-rule-support} 절에서 생성한 데이터 프레임 \texttt{transaction\_df}를 \texttt{arules} 패키지 내에 정의된 \texttt{transactions} 클래스 형태의 데이터로 변환한다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{requireNamespace}\NormalTok{(}\StringTok{"arules"}\NormalTok{)}
\NormalTok{transaction_df2 <-}\StringTok{ }\KeywordTok{as}\NormalTok{(}
  \KeywordTok{split}\NormalTok{(transaction_df}\OperatorTok{$}\NormalTok{item, transaction_df}\OperatorTok{$}\NormalTok{transaction_id),}
  \StringTok{"transactions"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

이후, \texttt{apriori} 함수를 호출하여 연관규칙 탐사를 수행한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rule_results <-}\StringTok{ }\NormalTok{arules}\OperatorTok{::}\KeywordTok{apriori}\NormalTok{(}
\NormalTok{  transaction_df2,}
  \DataTypeTok{parameter =} \KeywordTok{list}\NormalTok{(}
    \DataTypeTok{support =} \FloatTok{0.4}\NormalTok{,}
    \DataTypeTok{confidence =} \FloatTok{0.7}\NormalTok{,}
    \DataTypeTok{target =} \StringTok{"rules"}
\NormalTok{  ),}
  \DataTypeTok{control =} \KeywordTok{list}\NormalTok{(}
    \DataTypeTok{verbose =} \OtherTok{FALSE}
\NormalTok{  )}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

결과로 얻어지는 \texttt{rules} 클래스 객체에서 필요한 정보를 추출하여 데이터 프레임으로 저장하자.

\begin{itemize}
\tightlist
\item
  \texttt{lhs}: 조건부
\item
  \texttt{rhs}: 결과부
\item
  \texttt{quality}: 평가척도 (지지도, 신뢰도, 개선도, 관측수)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rule_results_df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{X =} \KeywordTok{as}\NormalTok{(rule_results}\OperatorTok{@}\NormalTok{lhs, }\StringTok{"list"}\NormalTok{),}
  \DataTypeTok{Y =} \KeywordTok{as}\NormalTok{(rule_results}\OperatorTok{@}\NormalTok{rhs, }\StringTok{"list"}\NormalTok{)}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_cols}\NormalTok{(rule_results}\OperatorTok{@}\NormalTok{quality)}
\end{Highlighting}
\end{Shaded}

해당 데이터 프레임은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rule_results_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rowwise}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{X =} \KeywordTok{str_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{str_c}\NormalTok{(}\KeywordTok{unlist}\NormalTok{(X), }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{),}
    \DataTypeTok{Y =} \KeywordTok{str_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{str_c}\NormalTok{(}\KeywordTok{unlist}\NormalTok{(Y), }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'c'}\NormalTok{, }\StringTok{'c'}\NormalTok{, }\StringTok{'c'}\NormalTok{, }\StringTok{'c'}\NormalTok{, }\StringTok{'c'}\NormalTok{, }\StringTok{'c'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'조건부 $X$'}\NormalTok{, }\StringTok{'결과부 $Y$'}\NormalTok{, }\StringTok{'지지도'}\NormalTok{,}
                  \StringTok{'신뢰도'}\NormalTok{, }\StringTok{'개선도'}\NormalTok{, }\StringTok{'관측수'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'최종 연관규칙 - arules::apriori'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:apriori-r-results}최종 연관규칙 - arules::apriori}
\centering
\begin{tabular}{cccccc}
\toprule
조건부 \$X\$ & 결과부 \$Y\$ & 지지도 & 신뢰도 & 개선도 & 관측수\\
\midrule
\{\} & \{c\} & 0.8 & 0.80 & 1.000000 & 4\\
\{\} & \{b\} & 1.0 & 1.00 & 1.000000 & 5\\
\{a\} & \{b\} & 0.4 & 1.00 & 1.000000 & 2\\
\{g\} & \{c\} & 0.6 & 1.00 & 1.250000 & 3\\
\{c\} & \{g\} & 0.6 & 0.75 & 1.250000 & 3\\
\addlinespace
\{g\} & \{b\} & 0.6 & 1.00 & 1.000000 & 3\\
\{e\} & \{f\} & 0.6 & 1.00 & 1.666667 & 3\\
\{f\} & \{e\} & 0.6 & 1.00 & 1.666667 & 3\\
\{e\} & \{b\} & 0.6 & 1.00 & 1.000000 & 3\\
\{f\} & \{b\} & 0.6 & 1.00 & 1.000000 & 3\\
\addlinespace
\{c\} & \{b\} & 0.8 & 1.00 & 1.000000 & 4\\
\{b\} & \{c\} & 0.8 & 0.80 & 1.000000 & 4\\
\{c, g\} & \{b\} & 0.6 & 1.00 & 1.000000 & 3\\
\{b, g\} & \{c\} & 0.6 & 1.00 & 1.250000 & 3\\
\{b, c\} & \{g\} & 0.6 & 0.75 & 1.250000 & 3\\
\addlinespace
\{c, e\} & \{f\} & 0.4 & 1.00 & 1.666667 & 2\\
\{c, f\} & \{e\} & 0.4 & 1.00 & 1.666667 & 2\\
\{e, f\} & \{b\} & 0.6 & 1.00 & 1.000000 & 3\\
\{b, e\} & \{f\} & 0.6 & 1.00 & 1.666667 & 3\\
\{b, f\} & \{e\} & 0.6 & 1.00 & 1.666667 & 3\\
\addlinespace
\{c, e\} & \{b\} & 0.4 & 1.00 & 1.000000 & 2\\
\{c, f\} & \{b\} & 0.4 & 1.00 & 1.000000 & 2\\
\{c, e, f\} & \{b\} & 0.4 & 1.00 & 1.000000 & 2\\
\{b, c, e\} & \{f\} & 0.4 & 1.00 & 1.666667 & 2\\
\{b, c, f\} & \{e\} & 0.4 & 1.00 & 1.666667 & 2\\
\bottomrule
\end{tabular}
\end{table}

위 Table \ref{tab:apriori-r-results}를 살펴보면, 결과부에는 오직 하나의 항목만 존재하는 것을 알 수 있다. 이는 Apriori 알고리즘이 제안된 원 논문 \citep{agrawal1993mining}에 따른 것이며, 위 \ref{apriori-rule-exploration} 절에서 여러 개의 항목이 결과부에 존재하는 방식은 이 Apriori 알고리즘을 보다 일반화한 것이라 생각할 수 있겠다.

\hypertarget{association-sequential-pattern}{%
\section{순차적 패턴의 탐사}\label{association-sequential-pattern}}

순차적 패턴(sequential pattern)이란 고객들의 시간에 따른 구매 행태를 말하는데, 예를 들어 ``냉장고를 구입한 후 김치냉장고를 구매한다''는 식이다.

순차적 패턴의 탐사를 위해서는 고객별, 시간별 트랜잭션 데이터가 필요하다. 항목 집합을 순서적으로 나열한 리스트를 시퀀스(sequence)라 하는데, \(A_j\)를 \(j\)번째의 항목집합이라 할 때, 시퀀스는 다음과 같이 표기한다.

\begin{equation*}
s = < A_1, A_2, \cdots, A_n >
\end{equation*}

시퀀스에 포함된 항목집합의 수를 시퀀스의 길이라 하며, 길이가 \(k\)인 시퀀스를 \(k\)-시퀀스라 한다.

\begin{equation*}
length(< A_1, A_2, \cdots, A_n >) = n
\end{equation*}

두 시퀀스 \(s_1 = < A_1, A_2, \cdots, A_n >\)과 \(s_2 = < B_1, B_2, \cdots, B_m >\)에 대하여 (\(n \leq m\)),

\begin{equation*}
A_1 \subseteq B_{i_1}, A_2 \subseteq B_{i_2}, \cdots,  A_n \subseteq B_{i_n}
\end{equation*}

이 성립하는 \(i_1 < i_2 < \cdots < i_n\)이 존재할 때, \(s_1\)은 \(s_2\)에 포함된다고 하며, 이 때 \(s_1\)을 \(s_2\)의 부분 시퀀스라 하며, 아래와 같이 표현한다.

\begin{equation*}
s_1 \prec s_2
\end{equation*}

시퀀스 \(s\)가 어떤 다른 시퀀스에 포함되지 않을 경우 최대 시퀀스(maximal sequence)라 한다.

\(N\)명의 고객 각자에 대한 트랜잭션 시퀀스를 고객 시퀀스(customer sequence)라 하며, \(i\)번째 고객에 대한 고객 시퀀스를 \(s_i\)라 할 때 (\(i = 1, \cdots, N\)), 임의의 시퀀스 \(s\)에 대한 지지도를 다음과 같이 정의한다.

\begin{equation*}
supp(s) = \frac{1}{N} \sum_{i = 1}^{N} I(s \prec s_i)
\end{equation*}

그리고, 미리 정한 최소 지지도 이상을 갖는 시퀀스를 빈발 시퀀스(large sequence)라 한다. 따라서, 순차적 패턴 탐사 문제는 빈발 시퀀스 중 최대 시퀀스(maximal sequence)들을 찾는 것이라 할 수 있다.

\hypertarget{association-aprioriall}{%
\subsection{AprioriAll 알고리즘}\label{association-aprioriall}}

AprioriAll 알고리즘은 빈발 시퀀스를 탐색하나, 탐색된 시퀀스가 최대 빈발 시퀀스임을 보장하지는 못한다. 따라서, 후에 최대화 단계를 요한다.

아래와 같은 고객 시퀀스가 존재한다고 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sequential_transaction_df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{customer_id, }\OperatorTok{~}\NormalTok{transaction_seq, }\OperatorTok{~}\NormalTok{item,}
  \DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"a"}\NormalTok{,}
  \DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"b"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"c"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"d"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"a"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"e"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"f"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"g"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"a"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"h"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"g"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"a"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"e"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"g"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"b"}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"b"}
\NormalTok{)}

\NormalTok{sequential_transaction_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(customer_id, transaction_seq) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{itemset =} \KeywordTok{str_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{str_c}\NormalTok{(item, }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{sequence =} \KeywordTok{str_c}\NormalTok{(}\StringTok{"<"}\NormalTok{, }\KeywordTok{str_c}\NormalTok{(itemset, }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{">"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{"c"}\NormalTok{, }\StringTok{"c"}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{"고객ID ($i$)"}\NormalTok{, }\StringTok{"고객 시퀀스 ($s_i$)"}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{"고객별 시퀀스"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:sequential-transaction-data}고객별 시퀀스}
\centering
\begin{tabular}{cc}
\toprule
고객ID (\$i\$) & 고객 시퀀스 (\$s\_i\$)\\
\midrule
1 & <\{a\}, \{b\}>\\
2 & <\{c, d\}, \{a\}, \{e, f, g\}>\\
3 & <\{a, h, g\}>\\
4 & <\{a\}, \{e, g\}, \{b\}>\\
5 & <\{b\}>\\
\bottomrule
\end{tabular}
\end{table}

고객 시퀀스의 항목집합 또는 이의 부분집합 중 최소 지지도 이상인 것들을 빈발항목 집합으로 도출한다.

우선 시퀀스가 특정 패턴을 포함하는지 여부를 판단하는 사용자 정의 함수 \texttt{is\_contained}와 고객 시퀀스 집합의 특정 패턴에 대한 지지도를 산출하는 사용자 정의 함수 \texttt{support\_sequence}를 아래와 같이 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{is_contained <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, pattern) \{}
\NormalTok{  n_x <-}\StringTok{ }\KeywordTok{length}\NormalTok{(x)}
\NormalTok{  n_pattern <-}\StringTok{ }\KeywordTok{length}\NormalTok{(pattern)}
  \ControlFlowTok{if}\NormalTok{ (n_pattern }\OperatorTok{==}\StringTok{ }\DecValTok{0}\NormalTok{) }\KeywordTok{return}\NormalTok{ (}\OtherTok{TRUE}\NormalTok{)}
  
\NormalTok{  rtn <-}\StringTok{ }\OtherTok{FALSE}
  
\NormalTok{  location <-}\StringTok{ }\KeywordTok{rep}\NormalTok{(}\OtherTok{NA_integer_}\NormalTok{, n_pattern)}

  \ControlFlowTok{if}\NormalTok{ (n_x }\OperatorTok{>=}\StringTok{ }\NormalTok{n_pattern) \{}
\NormalTok{    j <-}\StringTok{ }\NormalTok{1L}
    \ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \KeywordTok{seq_len}\NormalTok{(n_x)) \{}
      \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{is_empty}\NormalTok{(}\KeywordTok{setdiff}\NormalTok{(pattern[[j]], x[[i]]))) \{}
\NormalTok{        location[j] <-}\StringTok{ }\NormalTok{i}
\NormalTok{        j <-}\StringTok{ }\NormalTok{j }\OperatorTok{+}\StringTok{ }\DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ (j }\OperatorTok{>}\StringTok{ }\NormalTok{n_pattern) \{}
\NormalTok{          rtn <-}\StringTok{ }\OtherTok{TRUE}
          \ControlFlowTok{break}
\NormalTok{        \}}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}

\NormalTok{  rtn}
\NormalTok{\}}

\NormalTok{support_sequence <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(sequence_list, pattern) \{}
  \KeywordTok{map_lgl}\NormalTok{(sequence_list, is_contained, }\DataTypeTok{pattern =}\NormalTok{ pattern) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mean}\NormalTok{()}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

앞 \ref{apriori-large-itemsets}절에서와 같이 사용자 정의 함수 \texttt{apriori\_gen}을 이용하여 빈발항목집합(시퀀스 지지도 기준)을 아래와 같이 얻는다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s_min <-}\StringTok{ }\FloatTok{0.4}

\NormalTok{customer_sequence <-}\StringTok{ }\NormalTok{sequential_transaction_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(customer_id, transaction_seq) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{itemset =} \KeywordTok{list}\NormalTok{(item)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{sequence =} \KeywordTok{list}\NormalTok{(itemset))}

\NormalTok{candidate_itemsets <-}\StringTok{ }\KeywordTok{map}\NormalTok{(}\KeywordTok{sort}\NormalTok{(}\KeywordTok{unique}\NormalTok{(sequential_transaction_df}\OperatorTok{$}\NormalTok{item)), }\OperatorTok{~}\KeywordTok{list}\NormalTok{(.x))}
\NormalTok{large_itemsets <-}\StringTok{ }\KeywordTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\DataTypeTok{length =} \KeywordTok{length}\NormalTok{(candidate_itemsets))}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \KeywordTok{seq_along}\NormalTok{(large_itemsets)) \{}
\NormalTok{  large_itemsets[[i]] <-}\StringTok{ }\NormalTok{candidate_itemsets[}
    \KeywordTok{map_dbl}\NormalTok{(candidate_itemsets,}
            \OperatorTok{~}\KeywordTok{support_sequence}\NormalTok{(customer_sequence}\OperatorTok{$}\NormalTok{sequence, }\DataTypeTok{pattern =}\NormalTok{ .x)) }\OperatorTok{>=}\StringTok{ }\NormalTok{s_min}
\NormalTok{    ] }\OperatorTok{%>%}\StringTok{ }\KeywordTok{flatten}\NormalTok{()}

\NormalTok{  candidate_itemsets <-}\StringTok{ }\KeywordTok{map}\NormalTok{(}\KeywordTok{apriori_gen}\NormalTok{(large_itemsets[[i]]), }\OperatorTok{~}\KeywordTok{list}\NormalTok{(.x))}
\NormalTok{\}}

\NormalTok{large_itemsets <-}\StringTok{ }\NormalTok{large_itemsets }\OperatorTok{%>%}\StringTok{ }\KeywordTok{flatten}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

위 결과, 아래와 같은 빈발항목집합이 얻어진다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{large_itemsets}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] "a"
## 
## [[2]]
## [1] "b"
## 
## [[3]]
## [1] "e"
## 
## [[4]]
## [1] "g"
## 
## [[5]]
## [1] "e" "g"
\end{verbatim}

위 빈발항목집합에 일련번호를 부여한 뒤, 고객 시퀀스를 해당 일련번호를 이용한 시퀀스로 변환한다. 우선 아래와 같이 일련번호를 부여해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{large_itemset_df <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{itemset =}\NormalTok{ large_itemsets,}
  \DataTypeTok{mapped_to =} \KeywordTok{seq_along}\NormalTok{(large_itemsets)}
\NormalTok{)}

\NormalTok{large_itemset_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rowwise}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{itemset =} \KeywordTok{str_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{str_c}\NormalTok{(itemset, }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{"c"}\NormalTok{, }\StringTok{"c"}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{"빈발항목집합"}\NormalTok{, }\StringTok{"일련번호"}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{"고객 시퀀스 빈발항목집합"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:association-sequence-large-itemsets}고객 시퀀스 빈발항목집합}
\centering
\begin{tabular}{cc}
\toprule
빈발항목집합 & 일련번호\\
\midrule
\{a\} & 1\\
\{b\} & 2\\
\{e\} & 3\\
\{g\} & 4\\
\{e, g\} & 5\\
\bottomrule
\end{tabular}
\end{table}

원 고객 시퀀스에 대해, 각 항목집합이 위 빈발항목집합을 포함하는 경우, 해당 일련번호가 항목으로 포함되는 형태로 변환 시퀀스를 생성한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{customer_sequence}\OperatorTok{$}\NormalTok{transformed_sequence <-}\StringTok{ }\NormalTok{customer_sequence}\OperatorTok{$}\NormalTok{sequence }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{map}\NormalTok{(}\OperatorTok{~}\KeywordTok{map}\NormalTok{(.x, }\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{    large_itemset_df}\OperatorTok{$}\NormalTok{mapped_to[}
      \KeywordTok{map_lgl}\NormalTok{(large_itemset_df}\OperatorTok{$}\NormalTok{itemset, }\OperatorTok{~}\KeywordTok{is_contained}\NormalTok{(x, .x))}
\NormalTok{      ]}
\NormalTok{  \}) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{compact}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

원 고객 시퀀스와 변환 시퀀스는 아래와 같이 표현될 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{print_sequence <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(sequence) \{}
  \KeywordTok{str_c}\NormalTok{(}\StringTok{"<"}\NormalTok{, }\KeywordTok{str_c}\NormalTok{(}
    \KeywordTok{map}\NormalTok{(sequence, }\ControlFlowTok{function}\NormalTok{(x) }
      \KeywordTok{str_c}\NormalTok{(}\KeywordTok{map_chr}\NormalTok{(x, }\OperatorTok{~}\KeywordTok{str_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{str_c}\NormalTok{(.x, }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)), }
            \DataTypeTok{collapse =} \StringTok{", "}\NormalTok{)),}
    \StringTok{">"}\NormalTok{))}
\NormalTok{\}}

\NormalTok{customer_sequence }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(customer_id) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{sequence =} \KeywordTok{print_sequence}\NormalTok{(sequence),}
    \DataTypeTok{transformed_sequence =} \KeywordTok{print_sequence}\NormalTok{(transformed_sequence)}
\NormalTok{  ) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{"c"}\NormalTok{, }\StringTok{"c"}\NormalTok{, }\StringTok{"c"}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{"고객ID"}\NormalTok{, }\StringTok{"고객 시퀀스"}\NormalTok{, }\StringTok{"변환 시퀀스"}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{"고객 시퀀스의 변환"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:association-transformed-sequence}고객 시퀀스의 변환}
\centering
\begin{tabular}{ccc}
\toprule
고객ID & 고객 시퀀스 & 변환 시퀀스\\
\midrule
1 & <\{a\}, \{b\}> & <\{1\}, \{2\}>\\
2 & <\{c, d\}, \{a\}, \{e, f, g\}> & <\{1\}, \{3, 4, 5\}>\\
3 & <\{a, h, g\}> & <\{1, 4\}>\\
4 & <\{a\}, \{e, g\}, \{b\}> & <\{1\}, \{3, 4, 5\}, \{2\}>\\
5 & <\{b\}> & <\{2\}>\\
\bottomrule
\end{tabular}
\end{table}

변환 시퀀스를 기준으로, 길이가 1인 빈발 시퀀스를 구한다. 최소 지지도를 앞에서 빈발항목집합을 구할 때와 동일하게 설정할 때, 길이가 1인 빈발 시퀀스는 빈발항목집합(의 변환된 일련번호)과 동일하다.

우선, 최대 시퀀스 길이를 구하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{max_sequence_length <-}\StringTok{ }\KeywordTok{max}\NormalTok{(}\KeywordTok{map_int}\NormalTok{(customer_sequence}\OperatorTok{$}\NormalTok{transformed_sequence, }\OperatorTok{~}\KeywordTok{length}\NormalTok{(.x)))}
\end{Highlighting}
\end{Shaded}

1-시퀀스인 빈발시퀀스는 빈발항목집합과 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{large_sequences <-}\StringTok{ }\KeywordTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\DataTypeTok{length =}\NormalTok{ max_sequence_length)}
\NormalTok{large_sequences[[}\DecValTok{1}\NormalTok{]] <-}\StringTok{ }\KeywordTok{map}\NormalTok{(large_itemset_df}\OperatorTok{$}\NormalTok{mapped_to, }\OperatorTok{~}\KeywordTok{list}\NormalTok{(.x))}
\end{Highlighting}
\end{Shaded}

같은 길이의 두 시퀀스를 이용해서 길이가 1 증가한 새로운 시퀀스를 생성하는 함수 \texttt{generate\_sequence}를 아래와 같이 구현해보자. 새로운 시퀀스는 첫 번째 시퀀스 후에 두 번째 시퀀스의 가장 마지막 트랜잭션을 추가한 시퀀스이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{generate_sequence <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(seq1, seq2) \{}
  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{length}\NormalTok{(seq1) }\OperatorTok{!=}\StringTok{ }\KeywordTok{length}\NormalTok{(seq2)) }\KeywordTok{stop}\NormalTok{(}\StringTok{"Two sequences must be the same length."}\NormalTok{)}
  
  \CommentTok{# two k-sequences needs to be the same for first k-1 items to generate new sequence}
\NormalTok{  new_sequence <-}\StringTok{ }\OtherTok{NULL}
\NormalTok{  k <-}\StringTok{ }\KeywordTok{length}\NormalTok{(seq1)}
  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{identical}\NormalTok{(seq1[}\KeywordTok{seq_len}\NormalTok{(k }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)], seq2[}\KeywordTok{seq_len}\NormalTok{(k }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)])) \{}
\NormalTok{    new_sequence <-}\StringTok{ }\KeywordTok{c}\NormalTok{(seq1, seq2[[k]])}
\NormalTok{  \}}
  
\NormalTok{  new_sequence}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

빈발 \(k\)-시퀀스들로부터 \((k+1)\)-시퀀스들을 생성하는 함수 \texttt{apriori\_seq\_gen}을 아래와 같이 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{apriori_seq_gen <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(L) \{}
\NormalTok{  n_seqs <-}\StringTok{ }\KeywordTok{length}\NormalTok{(L)}
\NormalTok{  n_item <-}\StringTok{ }\KeywordTok{unique}\NormalTok{(}\KeywordTok{map_dbl}\NormalTok{(L, length))}
  
  \ControlFlowTok{if}\NormalTok{ (}\KeywordTok{length}\NormalTok{(n_item) }\OperatorTok{>}\StringTok{ }\DecValTok{1}\NormalTok{) }\KeywordTok{stop}\NormalTok{(}\StringTok{"All sequences must be the same length."}\NormalTok{)}
  
\NormalTok{  k <-}\StringTok{ }\NormalTok{n_item}
  
  \CommentTok{# generate large new sequences with length (k+1)}
\NormalTok{  C <-}\StringTok{ }\KeywordTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\DataTypeTok{length =}\NormalTok{ n_seqs }\OperatorTok{*}\StringTok{ }\NormalTok{n_seqs)}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \KeywordTok{seq_along}\NormalTok{(L)) \{}
    \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \KeywordTok{seq_along}\NormalTok{(L)) \{}
\NormalTok{      candidate_sequence <-}\StringTok{ }\KeywordTok{generate_sequence}\NormalTok{(L[[i]], L[[j]])}
      
      \CommentTok{# check whether all subsequences with length k are element of L}
      \ControlFlowTok{if}\NormalTok{ (}
        \KeywordTok{all}\NormalTok{(}\KeywordTok{map_lgl}\NormalTok{(}\KeywordTok{seq_len}\NormalTok{(k), }\ControlFlowTok{function}\NormalTok{(x) }
          \KeywordTok{any}\NormalTok{(}\KeywordTok{map_lgl}\NormalTok{(L, }\OperatorTok{~}\KeywordTok{identical}\NormalTok{(.x, candidate_sequence[}\OperatorTok{-}\NormalTok{x])))}
\NormalTok{        ))}
\NormalTok{      ) \{}
\NormalTok{        C[[n_seqs }\OperatorTok{*}\StringTok{ }\NormalTok{(i }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{) }\OperatorTok{+}\StringTok{ }\NormalTok{j]] <-}\StringTok{ }\NormalTok{candidate_sequence}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
  
  \KeywordTok{compact}\NormalTok{(C)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 \texttt{apriori\_seq\_gen} 함수 수행결과로 얻어지는 \((k+1)\)-시퀀스들이 모두 빈발 시퀀스라는 보장은 없으므로, 새로 생성된 각 시퀀스가 최소 지지도 이상의 지지도를 갖는지 검토하여, 빈발 시퀀스만을 남기기로 하자. 앞에서 정의했던 함수 \texttt{support\_sequence}를 활용하여, 새로운 함수 \texttt{get\_large\_sequence}를 정의하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{get_large_sequence <-}\StringTok{ }\ControlFlowTok{function}\NormalTok{(sequence_list, C, s_min) \{}
\NormalTok{  is_large <-}\StringTok{ }\KeywordTok{map_lgl}\NormalTok{(}
\NormalTok{    C, }\OperatorTok{~}\StringTok{ }\KeywordTok{support_sequence}\NormalTok{(sequence_list, .x) }\OperatorTok{>=}\StringTok{ }\NormalTok{s_min}
\NormalTok{  )}
  
\NormalTok{  C[is_large]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 빈발 \(k\)-시퀀스를 과정을 \(k\)값을 1씩 증가시켜가며 더 이상 빈발 시퀀스를 찾을 수 없을 때까지 반복한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s_min <-}\StringTok{ }\FloatTok{0.4}

\NormalTok{large_sequences <-}\StringTok{ }\KeywordTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\DataTypeTok{length =}\NormalTok{ max_sequence_length)}
\NormalTok{large_sequences[[}\DecValTok{1}\NormalTok{]] <-}\StringTok{ }\KeywordTok{map}\NormalTok{(large_itemset_df}\OperatorTok{$}\NormalTok{mapped_to, }\OperatorTok{~}\KeywordTok{list}\NormalTok{(.x))}

\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \KeywordTok{seq_len}\NormalTok{(max_sequence_length }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)) \{}
\NormalTok{  large_sequences[[i }\OperatorTok{+}\StringTok{ }\DecValTok{1}\NormalTok{]] <-}\StringTok{ }\KeywordTok{get_large_sequence}\NormalTok{(}
\NormalTok{    customer_sequence}\OperatorTok{$}\NormalTok{transformed_sequence,}
    \KeywordTok{apriori_seq_gen}\NormalTok{(large_sequences[[i]]),}
\NormalTok{    s_min}
\NormalTok{  )}
  
  \ControlFlowTok{if}\NormalTok{(}\KeywordTok{is_empty}\NormalTok{(large_sequences[[i }\OperatorTok{+}\StringTok{ }\DecValTok{1}\NormalTok{]])) }\ControlFlowTok{break}
\NormalTok{\}}

\NormalTok{large_sequences <-}\StringTok{ }\KeywordTok{flatten}\NormalTok{(}\KeywordTok{compact}\NormalTok{(large_sequences))}
\end{Highlighting}
\end{Shaded}

결과적으로 찾아진 빈발 시퀀스들은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{map_chr}\NormalTok{(large_sequences, }
    \OperatorTok{~}\KeywordTok{str_c}\NormalTok{(}\StringTok{"<"}\NormalTok{, }\KeywordTok{str_c}\NormalTok{(}\KeywordTok{str_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{unlist}\NormalTok{(.x), }\StringTok{"\}"}\NormalTok{), }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{">"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "<{1}>"      "<{2}>"      "<{3}>"      "<{4}>"      "<{5}>"     
## [6] "<{1}, {2}>" "<{1}, {3}>" "<{1}, {4}>" "<{1}, {5}>"
\end{verbatim}

이후 최대화 단계를 통해, 빈발 시퀀스 중 최대 시퀀스들만 추출한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{maximal_large_sequences <-}\StringTok{ }\NormalTok{large_sequences}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \KeywordTok{seq}\NormalTok{(}\DataTypeTok{from =} \KeywordTok{length}\NormalTok{(large_sequences), }\DataTypeTok{to =} \DecValTok{2}\NormalTok{)) \{}
  \ControlFlowTok{if}\NormalTok{(}\OperatorTok{!}\KeywordTok{is_empty}\NormalTok{(maximal_large_sequences[i])) \{}
\NormalTok{    is_subsequence <-}\StringTok{ }\KeywordTok{map_lgl}\NormalTok{(maximal_large_sequences[}\KeywordTok{seq_len}\NormalTok{(i }\OperatorTok{-}\StringTok{ }\DecValTok{1}\NormalTok{)],}
                              \OperatorTok{~}\KeywordTok{is_contained}\NormalTok{(maximal_large_sequences[i], .x))}
    
    \KeywordTok{walk}\NormalTok{(}\KeywordTok{which}\NormalTok{(is_subsequence), }\ControlFlowTok{function}\NormalTok{(x) maximal_large_sequences[[x]] <<-}\StringTok{ }\KeywordTok{list}\NormalTok{())}
\NormalTok{  \}}
\NormalTok{\}}

\NormalTok{maximal_large_sequences <-}\StringTok{ }\KeywordTok{compact}\NormalTok{(maximal_large_sequences)}
\end{Highlighting}
\end{Shaded}

최대 빈발 시퀀스(변환 시퀀스 기준)은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{map_chr}\NormalTok{(maximal_large_sequences, }
    \OperatorTok{~}\KeywordTok{str_c}\NormalTok{(}\StringTok{"<"}\NormalTok{, }\KeywordTok{str_c}\NormalTok{(}\KeywordTok{str_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\KeywordTok{unlist}\NormalTok{(.x), }\StringTok{"\}"}\NormalTok{), }\DataTypeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{">"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "<{1}, {2}>" "<{1}, {3}>" "<{1}, {4}>" "<{1}, {5}>"
\end{verbatim}

이외에도 AprioriSome 알고리즘, DynamicSome 알고리즘 등의 시퀀스 탐사 알고리즘 들이 존재한다. 보다 자세한 내용은 \citet{jun2012datamining} 및 \citet{agrawal1995mining} 참고.

\hypertarget{recommender-system}{%
\chapter{추천시스템}\label{recommender-system}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

추천시스템(recommender system)은 상품, 웹페이지, 신문 기사 등에 대한 소비자의 성향을 파악하여 그에 부합하는 새로운 상품 등을 추천하고자 하는 목적으로 개발되며, 접근 방식에 따라 내용기반(content-based) 방법, 협업 필터링(collaborative filtering), 결합방식(hybrid) 등으로 분류된다.

\hypertarget{recommender-packages-install}{%
\section{필요 R package 설치}\label{recommender-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.2.1\\
\hline
tidytext & 0.2.0\\
\hline
\end{tabular}

\hypertarget{content-based-recommender}{%
\section{내용기반 추천시스템}\label{content-based-recommender}}

내용기반 추천시스템은 주로 문서 등의 추천에 활용되고 있다.

\begin{itemize}
\tightlist
\item
  \(N\): 전체 문서의 수
\item
  \(f_{ij}\): 문서 \(j\)에 나타난 단어 \(i\)의 빈도수
\item
  \(n_i\): 단어 \(i\)가 한 번 이상 나타난 문서의 수
\end{itemize}

우선 \texttt{tidytext} 패키지를 로드하자.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidytext)}
\end{Highlighting}
\end{Shaded}

\texttt{janeaustenr} 패키지에 있는 Jane Austen의 6개 소설에 대한 텍스트 데이터를 로드하자. 해당 데이터는 책 내용이 담긴 \texttt{text}라는 컬럼과 책 제목인 \texttt{book} 컬럼으로 이루어진 데이터 프레임이다.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(janeaustenr)}
\NormalTok{tidy_books <-}\StringTok{ }\KeywordTok{austen_books}\NormalTok{()}
\KeywordTok{head}\NormalTok{(tidy_books)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   text                  book               
##   <chr>                 <fct>              
## 1 SENSE AND SENSIBILITY Sense & Sensibility
## 2 ""                    Sense & Sensibility
## 3 by Jane Austen        Sense & Sensibility
## 4 ""                    Sense & Sensibility
## 5 (1811)                Sense & Sensibility
## 6 ""                    Sense & Sensibility
\end{verbatim}

해당 데이터 프레임에 담긴 책의 수는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n_book <-}\StringTok{ }\KeywordTok{nlevels}\NormalTok{(tidy_books}\OperatorTok{$}\NormalTok{book)}
\KeywordTok{print}\NormalTok{(n_book)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6
\end{verbatim}

책의 내용 text를 단어 단위로 나누어 각 행으로 저장하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy_words <-}\StringTok{ }\NormalTok{tidy_books }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unnest_tokens}\NormalTok{(word, text)}
  
\KeywordTok{head}\NormalTok{(tidy_words)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   book                word       
##   <fct>               <chr>      
## 1 Sense & Sensibility sense      
## 2 Sense & Sensibility and        
## 3 Sense & Sensibility sensibility
## 4 Sense & Sensibility by         
## 5 Sense & Sensibility jane       
## 6 Sense & Sensibility austen
\end{verbatim}

이 데이터 프레임을 기반으로, 단어 \(i\)가 문서 \(j\)에 나타난 단어 빈도수(term frequency)를 모든 단어 \(i\)와 모든 문서 \(j\)에 대해 계산하자.

\begin{equation*}
TF_{ij} = \frac{f_{ij}}{\sum_k f_{kj}}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tf_results <-}\StringTok{ }\NormalTok{tidy_words }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(book, word) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{tf =}\NormalTok{ n }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(n)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{n) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{complete}\NormalTok{(book, word, }\DataTypeTok{fill =} \KeywordTok{list}\NormalTok{(}\DataTypeTok{tf =} \DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

이 때, 단어 빈도수가 높은 단어들은 대체로 너무 흔한 단어들이어서 중요한 의미를 지니지 않은 경우가 많다. 아래와 같이, ``the'', ``to'', ``and'' 등의 단어들이 사용 빈도가 매우 높은 단어들이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tf_results }\OperatorTok{%>%}\StringTok{ }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(tf)) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 3
##    book                word      tf
##    <fct>               <chr>  <dbl>
##  1 Northanger Abbey    the   0.0409
##  2 Persuasion          the   0.0398
##  3 Mansfield Park      the   0.0387
##  4 Pride & Prejudice   the   0.0354
##  5 Sense & Sensibility to    0.0343
##  6 Sense & Sensibility the   0.0342
##  7 Mansfield Park      to    0.0341
##  8 Pride & Prejudice   to    0.0341
##  9 Mansfield Park      and   0.0339
## 10 Persuasion          to    0.0336
\end{verbatim}

따라서, 단어의 중요도를 정의할 때 단어 \(i\)의 역문서 빈도수(inverse document frequency)를 함께 고려한다.

\begin{equation*}
IDF_{i} = \log \frac{N}{n_i}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{idf_results <-}\StringTok{ }\NormalTok{tf_results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(tf }\OperatorTok{>}\StringTok{ }\DecValTok{0}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(word) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{idf =} \KeywordTok{log}\NormalTok{(n_book }\OperatorTok{/}\StringTok{ }\NormalTok{n)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{n)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{idf_results }\OperatorTok{%>%}\StringTok{ }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(idf)) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##    word           idf
##    <chr>        <dbl>
##  1 _accepted_    1.79
##  2 _accident_    1.79
##  3 _adair_       1.79
##  4 _addition_    1.79
##  5 _advantages_  1.79
##  6 _affect_      1.79
##  7 _against_     1.79
##  8 _agreeable_   1.79
##  9 _air_         1.79
## 10 _allow_       1.79
\end{verbatim}

최종적으로 단어의 중요도를 위에서 정의한 단어 빈도수와 역문서 빈도수의 곱으로 아래와 같이 구하며, 이를 TF-IDF 가중치라 한다.

\begin{equation*}
w_{ij} = TF_{ij} \times IDF_{i}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tf_idf_results <-}\StringTok{ }\KeywordTok{inner_join}\NormalTok{(tf_results, idf_results, }\DataTypeTok{by =} \StringTok{"word"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{tf_idf =}\NormalTok{ tf }\OperatorTok{*}\StringTok{ }\NormalTok{idf)}
\end{Highlighting}
\end{Shaded}

TF-IDF 가중치가 높은 단어들을 살펴보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tf_idf_results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(tf_idf)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 5
##    book                word           tf   idf  tf_idf
##    <fct>               <chr>       <dbl> <dbl>   <dbl>
##  1 Sense & Sensibility elinor    0.00519  1.79 0.00931
##  2 Sense & Sensibility marianne  0.00410  1.79 0.00735
##  3 Mansfield Park      crawford  0.00307  1.79 0.00551
##  4 Pride & Prejudice   darcy     0.00305  1.79 0.00547
##  5 Persuasion          elliot    0.00304  1.79 0.00544
##  6 Emma                emma      0.00488  1.10 0.00536
##  7 Northanger Abbey    tilney    0.00252  1.79 0.00452
##  8 Emma                weston    0.00242  1.79 0.00433
##  9 Pride & Prejudice   bennet    0.00241  1.79 0.00431
## 10 Persuasion          wentworth 0.00228  1.79 0.00409
\end{verbatim}

대체로 소설에 나타나는 인물의 이름이 높은 가중치를 보이는데, 이는 인물의 이름이 소설 한 권에 걸쳐 여러 번 나타나 단어 빈도수가 높으며, 또한 각각의 소설이 서로 다른 인물명을 등장시킴으로써 역문서 빈도수 또한 높기 때문이다.

위와 같은 TF-IDF 가중치 계산은 \texttt{tidytext} 패키지의 \texttt{bind\_tf\_idf} 함수를 이용하여 간편하게 구할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy_words }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(book, word) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{n =} \KeywordTok{n}\NormalTok{()) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{bind_tf_idf}\NormalTok{(word, book, n) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(tf_idf)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 6
##    book                word          n      tf   idf  tf_idf
##    <fct>               <chr>     <int>   <dbl> <dbl>   <dbl>
##  1 Sense & Sensibility elinor      623 0.00519  1.79 0.00931
##  2 Sense & Sensibility marianne    492 0.00410  1.79 0.00735
##  3 Mansfield Park      crawford    493 0.00307  1.79 0.00551
##  4 Pride & Prejudice   darcy       373 0.00305  1.79 0.00547
##  5 Persuasion          elliot      254 0.00304  1.79 0.00544
##  6 Emma                emma        786 0.00488  1.10 0.00536
##  7 Northanger Abbey    tilney      196 0.00252  1.79 0.00452
##  8 Emma                weston      389 0.00242  1.79 0.00433
##  9 Pride & Prejudice   bennet      294 0.00241  1.79 0.00431
## 10 Persuasion          wentworth   191 0.00228  1.79 0.00409
\end{verbatim}

임의의 사용자 \(u\)가 아래와 같이 다섯 가지 단어에 각기 다른 관심도 \(w_{iu}\)를 지닌다고 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{words_of_interest <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{word =} \KeywordTok{c}\NormalTok{(}\StringTok{"kitty"}\NormalTok{, }\StringTok{"cottage"}\NormalTok{, }\StringTok{"judgment"}\NormalTok{, }\StringTok{"war"}\NormalTok{, }\StringTok{"sea"}\NormalTok{),}
  \DataTypeTok{weight =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.2}\NormalTok{)}
\NormalTok{)}

\NormalTok{words_of_interest }\OperatorTok{%>%}
\StringTok{  }\NormalTok{knitr}\OperatorTok{::}\KeywordTok{kable}\NormalTok{(}
    \DataTypeTok{booktabs =} \OtherTok{TRUE}\NormalTok{,}
    \DataTypeTok{align =} \KeywordTok{c}\NormalTok{(}\StringTok{'c'}\NormalTok{, }\StringTok{'c'}\NormalTok{),}
    \DataTypeTok{col.names =} \KeywordTok{c}\NormalTok{(}\StringTok{'단어 ($i$)'}\NormalTok{, }\StringTok{'가중치 ($w_\{iu\}$'}\NormalTok{),}
    \DataTypeTok{caption =} \StringTok{'목표 사용자의 관심 단어 및 가중치'}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[t]

\caption{\label{tab:word-of-interest}목표 사용자의 관심 단어 및 가중치}
\centering
\begin{tabular}{cc}
\toprule
단어 (\$i\$) & 가중치 (\$w\_\{iu\}\$\\
\midrule
kitty & 0.3\\
cottage & 0.3\\
judgment & 0.1\\
war & 0.1\\
sea & 0.2\\
\bottomrule
\end{tabular}
\end{table}

이 때, 목표 사용자 \(u\)의 문서 \(j\)에 대한 유용도(utility)를 다음과 같이 코사인 유사성 척도(cosine similarity measure)로 산출한다.

\begin{equation*}
u(a, j) = \frac{\sum_{i = 1}^{K} w_{iu} w_{ij}}{\sqrt{\sum_{i = 1}^{K} w_{iu}^2} \sqrt{\sum_{i = 1}^{K} w_{ij}^2}}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{utility_results <-}\StringTok{ }\NormalTok{tf_idf_results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(words_of_interest, }\DataTypeTok{by =} \StringTok{"word"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(book) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{utility =} \KeywordTok{sum}\NormalTok{(weight }\OperatorTok{*}\StringTok{ }\NormalTok{tf_idf) }\OperatorTok{/}\StringTok{ }
\StringTok{              }\NormalTok{(}\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{sum}\NormalTok{(weight }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)) }\OperatorTok{*}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{sum}\NormalTok{(tf_idf }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)))) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(utility))}

\KeywordTok{print}\NormalTok{(utility_results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   book                utility
##   <fct>                 <dbl>
## 1 Persuasion            0.753
## 2 Emma                  0.710
## 3 Sense & Sensibility   0.640
## 4 Pride & Prejudice     0.615
## 5 Northanger Abbey      0.529
## 6 Mansfield Park        0.404
\end{verbatim}

위 결과 Persuasion이 목표 사용자의 관심에 가장 유용도 높은 문서로 추천된다.

교재 \citet{jun2012datamining} 에 있는 예제에 대한 R 스크립트를 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{words_of_interest <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{word, }\OperatorTok{~}\NormalTok{weight,}
  \StringTok{"word1"}\NormalTok{, }\FloatTok{0.124}\NormalTok{,}
  \StringTok{"word2"}\NormalTok{, }\FloatTok{0.275}\NormalTok{,}
  \StringTok{"word3"}\NormalTok{, }\FloatTok{0.019}\NormalTok{,}
  \StringTok{"word4"}\NormalTok{, }\FloatTok{0.182}\NormalTok{,}
  \StringTok{"word5"}\NormalTok{, }\FloatTok{0.223}
\NormalTok{)}

\NormalTok{tf_idf_results <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{document, }\OperatorTok{~}\NormalTok{word, }\OperatorTok{~}\NormalTok{tf_idf,}
  \StringTok{"doc1"}\NormalTok{, }\StringTok{"word1"}\NormalTok{, }\FloatTok{0.0194}\NormalTok{,}
  \StringTok{"doc1"}\NormalTok{, }\StringTok{"word2"}\NormalTok{, }\FloatTok{0.0043}\NormalTok{,}
  \StringTok{"doc1"}\NormalTok{, }\StringTok{"word3"}\NormalTok{, }\FloatTok{0.0054}\NormalTok{,}
  \StringTok{"doc1"}\NormalTok{, }\StringTok{"word4"}\NormalTok{, }\FloatTok{0.0155}\NormalTok{,}
  \StringTok{"doc1"}\NormalTok{, }\StringTok{"word5"}\NormalTok{, }\FloatTok{0.0028}\NormalTok{,}
  \StringTok{"doc2"}\NormalTok{, }\StringTok{"word1"}\NormalTok{, }\FloatTok{0.0082}\NormalTok{,}
  \StringTok{"doc2"}\NormalTok{, }\StringTok{"word2"}\NormalTok{, }\FloatTok{0.0032}\NormalTok{,}
  \StringTok{"doc2"}\NormalTok{, }\StringTok{"word3"}\NormalTok{, }\FloatTok{0.0007}\NormalTok{,}
  \StringTok{"doc2"}\NormalTok{, }\StringTok{"word4"}\NormalTok{, }\FloatTok{0.0104}\NormalTok{,}
  \StringTok{"doc2"}\NormalTok{, }\StringTok{"word5"}\NormalTok{, }\FloatTok{0.0073}\NormalTok{,}
  \StringTok{"doc3"}\NormalTok{, }\StringTok{"word1"}\NormalTok{, }\FloatTok{0.0087}\NormalTok{,}
  \StringTok{"doc3"}\NormalTok{, }\StringTok{"word2"}\NormalTok{, }\FloatTok{0.0174}\NormalTok{,}
  \StringTok{"doc3"}\NormalTok{, }\StringTok{"word3"}\NormalTok{, }\FloatTok{0.0091}\NormalTok{,}
  \StringTok{"doc3"}\NormalTok{, }\StringTok{"word4"}\NormalTok{, }\FloatTok{0.0086}\NormalTok{,}
  \StringTok{"doc3"}\NormalTok{, }\StringTok{"word5"}\NormalTok{, }\FloatTok{0.0268}\NormalTok{,}
  \StringTok{"doc4"}\NormalTok{, }\StringTok{"word1"}\NormalTok{, }\FloatTok{0.0093}\NormalTok{,}
  \StringTok{"doc4"}\NormalTok{, }\StringTok{"word2"}\NormalTok{, }\FloatTok{0.0061}\NormalTok{,}
  \StringTok{"doc4"}\NormalTok{, }\StringTok{"word3"}\NormalTok{, }\FloatTok{0.0172}\NormalTok{,}
  \StringTok{"doc4"}\NormalTok{, }\StringTok{"word4"}\NormalTok{, }\FloatTok{0.0028}\NormalTok{,}
  \StringTok{"doc4"}\NormalTok{, }\StringTok{"word5"}\NormalTok{, }\FloatTok{0.0009}\NormalTok{,}
  \StringTok{"doc5"}\NormalTok{, }\StringTok{"word1"}\NormalTok{, }\FloatTok{0.0185}\NormalTok{,}
  \StringTok{"doc5"}\NormalTok{, }\StringTok{"word2"}\NormalTok{, }\FloatTok{0.0249}\NormalTok{,}
  \StringTok{"doc5"}\NormalTok{, }\StringTok{"word3"}\NormalTok{, }\FloatTok{0.0084}\NormalTok{,}
  \StringTok{"doc5"}\NormalTok{, }\StringTok{"word4"}\NormalTok{, }\FloatTok{0.0167}\NormalTok{,}
  \StringTok{"doc5"}\NormalTok{, }\StringTok{"word5"}\NormalTok{, }\FloatTok{0.0193}\NormalTok{,}
  \StringTok{"doc6"}\NormalTok{, }\StringTok{"word1"}\NormalTok{, }\FloatTok{0.0028}\NormalTok{,}
  \StringTok{"doc6"}\NormalTok{, }\StringTok{"word2"}\NormalTok{, }\FloatTok{0.0003}\NormalTok{,}
  \StringTok{"doc6"}\NormalTok{, }\StringTok{"word3"}\NormalTok{, }\FloatTok{0.0202}\NormalTok{,}
  \StringTok{"doc6"}\NormalTok{, }\StringTok{"word4"}\NormalTok{, }\FloatTok{0.0083}\NormalTok{,}
  \StringTok{"doc6"}\NormalTok{, }\StringTok{"word5"}\NormalTok{, }\FloatTok{0.0054}
\NormalTok{)}

\NormalTok{utility_results <-}\StringTok{ }\NormalTok{tf_idf_results }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(words_of_interest, }\DataTypeTok{by =} \StringTok{"word"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(document) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{utility =} \KeywordTok{sum}\NormalTok{(weight }\OperatorTok{*}\StringTok{ }\NormalTok{tf_idf) }\OperatorTok{/}\StringTok{ }
\StringTok{              }\NormalTok{(}\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{sum}\NormalTok{(weight }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)) }\OperatorTok{*}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{sum}\NormalTok{(tf_idf }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)))) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(utility))}

\KeywordTok{print}\NormalTok{(utility_results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   document utility
##   <chr>      <dbl>
## 1 doc5       0.972
## 2 doc3       0.919
## 3 doc2       0.841
## 4 doc1       0.659
## 5 doc4       0.448
## 6 doc6       0.373
\end{verbatim}

위 결과, 두 건의 문서를 추천할 경우 doc5, doc3를 추천할 수 있다.

\hypertarget{collaborative-filtering}{%
\section{협업 필터링}\label{collaborative-filtering}}

총 \(m\)개의 상품에 대한 \(n\)명의 소비자의 평점이 있다고 할 때, 관련 기호를 다음과 같이 정의하자.

\begin{itemize}
\tightlist
\item
  \(v_{ij}\): 고객 \(i\)의 상품 \(j\)에 대한 평점
\item
  \(I_i\): 고객 \(i\)가 평점을 매긴 상품집합
\item
  \(\left| I_i \right|\): 집합 \(I_i\)에 포함된 상품 수
\end{itemize}

이 때, 고객 \(i\)의 평균 평점은 다음과 같이 산출된다.

\begin{equation*}
\bar{v}_i  = \frac{1}{\left| I_i \right|} \sum_{j \in I_i} v_{ij}
\end{equation*}

이 때, 목표고객 \(a\)와 \(i\)번째 고객과의 유사성은 아래와 같이 평점에서 고객 평점을 뺀(mean-centering) 값에 대한 코사인 유사성 척도를 이용하여 정의한다.

\begin{equation*}
w(a, i) = \frac{\sum_{j \in I_a \cap I_i} (v_{aj} - \bar{v}_a) (v_{ij} - \bar{v}_i)}{\sqrt{\sum_{j \in I_a \cap I_i} (v_{aj} - \bar{v}_a)^2} \sqrt{\sum_{j \in I_a \cap I_i} (v_{ij} - \bar{v}_i)^2}}
\end{equation*}

이를 이용하여, 목표고객 \(a\)가 아직 구매하지 않은 상품 \(j\)에 매길 평점을 아래와 같이 추정한다.

\begin{equation*}
\hat{v}_{aj} = \bar{v}_a + \frac{1}{\sum_{i = 1}^{n} \left| w(a, i) \right|} \sum_{i = 1}^{n} w(a, i) (v_{ij} - \bar{v}_i)
\end{equation*}

교재 @jun2012datamining 에 있는 예제에 대한 R 스크립트를 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rating_df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{customer, }\OperatorTok{~}\NormalTok{item, }\OperatorTok{~}\NormalTok{rating,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{5}\NormalTok{,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 3"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 6"}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 3"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{5}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 3"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 6"}\NormalTok{, }\DecValTok{5}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{5}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 6"}\NormalTok{, }\DecValTok{5}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 6"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \StringTok{"목표고객"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{5}\NormalTok{,}
  \StringTok{"목표고객"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"목표고객"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{2}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

우선, 각 고객이 매긴 평균 평점 \(\bar{v}_i\)을 각 아이템에 대한 평점 \(v_{ij}\)에서 제외하여 mean\_centered rating을 아래와 같이 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{centered_rating_df <-}\StringTok{ }\NormalTok{rating_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(customer) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{centered_rating =}\NormalTok{ rating }\OperatorTok{-}\StringTok{ }\KeywordTok{mean}\NormalTok{(rating)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ungroup}\NormalTok{()}

\KeywordTok{print}\NormalTok{(centered_rating_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 33 x 4
##    customer item   rating centered_rating
##    <chr>    <chr>   <dbl>           <dbl>
##  1 고객 1   상품 1      5           2.4  
##  2 고객 1   상품 3      4           1.4  
##  3 고객 1   상품 5      1          -1.6  
##  4 고객 1   상품 6      0          -2.6  
##  5 고객 1   상품 7      3           0.400
##  6 고객 2   상품 1      4           0.75 
##  7 고객 2   상품 2      4           0.75 
##  8 고객 2   상품 3      4           0.75 
##  9 고객 2   상품 7      1          -2.25 
## 10 고객 3   상품 1      5           2    
## # ... with 23 more rows
\end{verbatim}

목표 고객과 다른 고객들간의 유사성 척도를 계산한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{similarity_df <-}\StringTok{ }\NormalTok{centered_rating_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(customer }\OperatorTok{==}\StringTok{ "목표고객"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(centered_rating_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(customer }\OperatorTok{!=}\StringTok{ "목표고객"}\NormalTok{), }\DataTypeTok{by =} \StringTok{"item"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(customer.y) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{similarity =} \KeywordTok{sum}\NormalTok{(centered_rating.x }\OperatorTok{*}\StringTok{ }\NormalTok{centered_rating.y) }\OperatorTok{/}
\StringTok{              }\NormalTok{(}\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{sum}\NormalTok{(centered_rating.x }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)) }\OperatorTok{*}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(}\KeywordTok{sum}\NormalTok{(centered_rating.y }\OperatorTok{^}\StringTok{ }\DecValTok{2}\NormalTok{)))) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{customer =}\NormalTok{ customer.y)}

\KeywordTok{print}\NormalTok{(similarity_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   customer similarity
##   <chr>         <dbl>
## 1 고객 1        0.903
## 2 고객 2        0.565
## 3 고객 3        0.961
## 4 고객 4       -0.875
## 5 고객 5       -0.853
## 6 고객 6        1
\end{verbatim}

유사성 척도의 절대값의 합이 1이 되도록 normalize한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{normalized_similarity_df <-}\StringTok{ }\NormalTok{similarity_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{normalized_similarity =}\NormalTok{ similarity }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\KeywordTok{abs}\NormalTok{(similarity)))}

\KeywordTok{print}\NormalTok{(normalized_similarity_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   customer similarity normalized_similarity
##   <chr>         <dbl>                 <dbl>
## 1 고객 1        0.903                 0.175
## 2 고객 2        0.565                 0.109
## 3 고객 3        0.961                 0.186
## 4 고객 4       -0.875                -0.170
## 5 고객 5       -0.853                -0.165
## 6 고객 6        1                     0.194
\end{verbatim}

이후 목표고객이 아직 평점을 매기지 않은 상품들에 대해 평점을 추정한다. 이 때, 상품 \(j\)에 대해 평점을 매기지 않은 고객의 경우, \(v_{ij} - \bar{v}_i = 0\)이라 가정하자.

\begin{equation*}
\hat{v}_{aj} = \bar{v}_a + \frac{1}{\sum_{i = 1}^{n} \left| w(a, i) \right|} \sum_{i = 1}^{n} w(a, i) (v_{ij} - \bar{v}_i)
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{items <-}\StringTok{ }\KeywordTok{sort}\NormalTok{(}\KeywordTok{setdiff}\NormalTok{(}\KeywordTok{unique}\NormalTok{(rating_df}\OperatorTok{$}\NormalTok{item), }
\NormalTok{                      rating_df}\OperatorTok{$}\NormalTok{item[rating_df}\OperatorTok{$}\NormalTok{customer }\OperatorTok{==}\StringTok{ "목표고객"}\NormalTok{]))}

\NormalTok{target_mean <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(rating_df}\OperatorTok{$}\NormalTok{rating[rating_df}\OperatorTok{$}\NormalTok{customer }\OperatorTok{==}\StringTok{ "목표고객"}\NormalTok{])}

\NormalTok{centered_rating_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(item }\OperatorTok{%in%}\StringTok{ }\NormalTok{items) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(normalized_similarity_df, }\DataTypeTok{by =} \StringTok{"customer"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(item) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{predicted_rating =}\NormalTok{ target_mean }\OperatorTok{+}\StringTok{ }
\StringTok{              }\KeywordTok{sum}\NormalTok{(normalized_similarity }\OperatorTok{*}\StringTok{ }\NormalTok{centered_rating)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(predicted_rating))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 2
##   item   predicted_rating
##   <chr>             <dbl>
## 1 상품 3             3.26
## 2 상품 2             3.14
## 3 상품 5             1.96
## 4 상품 6             1.63
\end{verbatim}

이번에는, 목표상품 \(j\)에 대한 평점을 추정할 때, 상품 \(j\)에 대해 평점을 매긴 고객과의 유사성만을 아래와 같이 고려하기로 하자.

\begin{equation*}
\hat{v}_{aj} = \bar{v}_a + \frac{1}{\sum_{i: j \in I_i} \left| w(a, i) \right|} \sum_{i: j \in I_i} w(a, i) (v_{ij} - \bar{v}_i)
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{centered_rating_df }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(item }\OperatorTok{%in%}\StringTok{ }\NormalTok{items) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(similarity_df, }\DataTypeTok{by =} \StringTok{"customer"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(item) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{predicted_rating =}\NormalTok{ target_mean }\OperatorTok{+}\StringTok{ }
\StringTok{              }\KeywordTok{sum}\NormalTok{(similarity }\OperatorTok{*}\StringTok{ }\NormalTok{centered_rating) }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\KeywordTok{abs}\NormalTok{(similarity))) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(predicted_rating))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 2
##   item   predicted_rating
##   <chr>             <dbl>
## 1 상품 3             3.97
## 2 상품 2             3.24
## 3 상품 5             1.87
## 4 상품 6             1.19
\end{verbatim}

\hypertarget{market-basket}{%
\section{시장바구니 데이터를 이용한 협업 필터링}\label{market-basket}}

아래와 같은 시장바구니 데이터가 있다.

\begin{equation*}
v_{ij} = \begin{cases}
1 & \text{ 고객 $i$가 상품 $j$를 구매한 경우}\\
0 & \text{ 그렇지 않은 경우}
\end{cases}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{market_basket_df <-}\StringTok{ }\KeywordTok{tribble}\NormalTok{(}
  \OperatorTok{~}\NormalTok{customer, }\OperatorTok{~}\NormalTok{item, }\OperatorTok{~}\NormalTok{purchase,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 3"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 3"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 3"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 6"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 6"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 6"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"목표고객"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"목표고객"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"목표고객"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

이 때, 총 상품의 개수를 \(m\)이라 하고, 고객 \(i\)에 대해

\begin{equation*}
p_i = \frac{|I_i|}{m}
\end{equation*}

이라 정의하자. 즉, \(p_i\)는 전체 상품 중 고객 \(i\)가 구입한 상품의 비율을 뜻한다. 또한, 두 고객 \(i\)와 \(k\)가 공통적으로 구입한 상품의 비율을 아래와 같이 \(p_{ik}\)라 정의하자.

\begin{equation*}
p_{ik} = \frac{|I_i \cap I_k|}{m}
\end{equation*}

우선 아래와 같이 가중치 \(w(a, i)\)를 계산해보자. 이 가중치는 목표고객 \(a\)과 각 고객 \(i\)간의 유사성 척도이다.

\begin{equation*}
w(a, i) = \frac{p_{ai} - p_a p_i}{\sqrt{p_a (1 - p_a)} \sqrt{p_i (1 - p_i)}}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m <-}\StringTok{ }\KeywordTok{length}\NormalTok{(}\KeywordTok{unique}\NormalTok{(market_basket_df}\OperatorTok{$}\NormalTok{item))}

\NormalTok{n_df <-}\StringTok{ }\NormalTok{market_basket_df }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(customer) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{p =} \KeywordTok{n}\NormalTok{() }\OperatorTok{/}\StringTok{ }\NormalTok{m)}

\NormalTok{common_df <-}\StringTok{ }\NormalTok{market_basket_df }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(customer }\OperatorTok{==}\StringTok{ "목표고객"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(market_basket_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{filter}\NormalTok{(customer }\OperatorTok{!=}\StringTok{ "목표고객"}\NormalTok{), }
             \DataTypeTok{by =} \StringTok{"item"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(customer.y) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{p =} \KeywordTok{n}\NormalTok{() }\OperatorTok{/}\StringTok{ }\NormalTok{m) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{customer =}\NormalTok{ customer.y)}

\NormalTok{similarity_df <-}\StringTok{ }\KeywordTok{crossing}\NormalTok{(}
  \DataTypeTok{target_customer =} \StringTok{"목표고객"}\NormalTok{,}
  \DataTypeTok{ref_customer =}\NormalTok{ n_df}\OperatorTok{$}\NormalTok{customer[n_df}\OperatorTok{$}\NormalTok{customer }\OperatorTok{!=}\StringTok{ "목표고객"}\NormalTok{]}
\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(n_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{target_p =}\NormalTok{ p),}
             \DataTypeTok{by =} \KeywordTok{c}\NormalTok{(}\StringTok{"target_customer"}\NormalTok{ =}\StringTok{ "customer"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(n_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{ref_p =}\NormalTok{ p),}
             \DataTypeTok{by =} \KeywordTok{c}\NormalTok{(}\StringTok{"ref_customer"}\NormalTok{ =}\StringTok{ "customer"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(common_df }\OperatorTok{%>%}\StringTok{ }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{common_p =}\NormalTok{ p),}
             \DataTypeTok{by =} \KeywordTok{c}\NormalTok{(}\StringTok{"ref_customer"}\NormalTok{ =}\StringTok{ "customer"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{similarity =}\NormalTok{ (common_p }\OperatorTok{-}\StringTok{ }\NormalTok{target_p }\OperatorTok{*}\StringTok{ }\NormalTok{ref_p) }\OperatorTok{/}
\StringTok{      }\NormalTok{(}\KeywordTok{sqrt}\NormalTok{(target_p }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{target_p)) }\OperatorTok{*}\StringTok{ }\KeywordTok{sqrt}\NormalTok{(ref_p }\OperatorTok{*}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{ref_p)))}
\NormalTok{  )}

\KeywordTok{print}\NormalTok{(similarity_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 6
##   target_customer ref_customer target_p ref_p common_p similarity
##   <chr>           <chr>           <dbl> <dbl>    <dbl>      <dbl>
## 1 목표고객        고객 1          0.429 0.571    0.286      0.167
## 2 목표고객        고객 2          0.429 0.571    0.286      0.167
## 3 목표고객        고객 3          0.429 0.714    0.429      0.548
## 4 목표고객        고객 4          0.429 0.857    0.429      0.354
## 5 목표고객        고객 5          0.429 0.571    0.143     -0.417
## 6 목표고객        고객 6          0.429 0.571    0.143     -0.417
\end{verbatim}

이후 목표고객이 아직 구매하지 않은 상품에 대해 평점을 추정한다. 목표고객 \(a\)의 상품 \(j\)에 대한 평점 추정치는 다음과 같이 산출한다.

\begin{equation*}
P_{aj} = \frac{\sum_{i = 1}^{n} w(a, i) v_{ij}}{\sum_{i = 1}^{n} | w(a, i) |}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{denom <-}\StringTok{ }\KeywordTok{sum}\NormalTok{(}\KeywordTok{abs}\NormalTok{(similarity_df}\OperatorTok{$}\NormalTok{similarity))}

\NormalTok{pred_df <-}\StringTok{ }\NormalTok{similarity_df }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{inner_join}\NormalTok{(market_basket_df, }\DataTypeTok{by =} \KeywordTok{c}\NormalTok{(}\StringTok{"ref_customer"}\NormalTok{ =}\StringTok{ "customer"}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{anti_join}\NormalTok{(market_basket_df }\OperatorTok{%>%}\StringTok{ }
\StringTok{              }\KeywordTok{filter}\NormalTok{(customer }\OperatorTok{==}\StringTok{ "목표고객"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{              }\KeywordTok{select}\NormalTok{(item),}
            \DataTypeTok{by =} \StringTok{"item"}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(item) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarize}\NormalTok{(}\DataTypeTok{est_score =} \KeywordTok{sum}\NormalTok{(similarity }\OperatorTok{*}\StringTok{ }\NormalTok{purchase) }\OperatorTok{/}\StringTok{ }\NormalTok{denom) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(est_score))}

\KeywordTok{print}\NormalTok{(pred_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 2
##   item   est_score
##   <chr>      <dbl>
## 1 상품 3    0.332 
## 2 상품 2    0.113 
## 3 상품 5   -0.0575
## 4 상품 6   -0.232
\end{verbatim}

\bibliography{book.bib,packages.bib}


\end{document}
