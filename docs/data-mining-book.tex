% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={데이터마이닝 with R},
  pdfauthor={전치혁, 이혜선, 이종석, 이영록},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage[utf]{kotex}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{데이터마이닝 with R}
\author{전치혁, 이혜선, 이종석, 이영록}
\date{2021-07-18}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{uxac1cuxc694}{%
\chapter*{개요}\label{uxac1cuxc694}}
\addcontentsline{toc}{chapter}{개요}

본 사이트는 전치혁 교수님의 책 \href{http://www.hannarae.net/books/area.php?ptype=view\&prdcode=1409250010}{}을 기반으로 한 R 예제를 제공할 목적으로 만들어졌으며, 지속적으로 업데이트될 예정입니다. 본 사이트의 R 예제들은 R 4.1.0 version에서 수행되었으며, R 프로그램은 \href{https://cran.r-project.org}{CRAN}에서 다운로드받아 설치할 수 있습니다.

본 사이트는 R을 이용한 데이터마이닝 수행에 초점을 두고 있으며, 예제 수행을 위해서는 기본적인 R 프로그래밍 지식이 필요합니다. R 프로그래밍에 대한 지식은 아래와 같은 자료들로부터 얻을 수 있습니다.

\begin{itemize}
\tightlist
\item
  R for Data Science (by Hadley Wickham \& Garrett Grolemund): \url{https://r4ds.had.co.nz}
\item
  Advanced R (by Hadley Wickham): \url{https://adv-r.hadley.nz}
\end{itemize}

\hypertarget{datamining-overview}{%
\chapter{데이터마이닝 개요}\label{datamining-overview}}

데이터마이닝은 다양한 목적으로 사용될 수 있다. 그러나 기본적인 목적에 따라 분류할 때, 예측(prediction), 분류(classification), 군집화(clustering), 연관규칙(association rule) 추출로 구분할 수 있겠다.

추후 내용 추가

\hypertarget{part-1uxbd80---uxc608uxce21}{%
\part{1부 - 예측}\label{part-1uxbd80---uxc608uxce21}}

\hypertarget{regression}{%
\chapter{회귀분석}\label{regression}}

\hypertarget{regression-packages-install}{%
\section{필요 R 패키지 설치}\label{regression-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.3.1\\
\hline
stats & 4.1.0\\
\hline
broom & 0.7.8\\
\hline
\end{tabular}

\hypertarget{multiple-linear-regression}{%
\section{다중회귀모형}\label{multiple-linear-regression}}

아래와 같이 \(n\)개의 객체와 \(k\)개의 독립변수(\(\mathbf{x}\))로 이루어지고 하나의 종속변수(\(y\))로 이루어진 선형 회귀모형을 정의하자.

\begin{equation}
y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \cdots + \beta_k x_{ik} + \epsilon_i
\label{eq:multiple-linear-regression}
\end{equation}

이 때, 오차항 \(\epsilon_i\)은 서로 독립이고 동일한 정규분포 \(N(0, \sigma^2)\)을 따른다.

위 회귀모형은 아래와 같이 행렬의 연산으로 표한할 수 있다.

\begin{equation}
\mathbf{y} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\epsilon} \label{eq:multiple-linear-regression-matrix}
\end{equation}

이 때,

\[
\mathbf{y} = \left[ \begin{array}{c}
y_1 \\ y_2 \\ y_3 \\ \vdots \\ y_n
\end{array} \right]
\]

\[
\mathbf{X} = \left[ \begin{array}{c c c c c}
1 & x_{11} & x_{12} & \cdots & x_{1k}\\
1 & x_{21} & x_{22} & \cdots & x_{2k}\\
\vdots & \vdots & \vdots & \ddots & \vdots \\
1 & x_{n1} & x_{n2} & \cdots & x_{nk}
\end{array} \right]
\]

\[
\boldsymbol{\beta} = \left[ \begin{array}{c}
\beta_0 \\ \beta_1 \\ \beta_2 \\ \vdots \\ \beta_k
\end{array} \right]
\]

\[
\boldsymbol{\epsilon} = \left[ \begin{array}{c}
\epsilon_1 \\ \epsilon_2 \\ \epsilon_3 \\ \vdots \\ \epsilon_n
\end{array} \right]
\]

로 정의되며,

\[
E[\boldsymbol{\epsilon}] = \mathbf{0}, \, Var[\boldsymbol{\epsilon}] = \sigma^2 \mathbf{I} 
\]

이다.

\hypertarget{regression-response-confidence-prediction}{%
\section{반응치에 대한 추정 및 예측}\label{regression-response-confidence-prediction}}

\hypertarget{regression-response-confidence}{%
\subsection{평균반응치의 추정}\label{regression-response-confidence}}

\hypertarget{regression-response-confidence-basic-script}{%
\subsubsection{기본 R 스트립트}\label{regression-response-confidence-basic-script}}

다음과 같은 10명의 나이(age), 키(height), 몸무게(weight)에 대한 데이터가 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{age, }\SpecialCharTok{\textasciitilde{}}\NormalTok{height, }\SpecialCharTok{\textasciitilde{}}\NormalTok{weight,}
  \DecValTok{21}\NormalTok{, }\DecValTok{170}\NormalTok{, }\DecValTok{60}\NormalTok{,}
  \DecValTok{47}\NormalTok{, }\DecValTok{167}\NormalTok{, }\DecValTok{65}\NormalTok{,}
  \DecValTok{36}\NormalTok{, }\DecValTok{173}\NormalTok{, }\DecValTok{67}\NormalTok{,}
  \DecValTok{15}\NormalTok{, }\DecValTok{165}\NormalTok{, }\DecValTok{54}\NormalTok{,}
  \DecValTok{54}\NormalTok{, }\DecValTok{168}\NormalTok{, }\DecValTok{73}\NormalTok{,}
  \DecValTok{25}\NormalTok{, }\DecValTok{177}\NormalTok{, }\DecValTok{71}\NormalTok{,}
  \DecValTok{32}\NormalTok{, }\DecValTok{169}\NormalTok{, }\DecValTok{68}\NormalTok{,}
  \DecValTok{18}\NormalTok{, }\DecValTok{172}\NormalTok{, }\DecValTok{62}\NormalTok{,}
  \DecValTok{43}\NormalTok{, }\DecValTok{171}\NormalTok{, }\DecValTok{66}\NormalTok{,}
  \DecValTok{28}\NormalTok{, }\DecValTok{175}\NormalTok{, }\DecValTok{68}
\NormalTok{)}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
  \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}나이 (age)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}키 (height)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}몸무게 (weight)\textquotesingle{}}\NormalTok{),}
  \AttributeTok{caption =} \StringTok{\textquotesingle{}나이, 키, 몸무게 데이터\textquotesingle{}}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:regression-age-height-weight-data}나이, 키, 몸무게 데이터}
\centering
\begin{tabular}[t]{rrr}
\toprule
나이 (age) & 키 (height) & 몸무게 (weight)\\
\midrule
21 & 170 & 60\\
47 & 167 & 65\\
36 & 173 & 67\\
15 & 165 & 54\\
54 & 168 & 73\\
\addlinespace
25 & 177 & 71\\
32 & 169 & 68\\
18 & 172 & 62\\
43 & 171 & 66\\
28 & 175 & 68\\
\bottomrule
\end{tabular}
\end{table}

회귀모형을 아래와 같이 학습한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm\_fit }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(weight }\SpecialCharTok{\textasciitilde{}}\NormalTok{ age }\SpecialCharTok{+}\NormalTok{ height, }\AttributeTok{data =}\NormalTok{ train\_df)}
\end{Highlighting}
\end{Shaded}

추정된 회귀계수는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(lm\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  (Intercept)          age       height 
## -108.1671993    0.3291212    0.9552913
\end{verbatim}

추정계수벡터의 분산-공분산 행렬은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vcov}\NormalTok{(lm\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              (Intercept)          age        height
## (Intercept) 1774.3280624 -0.671107283 -10.264885141
## age           -0.6711073  0.004794717   0.003035476
## height       -10.2648851  0.003035476   0.059566804
\end{verbatim}

나이가 40, 키가 170인 사람들의 평균 몸무게에 대한 95\% 신뢰구간은 아래와 같이 구할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(lm\_fit, }\AttributeTok{newdata =} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{age =} \DecValTok{40}\NormalTok{, }\AttributeTok{height =} \DecValTok{170}\NormalTok{),}
        \AttributeTok{interval =} \StringTok{"confidence"}\NormalTok{, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        fit      lwr      upr
## 1 67.39718 65.01701 69.77735
\end{verbatim}

\hypertarget{regression-response-confidence-variance}{%
\subsubsection{평균 반응치의 분산 추정}\label{regression-response-confidence-variance}}

새로운 독립변수에 대한 벡터를 아래와 같이 \(\mathbf{x}_0\)라 하면, 평균반응치의 추정량은 아래와 같이 표현된다.

\begin{equation}
\hat{y}_0 = \mathbf{x}_0^\top \hat{\boldsymbol{\beta}} \label{eq:response-estimate}
\end{equation}

식 \eqref{eq:response-estimate}의 분산은 아래와 같다.

\begin{eqnarray}
Var(\hat{y}_0) &=& \mathbf{x}_0^\top Var(\hat{\boldsymbol{\beta}}) \mathbf{x}_0\\
&=& \sigma^2 \mathbf{x}_0^\top \left(\mathbf{X}^\top \mathbf{X}\right)^{-1} \mathbf{x}_0 \label{eq:response-estimate-variance}
\end{eqnarray}

위 식 \eqref{eq:response-estimate-variance}에서 \(\sigma^2\) 대신 그 추정값인 \(MSE\) (mean squared error)를 대입하여 평균반응치의 분산을 추정한다.

\begin{equation}
\hat{Var}(\hat{y}_0) = MSE \times \left( \mathbf{x}_0^\top \left(\mathbf{X}^\top \mathbf{X}\right)^{-1} \mathbf{x}_0 \right) \label{eq:response-estimate-variance-est}
\end{equation}

우선 Table \ref{tab:regression-age-height-weight-data}에 대해 회귀모형 추정치 \(\hat{\boldsymbol{\beta}}\)와 \(MSE\)값을 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(train\_df)}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(}
  \AttributeTok{intercept =} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, n), }
\NormalTok{  train\_df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"height"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.matrix}\NormalTok{()}
\NormalTok{)}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ train\_df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"weight"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.matrix}\NormalTok{()}
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{ncol}\NormalTok{(X) }\SpecialCharTok{{-}} \DecValTok{1}

\CommentTok{\# regression coefficient}
\NormalTok{beta\_hat }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(}\FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ X) }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ y}

\CommentTok{\# response estimate}
\NormalTok{y\_hat }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ beta\_hat}

\CommentTok{\# MSE}
\NormalTok{MSE }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{((y }\SpecialCharTok{{-}}\NormalTok{ y\_hat) }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\NormalTok{ (n }\SpecialCharTok{{-}}\NormalTok{ k }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

이후, 나이가 40, 키가 170인 객체 \(\mathbf{x}_0\)에 대한 평균 반응치 \(\hat{y}_0\)의 95\% 신뢰구간을 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# variance of y\_hat on new\_x}
\NormalTok{new\_x }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
  \AttributeTok{intercept =} \DecValTok{1}\NormalTok{,}
  \AttributeTok{age =} \DecValTok{40}\NormalTok{,}
  \AttributeTok{height =} \DecValTok{170}
\NormalTok{), }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{)}

\NormalTok{new\_y\_hat }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(new\_x) }\SpecialCharTok{\%*\%}\NormalTok{ beta\_hat}

\NormalTok{var\_new\_y\_hat }\OtherTok{\textless{}{-}}\NormalTok{ MSE }\SpecialCharTok{*} \FunctionTok{t}\NormalTok{(new\_x) }\SpecialCharTok{\%*\%} \FunctionTok{solve}\NormalTok{(}\FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ X) }\SpecialCharTok{\%*\%}\NormalTok{ new\_x}
\NormalTok{se\_new\_y\_hat }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(var\_new\_y\_hat)}

\NormalTok{lci }\OtherTok{\textless{}{-}}\NormalTok{ new\_y\_hat }\SpecialCharTok{+} \FunctionTok{qt}\NormalTok{(}\FloatTok{0.025}\NormalTok{, n }\SpecialCharTok{{-}}\NormalTok{ k }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ se\_new\_y\_hat}
\NormalTok{uci }\OtherTok{\textless{}{-}}\NormalTok{ new\_y\_hat }\SpecialCharTok{+} \FunctionTok{qt}\NormalTok{(}\FloatTok{0.975}\NormalTok{, n }\SpecialCharTok{{-}}\NormalTok{ k }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ se\_new\_y\_hat}

\FunctionTok{str\_glue}\NormalTok{(}\StringTok{"(\{format(lci, nsmall = 3L)\}, \{format(uci, nsmall = 3L)\})"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (65.01701, 69.77735)
\end{verbatim}

\hypertarget{regression-response-prediction}{%
\subsection{미래반응치의 예측}\label{regression-response-prediction}}

\hypertarget{regression-response-prediction-basic-script}{%
\subsubsection{기본 R 스트립트}\label{regression-response-prediction-basic-script}}

\ref{regression-response-confidence} 절에서 추정한 회귀모형을 통해, 새로운 독립변수값(나이 = 40, 키 = 170)을 지닌 특정 객체에 대한 몸무게의 예측구간을 구한다. 이는 한 객체의 몸무게의 예측구간으로, \ref{regression-response-confidence} 절에서 구한 평균 몸무게의 신뢰구간보다 넓다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(lm\_fit, }\AttributeTok{newdata =} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{age =} \DecValTok{40}\NormalTok{, }\AttributeTok{height =} \DecValTok{170}\NormalTok{),}
        \AttributeTok{interval =} \StringTok{"prediction"}\NormalTok{, }\AttributeTok{level =} \FloatTok{0.95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        fit      lwr     upr
## 1 67.39718 60.68745 74.1069
\end{verbatim}

\hypertarget{regression-response-prediction-interval}{%
\subsubsection{미래 반응치의 예측구간 추정}\label{regression-response-prediction-interval}}

독립변수값들에 대응하는 미래반응치인 \(y_0\)의 예측치는 평균반응치의 추정치와 동일하며, 반응치의 예측구간을 구하기 위해서는 예측오차의 분산을 알아야 하는데, 이는 아래와 같이 식 \eqref{eq:response-estimate-variance}보다 \(\sigma^2\)이 더 크게 된다.

\begin{eqnarray}
Var(y_0 - \hat{y}_0) &=& Var(y_0) + Var(\hat{y}_0)\\
&=& \sigma^2 + \sigma^2 \mathbf{x}_0^\top \left(\mathbf{X}^\top \mathbf{X}\right)^{-1} \mathbf{x}_0 \\
&=& \sigma^2 \left( 1 + \mathbf{x}_0^\top \left(\mathbf{X}^\top \mathbf{X}\right)^{-1} \mathbf{x}_0 \right)
\label{eq:response-prediction-variance}
\end{eqnarray}

위 식 \eqref{eq:response-prediction-variance}에서 \(\sigma^2\) 대신 \(MSE\)를 대입함으로써 예측오차 분산을 추정할 수 있다.

\begin{equation}
\hat{Var}(y_0 - \hat{y}_0) = MSE \times \left( 1 + \mathbf{x}_0^\top \left(\mathbf{X}^\top \mathbf{X}\right)^{-1} \mathbf{x}_0 \right)
\label{eq:response-prediction-variance-est}
\end{equation}

앞 절에서 추정한 회귀모형을 이용하여, 나이가 40, 키가 170인 객체 \(\mathbf{x}_0\)에 대한 미래 반응치 \(y_0\)의 95\% 예측구간을 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# variance of y\_hat on new\_x}
\NormalTok{new\_x }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}
  \AttributeTok{intercept =} \DecValTok{1}\NormalTok{,}
  \AttributeTok{age =} \DecValTok{40}\NormalTok{,}
  \AttributeTok{height =} \DecValTok{170}
\NormalTok{), }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{)}

\NormalTok{new\_y\_hat }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(new\_x) }\SpecialCharTok{\%*\%}\NormalTok{ beta\_hat}

\NormalTok{var\_new\_y\_pred }\OtherTok{\textless{}{-}}\NormalTok{ MSE }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{t}\NormalTok{(new\_x) }\SpecialCharTok{\%*\%} \FunctionTok{solve}\NormalTok{(}\FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ X) }\SpecialCharTok{\%*\%}\NormalTok{ new\_x)}
\NormalTok{se\_new\_y\_pred }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(var\_new\_y\_pred)}

\NormalTok{lci }\OtherTok{\textless{}{-}}\NormalTok{ new\_y\_hat }\SpecialCharTok{+} \FunctionTok{qt}\NormalTok{(}\FloatTok{0.025}\NormalTok{, n }\SpecialCharTok{{-}}\NormalTok{ k }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ se\_new\_y\_pred}
\NormalTok{uci }\OtherTok{\textless{}{-}}\NormalTok{ new\_y\_hat }\SpecialCharTok{+} \FunctionTok{qt}\NormalTok{(}\FloatTok{0.975}\NormalTok{, n }\SpecialCharTok{{-}}\NormalTok{ k }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ se\_new\_y\_pred}

\FunctionTok{str\_glue}\NormalTok{(}\StringTok{"(\{format(lci, nsmall = 3L)\}, \{format(uci, nsmall = 3L)\})"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (60.68745, 74.1069)
\end{verbatim}

\hypertarget{regression-indicator-variable}{%
\section{지시변수와 회귀모형}\label{regression-indicator-variable}}

\hypertarget{regression-indicator-variable-basic-script}{%
\subsection{기본 R 스트립트}\label{regression-indicator-variable-basic-script}}

어떤 열연코일의 인장강도(TS)에 권취온도(CT)가 어떤 영향을 미치는가를 조사하기 위해 TS를 종속변수, CT를 독립변수로 하여 회귀분석을 실시하기로 하였다. 수집된 데이터에는 두 개의 두께 그룹(2mm, 6mm)이 포함되어 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{ct, }\SpecialCharTok{\textasciitilde{}}\NormalTok{thickness, }\SpecialCharTok{\textasciitilde{}}\NormalTok{ts,}
  \DecValTok{540}\NormalTok{, }\DecValTok{2}\NormalTok{, }\FloatTok{52.5}\NormalTok{,}
  \DecValTok{660}\NormalTok{, }\DecValTok{2}\NormalTok{, }\FloatTok{50.2}\NormalTok{,}
  \DecValTok{610}\NormalTok{, }\DecValTok{2}\NormalTok{, }\FloatTok{51.3}\NormalTok{,}
  \DecValTok{710}\NormalTok{, }\DecValTok{2}\NormalTok{, }\FloatTok{49.1}\NormalTok{,}
  \DecValTok{570}\NormalTok{, }\DecValTok{6}\NormalTok{, }\FloatTok{50.8}\NormalTok{,}
  \DecValTok{700}\NormalTok{, }\DecValTok{6}\NormalTok{, }\FloatTok{48.7}\NormalTok{,}
  \DecValTok{560}\NormalTok{, }\DecValTok{6}\NormalTok{, }\FloatTok{51.2}\NormalTok{,}
  \DecValTok{600}\NormalTok{, }\DecValTok{6}\NormalTok{, }\FloatTok{50.8}\NormalTok{,}
  \DecValTok{680}\NormalTok{, }\DecValTok{6}\NormalTok{, }\FloatTok{49.3}\NormalTok{,}
  \DecValTok{530}\NormalTok{, }\DecValTok{6}\NormalTok{, }\FloatTok{51.5}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{thickness =} \FunctionTok{factor}\NormalTok{(thickness, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{2}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(train\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## tibble [10 x 3] (S3: tbl_df/tbl/data.frame)
##  $ ct       : num [1:10] 540 660 610 710 570 700 560 600 680 530
##  $ thickness: Factor w/ 2 levels "6","2": 2 2 2 2 1 1 1 1 1 1
##  $ ts       : num [1:10] 52.5 50.2 51.3 49.1 50.8 48.7 51.2 50.8 49.3 51.5
\end{verbatim}

두께를 \texttt{factor}로 지정하고 회귀모형을 추정하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm\_fit }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(ts }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ct }\SpecialCharTok{+}\NormalTok{ thickness, }\AttributeTok{data =}\NormalTok{ train\_df)}
\end{Highlighting}
\end{Shaded}

회귀 계수는 아래와 같이 얻어진다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(lm\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept)          ct  thickness2 
## 61.10796610 -0.01767797  0.80415254
\end{verbatim}

두께 그룹에 따라 CT에 대한 TS의 기울기가 다르다고 예상되면 CT와 두께 간에 교호작용(interaction)이 존재한다고 말하며, 이 때 회귀모형은 다음과 같이 추정한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lm\_interaction\_fit }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(}
\NormalTok{  ts }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ct }\SpecialCharTok{+}\NormalTok{ thickness }\SpecialCharTok{+}\NormalTok{ ct}\SpecialCharTok{:}\NormalTok{thickness, }
  \AttributeTok{data =}\NormalTok{ train\_df}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

교호작용이 추가된 회귀 결과는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{(lm\_interaction\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 5
##   term          estimate std.error statistic  p.value
##   <chr>            <dbl>     <dbl>     <dbl>    <dbl>
## 1 (Intercept)   60.1       0.750       80.2  2.53e-10
## 2 ct            -0.0161    0.00123    -13.1  1.23e- 5
## 3 thickness2     3.28      1.21         2.71 3.52e- 2
## 4 ct:thickness2 -0.00399   0.00194     -2.05 8.57e- 2
\end{verbatim}

두께에 따른 CT와 TS의 관계를 그래프로 살펴보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_df }\OtherTok{\textless{}{-}} \FunctionTok{crossing}\NormalTok{(}
  \AttributeTok{ct =} \FunctionTok{seq}\NormalTok{(}\DecValTok{500}\NormalTok{, }\DecValTok{750}\NormalTok{, }\AttributeTok{by =} \DecValTok{10}\NormalTok{),}
  \AttributeTok{thickness =} \FunctionTok{factor}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{)}

\NormalTok{new\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ts\_hat =} \FunctionTok{predict}\NormalTok{(lm\_interaction\_fit, .)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ ct, }\AttributeTok{y =}\NormalTok{ ts\_hat)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{color =}\NormalTok{ thickness)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ ct, }\AttributeTok{y =}\NormalTok{ ts, }\AttributeTok{color =}\NormalTok{ thickness), }\AttributeTok{data =}\NormalTok{ train\_df) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{color =} \StringTok{"thickness"}\NormalTok{, }\AttributeTok{x =} \StringTok{"CT"}\NormalTok{, }\AttributeTok{y =} \StringTok{"TS"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/regression-ct-ts-by-thickness-plot-1} 

}

\caption{두께에 따른 CT와 TS의 관계}\label{fig:regression-ct-ts-by-thickness-plot}
\end{figure}

\hypertarget{pca}{%
\chapter{주성분분석}\label{pca}}

\hypertarget{pca-packages-install}{%
\section{필요 R 패키지 설치}\label{pca-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.3.1\\
\hline
stats & 4.1.0\\
\hline
broom & 0.7.8\\
\hline
Matrix & 1.3-4\\
\hline
nipals & 0.7\\
\hline
\end{tabular}

\hypertarget{pca-matrix-factorization}{%
\section{행렬의 분해}\label{pca-matrix-factorization}}

\hypertarget{pca-matrix-factorization-basic-script}{%
\subsection{기본 R 스트립트}\label{pca-matrix-factorization-basic-script}}

아래 Table \ref{tab:pca-matrix-factorization-data}는 국내 18개 증권회사의 주요 재무제표를 나열한 것이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{company, }\SpecialCharTok{\textasciitilde{}}\NormalTok{roa, }\SpecialCharTok{\textasciitilde{}}\NormalTok{roe, }\SpecialCharTok{\textasciitilde{}}\NormalTok{bis, }\SpecialCharTok{\textasciitilde{}}\NormalTok{de\_ratio, }\SpecialCharTok{\textasciitilde{}}\NormalTok{turnover,}
  \StringTok{"SK증권"}\NormalTok{, }\FloatTok{2.43}\NormalTok{, }\FloatTok{11.10}\NormalTok{, }\FloatTok{18.46}\NormalTok{, }\FloatTok{441.67}\NormalTok{, }\FloatTok{0.90}\NormalTok{,}
  \StringTok{"교보증권"}\NormalTok{, }\FloatTok{3.09}\NormalTok{, }\FloatTok{9.95}\NormalTok{, }\FloatTok{29.46}\NormalTok{, }\FloatTok{239.43}\NormalTok{, }\FloatTok{0.90}\NormalTok{,}
  \StringTok{"대신증권"}\NormalTok{, }\FloatTok{2.22}\NormalTok{, }\FloatTok{6.86}\NormalTok{, }\FloatTok{28.62}\NormalTok{, }\FloatTok{249.36}\NormalTok{, }\FloatTok{0.69}\NormalTok{,}
  \StringTok{"대우증권"}\NormalTok{, }\FloatTok{5.76}\NormalTok{, }\FloatTok{23.19}\NormalTok{, }\FloatTok{23.47}\NormalTok{, }\FloatTok{326.09}\NormalTok{, }\FloatTok{1.43}\NormalTok{,}
  \StringTok{"동부증권"}\NormalTok{, }\FloatTok{1.60}\NormalTok{, }\FloatTok{5.64}\NormalTok{, }\FloatTok{25.64}\NormalTok{, }\FloatTok{289.98}\NormalTok{, }\FloatTok{1.42}\NormalTok{,}
  \StringTok{"메리츠증권"}\NormalTok{, }\FloatTok{3.53}\NormalTok{, }\FloatTok{10.64}\NormalTok{, }\FloatTok{32.25}\NormalTok{, }\FloatTok{210.10}\NormalTok{, }\FloatTok{1.17}\NormalTok{,}
  \StringTok{"미래에셋증권"}\NormalTok{, }\FloatTok{4.26}\NormalTok{, }\FloatTok{15.56}\NormalTok{, }\FloatTok{24.40}\NormalTok{, }\FloatTok{309.78}\NormalTok{, }\FloatTok{0.81}\NormalTok{,}
  \StringTok{"부국증권"}\NormalTok{, }\FloatTok{3.86}\NormalTok{, }\FloatTok{5.50}\NormalTok{, }\FloatTok{70.74}\NormalTok{, }\FloatTok{41.36}\NormalTok{, }\FloatTok{0.81}\NormalTok{,}
  \StringTok{"브릿지증권"}\NormalTok{, }\FloatTok{4.09}\NormalTok{, }\FloatTok{6.44}\NormalTok{, }\FloatTok{64.38}\NormalTok{, }\FloatTok{55.32}\NormalTok{, }\FloatTok{0.32}\NormalTok{,}
  \StringTok{"삼성증권"}\NormalTok{, }\FloatTok{2.73}\NormalTok{, }\FloatTok{10.68}\NormalTok{, }\FloatTok{24.41}\NormalTok{, }\FloatTok{309.59}\NormalTok{, }\FloatTok{0.64}\NormalTok{,}
  \StringTok{"서울증권"}\NormalTok{, }\FloatTok{2.03}\NormalTok{, }\FloatTok{4.50}\NormalTok{, }\FloatTok{42.53}\NormalTok{, }\FloatTok{135.12}\NormalTok{, }\FloatTok{0.59}\NormalTok{,}
  \StringTok{"신영증권"}\NormalTok{, }\FloatTok{1.96}\NormalTok{, }\FloatTok{8.92}\NormalTok{, }\FloatTok{18.48}\NormalTok{, }\FloatTok{441.19}\NormalTok{, }\FloatTok{1.07}\NormalTok{,}
  \StringTok{"신흥증권"}\NormalTok{, }\FloatTok{3.25}\NormalTok{, }\FloatTok{7.96}\NormalTok{, }\FloatTok{40.42}\NormalTok{, }\FloatTok{147.41}\NormalTok{, }\FloatTok{1.19}\NormalTok{,}
  \StringTok{"우리투자증권"}\NormalTok{, }\FloatTok{2.01}\NormalTok{, }\FloatTok{10.28}\NormalTok{, }\FloatTok{17.46}\NormalTok{, }\FloatTok{472.78}\NormalTok{, }\FloatTok{1.25}\NormalTok{,}
  \StringTok{"유화증권"}\NormalTok{, }\FloatTok{2.28}\NormalTok{, }\FloatTok{3.65}\NormalTok{, }\FloatTok{63.71}\NormalTok{, }\FloatTok{56.96}\NormalTok{, }\FloatTok{0.12}\NormalTok{,}
  \StringTok{"한양증권"}\NormalTok{, }\FloatTok{4.51}\NormalTok{, }\FloatTok{7.50}\NormalTok{, }\FloatTok{63.52}\NormalTok{, }\FloatTok{57.44}\NormalTok{, }\FloatTok{0.80}\NormalTok{,}
  \StringTok{"한화증권"}\NormalTok{, }\FloatTok{3.29}\NormalTok{, }\FloatTok{12.37}\NormalTok{, }\FloatTok{24.47}\NormalTok{, }\FloatTok{308.63}\NormalTok{, }\FloatTok{0.57}\NormalTok{,}
  \StringTok{"현대증권"}\NormalTok{, }\FloatTok{1.73}\NormalTok{, }\FloatTok{7.57}\NormalTok{, }\FloatTok{19.59}\NormalTok{, }\FloatTok{410.45}\NormalTok{, }\FloatTok{1.19}
\NormalTok{)}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{rep}\NormalTok{(}\StringTok{"r"}\NormalTok{, }\FunctionTok{ncol}\NormalTok{(train\_df)),}
  \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}
    \StringTok{"회사"}\NormalTok{,}
    \StringTok{"총자본 순이익율 ($x\_1$)"}\NormalTok{,}
    \StringTok{"자기자본 순이익율 ($x\_2$)"}\NormalTok{,}
    \StringTok{"자기자본비율 ($x\_3$)"}\NormalTok{,}
    \StringTok{"부채비율 ($x\_4$)"}\NormalTok{,}
    \StringTok{"자기자본 회전율 ($x\_5$)"}
\NormalTok{  ),}
  \AttributeTok{caption =} \StringTok{"국내 증권회사의 주요 재무제표"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:pca-matrix-factorization-data}국내 증권회사의 주요 재무제표}
\centering
\begin{tabular}[t]{rrrrrr}
\toprule
회사 & 총자본 순이익율 (\$x\_1\$) & 자기자본 순이익율 (\$x\_2\$) & 자기자본비율 (\$x\_3\$) & 부채비율 (\$x\_4\$) & 자기자본 회전율 (\$x\_5\$)\\
\midrule
SK증권 & 2.43 & 11.10 & 18.46 & 441.67 & 0.90\\
교보증권 & 3.09 & 9.95 & 29.46 & 239.43 & 0.90\\
대신증권 & 2.22 & 6.86 & 28.62 & 249.36 & 0.69\\
대우증권 & 5.76 & 23.19 & 23.47 & 326.09 & 1.43\\
동부증권 & 1.60 & 5.64 & 25.64 & 289.98 & 1.42\\
\addlinespace
메리츠증권 & 3.53 & 10.64 & 32.25 & 210.10 & 1.17\\
미래에셋증권 & 4.26 & 15.56 & 24.40 & 309.78 & 0.81\\
부국증권 & 3.86 & 5.50 & 70.74 & 41.36 & 0.81\\
브릿지증권 & 4.09 & 6.44 & 64.38 & 55.32 & 0.32\\
삼성증권 & 2.73 & 10.68 & 24.41 & 309.59 & 0.64\\
\addlinespace
서울증권 & 2.03 & 4.50 & 42.53 & 135.12 & 0.59\\
신영증권 & 1.96 & 8.92 & 18.48 & 441.19 & 1.07\\
신흥증권 & 3.25 & 7.96 & 40.42 & 147.41 & 1.19\\
우리투자증권 & 2.01 & 10.28 & 17.46 & 472.78 & 1.25\\
유화증권 & 2.28 & 3.65 & 63.71 & 56.96 & 0.12\\
\addlinespace
한양증권 & 4.51 & 7.50 & 63.52 & 57.44 & 0.80\\
한화증권 & 3.29 & 12.37 & 24.47 & 308.63 & 0.57\\
현대증권 & 1.73 & 7.57 & 19.59 & 410.45 & 1.19\\
\bottomrule
\end{tabular}
\end{table}

이에 대하여 R 기본 \texttt{stats} 패키지 내의 \texttt{prcomp} 함수를 이용하여 주성분 분석을 수행할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pca\_fit }\OtherTok{\textless{}{-}} \FunctionTok{prcomp}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ roa }\SpecialCharTok{+}\NormalTok{ roe }\SpecialCharTok{+}\NormalTok{ bis }\SpecialCharTok{+}\NormalTok{ de\_ratio }\SpecialCharTok{+}\NormalTok{ turnover,}
                  \AttributeTok{data =}\NormalTok{ train\_df, }\AttributeTok{scale =} \ConstantTok{TRUE}\NormalTok{)}

\NormalTok{pca\_fit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Standard deviations (1, .., p=5):
## [1] 1.6617648 1.2671437 0.7419994 0.2531070 0.1351235
## 
## Rotation (n x k) = (5 x 5):
##                  PC1         PC2           PC3          PC4         PC5
## roa       0.07608427 -0.77966993  0.0008915975 -0.140755404  0.60540325
## roe      -0.39463007 -0.56541218 -0.2953216494  0.117644166 -0.65078503
## bis       0.56970191 -0.16228156  0.2412221065 -0.637721889 -0.42921686
## de_ratio -0.55982770  0.19654293 -0.2565972887 -0.748094314  0.14992183
## turnover -0.44778451 -0.08636803  0.8881182665 -0.003668418 -0.05711464
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(pca\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Importance of components:
##                           PC1    PC2    PC3     PC4     PC5
## Standard deviation     1.6618 1.2671 0.7420 0.25311 0.13512
## Proportion of Variance 0.5523 0.3211 0.1101 0.01281 0.00365
## Cumulative Proportion  0.5523 0.8734 0.9835 0.99635 1.00000
\end{verbatim}

각 주성분에 대한 고유값을 스크리 도표로 나타내면 아래 Figure \ref{fig:pca-screeplot}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{screeplot}\NormalTok{(pca\_fit, }\AttributeTok{main =} \ConstantTok{NULL}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/pca-screeplot-1} 

}

\caption{고유치 스크리 도표}\label{fig:pca-screeplot}
\end{figure}

\hypertarget{pca-ss}{%
\subsection{변수의 변동과 제곱합}\label{pca-ss}}

총 \(k\)개의 독립변수가 있고 각 독립변수에 대하여 \(n\)개의 관측치가 있다고 하자. 이 때, \(x_{ij}\)를 \(j\)번째 독립변수에 대한 \(i\)번째 관측치라 하자. 즉, 관측데이터는 아래와 같은 행렬로 표현할 수 있다.

\begin{equation*}
\mathbf{X} = \left[ \begin{array}{c c c c}
x_{11} & x_{12} & \cdots & x_{1k}\\
x_{21} & x_{22} & \cdots & x_{2k}\\
\vdots & \vdots & \ddots & \vdots \\
x_{n1} & x_{n2} & \cdots & x_{nk}
\end{array} \right]
\end{equation*}

주성분분석에서는 통상 원데이터를 그대로 사용하지 않고 적절한 변환을 취하는데, 주로 평균조정(mean-centered) 데이터를 이용한다. 이는 아래와 같이 독립변수에 대하여 표본평균을 뺌으로써 조정된 변수의 평균이 0이 되도록 하는 것이다.

\begin{equation}
x_{ij} \leftarrow x_{ij} - \frac{1}{n} \sum_{l = 1}^{n} x_{lj} \label{eq:pca-mean-centering}
\end{equation}

이후에 별도의 언급이 없는 한, 행렬 \(\mathbf{X}\) 및 변수값 \(x_{ij}\)는 식 \eqref{eq:pca-mean-centering}을 이용하여 평균조정된 것으로 가정한다.

이 밖에도 다른 변환이 사용되는 경우가 있는데, 특히 단위 등이 서로 상이할 경우에는 평균조정 이후 추가로 각 변수의 분산이 1이 되도록 분산조정을 한다.

\begin{equation*}
z_{ij} \leftarrow \frac{x_{ij}}{\sqrt{\frac{1}{n - 1} \sum_{l =1}^{n} x_{lj}^2}} \label{eq:pca-scaling}
\end{equation*}

이 때, 식 \eqref{eq:pca-scaling}에서 분모 부분은 변수의 표본 표준편차로 \(s_j\)로 표현된다.

\begin{equation*}
s_{j} = \sqrt{\frac{1}{n - 1} \sum_{l =1}^{n} x_{lj}^2}
\end{equation*}

이후 분산조정을 이용하는 경우 행렬 \(\mathbf{Z}\) 및 변수값 \(z_{ij}\)로 표현한다.

\begin{equation*}
\mathbf{Z} = \left[ \begin{array}{c c c c}
z_{11} & z_{12} & \cdots & z_{1k}\\
z_{21} & z_{22} & \cdots & z_{2k}\\
\vdots & \vdots & \ddots & \vdots \\
z_{n1} & z_{n2} & \cdots & z_{nk}
\end{array} \right]
\end{equation*}

변수벡터 \(\mathbf{x}_j = [x_{1j} \, x_{2j} \, \cdots \, x_{nj}]^\top\)에 대한 제곱합의 정의는 아래와 같다.

\begin{equation}
SS(\mathbf{x}_j) = \mathbf{x}_j^\top \mathbf{x}_j = \sum_{i = 1}^{n} x_{ij}^2
\end{equation}

따라서, 평균조정된 변수에 대해 제곱합고 표본분산은 다음과 같은 관계가 있다.

\begin{equation*}
SS(\mathbf{x}_j) = (n - 1) s_j^2
\end{equation*}

변수행렬 \(\mathbf{X}\)에 대한 제곱합은 각 변수들의 제곱합의 총합(총변동)으로 정의된다.

\begin{equation}
SS(\mathbf{X}) = \sum_{j = 1}^{k} SS(\mathbf{x}_j) = \sum_{j = 1}^{k} \sum_{i = 1}^{n} x_{ij}^2
\end{equation}

Table \ref{tab:pca-matrix-factorization-data} 데이터에 대하여 각 변수의 제곱합을 계산해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate\_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x)) }\SpecialCharTok{\%\textgreater{}\%}  \CommentTok{\# mean{-}centering}
  \FunctionTok{summarize\_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{sum}\NormalTok{(x }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{)) }\CommentTok{\# sum of squares by variable}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 5
##     roa   roe   bis de_ratio turnover
##   <dbl> <dbl> <dbl>    <dbl>    <dbl>
## 1  21.9  355. 5591.  347817.     2.23
\end{verbatim}

전체 데이터 행렬에 대한 제곱합은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate\_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x)) }\SpecialCharTok{\%\textgreater{}\%}  \CommentTok{\# mean{-}centering}
  \FunctionTok{summarize\_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{sum}\NormalTok{(x }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# sum of squares by variable}
\NormalTok{  \{}\FunctionTok{sum}\NormalTok{(.)\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 353786.6
\end{verbatim}

위 결과에서 부채비율(\texttt{de\_ratio})의 변동이 총변동의 대부분을 차지하고, 자기자본 회전율(\texttt{turnover})이 총변동에 미치는 영향은 미미한데, 이는 각 변수들이 측정하는 값의 분포(범위)가 크게 다르기 때문이다. 이러한 경우, 일반적으로 분산조정을 추가로 적용한 뒤 주성분분석을 수행한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{standardized\_df }\OtherTok{\textless{}{-}}\NormalTok{ train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate\_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x)) }\SpecialCharTok{\%\textgreater{}\%}  \CommentTok{\# mean{-}centering}
  \FunctionTok{mutate\_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) x }\SpecialCharTok{/} \FunctionTok{sd}\NormalTok{(x))  }\CommentTok{\# scaling}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{standardized\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 18 x 6
##    company          roa     roe    bis de_ratio turnover
##    <chr>          <dbl>   <dbl>  <dbl>    <dbl>    <dbl>
##  1 SK증권       -0.533   0.383  -0.918  1.34      0.0507
##  2 교보증권      0.0484  0.131  -0.312 -0.0749    0.0507
##  3 대신증권     -0.718  -0.545  -0.358 -0.00551  -0.530 
##  4 대우증권      2.40    3.03   -0.642  0.531     1.52  
##  5 동부증권     -1.26   -0.812  -0.522  0.278     1.49  
##  6 메리츠증권    0.436   0.282  -0.158 -0.280     0.797 
##  7 미래에셋증권  1.08    1.36   -0.591  0.417    -0.198 
##  8 부국증권      0.726  -0.843   1.96  -1.46     -0.198 
##  9 브릿지증권    0.929  -0.637   1.61  -1.36     -1.55  
## 10 삼성증권     -0.269   0.291  -0.590  0.416    -0.668 
## 11 서울증권     -0.885  -1.06    0.409 -0.804    -0.806 
## 12 신영증권     -0.947  -0.0942 -0.917  1.34      0.521 
## 13 신흥증권      0.189  -0.304   0.293 -0.718     0.852 
## 14 우리투자증권 -0.903   0.203  -0.973  1.56      1.02  
## 15 유화증권     -0.665  -1.25    1.58  -1.35     -2.11  
## 16 한양증권      1.30   -0.405   1.57  -1.35     -0.226 
## 17 한화증권      0.225   0.661  -0.587  0.409    -0.861 
## 18 현대증권     -1.15   -0.390  -0.856  1.12      0.852
\end{verbatim}

분산조정 이후의 각 변수의 제곱합은 모두 \(n - 1\)이 되는데, 이는 각 변수의 표본분산이 모두 1로 조정되기 때문이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{standardized\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize\_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{sum}\NormalTok{(x }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{)) }\CommentTok{\# sum of squares by variable}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 5
##     roa   roe   bis de_ratio turnover
##   <dbl> <dbl> <dbl>    <dbl>    <dbl>
## 1    17    17    17       17       17
\end{verbatim}

따라서, 분산조정 이후 총변동은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{total\_ss }\OtherTok{\textless{}{-}}\NormalTok{ standardized\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{summarize\_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{sum}\NormalTok{(x }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} \CommentTok{\# sum of squares by variable}
\NormalTok{  \{}\FunctionTok{sum}\NormalTok{(.)\}}

\NormalTok{total\_ss}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 85
\end{verbatim}

\hypertarget{pca-intro}{%
\subsection{주성분의 이해 및 행렬의 분해}\label{pca-intro}}

주성분분석은 원래의 변수들의 선형조합으로 서로 직교하는 새로운 변수들을 생성하는 것이라 할 수 있다. 이 때, 원래 변수의 수 \(k\)보다 작은 \(A\)개의 새로운 변수들이 원 데이터 행렬 \(\mathbf{X}\) 총변동의 대부분을 설명한다고 하면, 해당 새로운 변수들만을 사용하여 여러 가지 분석을 대신할 수 있다는 것이 주성분분석의 개념이라 하겠다.

새로운 변수 \(\mathbf{t}_1, \cdots, \mathbf{t}_A\)들은 다음과 같은 형태로 표현된다.

\begin{equation}
\mathbf{t}_a = \sum_{j = 1}^{k} p_{aj} \mathbf{x}_j, \, a = 1, \cdots, A
\end{equation}

결과적으로 주성분분석은 위와 같이 표현되는 새로운 변수를 만들 때 필요한 계수 \(p_{aj}\)를 구하는 것이라 할 수 있겠다. \(\mathbf{t}_1\)이 \(\mathbf{X}\)의 변동을 가장 많이 설명하도록, \(\mathbf{t}_2\)는 \(\mathbf{t}_1\)이 설명하지 못한 변동을 가장 많이 설명하도록 하는 방식으로 \(A\)개의 새로운 변수를 순차적으로 찾아내는 것이 기본적인 원리이다.

Table \ref{tab:pca-matrix-factorization-data} 데이터에 대하여 분산조정을 적용한 후 아래 식을 이용하여 새로운 변수를 도출해보자.

\[
t_1 = 0.07608427 \times roa - 0.39463007 \times roe + 0.56970191 \times bis - 0.55982770 \times de\_ratio - 0.44778451 \times turnover
\]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_df }\OtherTok{\textless{}{-}}\NormalTok{ standardized\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{t\_1 =} \FloatTok{0.07608427} \SpecialCharTok{*}\NormalTok{ roa }\SpecialCharTok{{-}} \FloatTok{0.39463007} \SpecialCharTok{*}\NormalTok{ roe }
         \SpecialCharTok{+} \FloatTok{0.56970191} \SpecialCharTok{*}\NormalTok{ bis }\SpecialCharTok{{-}} \FloatTok{0.55982770} \SpecialCharTok{*}\NormalTok{ de\_ratio }
         \SpecialCharTok{{-}} \FloatTok{0.44778451} \SpecialCharTok{*}\NormalTok{ turnover) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(company, t\_1) }\CommentTok{\# new variable}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(new\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 18 x 2
##    company         t_1
##    <chr>         <dbl>
##  1 SK증권       -1.49 
##  2 교보증권     -0.206
##  3 대신증권      0.197
##  4 대우증권     -2.35 
##  5 동부증권     -0.895
##  6 메리츠증권   -0.368
##  7 미래에셋증권 -0.935
##  8 부국증권      2.41 
##  9 브릿지증권    2.70 
## 10 삼성증권     -0.405
## 11 서울증권      1.40 
## 12 신영증권     -1.54 
## 13 신흥증권      0.322
## 14 우리투자증권 -2.03 
## 15 유화증권      3.04 
## 16 한양증권      2.01 
## 17 한화증권     -0.421
## 18 현대증권     -1.43
\end{verbatim}

이 때, 새로운 변수 \(\mathbf{t}_1\)는 분산조정된 행렬 \(\mathbf{Z}\)의 총변동의 약 55\%를 설명한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t1\_ss }\OtherTok{\textless{}{-}}\NormalTok{ new\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize\_if}\NormalTok{(is.numeric, }\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{sum}\NormalTok{(x }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{))}

\NormalTok{t1\_ss }\SpecialCharTok{/}\NormalTok{ total\_ss}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         t_1
## 1 0.5522924
\end{verbatim}

위 새로운 변수 \(\mathbf{t}_1\)는 실제로 행렬 \(\mathbf{Z}\)로부터 얻어지는 첫 번째 주성분이며, 행렬 \(\mathbf{Z}\)의 변동에 가장 많이 기여하는 하나의 선형조합이다.

행렬 \(\mathbf{Z}\)(혹은 \(\mathbf{X}\))로부터 주성분을 얻는 방법은 여러 가지가 있으며, 아래에서 하나씩 설명하기로 한다.

\hypertarget{pca-svd}{%
\subsection{특이치분해 (Singular Value Decomposition)}\label{pca-svd}}

분산조정된 \(\mathbf{Z}\)에 대해 주성분분석을 수행한다고 가정하자. 분산조정을 하지 않고 주성분분석을 수행하는 경우 아래 행렬 \(\mathbf{Z}\) 대신 \(\mathbf{X}\)를 사용하면 된다.

임의의 \((n \times k)\) 행렬 \(\mathbf{Z}\)는 다음과 같이 분해된다.

\begin{equation}
\mathbf{Z} = \mathbf{U} \mathbf{D} \mathbf{V}^\top \label{eq:pca-svd}
\end{equation}

이 때, \(r = \min\{n, k\}\)라 할 때,

\begin{itemize}
\tightlist
\item
  \(\mathbf{U}\): \((n \times r)\) 직교 (orthogonal) 행렬
\item
  \(\mathbf{D}\): \((r \times r)\) 대각 (diagonal) 행렬. rank 수만큼의 비음 대각원소들을 가지며, 각 비음 대각원소를 힝렬 \(\mathbf{Z}\)의 특이치(singular value)라 하고, 특이치가 내림차순으로 정렬되는 형태로 행렬이 구성된다.
\item
  \(\mathbf{V}\): \((k \times r)\) 직교 (orthogonal) 행렬
\end{itemize}

아래와 같이, R 함수 \texttt{svd}를 이용하여 분해한 행렬들을 곱한 결과가 원래 행렬 \(\mathbf{Z}\)와 동일함을 확인할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Z }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(standardized\_df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{])}
\NormalTok{svd\_Z }\OtherTok{\textless{}{-}} \FunctionTok{svd}\NormalTok{(Z)}
\NormalTok{Z\_rec }\OtherTok{\textless{}{-}}\NormalTok{ svd\_Z}\SpecialCharTok{$}\NormalTok{u }\SpecialCharTok{\%*\%} \FunctionTok{diag}\NormalTok{(svd\_Z}\SpecialCharTok{$}\NormalTok{d) }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(svd\_Z}\SpecialCharTok{$}\NormalTok{v)}
\FunctionTok{all}\NormalTok{(}\FunctionTok{near}\NormalTok{(Z, Z\_rec))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

이 때, 행렬 \(\mathbf{V}\)의 각 열벡터가 각 주성분을 도출하는 선형식의 계수가 된다. 즉, 행렬 \(\mathbf{V}\)의 첫 번째 열이 위에서 살펴본 새로운 변수 \(\mathbf{t}_1\)를 도출하는 선형식의 계수이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svd\_Z}\SpecialCharTok{$}\NormalTok{v[, }\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  0.07608427 -0.39463007  0.56970191 -0.55982770 -0.44778451
\end{verbatim}

특이치는 아래와 같이 추출된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svd\_Z}\SpecialCharTok{$}\NormalTok{d}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6.8516318 5.2245674 3.0593417 1.0435870 0.5571285
\end{verbatim}

이 특이치들은 아래 분광분해에서 살펴볼 고유치의 제곱근이다.

\hypertarget{pca-spectral}{%
\subsection{분광분해 (Spectral Decomposition)}\label{pca-spectral}}

임의의 정방행렬 \(\mathbf{A}\)에 대하여

\[\mathbf{A}\mathbf{v} = \lambda\mathbf{v} \]

가 성립하는 벡터 \(\mathbf{v} \neq \mathbf{0}\)과 상수 \(\lambda\)가 존재할 때, 상수 \(\lambda\)를 행렬 \(\mathbf{A}\)의 고유치(eigenvalue)라 하며, \(\mathbf{v}\)를 이에 대응하는 고유벡터(eigenvector)라 한다. 통상 \(\mathbf{v}^\top \mathbf{v} = 1\)을 가정한다.

분광분해는 정방행렬을 고유치와 고유벡터의 곱으로 분해하는 방법이다. \((r \times r)\) 정방행렬 \(\mathbf{A}\)에 대해 \(r\)개의 고유치 \(\lambda_1, \cdots, \lambda_r\)와 고유벡터 \(\mathbf{v}_1, \cdots, \mathbf{v}_r\)이 존재한다고 할 때, 행렬 \(\mathbf{A}\)는 다음과 같이 정리된다.

\[
\mathbf{A}\left[\mathbf{v}_1 \, \cdots \, \mathbf{v}_r\right] = \left[\mathbf{v}_1 \, \cdots \, \mathbf{v}_r\right] \left[ \begin{array}{c c c c}
\lambda_1 & 0 & \cdots & 0\\
0 & \lambda_2 &  & 0\\
\vdots &  & \ddots & 0\\
0 & 0 & \cdots & \lambda_r
\end{array} \right] \\
\mathbf{A} = \mathbf{A} \left[\mathbf{v}_1 \, \cdots \, \mathbf{v}_r\right] \left[\mathbf{v}_1 \, \cdots \, \mathbf{v}_r\right]^{-1} = \left[\mathbf{v}_1 \, \cdots \, \mathbf{v}_r\right] \left[ \begin{array}{c c c c}
\lambda_1 & 0 & \cdots & 0\\
0 & \lambda_2 &  & 0\\
\vdots &  & \ddots & 0\\
0 & 0 & \cdots & \lambda_r
\end{array} \right] \left[\mathbf{v}_1 \, \cdots \, \mathbf{v}_r\right]^{-1} = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^{-1}
\]

특히 행렬 \(\mathbf{A}\)가 대칭(symmetric)행렬인 경우, 고유벡터들은 서로 직교하므로 (\(\mathbf{V}\mathbf{V}^\top = \mathbf{I}\)), 위 식을 아래와 같이 표현할 수 있다.

\[ \mathbf{A} = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^\top \]

주성분 분석을 위해 정방행렬 \(\mathbf{Z}^\top \mathbf{Z}\)를 분해를 살펴보자. 식 \eqref{eq:pca-svd}로부터,

\[
\mathbf{Z}^\top \mathbf{Z} = \mathbf{V} \mathbf{D}^\top \mathbf{U}^\top \mathbf{U} \mathbf{D} \mathbf{V}^\top = \mathbf{V} \mathbf{D}^2 \mathbf{V}^\top = \mathbf{V} \mathbf{\Lambda} \mathbf{V}^\top
\]

즉, 분광분해를 통해 도출된 고유벡터들의 행렬 \(\mathbf{V}\)의 각 열벡터가 각 주성분을 도출하는 선형식의 계수를 나타내며, 대각행렬 \(\mathbf{\Lambda}\)의 각 대각원소값인 고유치는 특이치의 제곱임을 알 수 있다.

R 함수 \texttt{eigen}을 이용하여 분광분해를 아래와 같이 수행하여 보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eig\_Z }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(}\FunctionTok{t}\NormalTok{(Z) }\SpecialCharTok{\%*\%}\NormalTok{ Z, }\AttributeTok{symmetric =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{eig\_Z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## eigen() decomposition
## $values
## [1] 46.9448582 27.2961041  9.3595718  1.0890737  0.3103922
## 
## $vectors
##             [,1]        [,2]          [,3]         [,4]        [,5]
## [1,] -0.07608427 -0.77966993  0.0008915975 -0.140755404  0.60540325
## [2,]  0.39463007 -0.56541218 -0.2953216494  0.117644166 -0.65078503
## [3,] -0.56970191 -0.16228156  0.2412221065 -0.637721889 -0.42921686
## [4,]  0.55982770  0.19654293 -0.2565972887 -0.748094314  0.14992183
## [5,]  0.44778451 -0.08636803  0.8881182665 -0.003668418 -0.05711464
\end{verbatim}

결과에서 \texttt{values}는 행렬 \(\mathbf{Z}^\top \mathbf{Z}\)의 고유치(eigenvalue)들이다. 이들이 앞 장의 특이치 분해에서 얻은 특이치들의 제곱임을 확인하여 보자.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{all}\NormalTok{(}\FunctionTok{near}\NormalTok{(eig\_Z}\SpecialCharTok{$}\NormalTok{values, svd\_Z}\SpecialCharTok{$}\NormalTok{d }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

또한 분광분해 결과 \texttt{vectors}의 각 열은 행렬 \(\mathbf{Z}^\top \mathbf{Z}\)의 고유벡터(eigenvector)들이다. 이들이 앞 장의 특이치 분해에서 얻은 계수 행렬과 동일함을 확인하여 보자.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{all}\NormalTok{(}\FunctionTok{near}\NormalTok{(eig\_Z}\SpecialCharTok{$}\NormalTok{vectors, svd\_Z}\SpecialCharTok{$}\NormalTok{v))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

이 경우 두 행렬이 동일하지 않게 나타날 수 있는데, 그 이유는 경우에 따라 어떤 주성분을 생성하는 선형계수 부호가 정반대인 형태로 얻어질 수 있기 때문이다. 주성분의 설명력은 선형계수의 부호에 영향을 받지 않는다.

두 행렬의 계수 부호가 서로 동일하게 조정한 뒤 행렬을 비교해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sign\_adjust }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ ((eig\_Z}\SpecialCharTok{$}\NormalTok{vectors }\SpecialCharTok{*}\NormalTok{ svd\_Z}\SpecialCharTok{$}\NormalTok{v) }\SpecialCharTok{\textless{}} \DecValTok{0}\NormalTok{)}
\FunctionTok{all}\NormalTok{(}\FunctionTok{near}\NormalTok{(eig\_Z}\SpecialCharTok{$}\NormalTok{vectors }\SpecialCharTok{*}\NormalTok{ sign\_adjust, svd\_Z}\SpecialCharTok{$}\NormalTok{v))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

위 각 고유값들을 고유값들의 총합으로 나누면, 각 고유벡터에 해당하는 주성분이 설명하는 총변동의 비율을 얻을 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eig\_Z}\SpecialCharTok{$}\NormalTok{values }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(eig\_Z}\SpecialCharTok{$}\NormalTok{values)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.552292449 0.321130636 0.110112610 0.012812632 0.003651673
\end{verbatim}

평균 및 분산 조정된 \(\mathbf{Z}\)의 분산-공분산 행렬은 아래와 같다.

\[\frac{1}{n - 1} \mathbf{Z}^\top \mathbf{Z}\]

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{all}\NormalTok{(}\FunctionTok{near}\NormalTok{(}\FunctionTok{cov}\NormalTok{(Z), }\FunctionTok{t}\NormalTok{(Z) }\SpecialCharTok{\%*\%}\NormalTok{ Z }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{nrow}\NormalTok{(Z) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

여기에 위에서 구한 분광분해를 대입하면,

\[\frac{1}{n - 1} \mathbf{Z}^\top \mathbf{Z} = \frac{1}{n - 1} \mathbf{V} \mathbf{\Lambda} \mathbf{V}^\top =  \mathbf{V} \left( \frac{1}{n - 1} \mathbf{\Lambda} \right) \mathbf{V}^\top\]

따라서, \(\mathbf{Z}\)의 분산-공분산 행렬에 대한 분광분해 결과, 고유벡터 행렬 \(\mathbf{V}\)는 앞에서 구한 \(\mathbf{Z}^\top \mathbf{Z}\)의 고유벡터 행렬들과 동일하며, 고유값은 앞에서 구한 \(\mathbf{Z}^\top \mathbf{Z}\)의 고유값을 \((n - 1)\)으로 나눈 값이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eig\_cov\_Z }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(}\FunctionTok{cov}\NormalTok{(Z))}
\NormalTok{eig\_cov\_Z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## eigen() decomposition
## $values
## [1] 2.76146225 1.60565318 0.55056305 0.06406316 0.01825836
## 
## $vectors
##             [,1]        [,2]          [,3]         [,4]        [,5]
## [1,] -0.07608427  0.77966993  0.0008915975 -0.140755404  0.60540325
## [2,]  0.39463007  0.56541218 -0.2953216494  0.117644166 -0.65078503
## [3,] -0.56970191  0.16228156  0.2412221065 -0.637721889 -0.42921686
## [4,]  0.55982770 -0.19654293 -0.2565972887 -0.748094314  0.14992183
## [5,]  0.44778451  0.08636803  0.8881182665 -0.003668418 -0.05711464
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{all}\NormalTok{(}\FunctionTok{near}\NormalTok{(eig\_cov\_Z}\SpecialCharTok{$}\NormalTok{values, eig\_Z}\SpecialCharTok{$}\NormalTok{values }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{nrow}\NormalTok{(Z) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

또한 이 결과는 평균 및 분산조정 이전 원 데이터의 상관행렬(correlation matrix)에 대해 분광분해를 수행한 결과와 동일하다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{eig\_cor\_raw }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(}\FunctionTok{cor}\NormalTok{(train\_df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]))}
\NormalTok{eig\_cor\_raw}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## eigen() decomposition
## $values
## [1] 2.76146225 1.60565318 0.55056305 0.06406316 0.01825836
## 
## $vectors
##             [,1]        [,2]          [,3]         [,4]        [,5]
## [1,] -0.07608427  0.77966993  0.0008915975 -0.140755404  0.60540325
## [2,]  0.39463007  0.56541218 -0.2953216494  0.117644166 -0.65078503
## [3,] -0.56970191  0.16228156  0.2412221065 -0.637721889 -0.42921686
## [4,]  0.55982770 -0.19654293 -0.2565972887 -0.748094314  0.14992183
## [5,]  0.44778451  0.08636803  0.8881182665 -0.003668418 -0.05711464
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{all}\NormalTok{(}\FunctionTok{near}\NormalTok{(eig\_cov\_Z}\SpecialCharTok{$}\NormalTok{values, eig\_cor\_raw}\SpecialCharTok{$}\NormalTok{values))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{all}\NormalTok{(}\FunctionTok{near}\NormalTok{(eig\_cov\_Z}\SpecialCharTok{$}\NormalTok{vectors, eig\_cor\_raw}\SpecialCharTok{$}\NormalTok{vectors))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\hypertarget{pca-nipals}{%
\subsection{NIPALS 알고리즘}\label{pca-nipals}}

NIPALS(Nonlinear Iterative Paritial Least Squares) 알고리즘은 반복적(iterative) 알고리즘을 이용하여 변동 기여율이 가장 큰 주성분부터 가장 작은 주성분까지 순차적으로 고유벡터와 주성분 스코어를 구하는 방법이다.

우선, 특이치 분해에서 사용한 식을 단순화하여, 분산조정된 행렬 \(\mathbf{Z}\)가 아래와 같이 주성분 스코어 행렬 \(\mathbf{T}\)와 고유벡터 행렬 \(\mathbf{V}\)로 분해된다고 하자. (분산조정 대신 평균조정만을 원할 경우 \(\mathbf{Z}\) 대신 \(\mathbf{X}\)를 사용)

\[ \mathbf{Z} = \mathbf{U} \mathbf{D} \mathbf{V}^\top = \mathbf{T} \mathbf{V}^\top \]

즉, 주성분 스코어 \(\mathbf{T}\)는 아래와 같다.

\[ \mathbf{T} = \mathbf{Z} \mathbf{V} \]

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{T\_mat }\OtherTok{\textless{}{-}}\NormalTok{ Z }\SpecialCharTok{\%*\%}\NormalTok{ svd\_Z}\SpecialCharTok{$}\NormalTok{v}
\NormalTok{T\_mat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             [,1]       [,2]        [,3]        [,4]         [,5]
##  [1,] -1.4870243  0.6066594 -0.63361774 -0.29625002  0.020293731
##  [2,] -0.2063797 -0.0804627 -0.04965017  0.26323513  0.063581473
##  [3,]  0.1968538  0.9704605 -0.39507856  0.27123746  0.103351746
##  [4,] -2.3542884 -3.5056480  0.16252734  0.02524924 -0.249920974
##  [5,] -0.8953707  1.4552899  1.36265905  0.20161775 -0.055517167
##  [6,] -0.3682082 -0.5976313  0.65857722  0.27901317  0.060458248
##  [7,] -0.9354306 -1.4144519 -0.82574638  0.07358977  0.095960908
##  [8,]  2.4129728 -0.6785064  0.92207607 -0.36161577 -0.062593521
##  [9,]  2.6991862 -0.7596591 -0.45091077 -0.21030378  0.168645128
## [10,] -0.4050098  0.2800099 -0.92835441  0.13993488  0.001811118
## [11,]  1.3958199  1.1353513 -0.09819177  0.34335126 -0.094986796
## [12,] -1.5381192  1.1576616 -0.07467334 -0.29404424  0.052430946
## [13,]  0.3217681 -0.2378023  1.10180230  0.28507243  0.030666763
## [14,] -2.0306806  0.9646122  0.20906175 -0.39639758 -0.085778570
## [15,]  3.0389460  0.8841645 -0.77478769 -0.04079854 -0.349688462
## [16,]  2.0064063 -1.2831337  0.64388897 -0.22077705  0.188366871
## [17,] -0.4211779 -0.2987099 -1.20644766  0.11766274  0.068250991
## [18,] -1.4302634  1.4017959  0.37686579 -0.17977686  0.044667568
\end{verbatim}

NIPALS 알고리즘은 아래와 같이 주성분 스코어 행렬 \(\mathbf{T}\)의 열과 고유벡터행렬 \(\mathbf{V}\)의 열을 동시에 구한다.

\begin{itemize}
\tightlist
\item
  \textbf{{[}단계 0{]}} 반복알고리즘 수행을 위한 초기화를 한다. \(h \leftarrow 1\), \(\mathbf{Z}_h \leftarrow \mathbf{Z}\).
\item
  \textbf{{[}단계 1{]}} 데이터 행렬 \(\mathbf{Z}_h\)의 임의의 열 하나를 주성분 스코어 벡터 \(\mathbf{t}_h\)로 선정한다.
\item
  \textbf{{[}단계 2{]}} 로딩벡터를 구한다. \(\mathbf{v}_h \leftarrow \mathbf{Z}_h \mathbf{t}_h \left/ \sqrt{\mathbf{t}_h^\top \mathbf{t}_h} \right.\)
\item
  \textbf{{[}단계 3{]}} 로딩벡터의 크기가 1이 되도록 한다. \(\mathbf{v}_h \leftarrow \mathbf{v}_h \left/ \sqrt{\mathbf{v}_h^\top \mathbf{v}_h} \right.\)
\item
  \textbf{{[}단계 4{]}} 주성분 스코어 벡터를 로딩벡터에 기반하여 계산한다. \(\mathbf{t}_h \leftarrow \mathbf{Z}_h \mathbf{v}_h\)
\item
  \textbf{{[}단계 5{]}} 주성분 스코어 벡터 \(\mathbf{t}_h\)가 수렴하였으면 {[}단계 6{]}으로 진행하고, 그렇지 않으면 {[}단계 2{]}로 돌아간다.
\item
  \textbf{{[}단계 6{]}} 데이터 행렬 \(\mathbf{Z}_h\)로부터 새로 얻어진 주성분 벡터 \(\mathbf{t}_h\)와 고유벡터 \(\mathbf{v}_h\)가 설명하는 부분을 제거하고 나머지 변동만을 담은 새로운 데이터 행렬 \(\mathbf{Z}_{h + 1}\)을 구한다.
  \[ \mathbf{Z}_{h + 1} \leftarrow \mathbf{Z}_{h} - \mathbf{t}_h \mathbf{v}_h^\top \]
\item
  \textbf{{[}단계 7{]}} \(h \leftarrow h + 1\)로 업데이트하고, {[}단계 1{]}로 돌아간다. {[}단계 1{]} - {[}단계 7{]}의 과정을 \(\mathbf{Z}\)의 rank 수만큼의 주성분을 얻을 때까지 반복한다.
\end{itemize}

위 반복 알고리즘을 수행하는 함수를 아래와 같이 구성해보자. 아래 함수에서 입력변수 \texttt{X}는 데이터 행렬으로, 평균조정된 행렬 \(\mathbf{X}\)나 분산조정된 \(\mathbf{Z}\) 모두 사용 가능하다. 입력변수 \texttt{r}은 추출하고자 하는 주성분의 개수이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nipals\_pca }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(X, }\AttributeTok{r =} \ConstantTok{NULL}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{is\_empty}\NormalTok{(r) }\SpecialCharTok{||}\NormalTok{ (r }\SpecialCharTok{\textgreater{}} \FunctionTok{min}\NormalTok{(}\FunctionTok{dim}\NormalTok{(X)))) \{}
\NormalTok{    r }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(}\FunctionTok{dim}\NormalTok{(X))}
\NormalTok{  \}}
  
\NormalTok{  Th }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{nrow}\NormalTok{(X), }\AttributeTok{ncol =}\NormalTok{ r)}
\NormalTok{  Vh }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{ncol}\NormalTok{(X), }\AttributeTok{ncol =}\NormalTok{ r)}
  
  \ControlFlowTok{for}\NormalTok{ (h }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(r)) \{}
    \CommentTok{\# 단계 1}
\NormalTok{    j }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\FunctionTok{ncol}\NormalTok{(X), }\DecValTok{1}\NormalTok{)}
\NormalTok{    Th[, h] }\OtherTok{\textless{}{-}}\NormalTok{ X[, j]}
    
    \ControlFlowTok{while}\NormalTok{ (}\ConstantTok{TRUE}\NormalTok{) \{}
      \CommentTok{\# 단계 2}
\NormalTok{      Vh[, h] }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(}\FunctionTok{t}\NormalTok{(Th[, h]) }\SpecialCharTok{\%*\%}\NormalTok{ X }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{norm}\NormalTok{(Th[, h], }\StringTok{"2"}\NormalTok{) }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{))}
      
      \CommentTok{\# 단계 3}
\NormalTok{      Vh[, h] }\OtherTok{\textless{}{-}}\NormalTok{ Vh[, h] }\SpecialCharTok{/} \FunctionTok{norm}\NormalTok{(Vh[, h], }\StringTok{"2"}\NormalTok{)}
      
      \CommentTok{\# 단계 4}
\NormalTok{      th }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ Vh[, h]}
      
      \CommentTok{\# 단계 5}
      \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{all}\NormalTok{(}\FunctionTok{near}\NormalTok{(Th[, h], th))) }\ControlFlowTok{break}
\NormalTok{      Th[, h] }\OtherTok{\textless{}{-}}\NormalTok{ th}
\NormalTok{    \}}
    
    \CommentTok{\#단계 6}
\NormalTok{    X }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{{-}}\NormalTok{ Th[, h] }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(Vh[, h])}
\NormalTok{  \}}
  
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{T =}\NormalTok{ Th, }\AttributeTok{V =}\NormalTok{ Vh))}
\NormalTok{\}}

\NormalTok{nipals\_Z }\OtherTok{\textless{}{-}} \FunctionTok{nipals\_pca}\NormalTok{(Z)}
\NormalTok{nipals\_Z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $T
##             [,1]       [,2]        [,3]        [,4]         [,5]
##  [1,] -1.4870243 -0.6066594  0.63361775  0.29625002 -0.020293733
##  [2,] -0.2063797  0.0804627  0.04965017 -0.26323513 -0.063581471
##  [3,]  0.1968538 -0.9704605  0.39507856 -0.27123747 -0.103351743
##  [4,] -2.3542884  3.5056480 -0.16252734 -0.02524923  0.249920974
##  [5,] -0.8953708 -1.4552900 -1.36265905 -0.20161775  0.055517169
##  [6,] -0.3682082  0.5976313 -0.65857723 -0.27901317 -0.060458246
##  [7,] -0.9354306  1.4144520  0.82574637 -0.07358977 -0.095960907
##  [8,]  2.4129728  0.6785064 -0.92207607  0.36161577  0.062593518
##  [9,]  2.6991862  0.7596591  0.45091077  0.21030377 -0.168645129
## [10,] -0.4050098 -0.2800099  0.92835441 -0.13993489 -0.001811117
## [11,]  1.3958199 -1.1353513  0.09819177 -0.34335126  0.094986799
## [12,] -1.5381192 -1.1576616  0.07467335  0.29404424 -0.052430948
## [13,]  0.3217681  0.2378023 -1.10180230 -0.28507243 -0.030666760
## [14,] -2.0306806 -0.9646122 -0.20906175  0.39639758  0.085778567
## [15,]  3.0389460 -0.8841645  0.77478770  0.04079855  0.349688462
## [16,]  2.0064063  1.2831337 -0.64388897  0.22077705 -0.188366873
## [17,] -0.4211779  0.2987099  1.20644766 -0.11766275 -0.068250990
## [18,] -1.4302634 -1.4017959 -0.37686579  0.17977686 -0.044667569
## 
## $V
##             [,1]        [,2]          [,3]         [,4]        [,5]
## [1,]  0.07608428  0.77966993 -0.0008916024  0.140755398 -0.60540326
## [2,] -0.39463007  0.56541218  0.2953216455 -0.117644164  0.65078503
## [3,]  0.56970191  0.16228156 -0.2412221067  0.637721895  0.42921684
## [4,] -0.55982770 -0.19654293  0.2565972909  0.748094309 -0.14992185
## [5,] -0.44778451  0.08636803 -0.8881182671  0.003668428  0.05711464
\end{verbatim}

위 분해된 행렬의 곱이 원 데이터 행렬 \(\mathbf{Z}\)과 일치하는지 확인해보자.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{all}\NormalTok{(}\FunctionTok{near}\NormalTok{(Z, nipals\_Z}\SpecialCharTok{$}\NormalTok{T }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(nipals\_Z}\SpecialCharTok{$}\NormalTok{V)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

R 패키지 \texttt{nipals}내의 함수 \texttt{nipals}가 이 장에서 설명한 NIPALS 알고리즘에 기반한 주성분 분석을 아래와 같이 제공한다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(nipals)}
\FunctionTok{nipals}\NormalTok{(Z, }\AttributeTok{center =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $eig
## [1] 6.8516317 5.2245674 3.0593417 1.0435869 0.5571285
## 
## $scores
##               PC1         PC2         PC3         PC4          PC5
##  [1,] -0.21705404 -0.11608067 -0.20710543  0.28388475 -0.036368396
##  [2,] -0.03011834  0.01540551 -0.01623006 -0.25221776 -0.114174269
##  [3,]  0.02869590 -0.18575892 -0.12913406 -0.25987079 -0.185560165
##  [4,] -0.34348333  0.67105909  0.05310696 -0.02428657  0.448582844
##  [5,] -0.13073246 -0.27851123  0.44541637 -0.19321728  0.099609669
##  [6,] -0.05371865  0.11440401  0.21526389 -0.26733867 -0.108571464
##  [7,] -0.13647563  0.27074924 -0.26991736 -0.07048155 -0.172255999
##  [8,]  0.35219939  0.12981093  0.30139420  0.34648877  0.112419837
##  [9,]  0.39397535  0.14532356 -0.14739177  0.20158102 -0.302663550
## [10,] -0.05912155 -0.05359220 -0.30344792 -0.13408884 -0.003277662
## [11,]  0.20367981 -0.21735017 -0.03209051 -0.32904441  0.170427304
## [12,] -0.22453126 -0.22153804 -0.02440174  0.28178254 -0.094052577
## [13,]  0.04697085  0.04551641  0.36014173 -0.27315578 -0.055099430
## [14,] -0.29641393 -0.18457147  0.06834143  0.37981073  0.154041866
## [15,]  0.44350417 -0.16932257 -0.25324815  0.03896920  0.627670066
## [16,]  0.29288258  0.24554714  0.21046020  0.21162296 -0.338060584
## [17,] -0.06146040  0.05717479 -0.39435062 -0.11272299 -0.122527440
## [18,] -0.20879845 -0.26826541  0.12319285  0.17228468 -0.080140048
## 
## $loadings
##                  PC1        PC2           PC3          PC4         PC5
## roa       0.07627711  0.7796534  0.0008551484  0.140974596 -0.60534928
## roe      -0.39449021  0.5654941 -0.2953469599 -0.117893972  0.65074198
## bis       0.56974203  0.1621586  0.2412197864  0.637556663  0.42945678
## de_ratio -0.55987629 -0.1964075 -0.2565837179  0.748154680 -0.14963952
## turnover -0.44776314  0.0865197  0.8881144365  0.003640124  0.05711403
## 
## $fitted
## NULL
## 
## $ncomp
## [1] 5
## 
## $R2
## [1] 0.552292435 0.321130644 0.110112610 0.012812631 0.003651673
## 
## $iter
## [1] 14  4  4  6  3
## 
## $center
## [1] NA
## 
## $scale
## [1] NA
\end{verbatim}

평균 및 분산조정 이전의 원래 데이터를 입력하고, 파라미터 \texttt{center}(평균조정) 및 \texttt{scale}(분산조정)의 값을 모두 \texttt{TRUE}로 설정하면 동일한 결과를 얻을 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(nipals)}
\FunctionTok{nipals}\NormalTok{(train\_df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{center =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $eig
## [1] 6.8516317 5.2245674 3.0593417 1.0435869 0.5571285
## 
## $scores
##               PC1         PC2         PC3         PC4          PC5
##  [1,] -0.21705404 -0.11608067 -0.20710543  0.28388475 -0.036368396
##  [2,] -0.03011834  0.01540551 -0.01623006 -0.25221776 -0.114174269
##  [3,]  0.02869590 -0.18575892 -0.12913406 -0.25987079 -0.185560165
##  [4,] -0.34348333  0.67105909  0.05310696 -0.02428657  0.448582844
##  [5,] -0.13073246 -0.27851123  0.44541637 -0.19321728  0.099609669
##  [6,] -0.05371865  0.11440401  0.21526389 -0.26733867 -0.108571464
##  [7,] -0.13647563  0.27074924 -0.26991736 -0.07048155 -0.172255999
##  [8,]  0.35219939  0.12981093  0.30139420  0.34648877  0.112419837
##  [9,]  0.39397535  0.14532356 -0.14739177  0.20158102 -0.302663550
## [10,] -0.05912155 -0.05359220 -0.30344792 -0.13408884 -0.003277662
## [11,]  0.20367981 -0.21735017 -0.03209051 -0.32904441  0.170427304
## [12,] -0.22453126 -0.22153804 -0.02440174  0.28178254 -0.094052577
## [13,]  0.04697085  0.04551641  0.36014173 -0.27315578 -0.055099430
## [14,] -0.29641393 -0.18457147  0.06834143  0.37981073  0.154041866
## [15,]  0.44350417 -0.16932257 -0.25324815  0.03896920  0.627670066
## [16,]  0.29288258  0.24554714  0.21046020  0.21162296 -0.338060584
## [17,] -0.06146040  0.05717479 -0.39435062 -0.11272299 -0.122527440
## [18,] -0.20879845 -0.26826541  0.12319285  0.17228468 -0.080140048
## 
## $loadings
##                  PC1        PC2           PC3          PC4         PC5
## roa       0.07627711  0.7796534  0.0008551484  0.140974596 -0.60534928
## roe      -0.39449021  0.5654941 -0.2953469599 -0.117893972  0.65074198
## bis       0.56974203  0.1621586  0.2412197864  0.637556663  0.42945678
## de_ratio -0.55987629 -0.1964075 -0.2565837179  0.748154680 -0.14963952
## turnover -0.44776314  0.0865197  0.8881144365  0.003640124  0.05711403
## 
## $fitted
## NULL
## 
## $ncomp
## [1] 5
## 
## $R2
## [1] 0.552292435 0.321130644 0.110112610 0.012812631 0.003651673
## 
## $iter
## [1] 14  4  4  6  3
## 
## $center
##         roa         roe         bis    de_ratio    turnover 
##   3.0350000   9.3505556  35.1116667 250.1477778   0.8816667 
## 
## $scale
##         roa         roe         bis    de_ratio    turnover 
##   1.1356949   4.5692430  18.1343662 143.0378269   0.3618132
\end{verbatim}

\hypertarget{pca-regression}{%
\section{주성분 회귀분석}\label{pca-regression}}

\ref{multiple-linear-regression} 장에서 살펴본 다중회귀모형의 식 \eqref{eq:multiple-linear-regression-matrix}을 아래에 다시 살펴보자.

\begin{equation}
\mathbf{y} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\epsilon} \label{eq:pca-multiple-linear-regression-matrix}
\end{equation}

여기서, \(\boldsymbol{\beta}\) 와 \(\boldsymbol{\epsilon}\)는 각각 회귀계수와 오차항을 나타내는 벡터이며, 독립변수 데이터 행렬 \(\mathbf{X}\)와 종속변수 관측치 벡터 \(\mathbf{y}\) 모두 평균조정한 데이터라 간주하자. \(\mathbf{X}\)의 열벡터 간 다중공선성(multicollinearity)이 높으면 최소자승법에 의한 \(\boldsymbol{\beta}\)의 추정치의 분산이 커지는 문제가 있으며, \(\mathbf{X}\) 행렬의 관측수보다 변수 수가 많을 때는 \(\boldsymbol{\beta}\) 추정치를 구할 수 없다. 이 문제를 해결하기 위해 주성분 회귀분석(principal component regression; PCR)에서는 \(\mathbf{X}\) 변동 대부분을 설명하는 \(A\)개 (\(A \leq rank(\mathbf{X})\))의 주성분 스코어를 다음과 같이 독립변수로 사용한다.

\begin{equation}
\mathbf{y} = q_1 \mathbf{t}_1 + q_2 \mathbf{t}_2 + \cdots + q_A \mathbf{t}_A + \mathbf{f} \label{eq:pcr-model}
\end{equation}

여기서 \(\mathbf{f}\)는 오차항을 나타내는 벡터이며, \(q_1, \cdots, q_A\)는 회귀계수들이다. 이 때, \(A\)개의 주성분 스코어로 구성되는 \((n \times A)\) 주성분행렬을 \(\mathbf{T}_A = [\mathbf{t}_1 \, \cdots \, \mathbf{t}_A]\)로, 회귀계수벡터를 \(\mathbf{q} = [q_1 \, \cdots \, q_A]^\top\)으로 표기하면, 식 \eqref{eq:pcr-model}의 모형은 다음과 같이 표현된다.

\begin{equation}
\mathbf{y} = \mathbf{T}_A \mathbf{q}_A + \mathbf{f} \label{eq:pcr-matrix-model}
\end{equation}

위 모형은 다중회귀모형으로 볼 수 있으므로, 다중회귀모형에 대한 모든 이론이 적용될 수 있다. 또한 위 모형에서 각 주성분 스코어 벡터 \(\mathbf{t}_1, \cdots, \mathbf{t}_A\)는 서로 선형 독립적(linearly independent)이므로, 회귀성 검정이 용이한 측면이 있다.

\hypertarget{pcr-basic-script}{%
\subsection{기본 R 스트립트}\label{pcr-basic-script}}

3개의 독립변수와 1개의 종속변수(\texttt{y})를 관측한 데이터가 아래와 같다고 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{x1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x2, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x3, }\SpecialCharTok{\textasciitilde{}}\NormalTok{y,}
  \SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{30}\NormalTok{,}
  \SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{7}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{20}\NormalTok{,}
  \DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{5}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{11}\NormalTok{, }\DecValTok{35}
\NormalTok{)}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{rep}\NormalTok{(}\StringTok{"r"}\NormalTok{, }\FunctionTok{ncol}\NormalTok{(train\_df)),}
  \AttributeTok{caption =} \StringTok{"주성분 회귀분석 예제 데이터"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:pcr-example-data}주성분 회귀분석 예제 데이터}
\centering
\begin{tabular}[t]{rrrr}
\toprule
x1 & x2 & x3 & y\\
\midrule
-3 & -3 & 5 & -30\\
-2 & -3 & 7 & -20\\
0 & 0 & 4 & 0\\
1 & 2 & 0 & 5\\
2 & 2 & -5 & 10\\
\addlinespace
2 & 2 & -11 & 35\\
\bottomrule
\end{tabular}
\end{table}

3개의 독립변수로 이루어진 데이터에서 2개의 주성분만을 추출하여 회귀모형을 추정하여 보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pcr\_fit }\OtherTok{\textless{}{-}}\NormalTok{ pls}\SpecialCharTok{::}\FunctionTok{pcr}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2 }\SpecialCharTok{+}\NormalTok{ x3, }\AttributeTok{data =}\NormalTok{ train\_df, }\AttributeTok{ncomp =} \DecValTok{2}\NormalTok{)}
\FunctionTok{coef}\NormalTok{(pcr\_fit, }\AttributeTok{intercept =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## , , 2 comps
## 
##                     y
## (Intercept)  0.000000
## x1           2.130440
## x2           2.721789
## x3          -1.737825
\end{verbatim}

위 회귀계수들은 주성분을 이용하여 추정한 회귀 모형을 원래 독립변수를 이용한 회귀식(평균조정 이전)으로 다시 선형변환한 결과이다. 이에 대해서는 다음 절에서 좀 더 자세히 살펴보도록 하자.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(pcr\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Data:    X dimension: 6 3 
##  Y dimension: 6 1
## Fit method: svdpc
## Number of components considered: 2
## TRAINING: % variance explained
##    1 comps  2 comps
## X    94.98    99.79
## y    87.94    91.31
\end{verbatim}

위 요약표는 하나의 주성분과 두 개의 주성분을 이용하였을 때 추정된 회귀모형들이 종속변수의 총 변량을 각각 87.9415591\%와 91.3101613\% 만큼을 설명함을 알려준다.

\hypertarget{pcr-regression-coefficient}{%
\subsection{주성분 회귀계수 추정}\label{pcr-regression-coefficient}}

우선 Table \ref{tab:pcr-example-data}의 세 독립변수에 대해 주성분 분석을 수행하여 두 개의 주성분을 추출하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pca\_fit }\OtherTok{\textless{}{-}} \FunctionTok{prcomp}\NormalTok{(train\_df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{)], }\AttributeTok{rank. =} \DecValTok{2}\NormalTok{,}
                  \AttributeTok{center =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{scale. =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{pca\_fit}\SpecialCharTok{$}\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             PC1        PC2
## [1,] -6.2346992  1.9880169
## [2,] -7.8320036  0.6817026
## [3,] -3.6996775 -1.5151642
## [4,]  0.8208672 -2.0392493
## [5,]  5.6979984 -0.6940262
## [6,] 11.2475146  1.5787202
\end{verbatim}

또한 평균조정된 종속변수 벡터를 계산하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_centered }\OtherTok{\textless{}{-}}\NormalTok{ train\_df}\SpecialCharTok{$}\NormalTok{y }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(train\_df}\SpecialCharTok{$}\NormalTok{y)}
\NormalTok{y\_centered}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -30 -20   0   5  10  35
\end{verbatim}

주성분 스코어와 평균조정된 종속변수를 이용하여 회귀모형을 추정하자. 이 때, intercept가 없는 모형을 가정한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pc\_lm\_fit }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(y\_centered }\SpecialCharTok{\textasciitilde{}} \SpecialCharTok{{-}} \DecValTok{1} \SpecialCharTok{+}\NormalTok{ pca\_fit}\SpecialCharTok{$}\NormalTok{x)}
\FunctionTok{coef}\NormalTok{(pc\_lm\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## pca_fit$xPC1 pca_fit$xPC2 
##     2.918798    -2.539206
\end{verbatim}

위 회귀계수 벡터가 식 \eqref{eq:pcr-matrix-model}의 회귀계수 벡터 \(\mathbf{q}_A\)의 값이다 (\(A = 2\)).

\hypertarget{pcr-regression-transform}{%
\subsection{회귀계수 선형변환}\label{pcr-regression-transform}}

앞장에서 얻어진 주성분을 이용한 회귀식을 원 데이터에서 관측된 독립변수와 종속변수에 대한 식으로 변환하여 보자.

각 주성분은 평균조정된 독립변수들의 선형조합으로 아래와 같이 얻어진다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pca\_fit}\SpecialCharTok{$}\NormalTok{rotation}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           PC1        PC2
## x1  0.2525343 -0.5487321
## x2  0.2841664 -0.7452586
## x3 -0.9249194 -0.3787911
\end{verbatim}

따라서, 아래와 같이 주성분에 대한 회귀계수를 원래 독립변수(평균조정 이후)에 대한 회귀계수로 변환할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beta\_x }\OtherTok{\textless{}{-}}\NormalTok{ pca\_fit}\SpecialCharTok{$}\NormalTok{rotation }\SpecialCharTok{\%*\%} \FunctionTok{coef}\NormalTok{(pc\_lm\_fit)}
\NormalTok{beta\_x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         [,1]
## x1  2.130440
## x2  2.721789
## x3 -1.737825
\end{verbatim}

Intercept는 평균조정 이전 종속변수의 평균에서 위 회귀계수벡터를 평균조정 이전 독립변수의 평균벡터와 곱한 결과를 뺀 값이다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(train\_df}\SpecialCharTok{$}\NormalTok{y) }\SpecialCharTok{{-}} \FunctionTok{colMeans}\NormalTok{(train\_df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{)]) }\SpecialCharTok{\%*\%}\NormalTok{ beta\_x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      [,1]
## [1,]    0
\end{verbatim}

본 장에서 사용한 Table \ref{tab:pcr-example-data}는 이미 평균조정이 되어 있어서 Intercept가 0으로 추정된다.

본 장에서 분산조정된 주성분에 대한 회귀계수 변환은 다루지 않았으나, 이 또한 간단하게 변환할 수 있다.

\hypertarget{plsr}{%
\chapter{부분최소자승법}\label{plsr}}

회귀분석에서와 같이 하나의 종속변수에 영향을 주는 \(k\)개의 독립변수가 있다고 하자. 모든 변수는 평균조정되었다고 간주한다. 본 장에서 다루고자 하는 부분최소자승법(partial least squares: PLS)는 앞에서 다룬 주성분 회귀분석(PCR)과 유사하나, 도출되는 새로운 잠재변수들이 다르다.

독립변수와 종속변수간의 관계를 설명하기 위해, 우선 독립변수 행렬과 종속변수 행렬(또는 벡터)가 각각 서로 다른 잠재변수들에 의해 설명된다고 가정한 뒤, 두 잠재변수들간의 관계에 대한 모형을 세운다. 이 때, 본 장에서는 두 잠재변수들간의 관계가 선형인 모형(선형 PLS)만을 살펴본다.

\hypertarget{plsr-packages-install}{%
\section{필요 R 패키지 설치}\label{plsr-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.3.1\\
\hline
pls & 2.7-3\\
\hline
\end{tabular}

\hypertarget{plsr-single-target}{%
\section{하나의 종속변수의 경우}\label{plsr-single-target}}

\hypertarget{plsr-basic-script}{%
\subsection{기본 R 스크립트}\label{plsr-basic-script}}

앞 장의 주성분 회귀분석에서 사용했던 데이터에 대해 부분최소자승 회귀분석을 수행해보도록 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{x1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x2, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x3, }\SpecialCharTok{\textasciitilde{}}\NormalTok{y,}
  \SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{30}\NormalTok{,}
  \SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\DecValTok{7}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{20}\NormalTok{,}
  \DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{5}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{11}\NormalTok{, }\DecValTok{35}
\NormalTok{)}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{rep}\NormalTok{(}\StringTok{"r"}\NormalTok{, }\FunctionTok{ncol}\NormalTok{(train\_df)),}
  \AttributeTok{caption =} \StringTok{"부분최소자승 회귀분석 예제 데이터"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:plsr-example-data}부분최소자승 회귀분석 예제 데이터}
\centering
\begin{tabular}[t]{rrrr}
\toprule
x1 & x2 & x3 & y\\
\midrule
-3 & -3 & 5 & -30\\
-2 & -3 & 7 & -20\\
0 & 0 & 4 & 0\\
1 & 2 & 0 & 5\\
2 & 2 & -5 & 10\\
\addlinespace
2 & 2 & -11 & 35\\
\bottomrule
\end{tabular}
\end{table}

R 패키지 \texttt{pls} 내의 함수 \texttt{plsr()}을 이용하여 PLS 모형을 아래와 같이 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plsr\_fit }\OtherTok{\textless{}{-}}\NormalTok{ pls}\SpecialCharTok{::}\FunctionTok{plsr}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2 }\SpecialCharTok{+}\NormalTok{ x3, }\AttributeTok{data =}\NormalTok{ train\_df, }\AttributeTok{ncomp =} \DecValTok{2}\NormalTok{)}
\FunctionTok{coef}\NormalTok{(plsr\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## , , 2 comps
## 
##            y
## x1  2.475395
## x2  2.523238
## x3 -1.704636
\end{verbatim}

수행결과 object에 \texttt{summary()} 함수를 사용하여 학습된 모형의 독립변수 \(\mathbf{X}\) 및 종속변수 \(\mathbf{y}\)의 총변동에 대한 기여율을 확인할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(plsr\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Data:    X dimension: 6 3 
##  Y dimension: 6 1
## Fit method: kernelpls
## Number of components considered: 2
## TRAINING: % variance explained
##    1 comps  2 comps
## X    94.97    99.78
## y    88.28    91.46
\end{verbatim}

위 요약표는 하나의 잠재변수와 두 개의 잠재변수를 이용하였을 때 추정된 회귀모형들이 종속변수의 총 변량을 각각 88.2814529\%와 91.4578959\% 만큼을 설명함을 알려준다. 이는 앞 장에서 살펴보았던 주성분 회귀모형보다 더 높은 수치이다.

\hypertarget{plsr-model}{%
\subsection{PLS 모형}\label{plsr-model}}

종속변수가 하나만 존재하는 경우에는 데이터 행렬 \(\mathbf{X}\)와 종속변수벡터 \(\mathbf{y}\)가 동일한 잠재변수로 설명된다고 가정할 수 있다. (\(n \times k\)) 데이터 행렬 \(\mathbf{X}\)와 종속변수벡터 \(\mathbf{y}\)에 대하여 동시에 \(A\)개의 잠재변수벡터 \(\mathbf{t}_1, \cdots, \mathbf{t}_A\)로 설명하는 모형을 아래와 같이 기술해보자.

\begin{eqnarray}
\mathbf{X} &=& \mathbf{t}_1 \mathbf{p}_1^\top + \mathbf{t}_2 \mathbf{p}_2^\top + \cdots + \mathbf{t}_A \mathbf{p}_A^\top + \mathbf{E} \label{eq:plsr-x-single}\\
\mathbf{y} &=& \mathbf{t}_1 b_1 + \mathbf{t}_2 b_2 + \cdots + \mathbf{t}_A b_A + \mathbf{f} \label{eq:plsr-y-single}
\end{eqnarray}

여기서 계수벡터 \(\mathbf{p}_a\)는 \(\mathbf{X}\)에 해당하는 로딩(loading)을, 그리고 계수 \(b_a\)는 \(\mathbf{y}\)에 해당하는 로딩을 나타내며, \(\mathbf{E}\)와 \(\mathbf{f}\)는 각 모형에 해당하는 오차항(행렬 또는 벡터)이다.

위 모형을 (\(n \times A\)) 잠재변수 행렬 \(\mathbf{T} = \left[\mathbf{t}_1 \, \cdots \mathbf{t}_A \right]\)와 (\(k \times A\)) 로딩행렬 \(\mathbf{P} = \left[\mathbf{p}_1 \, \cdots \mathbf{p}_A \right]\), 그리고 로딩벡터 \(\mathbf{b} = \left[b_1 \, \cdots b_A \right]^\top\) 을 이용하여 아래와 같이 행렬식으로 나타낼 수 있다.

\begin{eqnarray}
\mathbf{X} &=& \mathbf{T}\mathbf{P}^\top + \mathbf{E} \label{eq:plsr-x-single-matrix}\\
\mathbf{y} &=& \mathbf{T}\mathbf{b} + \mathbf{f} \label{eq:plsr-y-single-matrix}
\end{eqnarray}

\hypertarget{plsr-single-nipals}{%
\subsection{NIPALS 알고리즘}\label{plsr-single-nipals}}

\begin{itemize}
\tightlist
\item
  \textbf{{[}단계 0{]}} 반복알고리즘 수행을 위한 초기화를 한다. \(a \leftarrow 1\), \(\mathbf{X}_a \leftarrow \mathbf{X}\), \(\mathbf{y}_a \leftarrow \mathbf{y}\).
\item
  \textbf{{[}단계 1{]}} \(\mathbf{X}_a\)을 다중종속변수 행렬으로, \(\mathbf{y}_a\)를 독립변수 벡터로 하는 회귀모형으로부터 기울기 \(\mathbf{w}_a = [w_{a1} \, \cdots \, w_{ak}]^\top\)를 산출한다.
  \[\mathbf{w}_a \leftarrow \left. \mathbf{X}_a^\top \mathbf{y}_a \middle/ \mathbf{y}_a^\top \mathbf{y}_a \right.  \]
\item
  \textbf{{[}단계 2{]}} 기울기 벡터 \(\mathbf{w}_a\)의 크기가 1이 되도록 한다.
  \[\left. \mathbf{w}_a \leftarrow \mathbf{w}_a \middle/ \sqrt{\mathbf{w}_a^\top \mathbf{w}_a} \right.\]
\item
  \textbf{{[}단계 3{]}} 잠재변수 \(\mathbf{t}_a\)를 행렬 \(\mathbf{X}_a\)의 각 열의 가중평균으로 구한다. 이 때, 가중치는 기울기 벡터 \(\mathbf{w}_a\)를 이용한다.
  \[\mathbf{t}_a \leftarrow \mathbf{X}_a \mathbf{w}_a\]
\item
  \textbf{{[}단계 4{]}} 식 \eqref{eq:plsr-x-single}와 같이 \(\mathbf{X}_a\)을 다중종속변수 행렬으로, \(\mathbf{t}_a\)를 독립변수 벡터로 하는 회귀모형으로부터 로딩벡터 \(\mathbf{p}_a\)를 구한다.
  \[\mathbf{p}_a \leftarrow \left. \mathbf{X}_a^\top \mathbf{t}_a \middle/ \mathbf{t}_a^\top \mathbf{t}_a \right.\]
\item
  \textbf{{[}단계 5{]}} 로딩벡터 \(\mathbf{p}_a\)의 크기를 1로 조정하고, 잠재변수 벡터 \(\mathbf{t}_a\)와 기울기 벡터 \(\mathbf{w}_a\)의 크기를 그에 따라 보정한다.
  \[d \leftarrow \sqrt{\mathbf{p}_a^\top \mathbf{p}_a}, \, \mathbf{t}_a \leftarrow \mathbf{t}_a d, \, \mathbf{w}_a \leftarrow \mathbf{w}_a d, \, \mathbf{p}_a \leftarrow \frac{1}{d} \mathbf{p}_a \]
\item
  \textbf{{[}단계 6{]}} 식 \eqref{eq:plsr-y-single}와 같이 잠재변수 \(\mathbf{t}_a\)를 종속변수 \(\mathbf{y}_a\)에 회귀시킬 때 계수 \(b_a\)를 산출한다.
  \[b_a \leftarrow \left. \mathbf{y}_a^\top \mathbf{t}_a \middle/ \mathbf{t}_a^\top \mathbf{t}_a \right. \]
\item
  \textbf{{[}단계 7{]}} 독립변수 행렬 \(\mathbf{X}_a\)와 종속변수벡터 \(\mathbf{y}_a\)로부터 새로 얻어진 잠재변수 벡터 \(\mathbf{t}_a\)가 설명하는 부분을 제거하고 나머지 변동만을 담은 독립변수 행렬 \(\mathbf{X}_{a + 1}\)과 종속변수벡터 \(\mathbf{y}_{a + 1}\)을 구한다.
  \[\mathbf{X}_{a + 1} \leftarrow \mathbf{X}_a - \mathbf{t}_a \mathbf{p}_a^\top, \, \mathbf{y}_{a + 1} \leftarrow \mathbf{y}_a - \mathbf{t}_a b_a\]
\item
  \textbf{{[}단계 8{]}} \(a \leftarrow a + 1\)로 업데이트하고, {[}단계 1{]}로 돌아간다. {[}단계 1{]} - {[}단계 8{]}의 과정을 \(A\)개의 잠재변수를 얻을 때까지 반복한다.
\end{itemize}

위 NIPALS 알고리즘을 아래 \texttt{nipals\_plsr}이라는 함수로 구현해보자. 이 때, 함수의 입력변수는 아래와 같다.

\begin{itemize}
\tightlist
\item
  \texttt{X}: 평균조정된 (\(n \times k\)) 행렬
\item
  \texttt{y}: 평균조정된 종속변수 벡터
\item
  \texttt{A}: 잠재변수 개수
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nipals\_plsr }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(X, y, }\AttributeTok{A =} \ConstantTok{NULL}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{is\_empty}\NormalTok{(A) }\SpecialCharTok{||}\NormalTok{ (A }\SpecialCharTok{\textgreater{}} \FunctionTok{min}\NormalTok{(}\FunctionTok{dim}\NormalTok{(X)))) \{}
\NormalTok{    A }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(}\FunctionTok{dim}\NormalTok{(X))}
\NormalTok{  \}}
  
\NormalTok{  Tmat }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{nrow}\NormalTok{(X), }\AttributeTok{ncol =}\NormalTok{ A)}
\NormalTok{  Wmat }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{ncol}\NormalTok{(X), }\AttributeTok{ncol =}\NormalTok{ A)}
\NormalTok{  Pmat }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{ncol}\NormalTok{(X), }\AttributeTok{ncol =}\NormalTok{ A)}
\NormalTok{  b }\OtherTok{\textless{}{-}} \FunctionTok{vector}\NormalTok{(}\StringTok{"numeric"}\NormalTok{, }\AttributeTok{length =}\NormalTok{ A)}
  
  \ControlFlowTok{for}\NormalTok{ (a }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(A)) \{}
    \CommentTok{\# 단계 1}
\NormalTok{    Wmat[, a] }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(}\FunctionTok{lm}\NormalTok{(X }\SpecialCharTok{\textasciitilde{}} \SpecialCharTok{{-}}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ y))}
    
    \CommentTok{\# 단계 2}
\NormalTok{    Wmat[, a] }\OtherTok{\textless{}{-}}\NormalTok{ Wmat[, a] }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(Wmat[, a] }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{))}

    \CommentTok{\# 단계 3}
\NormalTok{    Tmat[, a] }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ Wmat[, a]}
    
    \CommentTok{\# 단계 4}
\NormalTok{    Pmat[, a] }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(}\FunctionTok{lm}\NormalTok{(X }\SpecialCharTok{\textasciitilde{}} \SpecialCharTok{{-}}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Tmat[, a]))}
    
    \CommentTok{\# 단계 5}
\NormalTok{    p\_size }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(Pmat[, a] }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{))}
\NormalTok{    Tmat[, a] }\OtherTok{\textless{}{-}}\NormalTok{ Tmat[, a] }\SpecialCharTok{*}\NormalTok{ p\_size}
\NormalTok{    Wmat[, a] }\OtherTok{\textless{}{-}}\NormalTok{ Wmat[, a] }\SpecialCharTok{*}\NormalTok{ p\_size}
\NormalTok{    Pmat[, a] }\OtherTok{\textless{}{-}}\NormalTok{ Pmat[, a] }\SpecialCharTok{/}\NormalTok{ p\_size}
    
    \CommentTok{\# 단계 6}
\NormalTok{    b[a] }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(}\FunctionTok{lm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}} \SpecialCharTok{{-}}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Tmat[, a]))}

    \CommentTok{\# 단계 7}
\NormalTok{    X }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{{-}}\NormalTok{ Tmat[, a] }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(Pmat[, a])}
\NormalTok{    y }\OtherTok{\textless{}{-}}\NormalTok{ y }\SpecialCharTok{{-}}\NormalTok{ Tmat[, a] }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(b[a])}
\NormalTok{  \}}
  
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{T =}\NormalTok{ Tmat, }\AttributeTok{W =}\NormalTok{ Wmat, }\AttributeTok{P =}\NormalTok{ Pmat, }\AttributeTok{b =}\NormalTok{ b))}
\NormalTok{\}}

\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(train\_df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{)])}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ train\_df}\SpecialCharTok{$}\NormalTok{y}
\NormalTok{nipals\_fit }\OtherTok{\textless{}{-}} \FunctionTok{nipals\_plsr}\NormalTok{(X, y, }\AttributeTok{A =} \DecValTok{2}\NormalTok{)}
\NormalTok{nipals\_fit}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $T
##            [,1]       [,2]
## [1,] -6.3243200 -2.0380766
## [2,] -7.8584372 -0.5965965
## [3,] -3.6317877  1.5429616
## [4,]  0.9079469  1.9745198
## [5,]  5.7294582  0.7158171
## [6,] 11.1771398 -1.5986253
## 
## $W
##            [,1]      [,2]
## [1,]  0.2817766 0.6579688
## [2,]  0.3130851 0.6388931
## [3,] -0.9079469 0.4245052
## 
## $P
##            [,1]      [,2]
## [1,]  0.2537679 0.5424154
## [2,]  0.2858180 0.7279599
## [3,] -0.9240724 0.4193565
## 
## $b
## [1] 2.924570 2.464658
\end{verbatim}

식 \eqref{eq:plsr-x-single-matrix}과 \eqref{eq:plsr-y-single-matrix}에서, 잠재변수 행렬 \(\mathbf{T}\)가 주어졌다 가정할 때 로딩행렬 및 벡터 \(\mathbf{P}\)와 \(\mathbf{b}\)는 아래와 같이 추정된다.

\begin{eqnarray}
\hat{\mathbf{P}}^\top = \left(\mathbf{T}^\top \mathbf{T}\right)^{-1} \mathbf{T}^\top \mathbf{X} \label{eq:plsr-x-single-loading-est}\\
\hat{\mathbf{b}} = \left(\mathbf{T}^\top \mathbf{T}\right)^{-1} \mathbf{T}^\top \mathbf{y} \label{eq:plsr-y-single-loading-est}
\end{eqnarray}

위 NIPALS 알고리즘 수행 결과에서 이를 확인해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{P\_hat }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(}\FunctionTok{solve}\NormalTok{(}\FunctionTok{t}\NormalTok{(nipals\_fit}\SpecialCharTok{$}\NormalTok{T) }\SpecialCharTok{\%*\%}\NormalTok{ nipals\_fit}\SpecialCharTok{$}\NormalTok{T) }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(nipals\_fit}\SpecialCharTok{$}\NormalTok{T) }\SpecialCharTok{\%*\%}\NormalTok{ X)}
\FunctionTok{all}\NormalTok{(}\FunctionTok{near}\NormalTok{(nipals\_fit}\SpecialCharTok{$}\NormalTok{P, P\_hat))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b\_hat }\OtherTok{\textless{}{-}} \FunctionTok{as.vector}\NormalTok{(}\FunctionTok{t}\NormalTok{(}\FunctionTok{solve}\NormalTok{(}\FunctionTok{t}\NormalTok{(nipals\_fit}\SpecialCharTok{$}\NormalTok{T) }\SpecialCharTok{\%*\%}\NormalTok{ nipals\_fit}\SpecialCharTok{$}\NormalTok{T) }\SpecialCharTok{\%*\%} 
                       \FunctionTok{t}\NormalTok{(nipals\_fit}\SpecialCharTok{$}\NormalTok{T) }\SpecialCharTok{\%*\%} \FunctionTok{as.matrix}\NormalTok{(y, }\AttributeTok{ncol =} \DecValTok{1}\NormalTok{)))}
\FunctionTok{all}\NormalTok{(}\FunctionTok{near}\NormalTok{(nipals\_fit}\SpecialCharTok{$}\NormalTok{b, b\_hat))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\hypertarget{plsr-single-transform}{%
\subsection{회귀식 변환}\label{plsr-single-transform}}

위 NIPALS 알고리즘 수행 결과를 원래 독립변수 \(\mathbf{X}\)와 종속변수 \(\mathbf{y}\)에 대한 식으로 변환하는 방법은 아래와 같다.

잠재변수행렬 \(\mathbf{T}\)는 아래와 같이 독립변수 행렬 \(\mathbf{X}\)와 가중치행렬 \(\mathbf{W}\), 그리고 로딩행렬 \(\mathbf{P}\)의 연산으로 표현된다.

\begin{equation}
\mathbf{T} = \mathbf{X} \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1} \label{eq:plsr-x-t-relation}
\end{equation}

이를 식 \eqref{eq:plsr-y-single-matrix}에 대입하면,

\begin{equation}
\begin{split}
\mathbf{y} &= \mathbf{X} \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1} \mathbf{b} + \mathbf{f}\\
&= \mathbf{X} \boldsymbol{\beta}_{PLS} + \mathbf{f}
\end{split} \label{eq:plsr-single-beta}
\end{equation}

따라서, 원 독립변수 행렬 \(\mathbf{X}\)에 대한 회귀계수는 아래와 같이 정리된다.

\begin{equation}
\boldsymbol{\beta}_{PLS} = \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1} \mathbf{b}
\end{equation}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beta\_pls }\OtherTok{\textless{}{-}}\NormalTok{ nipals\_fit}\SpecialCharTok{$}\NormalTok{W }\SpecialCharTok{\%*\%} 
  \FunctionTok{solve}\NormalTok{(}\FunctionTok{t}\NormalTok{(nipals\_fit}\SpecialCharTok{$}\NormalTok{P) }\SpecialCharTok{\%*\%}\NormalTok{ nipals\_fit}\SpecialCharTok{$}\NormalTok{W) }\SpecialCharTok{\%*\%}
  \FunctionTok{as.matrix}\NormalTok{(nipals\_fit}\SpecialCharTok{$}\NormalTok{b, }\AttributeTok{ncol =}\NormalTok{ 1L)}
\NormalTok{beta\_pls}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           [,1]
## [1,]  2.475395
## [2,]  2.523238
## [3,] -1.704636
\end{verbatim}

\hypertarget{plsr-sst}{%
\subsection{제곱합 분해}\label{plsr-sst}}

\(A\)개의 잠재변수를 사용하는 모형에 대하여 모형이 설명하는 \(\mathbf{y}\)의 변동(제곱합)을 \({SSR}\), 설명하지 못하는 변동을 \({SSE}\)라 할 때, \(\mathbf{y}\)의 전체제곱합(\({SST}\))은 다음과 같이 분해된다.

\[{SST} = {SS}(\mathbf{y}) = {SSR} + {SSE}\]

여기서 \({SS}()\)는 제곱합 함수로, 임의의 벡터 \(\mathbf{x}\)에 대해 아래와 같이 정의된다.

\[
{SS}(\mathbf{x}) = \mathbf{x}^\top \mathbf{x}
\]

이 때, \({SSR}\)은 다음과 같이 산출할 수 있다.

\begin{equation}
\begin{split}
SSR &= \sum_{a = 1}^{A} SS(b_a \mathbf{t}_a)\\
&= \sum_{a = 1}^{A} b_a^2 SS(\mathbf{t}_a)
\end{split} \label{eq:plsr-ssr}
\end{equation}

\(a\)번째 잠재변수 \(\mathbf{t}_a\)가 \(\mathbf{y}\)를 설명하는 회귀제곱합을 \(SSR_a = b_a^2 SS(\mathbf{t}_a)\)라 할 때, \(SSR\)은 아래와 같이 분해된다.

\[
SSR = \sum_{a = 1}^{A} SSR_a
\]

위 예제에서 2개의 잠재변수가 설명하는 \(\mathbf{y}\)의 총변동을 PLS 결과를 이용하여 계산하면 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SSR\_a }\OtherTok{\textless{}{-}}\NormalTok{ nipals\_fit}\SpecialCharTok{$}\NormalTok{b }\SpecialCharTok{\^{}} \DecValTok{2} \SpecialCharTok{*} \FunctionTok{diag}\NormalTok{(}\FunctionTok{t}\NormalTok{(nipals\_fit}\SpecialCharTok{$}\NormalTok{T) }\SpecialCharTok{\%*\%}\NormalTok{ nipals\_fit}\SpecialCharTok{$}\NormalTok{T)}
\NormalTok{SSR\_a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2339.45850   84.17574
\end{verbatim}

이 때, 각 주성분이 설명하는 \(\mathbf{y}\) 변동의 기여율을 아래와 같이 정의한다.

\begin{equation}
\Delta R_a^2 = \frac{SSR_a}{SST} \label{eq:plsr-rsq}
\end{equation}

앞 예제에서 각 잠재변수의 \(\mathbf{y}\) 변동에 대한 기여율을 계산해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SST }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(y }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{)}
\NormalTok{delta\_Rsq }\OtherTok{\textless{}{-}}\NormalTok{ SSR\_a }\SpecialCharTok{/}\NormalTok{ SST}
\NormalTok{delta\_Rsq}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.88281453 0.03176443
\end{verbatim}

잠재변수 \(A\)개를 이용한 PLS 모형이 설명하는 \(\mathbf{y}\)의 총 변동에 대한 기여도(\(SSR / SST\))은 아래와 같이 각 잠재변수의 기여도의 합으로 산출된다.

\[
R^2 = \frac{SSR}{SST} = \frac{\sum_{a = 1}^{A} SSR_a}{SST} = \sum_{a = 1}^{A} \Delta R_a^2
\]

따라서, 잠재변수 \(A\)개를 이용한 PLS 모형이 설명하는 \(\mathbf{y}\)의 총 변동에 대한 기여도(\(SSR / SST\))은 아래와 같이 각 잠재변수의 기여도의 합으로 산출된다.

앞 예제에서 잠재변수 2개를 이용한 최종모형이 설명하는 \(\mathbf{y}\)의 변동은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(delta\_Rsq)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.914579
\end{verbatim}

이는 앞 \ref{plsr-basic-script}절에서 R 패키지 \texttt{pls}를 이용하여 얻어진 결과와 동일함을 확인할 수 있다.

한편, 잠재변수들이 독립변수행렬 \(\mathbf{X}\)의 변동을 얼마나 설명하는지 동시에 검토할 필요가 있다. 각 잠재변수들의 제곱합 \(SS(\mathbf{t}_a)\)의 \(\mathbf{X}\)의 총변동 (\(SS(\mathbf{X})\))에 대한 비율이 그 기여율을 설명한다.

앞 예제에서 각각의 잠재변수의 \(\mathbf{X}\)에 대한 기여율은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{diag}\NormalTok{(}\FunctionTok{t}\NormalTok{(nipals\_fit}\SpecialCharTok{$}\NormalTok{T) }\SpecialCharTok{\%*\%}\NormalTok{ nipals\_fit}\SpecialCharTok{$}\NormalTok{T) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(}\FunctionTok{diag}\NormalTok{(}\FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ X))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.94972728 0.04811507
\end{verbatim}

잠재변수 2개를 이용한 PLS 모형의 \(\mathbf{X}\)에 대한 기여율은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sum}\NormalTok{(}\FunctionTok{diag}\NormalTok{(}\FunctionTok{t}\NormalTok{(nipals\_fit}\SpecialCharTok{$}\NormalTok{T) }\SpecialCharTok{\%*\%}\NormalTok{ nipals\_fit}\SpecialCharTok{$}\NormalTok{T)) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(}\FunctionTok{diag}\NormalTok{(}\FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ X))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.9978423
\end{verbatim}

잠재변수 2개가 독립변수행렬의 대부분의 변동을 설명함을 알 수 있으며, 위 결과는 역시 앞 \ref{plsr-basic-script}절에서 R 패키지 \texttt{pls}를 이용하여 얻어진 결과와 동일함을 확인할 수 있다.

\hypertarget{plsr-variable-importance}{%
\subsection{독립변수의 중요도}\label{plsr-variable-importance}}

원래의 각 독립변수가 종속변수를 설명하는 데 얼마나 영향을 미치는지는 공정분석 등에서 매우 중요하다. 식 \eqref{eq:plsr-x-t-relation}의 \(\mathbf{T}\)와 \(\mathbf{X}\)간의 관계식을 아래와 같이 다시 표현해보자.

\begin{equation}
\begin{split}
\mathbf{T} &= \mathbf{X} \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1}\\
&= \mathbf{X} \mathbf{W}^{*}
\end{split}
\end{equation}

이 때, \(\mathbf{W}^{*} = \left[\mathbf{w}^{*}_1 \, \cdots \, \mathbf{w}^{*}_A \right]\)를 변환가중치행렬이라 한다.

\begin{equation}
\mathbf{W}^{*} = \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1}
\end{equation}

이 때, 각 잠재변수가 설명하는 \(\mathbf{y}\)의 변동과 각 독립변수가 각 잠재변수에 기여하는 가중치를 고려하여, \(j\)번째 독립변수의 종속변수에 대한 중요도 척도로 \(VIP\)(variable importance in projection)를 다음과 같이 정의한다.

\begin{equation}
VIP_j = \sqrt{\frac{k}{SSR} \sum_{a = 1}^{A} SSR_a \left( w^{*}_{aj} \middle/ \| \mathbf{w}^{*}_a \|  \right)^2} \label{eq:plsr-single-vip}
\end{equation}

위 정의에 의하면 다음이 성립한다.

\[
\sum_{j = 1}^{k} VIP_j^2 = k
\]

즉, 독립변수당 중요도 제곱의 평균은 1이 된다. 이에 따라, 통상 \(VIP\)가 1보다 큰 독립변수를 의미있는 변수로 간주한다.

앞 예제에 대해 각 변수의 중요도를 계산해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{ncol}\NormalTok{(X)}
\NormalTok{Wx }\OtherTok{\textless{}{-}}\NormalTok{ nipals\_fit}\SpecialCharTok{$}\NormalTok{W }\SpecialCharTok{\%*\%} \FunctionTok{solve}\NormalTok{(}\FunctionTok{t}\NormalTok{(nipals\_fit}\SpecialCharTok{$}\NormalTok{P) }\SpecialCharTok{\%*\%}\NormalTok{ nipals\_fit}\SpecialCharTok{$}\NormalTok{W)}
\NormalTok{VIP }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}
  \FunctionTok{colSums}\NormalTok{(}
\NormalTok{    k }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(SSR\_a) }\SpecialCharTok{*}\NormalTok{ SSR\_a }\SpecialCharTok{*} 
\NormalTok{      (}\FunctionTok{t}\NormalTok{(Wx }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{) }\SpecialCharTok{/}\FunctionTok{diag}\NormalTok{(}\FunctionTok{t}\NormalTok{(Wx) }\SpecialCharTok{\%*\%}\NormalTok{ Wx))}
\NormalTok{    )}
\NormalTok{  )}
\NormalTok{VIP}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.5246196 0.5715532 1.5485804
\end{verbatim}

즉, \(x_3\)가 가장 영향력있는 변수라 할 수 있겠다.

\hypertarget{plsr-multivariate-target}{%
\section{다수의 종속변수의 경우}\label{plsr-multivariate-target}}

\(m\)개의 종속변수가 존재하여, 종속변수 데이터가 벡터가 아닌 (\(n \times m\)) 행렬

\[\mathbf{Y} = \left[ \mathbf{y}_1 \, \cdots \, \mathbf{y}_m \right]\]

으로 표현될 때, 각각의 종속변수에 대해 따로 잠재변수를 산출하기보다는, 여러 종속변수를 설명하는 공통의 잠재변수행렬 \(\mathbf{T}\)를 산출하는 것이 합리적이라 할 수 있다.

\hypertarget{plsr-multivariate-basic-script}{%
\subsection{기본 R 스크립트}\label{plsr-multivariate-basic-script}}

4개의 독립변수 및 2개의 종속변수에 대한 평균조정된 데이터가 다음과 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{x1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x2, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x3, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x4, }\SpecialCharTok{\textasciitilde{}}\NormalTok{y1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{y2,}
  \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{0.5}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{5.9}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{10}\NormalTok{,}
  \DecValTok{1}\NormalTok{, }\FloatTok{1.1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{6}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{6}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{3.7}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{,}
  \DecValTok{0}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{5}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{11}\NormalTok{,}
  \SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{3.2}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{9}\NormalTok{, }\DecValTok{19}\NormalTok{, }\FloatTok{7.7}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{22}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\FloatTok{1.2}\NormalTok{, }\DecValTok{14}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{12}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{7.5}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{2.6}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{, }\DecValTok{9}\NormalTok{, }\FloatTok{2.8}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{1}\NormalTok{, }\FloatTok{3.7}\NormalTok{, }\DecValTok{9}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{9}\NormalTok{, }\SpecialCharTok{{-}}\FloatTok{6.2}\NormalTok{, }\DecValTok{18}
\NormalTok{)}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{rep}\NormalTok{(}\StringTok{"r"}\NormalTok{, }\FunctionTok{ncol}\NormalTok{(train\_df)),}
  \AttributeTok{caption =} \StringTok{"다수의 종속변수에 대한 부분최소자승 회귀분석 예제 데이터"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:plsr-multivariate-example-data}다수의 종속변수에 대한 부분최소자승 회귀분석 예제 데이터}
\centering
\begin{tabular}[t]{rrrrrr}
\toprule
x1 & x2 & x3 & x4 & y1 & y2\\
\midrule
-1 & -0.5 & -1 & 1 & 5.9 & -10\\
1 & 1.1 & -6 & -6 & -3.7 & -2\\
0 & 0.3 & -5 & -2 & 1.0 & 11\\
-3 & -3.2 & -9 & 19 & 7.7 & -22\\
4 & 1.2 & 14 & -12 & -7.5 & 4\\
\addlinespace
-2 & -2.6 & -2 & 9 & 2.8 & 1\\
1 & 3.7 & 9 & -9 & -6.2 & 18\\
\bottomrule
\end{tabular}
\end{table}

앞서 하나의 종속변수를 다루는 경우와 마찬가지로, R 패키지 \texttt{pls} 내의 함수 \texttt{plsr()}을 이용하여 PLS 모형을 추정할 수 있다. 이 때, \texttt{formula} 입력 시 종속변수의 행렬을 이용한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(train\_df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{, }\StringTok{"x4"}\NormalTok{)])}
\NormalTok{Y }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(train\_df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"y1"}\NormalTok{, }\StringTok{"y2"}\NormalTok{)])}
\NormalTok{plsr\_multi\_fit }\OtherTok{\textless{}{-}}\NormalTok{ pls}\SpecialCharTok{::}\FunctionTok{plsr}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ X, }\AttributeTok{ncomp =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

함수 수행 결과 추정된 PLS 모형으로부터 원 독립변수 \(x_1, \cdots, x_4\)와 종속변수 \(y_1, y_2\)간의 선형관계를 함수 \texttt{coef()}를 적용하여 아래와 같이 얻을 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{coef}\NormalTok{(plsr\_multi\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## , , 3 comps
## 
##             y1         y2
## x1 -0.26509645 -2.8773570
## x2  0.08864959  2.7249194
## x3 -0.14258488  0.3377420
## x4  0.37330470 -0.7406377
\end{verbatim}

또한 \texttt{summary()} 함수를 적용하여 잠재변수들이 독립변수행렬 및 각 종속변수의 총변동에 기여하는 비율을 확인할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(plsr\_multi\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Data:    X dimension: 7 4 
##  Y dimension: 7 2
## Fit method: kernelpls
## Number of components considered: 3
## TRAINING: % variance explained
##     1 comps  2 comps  3 comps
## X     86.59    99.00    99.81
## y1    81.71    81.89    82.19
## y2    53.98    56.50    65.99
\end{verbatim}

\hypertarget{plsr-multivariate-model}{%
\subsection{PLS 모형}\label{plsr-multivariate-model}}

앞 \ref{plsr-model}절의 모형을 일반화하여 아래와 같은 모형을 가정한다.

\begin{eqnarray}
\mathbf{X} &=& \mathbf{T} \mathbf{P}^\top + \mathbf{E} \label{eq:plsr-x-multivariate-matrix}\\
\mathbf{Y} &=& \mathbf{U} \mathbf{Q}^\top + \mathbf{F} \label{eq:plsr-y-multivariate-matrix}\\
\mathbf{U} &=& \mathbf{T} \mathbf{B} + \mathbf{H}  \label{eq:plsr-inner-multivariate-matrix}
\end{eqnarray}

식 \eqref{eq:plsr-x-multivariate-matrix}의 모형은 앞서 하나의 종속변수의 경우에서 살펴본 모형식 \eqref{eq:plsr-x-single-matrix}와 동일하다. 식 \eqref{eq:plsr-y-multivariate-matrix}에서 (\(n \times A\)) 행렬 \(\mathbf{U}\)는 \(\mathbf{Y}\)를 설명하는 \(A\)개의 잠재변수를 나타내는 행렬이며, (\(m \times A\)) 행렬 \(\mathbf{Q}\)는 종속변수행렬 \(\mathbf{Y}\)와 잠재변수행렬 \(\mathbf{U}\)간의 선형관계를 나타내는 로딩행렬이다. 또한 식 \eqref{eq:plsr-inner-multivariate-matrix}는 잠재변수행렬 \(\mathbf{T}\)와 \(\mathbf{U}\)간의 선형관계를 나타내는데, 특히 \(\mathbf{B}\)는 (\(A \times A\)) 대각행렬(diagonal matrix)로써, \(\mathbf{U}\)와 \(\mathbf{T}\)간에는 서로 대응하는 열 간에만 관계가 성립하며, 그 관계는 아래와 같다.

\begin{equation*}
\mathbf{u}_a = b_a \mathbf{t}_a + \mathbf{h}_a, \, a = 1, \cdots, A
\end{equation*}

이 때, \(b_a\)는 행렬 \(\mathbf{B}\)의 \(a\)번째 대각 원소를 나타낸다.

\[\mathbf{B} = \left[ \begin{array}{c c c c}
b_{1} & 0 & \cdots & 0\\
0 & b_{2} &  & 0\\
\vdots &  & \ddots & \vdots \\
0 & 0 & \cdots & b_{A}
\end{array} \right]
\]

행렬 \(\mathbf{E}\), \(\mathbf{F}\), \(\mathbf{H}\)는 오차항에 해당하는 행렬이다.

\hypertarget{plsr-multivariate-nipals}{%
\subsection{NIPALS 알고리즘}\label{plsr-multivariate-nipals}}

다수의 종속변수가 존재하는 경우에도 NIPALS 알고리즘을 이용하여 모형을 추정한다. 이때는 각 잠재변수 \(\mathbf{t}_a\)를 추출할 때 추출한 잠재변수의 수렴 여부를 확인할 필요가 없었던 위 \ref{plsr-single-nipals}절의 경우와는 달리, 각 잠재변수 \(\mathbf{t}_a\)와 \(\mathbf{u}_a\)를 추출하는 과정에서 반복적인(iterative) 기법으로 두 잠재변수 벡터들을 업데이트하며 수렴 여부를 확인하여야 한다.

\begin{itemize}
\tightlist
\item
  \textbf{{[}단계 0{]}} 반복알고리즘 수행을 위한 초기화를 한다. \(a \leftarrow 1\), \(\mathbf{X}_a \leftarrow \mathbf{X}\), \(\mathbf{Y}_a \leftarrow \mathbf{Y}\).
\item
  \textbf{{[}단계 1{]}} 종속변수 행렬 \(\mathbf{Y}_a\)의 임의의 열 하나를 잠재변수 벡터 \(\mathbf{u}_a\)로 선정한다.
\item
  \textbf{{[}단계 2{]}} \(\mathbf{X}_a\)을 다중종속변수 행렬으로, 잠재변수 \(\mathbf{u}_a\)를 독립변수 벡터로 하는 회귀모형으로부터 기울기 \(\mathbf{w}_a = [w_{a1} \, \cdots \, w_{ak}]^\top\)를 산출한다.
  \[\mathbf{w}_a \leftarrow \left. \mathbf{X}_a^\top \mathbf{u}_a \middle/ \mathbf{u}_a^\top \mathbf{u}_a \right.  \]
\item
  \textbf{{[}단계 3{]}} 기울기 벡터 \(\mathbf{w}_a\)의 크기가 1이 되도록 한다.
  \[\left. \mathbf{w}_a \leftarrow \mathbf{w}_a \middle/ \sqrt{\mathbf{w}_a^\top \mathbf{w}_a} \right.\]
\item
  \textbf{{[}단계 4{]}} 잠재변수 \(\mathbf{t}_a\)를 행렬 \(\mathbf{X}_a\)의 각 열의 가중평균으로 구한다. 이 때, 가중치는 기울기 벡터 \(\mathbf{w}_a\)를 이용한다.
  \[\mathbf{t}_a \leftarrow \mathbf{X}_a \mathbf{w}_a\]
\item
  \textbf{{[}단계 5{]}} \(\mathbf{Y}_a\)을 다중종속변수 행렬으로, 잠재변수 \(\mathbf{t}_a\)를 독립변수 벡터로 하는 회귀모형으로부터 기울기 (로딩벡터) \(\mathbf{q}_a = [q_{a1} \, \cdots \, q_{am}]^\top\)를 산출한다.
  \[\mathbf{q}_a \leftarrow \left. \mathbf{Y}_a^\top \mathbf{t}_a \middle/ \mathbf{t}_a^\top \mathbf{t}_a \right.  \]
\item
  \textbf{{[}단계 6{]}} 기울기 벡터 \(\mathbf{q}_a\)의 크기가 1이 되도록 한다.
  \[\left. \mathbf{q}_a \leftarrow \mathbf{q}_a \middle/ \sqrt{\mathbf{q}_a^\top \mathbf{q}_a} \right.\]
\item
  \textbf{{[}단계 7{]}} 잠재변수 \(\mathbf{u}_a\)를 행렬 \(\mathbf{Y}_a\)의 각 열의 가중평균으로 구한다. 이 때, 가중치는 기울기 벡터 \(\mathbf{q}_a\)를 이용한다.
  \[\mathbf{u}_a \leftarrow \mathbf{Y}_a \mathbf{q}_a\]
\item
  \textbf{{[}단계 8{]}} (수렴 확인) {[}단계 2{]}에서 {[}단계 7{]}까지의 과정을 잠재변수 벡터 \(\mathbf{u}_a\)의 모든 원소값이 수렴할 때까지 반복한다. 수렴이 확인되면 {[}단계 9{]}로 진행한다.
\item
  \textbf{{[}단계 9{]}} \(\mathbf{t}_a\)를 \(\mathbf{X}_a\)에 회귀시켜, \(\mathbf{X}_a\)을 다중종속변수 행렬으로, \(\mathbf{t}_a\)를 독립변수 벡터로 하는 회귀모형으로부터 로딩벡터 \(\mathbf{p}_a\)를 구한다.
  \[\mathbf{p}_a \leftarrow \left. \mathbf{X}_a^\top \mathbf{t}_a \middle/ \mathbf{t}_a^\top \mathbf{t}_a \right.\]
\item
  \textbf{{[}단계 10{]}} 로딩벡터 \(\mathbf{p}_a\)의 크기를 1로 조정하고, 잠재변수 벡터 \(\mathbf{t}_a\)와 기울기 벡터 \(\mathbf{w}_a\)의 크기를 그에 따라 보정한다.
  \[d \leftarrow \sqrt{\mathbf{p}_a^\top \mathbf{p}_a}, \, \mathbf{t}_a \leftarrow \mathbf{t}_a d, \, \mathbf{w}_a \leftarrow \mathbf{w}_a d, \, \mathbf{p}_a \leftarrow \frac{1}{d} \mathbf{p}_a \]
\item
  \textbf{{[}단계 11{]}} 잠재변수벡터 \(\mathbf{u}_a\)와 \(\mathbf{t}_a\)간의 내부관계 계수 \(b_a\)를 산출한다.
  \[b_a \leftarrow \left. \mathbf{u}_a^\top \mathbf{t}_a \middle/ \mathbf{t}_a^\top \mathbf{t}_a \right. \]
\item
  \textbf{{[}단계 12{]}} 독립변수행렬 \(\mathbf{X}_a\)와 종속변수행렬 \(\mathbf{Y}_a\)로부터 새로 얻어진 잠재변수 벡터 \(\mathbf{t}_a\)가 설명하는 부분을 제거하고 나머지 변동만을 담은 독립변수행렬 \(\mathbf{X}_{a + 1}\)과 종속변수행렬 \(\mathbf{Y}_{a + 1}\)을 구한다.
  \[\mathbf{X}_{a + 1} \leftarrow \mathbf{X}_a - \mathbf{t}_a \mathbf{p}_a^\top, \, \mathbf{Y}_{a + 1} \leftarrow \mathbf{Y}_a - b_a \mathbf{t}_a \mathbf{q}_a^\top \]
\item
  \textbf{{[}단계 13{]}} \(a \leftarrow a + 1\)로 업데이트하고, {[}단계 1{]}로 돌아간다. {[}단계 1{]} - {[}단계 13{]}의 과정을 \(A\)개의 잠재변수를 얻을 때까지 반복한다.
\end{itemize}

위 알고리즘을 아래 \texttt{nipals\_plsr2}이라는 함수로 구현해보자. 이 때, 함수의 입력변수는 아래와 같다.

\begin{itemize}
\tightlist
\item
  \texttt{X}: 평균조정된 (\(n \times k\)) 독립변수행렬
\item
  \texttt{Y}: 평균조정된 (\(n \times m\)) 종속변수행렬
\item
  \texttt{A}: 잠재변수 개수
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nipals\_plsr2 }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(X, Y, }\AttributeTok{A =} \ConstantTok{NULL}\NormalTok{) \{}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{is.vector}\NormalTok{(Y)) \{}
\NormalTok{    Y }\OtherTok{\textless{}{-}} \FunctionTok{as.matrix}\NormalTok{(Y, }\AttributeTok{ncol =}\NormalTok{ 1L)}
\NormalTok{  \}}
  
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{nrow}\NormalTok{(X) }\SpecialCharTok{!=} \FunctionTok{nrow}\NormalTok{(Y)) }\FunctionTok{stop}\NormalTok{(}\StringTok{"X and Y must have the same numbers of observations."}\NormalTok{)}
  
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{is\_empty}\NormalTok{(A) }\SpecialCharTok{||}\NormalTok{ (A }\SpecialCharTok{\textgreater{}} \FunctionTok{min}\NormalTok{(}\FunctionTok{dim}\NormalTok{(X)))) \{}
\NormalTok{    A }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(}\FunctionTok{dim}\NormalTok{(X))}
\NormalTok{  \}}
  
\NormalTok{  Tmat }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{nrow}\NormalTok{(X), }\AttributeTok{ncol =}\NormalTok{ A)}
\NormalTok{  Umat }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{nrow}\NormalTok{(X), }\AttributeTok{ncol =}\NormalTok{ A)}
\NormalTok{  Wmat }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{ncol}\NormalTok{(X), }\AttributeTok{ncol =}\NormalTok{ A)}
\NormalTok{  Pmat }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{ncol}\NormalTok{(X), }\AttributeTok{ncol =}\NormalTok{ A)}
\NormalTok{  Qmat }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\ConstantTok{NA}\NormalTok{, }\AttributeTok{nrow =} \FunctionTok{ncol}\NormalTok{(Y), }\AttributeTok{ncol =}\NormalTok{ A)}
\NormalTok{  Bmat }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(}\AttributeTok{nrow =}\NormalTok{ A)}
  
  \ControlFlowTok{for}\NormalTok{ (a }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(A)) \{}
    \CommentTok{\# 단계 1}
\NormalTok{    j }\OtherTok{\textless{}{-}} \FunctionTok{sample.int}\NormalTok{(}\FunctionTok{ncol}\NormalTok{(Y), }\AttributeTok{size =}\NormalTok{ 1L)}
\NormalTok{    Umat[, a] }\OtherTok{\textless{}{-}}\NormalTok{ Y[, j]}
    
    \ControlFlowTok{while}\NormalTok{ (}\ConstantTok{TRUE}\NormalTok{) \{}
      \CommentTok{\# 단계 2}
\NormalTok{      Wmat[, a] }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(}\FunctionTok{lm}\NormalTok{(X }\SpecialCharTok{\textasciitilde{}} \SpecialCharTok{{-}}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Umat[, a]))}
      
      \CommentTok{\# 단계 3}
\NormalTok{      Wmat[, a] }\OtherTok{\textless{}{-}}\NormalTok{ Wmat[, a] }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(Wmat[, a] }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{))}
      
      \CommentTok{\# 단계 4}
\NormalTok{      Tmat[, a] }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ Wmat[, a]}
      
      \CommentTok{\# 단계 5}
\NormalTok{      Qmat[, a] }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(}\FunctionTok{lm}\NormalTok{(Y }\SpecialCharTok{\textasciitilde{}} \SpecialCharTok{{-}}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Tmat[, a]))}
      
      \CommentTok{\# 단계 6}
\NormalTok{      Qmat[, a] }\OtherTok{\textless{}{-}}\NormalTok{ Qmat[, a] }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(Qmat[, a] }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{))}
      
      \CommentTok{\# 단계 7}
\NormalTok{      u\_new }\OtherTok{\textless{}{-}}\NormalTok{ Y }\SpecialCharTok{\%*\%}\NormalTok{ Qmat[, a]}
      
      \CommentTok{\# 단계 8}
      \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{all}\NormalTok{(}\FunctionTok{near}\NormalTok{(u\_new, Umat[, a]))) }\ControlFlowTok{break}
      
\NormalTok{      Umat[, a] }\OtherTok{\textless{}{-}}\NormalTok{ u\_new}
\NormalTok{    \}}

    \CommentTok{\# 단계 9}
\NormalTok{    Pmat[, a] }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(}\FunctionTok{lm}\NormalTok{(X }\SpecialCharTok{\textasciitilde{}} \SpecialCharTok{{-}}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Tmat[, a]))}
    
    \CommentTok{\# 단계 10}
\NormalTok{    p\_size }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(Pmat[, a] }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{))}
\NormalTok{    Tmat[, a] }\OtherTok{\textless{}{-}}\NormalTok{ Tmat[, a] }\SpecialCharTok{*}\NormalTok{ p\_size}
\NormalTok{    Wmat[, a] }\OtherTok{\textless{}{-}}\NormalTok{ Wmat[, a] }\SpecialCharTok{*}\NormalTok{ p\_size}
\NormalTok{    Pmat[, a] }\OtherTok{\textless{}{-}}\NormalTok{ Pmat[, a] }\SpecialCharTok{/}\NormalTok{ p\_size}
    
    \CommentTok{\# 단계 11}
\NormalTok{    Bmat[a, a] }\OtherTok{\textless{}{-}} \FunctionTok{coef}\NormalTok{(}\FunctionTok{lm}\NormalTok{(Umat[, a] }\SpecialCharTok{\textasciitilde{}} \SpecialCharTok{{-}}\DecValTok{1} \SpecialCharTok{+}\NormalTok{ Tmat[, a]))}

    \CommentTok{\# 단계 12}
\NormalTok{    X }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{{-}}\NormalTok{ Tmat[, a] }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(Pmat[, a])}
\NormalTok{    Y }\OtherTok{\textless{}{-}}\NormalTok{ Y }\SpecialCharTok{{-}}\NormalTok{ Bmat[a, a] }\SpecialCharTok{*}\NormalTok{ Tmat[, a] }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(Qmat[, a])}
\NormalTok{  \}}
  
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{T =}\NormalTok{ Tmat, }\AttributeTok{W =}\NormalTok{ Wmat, }\AttributeTok{P =}\NormalTok{ Pmat, }
              \AttributeTok{U =}\NormalTok{ Umat, }\AttributeTok{Q =}\NormalTok{ Qmat, }\AttributeTok{B =}\NormalTok{ Bmat))}
\NormalTok{\}}

\NormalTok{nipals\_fit2 }\OtherTok{\textless{}{-}} \FunctionTok{nipals\_plsr2}\NormalTok{(X, Y, }\AttributeTok{A =} \DecValTok{3}\NormalTok{)}
\NormalTok{nipals\_fit2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $T
##             [,1]       [,2]        [,3]
## [1,]   1.5777938 -0.4117531  0.44707709
## [2,]  -2.2993972 -8.0194451 -0.79803681
## [3,]   0.8145895 -5.1398023 -0.30016399
## [4,]  21.3867331  3.2065797 -0.01083136
## [5,] -17.8784038  5.7770058 -1.68928119
## [6,]   9.2701258  3.6198261 -0.09042238
## [7,] -12.8714412  0.9675888  2.44165865
## 
## $W
##            [,1]       [,2]       [,3]
## [1,] -0.1476019  0.4020251 -0.6921766
## [2,] -0.1848598 -0.4862964  0.5027723
## [3,] -0.5065102  0.8236460  0.4768770
## [4,]  0.8312518  0.4651155  0.2794808
## 
## $P
##            [,1]         [,2]       [,3]
## [1,] -0.1648502 -0.002634502 -0.5484068
## [2,] -0.1588038 -0.130002426  0.6241044
## [3,] -0.5486716  0.859489687  0.4559029
## [4,]  0.8040928  0.494337847  0.3192118
## 
## $U
##              [,1]       [,2]      [,3]
## [1,]  11.60599122   9.401433 -8.559602
## [2,]  -0.03696152   3.340983 -7.252566
## [3,]  -9.14720168 -11.437784  9.474719
## [4,]  22.98172912   6.021677 -4.914480
## [5,]  -7.12619591   9.125035 -6.794076
## [6,]   0.47754875  -7.914057  9.259791
## [7,] -18.75490997  -8.537286  8.786214
## 
## $Q
##            [,1]       [,2]       [,3]
## [1,]  0.4832295  0.1202142 0.07948906
## [2,] -0.8754937 -0.9927480 0.99683574
## 
## $B
##           [,1]      [,2]     [,3]
## [1,] 0.8443757 0.0000000 0.000000
## [2,] 0.0000000 0.4255916 0.000000
## [3,] 0.0000000 0.0000000 3.206299
\end{verbatim}

\hypertarget{plsr-multivariate-transform}{%
\subsection{회귀식 변환}\label{plsr-multivariate-transform}}

위 NIPALS 알고리즘 수행 결과를 원래 독립변수 \(\mathbf{X}\)와 종속변수 \(\mathbf{Y}\)에 대한 식으로 변환하는 방법은 아래와 같다.

잠재변수행렬 \(\mathbf{T}\)는 하나의 종속변수일 때 살펴봤던 바와 같이 독립변수행렬 \(\mathbf{X}\)와 가중치행렬 \(\mathbf{W}\), 그리고 로딩행렬 \(\mathbf{P}\)의 연산으로 표현된다.

\begin{equation}
\mathbf{T} = \mathbf{X} \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1}
\end{equation}

이를 식 \eqref{eq:plsr-inner-multivariate-matrix}에 대입하면,

\begin{equation}
\mathbf{U} = \mathbf{X} \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1} \mathbf{B} + \mathbf{H}
\end{equation}

이를 다시 식 \eqref{eq:plsr-y-multivariate-matrix}에 대입하면,

\begin{equation}
\begin{split}
\mathbf{Y} &= \mathbf{X} \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1} \mathbf{B} \mathbf{Q}^\top + \mathbf{H} \mathbf{Q}^\top + \mathbf{F}\\
&= \mathbf{X} \mathbf{B}_{PLS} + \mathbf{G}
\end{split} \label{eq:plsr-multivariate-beta}
\end{equation}

여기에서 \(\mathbf{G} = \mathbf{H} \mathbf{Q}^\top + \mathbf{F}\)는 독립변수 \(\mathbf{X}\)를 종속변수 \(\mathbf{Y}\)에 회귀시킨 뒤 남은 오차항 행렬이다. 따라서, PLS 모형을 원 독립변수 행렬 \(\mathbf{X}\)에 대한 모형으로 변환할 때의 회귀계수는 아래와 같이 정리된다.

\begin{equation}
\mathbf{B}_{PLS} = \mathbf{W} \left(\mathbf{P}^\top \mathbf{W}\right)^{-1} \mathbf{B} \mathbf{Q}^\top
\end{equation}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{beta\_pls2 }\OtherTok{\textless{}{-}}\NormalTok{ nipals\_fit2}\SpecialCharTok{$}\NormalTok{W }\SpecialCharTok{\%*\%} 
  \FunctionTok{solve}\NormalTok{(}\FunctionTok{t}\NormalTok{(nipals\_fit2}\SpecialCharTok{$}\NormalTok{P) }\SpecialCharTok{\%*\%}\NormalTok{ nipals\_fit2}\SpecialCharTok{$}\NormalTok{W) }\SpecialCharTok{\%*\%} 
\NormalTok{  nipals\_fit2}\SpecialCharTok{$}\NormalTok{B }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(nipals\_fit2}\SpecialCharTok{$}\NormalTok{Q)}
\NormalTok{beta\_pls2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             [,1]       [,2]
## [1,] -0.26509645 -2.8773570
## [2,]  0.08864959  2.7249194
## [3,] -0.14258488  0.3377420
## [4,]  0.37330470 -0.7406377
\end{verbatim}

이는 앞 \ref{plsr-multivariate-basic-script} 절에서 R 패키지 \texttt{pls}를 통해 얻어진 결과와 동일함을 확인할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{all}\NormalTok{(}\FunctionTok{near}\NormalTok{(beta\_pls2, }\FunctionTok{coef}\NormalTok{(plsr\_multi\_fit)[, , }\DecValTok{1}\NormalTok{]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\hypertarget{plsr-multivariate-sst}{%
\subsection{제곱합 분해}\label{plsr-multivariate-sst}}

\(\mathbf{Y}\)의 전체제곱합은

\[SST = SSR + SSE\]

로 분해되며, 여기서 \(SSR\)은 다음과 같이 산출된다.

\begin{equation}
\begin{split}
SSR &= \sum_{a = 1}^{A} SSR_a\\
&= \sum_{a = 1}^{A} SS(b_a \mathbf{t}_a \mathbf{q}_a^\top)\\ 
&= \sum_{a = 1}^{A} b_a^2 SS(\mathbf{t}_a)
\end{split} \label{eq:plsr-multivariate-ssr}
\end{equation}

이 때, \(SSR_a\)는 잠재변수 \(\mathbf{t}_a\)에 의해 설명되는 \(\mathbf{Y}\)의 변동을 나타낸다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SSR\_a }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(}
  \FunctionTok{t}\NormalTok{(nipals\_fit2}\SpecialCharTok{$}\NormalTok{T }\SpecialCharTok{\%*\%}\NormalTok{ nipals\_fit2}\SpecialCharTok{$}\NormalTok{B) }\SpecialCharTok{\%*\%} 
\NormalTok{    (nipals\_fit2}\SpecialCharTok{$}\NormalTok{T }\SpecialCharTok{\%*\%}\NormalTok{ nipals\_fit2}\SpecialCharTok{$}\NormalTok{B)}
\NormalTok{)}
\NormalTok{SSR\_a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 739.40663  26.91455 100.23860
\end{verbatim}

\(SSR_a\)를 전체제곱합 \(SST\)로 나누면 각 잠재변수가 \(\mathbf{Y}\)의 변동에 기여하는 비율을 산출할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SST }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(Y }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{)}
\NormalTok{SSR\_a }\SpecialCharTok{/}\NormalTok{ SST}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.58621653 0.02133840 0.07947119
\end{verbatim}

또한, 잠재변수 \(\mathbf{t}_a\)가 설명하는 종속변수행렬 \(\mathbf{Y}\)의 \(j\)번째 열의 변동을 \(SSR_{aj}\)라 할 때, 이는 다음과 같이 산출된다.

\begin{equation}
SSR_{aj} = q_{ja}^2 SSR_a
\end{equation}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SSR\_aj }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(SSR\_a) }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(nipals\_fit2}\SpecialCharTok{$}\NormalTok{Q }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{)}
\NormalTok{SSR\_aj}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             [,1]      [,2]
## [1,] 172.6593685 566.74726
## [2,]   0.3889542  26.52560
## [3,]   0.6333587  99.60524
\end{verbatim}

이렇게 산출된 \(SSR_{aj}\)를 \(j\)번째 종속변수 \(\mathbf{y}_j\)의 제곱합 \(SS(\mathbf{y}_j)\)로 나누면, \(\mathbf{y}_j\)에 대한 \(\mathbf{t}_a\)의 기여도를 얻을 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{SS\_j }\OtherTok{\textless{}{-}} \FunctionTok{colSums}\NormalTok{(Y }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{)}
\NormalTok{SSR\_aj }\SpecialCharTok{\%*\%} \FunctionTok{diag}\NormalTok{(}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ SS\_j)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             [,1]       [,2]
## [1,] 0.817051715 0.53975930
## [2,] 0.001840593 0.02526248
## [3,] 0.002997154 0.09486213
\end{verbatim}

위의 결과에서 \(\mathbf{y}_1\)의 변동은 잠재변수 \(\mathbf{t}_1\)으로 대부분 설명되는 반면, \(\mathbf{y}_2\)의 변동은 잠재변수 \(\mathbf{t}_2\) 및 \(\mathbf{t}_3\)에 의해서도 설명됨을 볼 수 있다.

\hypertarget{part-2uxbd80---uxbd84uxb958uxbd84uxc11d}{%
\part{2부 - 분류분석}\label{part-2uxbd80---uxbd84uxb958uxbd84uxc11d}}

\hypertarget{classification-analysis}{%
\chapter{분류분석 개요}\label{classification-analysis}}

분류분석(classification analysis)은 다수의 속성(attribute) 또는 변수를 갖는 객체(object)를 사전에 정해진 그룹 또는 범주(class, category) 중의 하나로 분류하는 것이다. 예를 들어, 기업의 3개의 재무제표를 기준으로 우량 또는 불량으로 분류하는 것은 범주수가 2이고 변수수가 3인 분류분석 문제가 될 것이다. 이를 위해서는 이미 범주(우량 또는 불량)가 알려진 여러 기업에 대하여 3개의 재무제표 데이터를 수집한 후 효율적인 분류규칙(classification rule)을 만들어야 할 것이다. 여기서 효율적이라 함은 기존 객체를 잘 분류할 뿐만 아니라 새로운 객체 역시 잘 분류함을 의미한다. 분류규칙을 만들기 위해서는 기존의 범주가 알려진 객체 데이터를 수집하여야 하며, 이를 학습표본(learning sample)이라 한다.

\hypertarget{classification-packages-install}{%
\section{필요 R 패키지 설치}\label{classification-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.3.1\\
\hline
stats & 4.1.0\\
\hline
class & 7.3-19\\
\hline
\end{tabular}

\hypertarget{classification-problem-methods}{%
\section{분류문제 및 분류기법}\label{classification-problem-methods}}

분류문제를 설명하기 위하여 \(N\)개의 객체로 이루어진 학습데이터 \(\{(\mathbf{x}_i, y_i)\}_{i = 1, \cdots, N}\)를 아래와 같이 정의하자.

\begin{itemize}
\tightlist
\item
  \(\mathbf{x}_i\): \(p\)개의 독립변수로 이루어진 \(i\)번째 객체의 변수벡터 (\(\mathbf{x}_i = [x_{i1} \, x_{i2} \, \cdots \, x_{ip}]^\top\))
\item
  \(J\): 총 범주 수
\item
  \(y_i\): \(i\)번째 객체의 범주 변수; \(y_i \in \{1, 2, \cdots, J\}\)
\end{itemize}

이 때 학습표본을 다음과 같이 나타낼 수 있다.

\begin{equation*}
\{(\mathbf{x}_1, y_1), (\mathbf{x}_2, y_2), \cdots, (\mathbf{x}_N, y_N)\}
\end{equation*}

분류문제는 새로운 객체를 범주 중의 하나로 분류하기 위하여 학습표본을 바탕으로 분류규칙을 만드는 것이다. 이 때 분류규칙은 객체의 변수벡터의 함수로 도출되므로 이를 \(r(\mathbf{x})\)로 나타낸다. 이 때, \(r(\mathbf{x})\)는 \(1, \cdots, J\) 중 하나의 값을 가지며, 이를 분류기(classifier)라 부르기도 한다. 분류규칙의 성능을 관찰하기 위하여 우선 학습표본에 적용하여 실제범주와 추정된 범주를 비교한다. 즉, \(r(\mathbf{x}_i)\)와 \(y_i\)를 비교하여 오분류율 등을 분석한다. 다시 말하면, \(r(\mathbf{x}_i) = y_i\) 이면 올바르게 분류된 것이나, 그렇지 않으면 잘못 분류된 것이다. 학습표본에 있는 전체 객체는 서로 배타적인 \(J\)개의 집합으로 나누어진다. 분류규칙의 성능평가에 대한 보다 자세한 설명은 이후 \ref{classifier-evaluation}장에서 하기로 한다.

분류를 위한 방법론은 무수하게 많은데, 크게 아래와 같이 대별된다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  통계적 방법: 로지스틱 회귀분석, 반별분석 등 다변량 통계이론에 바탕을 둔 방법
\item
  트리기반 기법: CART, C4.5, CHAID 등 트리 형태의 분지방법을 이용하는 기법
\item
  비선형 최적화 기법: 서포트 벡터 머신(support vector machine; SVM) 등
\item
  기계학습 기법: 신경망(neural network) 등의 블랙박스 형태의 기법
\end{enumerate}

\ref{logistic-regression}장에서는 로지스틱 회귀분석을, \ref{da}장에서는 판별분석에 의한 분류분석을, \ref{tree-based-method}장에서는 트리기반 기법을 다루며, \ref{svm}장에서는 서포트 벡터 머신을 다루고자 한다.

\hypertarget{simple-classification-methods}{%
\section{기본적인 분류기법}\label{simple-classification-methods}}

본 절에서는 위에서 언급하지 않은 기본적인 몇 가지 분류기법에 대하여 설명하고자 한다.

\hypertarget{nearest-neighbor-classification}{%
\subsection{인접객체법}\label{nearest-neighbor-classification}}

인접객체법(nearest neighbor classification)은 학습 데이터를 활용하지만 규칙을 도출하는 기법은 아니다. 분류하고자 하는 새로운 객체에 대하여 학습 데이터에 있는 가장 가까운 몇 개의 객체들을 찾은 후 이들 인접객체들의 다수 범주로 분류하는 기법이다. \(k\)개의 인접객체를 고려할 때, \(k\)-인접객체법(k-nearest neighbor method)이라 한다. 가까운 정도의 척도는 유사성 척도 또는 유클리드 거리 등의 비유사성 척도가 사용되는데, 이들에 대한 자세한 설명은 \ref{clustering-overview}장에서 이루어진다.

\hypertarget{nearest-neighbor-classificaiton-basic-script}{%
\subsubsection{기본 R 스트립트}\label{nearest-neighbor-classificaiton-basic-script}}

다음과 같은 7개의 객체에 대한 학습표본이 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{id, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x2, }\SpecialCharTok{\textasciitilde{}}\NormalTok{y,}
  \DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{2}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{y =} \FunctionTok{factor}\NormalTok{(y, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)))}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
  \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}범주\textquotesingle{}}\NormalTok{),}
  \AttributeTok{caption =} \StringTok{\textquotesingle{}인접객체법 학습표본\textquotesingle{}}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:knn-classification-data}인접객체법 학습표본}
\centering
\begin{tabular}[t]{rrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 범주\\
\midrule
1 & 5 & 7 & 1\\
2 & 4 & 3 & 2\\
3 & 7 & 8 & 2\\
4 & 8 & 6 & 2\\
5 & 3 & 6 & 1\\
\addlinespace
6 & 2 & 5 & 1\\
7 & 9 & 6 & 2\\
\bottomrule
\end{tabular}
\end{table}

\texttt{class} 패키지의 \texttt{knn.cv} 함수는 학습표본의 각각의 객체에 대해 그 객체를 제외한 나머지 학습표본 중 객체에서 가장 가까운(유클리드 거리 기반) \(k\)개의 객체의 범주값을 이용하여 대상 학습표본의 범주값을 추정하는 leave-one-out cross validation을 수행한다. 아래 스크립트는 Table \ref{tab:knn-classification-data}의 학습표본 데이터에 대해 3-인접객체 leave-one-out cross validation 결과 추정된 범주값을 산출한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_hat }\OtherTok{\textless{}{-}}\NormalTok{ class}\SpecialCharTok{::}\FunctionTok{knn.cv}\NormalTok{(}
  \AttributeTok{train =}\NormalTok{ train\_df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)],}
  \AttributeTok{cl =}\NormalTok{ train\_df}\SpecialCharTok{$}\NormalTok{y,}
  \AttributeTok{k =} \DecValTok{3}
\NormalTok{)}

\NormalTok{train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{y\_hat =}\NormalTok{ y\_hat) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}실제범주\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}추정범주\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}인접객체법 추정범주 {-} 학습데이터\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:knn-classification-cv}인접객체법 추정범주 - 학습데이터}
\centering
\begin{tabular}[t]{rrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & 추정범주\\
\midrule
1 & 5 & 7 & 1 & 2\\
2 & 4 & 3 & 2 & 1\\
3 & 7 & 8 & 2 & 2\\
4 & 8 & 6 & 2 & 2\\
5 & 3 & 6 & 1 & 1\\
\addlinespace
6 & 2 & 5 & 1 & 1\\
7 & 9 & 6 & 2 & 2\\
\bottomrule
\end{tabular}
\end{table}

\texttt{class} 패키지의 \texttt{knn} 함수는 새로운 객체에 대해 인접한 학습데이터를 이용하여 범주를 추정하는 함수이다. 아래 스크립트는 두 개의 새로운 객체 \((6, 7)^\top\)과 \((4, 2)^\top\)에 대해 3-인근객체법으로 추정범주를 구하는 스크립트이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{id, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x2,}
  \DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}
\NormalTok{)}

\NormalTok{y\_hat }\OtherTok{\textless{}{-}}\NormalTok{ class}\SpecialCharTok{::}\FunctionTok{knn}\NormalTok{(}
  \AttributeTok{train =}\NormalTok{ train\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(x1, x2),}
  \AttributeTok{test =}\NormalTok{ test\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(x1, x2),}
  \AttributeTok{cl =}\NormalTok{ train\_df}\SpecialCharTok{$}\NormalTok{y,}
  \AttributeTok{k =} \DecValTok{3}
\NormalTok{)}

\NormalTok{test\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{y\_hat =}\NormalTok{ y\_hat) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}추정범주\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}인접객체법 추정범주 {-} 새로운 객체\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:knn-classification-test}인접객체법 추정범주 - 새로운 객체}
\centering
\begin{tabular}[t]{rrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 추정범주\\
\midrule
8 & 6 & 7 & 2\\
9 & 4 & 2 & 1\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{nearest-neighbor-classification-algorithm}{%
\subsubsection{인접객체법 알고리즘}\label{nearest-neighbor-classification-algorithm}}

\(k\)-인접객체법의 알고리즘은 다음과 같다.

\begin{itemize}
\tightlist
\item
  \textbf{{[}단계 1{]}} \(k\)값을 정한다.
\item
  \textbf{{[}단계 2{]}} 분류하고자 하는 새로운 객체 \(\mathbf{z}\)에 대하여

  \begin{itemize}
  \tightlist
  \item
    2-1. 학습표본에 있는 각 객체 \(\mathbf{x}_i\)와의 거리 \(d(\mathbf{z}, \mathbf{x}_i)\)를 산출한다.
  \item
    2-2. 위의 거리가 짧은 순으로 \(k\)개의 객체를 선정한다.
  \item
    2-3. \(k\)개의 인근객체가 취하는 범주 중 최빈값을 새로운 객체 \(\mathbf{z}\)의 범주로 정한다.
  \end{itemize}
\end{itemize}

위 알고리즘을 학습표본 Table \ref{tab:knn-classification-data}와 두 새로운 객체 \((6, 7)^\top\) 및 \((4, 2)^\top\)에 적용해보자.

{[}단계 1{]} 우선 각 학습표본 객체에 대해 \(k\)값을 변화시키며 인접객체법으로 분류해보자. 이 때, 각 객체 스스로는 인접객체에 포함되지 않는다.

우선 아래 스크립트는 각 학습 객체간 유클리드 거리를 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_pairwise\_dist }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(train\_df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)], }\AttributeTok{upper =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{()}

\NormalTok{train\_pairwise\_dist}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 42 x 3
##    item1 item2 distance
##    <fct> <fct>    <dbl>
##  1 1     2         4.12
##  2 1     3         2.24
##  3 1     4         3.16
##  4 1     5         2.24
##  5 1     6         3.61
##  6 1     7         4.12
##  7 2     1         4.12
##  8 2     3         5.83
##  9 2     4         5   
## 10 2     5         3.16
## # ... with 32 more rows
\end{verbatim}

각 객체별로 가장 인접한 객체 순으로 순서(rank)를 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_nn\_rank }\OtherTok{\textless{}{-}}\NormalTok{ train\_pairwise\_dist }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{nn\_rank =} \FunctionTok{rank}\NormalTok{(distance, }\AttributeTok{ties.method =} \StringTok{"random"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(item1, nn\_rank)}

\NormalTok{train\_nn\_rank}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 42 x 4
##    item1 item2 distance nn_rank
##    <fct> <fct>    <dbl>   <int>
##  1 1     3         2.24       1
##  2 1     5         2.24       2
##  3 1     4         3.16       3
##  4 1     6         3.61       4
##  5 1     7         4.12       5
##  6 1     2         4.12       6
##  7 2     6         2.83       1
##  8 2     5         3.16       2
##  9 2     1         4.12       3
## 10 2     4         5          4
## # ... with 32 more rows
\end{verbatim}

이후 각 \(k\)값에 대하여 각 객체 대해 \(k\)-인접객체법에 대한 추정범주를 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loo\_cv }\OtherTok{\textless{}{-}} \FunctionTok{bind\_cols}\NormalTok{(}
\NormalTok{  train\_nn\_rank }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(item1, nn\_rank),}
  \FunctionTok{map2\_dfr}\NormalTok{(}
\NormalTok{    train\_nn\_rank}\SpecialCharTok{$}\NormalTok{item1,}
\NormalTok{    train\_nn\_rank}\SpecialCharTok{$}\NormalTok{nn\_rank,}
    \ControlFlowTok{function}\NormalTok{(.x, .y, df, y) \{}
\NormalTok{      df }\SpecialCharTok{\%\textgreater{}\%}
        \FunctionTok{filter}\NormalTok{(}
\NormalTok{          item1 }\SpecialCharTok{==}\NormalTok{ .x,}
\NormalTok{          nn\_rank }\SpecialCharTok{\textless{}=}\NormalTok{ .y}
\NormalTok{        ) }\SpecialCharTok{\%\textgreater{}\%}
        \FunctionTok{mutate}\NormalTok{(}\AttributeTok{y =}\NormalTok{ y[item2]) }\SpecialCharTok{\%\textgreater{}\%}
        \FunctionTok{count}\NormalTok{(y) }\SpecialCharTok{\%\textgreater{}\%}
        \FunctionTok{slice}\NormalTok{(}\FunctionTok{which.max}\NormalTok{(n))}
\NormalTok{    \},}
    \AttributeTok{df =}\NormalTok{ train\_nn\_rank,}
    \AttributeTok{y =}\NormalTok{ train\_df}\SpecialCharTok{$}\NormalTok{y}
\NormalTok{  )}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{k =}\NormalTok{ nn\_rank, }\AttributeTok{y\_hat =}\NormalTok{ y) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{y =}\NormalTok{ train\_df}\SpecialCharTok{$}\NormalTok{y[item1])}

\NormalTok{loo\_cv}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 42 x 5
##    item1     k y_hat     n y    
##    <fct> <int> <fct> <int> <fct>
##  1 1         1 2         1 1    
##  2 1         2 1         1 1    
##  3 1         3 2         2 1    
##  4 1         4 1         2 1    
##  5 1         5 2         3 1    
##  6 1         6 2         4 1    
##  7 2         1 1         1 2    
##  8 2         2 1         2 2    
##  9 2         3 1         3 2    
## 10 2         4 1         3 2    
## # ... with 32 more rows
\end{verbatim}

학습객체들의 \(k\)-인접객체법 추정범주와 실제범주가 같은 비율을 정확도라 하여, 각 \(k\)값에 대해 정확도를 계산해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{loo\_cv }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{is\_correct =}\NormalTok{ (y }\SpecialCharTok{==}\NormalTok{ y\_hat)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(k) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{accuracy =} \FunctionTok{mean}\NormalTok{(is\_correct)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(accuracy))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##       k accuracy
##   <int>    <dbl>
## 1     1    0.714
## 2     2    0.714
## 3     3    0.714
## 4     4    0.571
## 5     5    0.286
## 6     6    0
\end{verbatim}

위의 결과에 기반하여, 정확도가 가장 높은 경우의 \(k\)들 중 가장 큰 값인 \(k = 3\) 을 최적 \(k\)값으로 선정하자.

{[}단계 2{]} 두 새로운 객체에 대한 3-인접객체법 추정범주를 구해보자.

우선 새로운 객체들과 기존 학습표본 객체들간의 거리를 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{id, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x2,}
  \DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}
\NormalTok{)}

\NormalTok{test\_train\_dist }\OtherTok{\textless{}{-}}\NormalTok{ flexclust}\SpecialCharTok{::}\FunctionTok{dist2}\NormalTok{(}
\NormalTok{  test\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(x1, x2), }
\NormalTok{  train\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(x1, x2)}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \StringTok{\textasciigrave{}}\AttributeTok{names\textless{}{-}}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(train\_df))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{item1 =} \FunctionTok{seq\_len}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(test\_df))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{gather}\NormalTok{(}\AttributeTok{key =} \StringTok{"item2"}\NormalTok{, }\AttributeTok{value =} \StringTok{"distance"}\NormalTok{, }\SpecialCharTok{{-}}\NormalTok{item1) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{item2 =} \FunctionTok{as.numeric}\NormalTok{(item2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: The `x` argument of `as_tibble.matrix()` must have unique column names if `.name_repair` is omitted as of tibble 2.0.0.
## Using compatibility `.name_repair`.
\end{verbatim}

\begin{verbatim}
## Warning: The `value` argument of `names<-` must be a character vector as of
## tibble 3.0.0.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_train\_dist}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 14 x 3
##    item1 item2 distance
##    <int> <dbl>    <dbl>
##  1     1     1     1   
##  2     2     1     5.10
##  3     1     2     4.47
##  4     2     2     1   
##  5     1     3     1.41
##  6     2     3     6.71
##  7     1     4     2.24
##  8     2     4     5.66
##  9     1     5     3.16
## 10     2     5     4.12
## 11     1     6     4.47
## 12     2     6     3.61
## 13     1     7     3.16
## 14     2     7     6.40
\end{verbatim}

각 새로운 객체에 대하여 가장 인접한 3개의 학습표본만 남긴다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_nn }\OtherTok{\textless{}{-}}\NormalTok{ test\_train\_dist }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(distance) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{nn\_rank =} \FunctionTok{row\_number}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(nn\_rank }\SpecialCharTok{\textless{}=} \DecValTok{3}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{()}

\NormalTok{test\_nn}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 4
##   item1 item2 distance nn_rank
##   <int> <dbl>    <dbl>   <int>
## 1     1     1     1          1
## 2     2     2     1          1
## 3     1     3     1.41       2
## 4     1     4     2.24       3
## 5     2     6     3.61       2
## 6     2     5     4.12       3
\end{verbatim}

해당 인접 학습표본들의 범주값을 관측하여, 가장 자주 발견되는 범주값을 새로운 객체의 범주값으로 추정한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_yhat }\OtherTok{\textless{}{-}}\NormalTok{ test\_nn }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{id =}\NormalTok{ test\_df}\SpecialCharTok{$}\NormalTok{id[item1],}
    \AttributeTok{y =}\NormalTok{ train\_df}\SpecialCharTok{$}\NormalTok{y[item2]}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(id, y) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{n =} \FunctionTok{n}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(n)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{y\_hat =}\NormalTok{ y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'id'. You can override using the `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_yhat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 3
##      id y_hat     n
##   <dbl> <fct> <int>
## 1     8 2         2
## 2     9 1         2
\end{verbatim}

위 결과, 객체 \((6, 7)^\top\)는 범주 2로, 객체 \((4, 2)^\top\)는 범주 1로 분류된다.

\hypertarget{naive-bayes}{%
\subsection{나이브 베이지안 분류법}\label{naive-bayes}}

나이브 베이지안(Naive Bayesian) 분류법이란 속성변수들과 범주변수가 확률분포를 따른다고 간주하여 베이즈 정리와 조건부 독립성을 활용한 분류기법이다. 속성변수들이 범주형일 때 주로 사용되나, 연속형인 경우에도 확률분포의 형태를 가정하여 사용할 수 있다. 본 장에서는 범주형 변수인 경우를 설명한다.

\hypertarget{naive-bayes-basic-script}{%
\subsubsection{기본 R 스크립트}\label{naive-bayes-basic-script}}

아래와 같은 9명의 고객에 대한 학습표본이 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{id, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x2, }\SpecialCharTok{\textasciitilde{}}\NormalTok{y,}
  \DecValTok{1}\NormalTok{, }\StringTok{"남"}\NormalTok{, }\StringTok{"20대"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\StringTok{"남"}\NormalTok{, }\StringTok{"20대"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\StringTok{"남"}\NormalTok{, }\StringTok{"30대"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\StringTok{"남"}\NormalTok{, }\StringTok{"40대"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\StringTok{"여"}\NormalTok{, }\StringTok{"10대"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\StringTok{"여"}\NormalTok{, }\StringTok{"20대"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\StringTok{"여"}\NormalTok{, }\StringTok{"20대"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{8}\NormalTok{, }\StringTok{"여"}\NormalTok{, }\StringTok{"30대"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\StringTok{"여"}\NormalTok{, }\StringTok{"40대"}\NormalTok{, }\DecValTok{2}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{y =} \FunctionTok{factor}\NormalTok{(y, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{)))}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
  \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}고객번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}성별 ($x\_1$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}나이 ($x\_2$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}범주 ($y$)\textquotesingle{}}\NormalTok{),}
  \AttributeTok{caption =} \StringTok{\textquotesingle{}나이브 베이지안 분류법 학습표본\textquotesingle{}}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:naive-bayes-data}나이브 베이지안 분류법 학습표본}
\centering
\begin{tabular}[t]{rrrr}
\toprule
고객번호 & 성별 (\$x\_1\$) & 나이 (\$x\_2\$) & 범주 (\$y\$)\\
\midrule
1 & 남 & 20대 & 1\\
2 & 남 & 20대 & 2\\
3 & 남 & 30대 & 1\\
4 & 남 & 40대 & 1\\
5 & 여 & 10대 & 1\\
\addlinespace
6 & 여 & 20대 & 2\\
7 & 여 & 20대 & 1\\
8 & 여 & 30대 & 2\\
9 & 여 & 40대 & 2\\
\bottomrule
\end{tabular}
\end{table}

\texttt{e1071} 패키지의 \texttt{naiveBayes} 함수를 이용하면, 객체가 각 범주에 속할 조건부 확률분포 모델을 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nb\_fit }\OtherTok{\textless{}{-}}\NormalTok{ e1071}\SpecialCharTok{::}\FunctionTok{naiveBayes}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, }\AttributeTok{data =}\NormalTok{ train\_df)}

\FunctionTok{print}\NormalTok{(nb\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Naive Bayes Classifier for Discrete Predictors
## 
## Call:
## naiveBayes.default(x = X, y = Y, laplace = laplace)
## 
## A-priori probabilities:
## Y
##         1         2 
## 0.5555556 0.4444444 
## 
## Conditional probabilities:
##    x1
## Y     남   여
##   1 0.60 0.40
##   2 0.25 0.75
## 
##    x2
## Y   10대 20대 30대 40대
##   1 0.20 0.40 0.20 0.20
##   2 0.00 0.50 0.25 0.25
\end{verbatim}

추정된 모델을 학습표본에 적용하여 범주를 추정해보자.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 범주 추정값}
\NormalTok{y\_hat }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(nb\_fit, train\_df)}

\CommentTok{\# 사후확률 추정값}
\NormalTok{nb\_posterior }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(nb\_fit, train\_df, }\AttributeTok{type =} \StringTok{"raw"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \StringTok{\textasciigrave{}}\AttributeTok{colnames\textless{}{-}}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{str\_c}\NormalTok{(}\StringTok{"p"}\NormalTok{, }\FunctionTok{levels}\NormalTok{(train\_df}\SpecialCharTok{$}\NormalTok{y)))}

\NormalTok{train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{y\_hat =}\NormalTok{ y\_hat) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_cols}\NormalTok{(nb\_posterior) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}고객번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}성별 ($x\_1$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}나이 ($x\_2$)\textquotesingle{}}\NormalTok{, }
                  \StringTok{\textquotesingle{}실제범주 ($y$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}추정범주 ($}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{hat\{y\}$)\textquotesingle{}}\NormalTok{, }
                  \FunctionTok{str\_c}\NormalTok{(}\StringTok{\textquotesingle{}사후확률 ($y$ = \textquotesingle{}}\NormalTok{, }\FunctionTok{levels}\NormalTok{(train\_df}\SpecialCharTok{$}\NormalTok{y), }\StringTok{\textquotesingle{})\textquotesingle{}}\NormalTok{)),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}나이브 베이지안 분류법에 의한 추정 범주\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:naive-bayes-posterior}나이브 베이지안 분류법에 의한 추정 범주}
\centering
\begin{tabular}[t]{rrrrrrr}
\toprule
고객번호 & 성별 (\$x\_1\$) & 나이 (\$x\_2\$) & 실제범주 (\$y\$) & 추정범주 (\$\textbackslash{}hat\{y\}\$) & 사후확률 (\$y\$ = 1) & 사후확률 (\$y\$ = 2)\\
\midrule
1 & 남 & 20대 & 1 & 1 & 0.7058824 & 0.2941176\\
2 & 남 & 20대 & 2 & 1 & 0.7058824 & 0.2941176\\
3 & 남 & 30대 & 1 & 1 & 0.7058824 & 0.2941176\\
4 & 남 & 40대 & 1 & 1 & 0.7058824 & 0.2941176\\
5 & 여 & 10대 & 1 & 1 & 0.9925558 & 0.0074442\\
\addlinespace
6 & 여 & 20대 & 2 & 2 & 0.3478261 & 0.6521739\\
7 & 여 & 20대 & 1 & 2 & 0.3478261 & 0.6521739\\
8 & 여 & 30대 & 2 & 2 & 0.3478261 & 0.6521739\\
9 & 여 & 40대 & 2 & 2 & 0.3478261 & 0.6521739\\
\bottomrule
\end{tabular}
\end{table}

또한, 학습표본에 포함되지 않은 10대 남자인 새로운 고객에 대한 범주가 아래와 같이 추정된다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(nb\_fit, }\FunctionTok{tibble}\NormalTok{(}\AttributeTok{x1 =} \StringTok{"남"}\NormalTok{, }\AttributeTok{x2 =} \StringTok{"10대"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
## Levels: 1 2
\end{verbatim}

\hypertarget{naive-bayes-algorithm}{%
\subsubsection{알고리즘}\label{naive-bayes-algorithm}}

어떤 객체 \(\mathbf{x}\)에 대해 범주가 \(y\)일 조건부 확률분포는 베이즈 정리에 의하여 다음과 같이 표현된다.

\begin{equation}
P(y \, | \, \mathbf{x}) \propto P(y) P(\mathbf{x} \, | \, y), \, y = 1, \cdots, J \label{eq:bayes-posterior}
\end{equation}

여기서 \(P(y)\)는 임의의 객체가 범주 \(y\)에 속할 사전확률을 의미하며, \(P(y \, | \, \mathbf{x})\)는 객체 속성변수 \(\mathbf{x}\)의 관측값에 따른 범주 \(y\)의 사후확률을 나타낸다. 그리고 \(P(\mathbf{x} \, | \, y)\)는 범주 \(y\)에 속한 객체들의 속성변수 분포를 나타낸다.

나이브 베이지안 분류법에서는 속성변수들의 조건부 결합확률분포 \(P(\mathbf{x} \, | \, y)\)에 대한 조건부 독립성을 가정하여, \(p\)개의 변수로 이루어진 객체 속성변수 벡터 \(\mathbf{x} = (x_1, x_2, \cdots, x_p)\)에 대하여 다음이 성립한고 가정한다.

\begin{equation*}
P(x_a \, | x_{a + 1}, x_{a + 2}, \cdots, x_p, y) = P(x_a \,|\, y)
\end{equation*}

이 때, 식 \eqref{eq:bayes-posterior}는 아래와 같이 표현될 수 있다.

\begin{equation}
P(y \, | \, \mathbf{x}) \propto P(y) \prod_{a = 1}^{p} P(x_a \, | \, y), \, y = 1, \cdots, J \label{eq:naive-bayes-posterior}
\end{equation}

우선, 학습표본 \ref{tab:naive-bayes-data}을 이용하여 범주의 사전확률 \(P(y)\)를 추정해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prior\_prob }\OtherTok{\textless{}{-}}\NormalTok{ train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(y) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{n =} \FunctionTok{n}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{prior =}\NormalTok{ n }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{n)}

\NormalTok{prior\_prob}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 2
##   y     prior
##   <fct> <dbl>
## 1 1     0.556
## 2 2     0.444
\end{verbatim}

또한, 학습표본 \ref{tab:naive-bayes-data}에 대해 각 변수의 조건부 확률 \(P(x_a \,|\, y)\)를 추정해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{condition\_prob }\OtherTok{\textless{}{-}}\NormalTok{ train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{gather}\NormalTok{(}\AttributeTok{key =} \StringTok{"variable"}\NormalTok{, }\AttributeTok{value =} \StringTok{"value"}\NormalTok{, x1, x2) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(y, variable, value) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{n =} \FunctionTok{n}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{cond\_prob =}\NormalTok{ n }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{n) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{complete}\NormalTok{(y, }\FunctionTok{nesting}\NormalTok{(variable, value), }\AttributeTok{fill =} \FunctionTok{list}\NormalTok{(}\AttributeTok{cond\_prob =} \DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'y', 'variable'. You can override using the `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{condition\_prob}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 12 x 4
##    y     variable value cond_prob
##    <fct> <chr>    <chr>     <dbl>
##  1 1     x1       남         0.6 
##  2 1     x1       여         0.4 
##  3 1     x2       10대       0.2 
##  4 1     x2       20대       0.4 
##  5 1     x2       30대       0.2 
##  6 1     x2       40대       0.2 
##  7 2     x1       남         0.25
##  8 2     x1       여         0.75
##  9 2     x2       10대       0   
## 10 2     x2       20대       0.5 
## 11 2     x2       30대       0.25
## 12 2     x2       40대       0.25
\end{verbatim}

추정된 확률을 식 \eqref{eq:naive-bayes-posterior}에 적용하여, 각 학습데이터에 대한 범주의 사후확률을 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior\_prob }\OtherTok{\textless{}{-}}\NormalTok{ train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{y) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{gather}\NormalTok{(}\AttributeTok{key =} \StringTok{"variable"}\NormalTok{, }\AttributeTok{value =} \StringTok{"value"}\NormalTok{, x1, x2) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(condition\_prob, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"variable"}\NormalTok{, }\StringTok{"value"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(id, y) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{cond\_prob =} \FunctionTok{reduce}\NormalTok{(cond\_prob, }\StringTok{\textasciigrave{}}\AttributeTok{*}\StringTok{\textasciigrave{}}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(prior\_prob, }\AttributeTok{by =} \StringTok{"y"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{posterior\_unadjust =}\NormalTok{ prior }\SpecialCharTok{*}\NormalTok{ cond\_prob) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{posterior =}\NormalTok{ posterior\_unadjust }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(posterior\_unadjust)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(id, y, posterior) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'id'. You can override using the `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior\_prob }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{spread}\NormalTok{(}\AttributeTok{key =}\NormalTok{ y, }\AttributeTok{value =}\NormalTok{ posterior)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 9 x 3
##      id   `1`   `2`
##   <dbl> <dbl> <dbl>
## 1     1 0.706 0.294
## 2     2 0.706 0.294
## 3     3 0.706 0.294
## 4     4 0.706 0.294
## 5     5 1     0    
## 6     6 0.348 0.652
## 7     7 0.348 0.652
## 8     8 0.348 0.652
## 9     9 0.348 0.652
\end{verbatim}

추정범주는 사후확률이 가장 큰 범주를 선택한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{posterior\_prob }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(id) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{top\_n}\NormalTok{(}\DecValTok{1}\NormalTok{, posterior) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 9 x 3
## # Groups:   id [9]
##      id y     posterior
##   <dbl> <fct>     <dbl>
## 1     1 1         0.706
## 2     2 1         0.706
## 3     3 1         0.706
## 4     4 1         0.706
## 5     5 1         1    
## 6     6 2         0.652
## 7     7 2         0.652
## 8     8 2         0.652
## 9     9 2         0.652
\end{verbatim}

\hypertarget{naive-bayes-pkg}{%
\subsubsection{R 패키지 내 나이브 베이지안 분류법}\label{naive-bayes-pkg}}

위 \ref{naive-bayes-basic-script}절에서 살펴본 바와 같이 \texttt{e1071} 패키지 내의 \texttt{naiveBayes} 함수를 이용하여 분류 모델을 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nb\_fit }\OtherTok{\textless{}{-}}\NormalTok{ e1071}\SpecialCharTok{::}\FunctionTok{naiveBayes}\NormalTok{(}\AttributeTok{formula =}\NormalTok{ y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, }\AttributeTok{data =}\NormalTok{ train\_df)}
\end{Highlighting}
\end{Shaded}

위 \texttt{naiveBayes} 모델 객체의 component 중 \texttt{apriori}는 객체가 각 범주에 속할 사전분포를 나타내는 \texttt{table} 형태의 객체로, 본 예에서 학습표본 중 각 범주에 속한 객체 수를 나타낸다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{str}\NormalTok{(nb\_fit}\SpecialCharTok{$}\NormalTok{apriori)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  'table' int [1:2(1d)] 5 4
##  - attr(*, "dimnames")=List of 1
##   ..$ Y: chr [1:2] "1" "2"
\end{verbatim}

아래와 같이, 각 범주에 속한 객체 수를 전체 객체 수로 나눔으로써 추정된 사전분포(prior distribution)을 확인할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nb\_fit}\SpecialCharTok{$}\NormalTok{apriori }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{p =}\NormalTok{ n }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: 'tidy.table' is deprecated.
## See help("Deprecated")
\end{verbatim}

\begin{verbatim}
## # A tibble: 2 x 3
##   Y         n     p
##   <chr> <int> <dbl>
## 1 1         5 0.556
## 2 2         4 0.444
\end{verbatim}

각 변수별 조건부 확률은 \texttt{tables}라는 리스트 객체에서 변수별로 확인할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nb\_fit}\SpecialCharTok{$}\NormalTok{tables}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $x1
##    x1
## Y     남   여
##   1 0.60 0.40
##   2 0.25 0.75
## 
## $x2
##    x2
## Y   10대 20대 30대 40대
##   1 0.20 0.40 0.20 0.20
##   2 0.00 0.50 0.25 0.25
\end{verbatim}

\texttt{predict} 함수를 이용하여 사후확률을 구할 때, \texttt{threshold} 파라미터값을 이용하여 최소 사후확률값을 지정할 수 있다. 기본값은 0.001로, 추정 사후확률값이 최소 0.1\%보다 커야한다는 것을 의미한다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(nb\_fit, }\AttributeTok{newdata =}\NormalTok{ train\_df[}\DecValTok{5}\NormalTok{, ], }\AttributeTok{type =} \StringTok{"raw"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              1           2
## [1,] 0.9925558 0.007444169
\end{verbatim}

해당 파라미터값을 0.01으로 지정할 경우, 위에서 범주 2에 속할 사후확률이 보다 크게 얻어짐을 확인할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(nb\_fit, }\AttributeTok{newdata =}\NormalTok{ train\_df[}\DecValTok{5}\NormalTok{, ], }\AttributeTok{type =} \StringTok{"raw"}\NormalTok{, }\AttributeTok{threshold =} \FloatTok{0.01}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              1          2
## [1,] 0.9302326 0.06976744
\end{verbatim}

\hypertarget{logistic-regression}{%
\chapter{로지스틱 회귀분석}\label{logistic-regression}}

로지스틱 회귀분석(logistic regression)은 종속변수가 통상 2개의 범주(있음/없음, 불량/양호, 합격/불합격 등)를 다루는 모형을 지칭하나, 3개 이상의 범주를 다루기도 한다. 후자의 경우는 다시 서열형(ordinal) 데이터와 명목형(nominal) 데이터인 경우에 따라 서로 다른 모형이 사용된다.

\hypertarget{logistic-packages-install}{%
\section{필요 R 패키지 설치}\label{logistic-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.3.1\\
\hline
stats & 4.1.0\\
\hline
nnet & 7.3-16\\
\hline
MASS & 7.3-54\\
\hline
VGAM & 1.1-5\\
\hline
\end{tabular}

\hypertarget{binary-logistic-regression}{%
\section{이분 로지스틱 회귀모형}\label{binary-logistic-regression}}

\hypertarget{bianry-logistic-reg-basic-script}{%
\subsection{기본 R 스크립트}\label{bianry-logistic-reg-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{id, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x2, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x3, }\SpecialCharTok{\textasciitilde{}}\NormalTok{y,}
  \DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"우수"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"우수"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{0}\NormalTok{, }\StringTok{"우수"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{4}\NormalTok{, }\StringTok{"우수"}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"우수"}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"우수"}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{0}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{8}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{10}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{11}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{12}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{0}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{13}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{14}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"보통"}\NormalTok{,}
  \DecValTok{15}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"보통"}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{y =} \FunctionTok{factor}\NormalTok{(y, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"보통"}\NormalTok{, }\StringTok{"우수"}\NormalTok{)))}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
             \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
             \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}아침식사여부($x\_1$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}수면시간($x\_2$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}서클활동시간($x\_3$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}범주(y)\textquotesingle{}}\NormalTok{),}
             \AttributeTok{caption =} \StringTok{\textquotesingle{}우수/보통 학생에 대한 설문조사 결과\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:binary-logistic-reg-train-data}우수/보통 학생에 대한 설문조사 결과}
\centering
\begin{tabular}[t]{rrrrr}
\toprule
객체번호 & 아침식사여부(\$x\_1\$) & 수면시간(\$x\_2\$) & 서클활동시간(\$x\_3\$) & 범주(y)\\
\midrule
1 & 0 & 8 & 2 & 우수\\
2 & 1 & 7 & 1 & 우수\\
3 & 0 & 9 & 0 & 우수\\
4 & 1 & 6 & 4 & 우수\\
5 & 1 & 8 & 2 & 우수\\
\addlinespace
6 & 0 & 7 & 3 & 우수\\
7 & 0 & 7 & 0 & 보통\\
8 & 1 & 6 & 1 & 보통\\
9 & 0 & 7 & 2 & 보통\\
10 & 0 & 8 & 1 & 보통\\
\addlinespace
11 & 0 & 5 & 2 & 보통\\
12 & 1 & 8 & 0 & 보통\\
13 & 0 & 6 & 3 & 보통\\
14 & 1 & 7 & 2 & 보통\\
15 & 0 & 6 & 1 & 보통\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:binary-logistic-reg-train-data}와 같이 세 개의 독립변수 \(x_1\), \(x_2\), \(x_3\)와 이분형 종속변수 \(y\)의 관측값(보통 = 0, 우수 = 1)으로 이루어진 15개의 학습표본을 \texttt{train\_df}라는 data frame에 저장한다.

아래와 같이 \texttt{glm} 함수를 이용하여 로지스틱 회귀모형을 간편하게 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{glm\_fit }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2 }\SpecialCharTok{+}\NormalTok{ x3, }\AttributeTok{family =} \FunctionTok{binomial}\NormalTok{(}\AttributeTok{link =} \StringTok{"logit"}\NormalTok{), }\AttributeTok{data =}\NormalTok{ train\_df)}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  glm\_fit }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{  broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{(),}
  \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{caption =} \StringTok{"위 우수/보통 학생 설문조사 데이터에 대한 Logistic Regression 결과"}
\CommentTok{\#  caption = "Table \textbackslash{}\textbackslash{}@ref(tab:binary{-}logistic{-}reg{-}train{-}data)에 대한 Logistic Regression 결과"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:binary-logistic-reg-coef}위 우수/보통 학생 설문조사 데이터에 대한 Logistic Regression 결과}
\centering
\begin{tabular}[t]{lrrrr}
\toprule
term & estimate & std.error & statistic & p.value\\
\midrule
(Intercept) & -30.510836 & 18.018256 & -1.693329 & 0.0903929\\
x1 & 2.031278 & 1.983692 & 1.023989 & 0.3058406\\
x2 & 3.470671 & 2.074978 & 1.672631 & 0.0944000\\
x3 & 2.414387 & 1.396372 & 1.729043 & 0.0838015\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:binary-logistic-reg-coef}은 추정된 회귀계수 추정치 \texttt{estmate}과 그 표준오차 \texttt{std.error}, 표준화(standardized)된 회귀계수값 \texttt{statistic} (= \texttt{estmate} / \texttt{std.error}), 그리고 귀무가설 \(H_0\): \texttt{statistic} = 0 에 대한 유의확률 \texttt{p.value}를 보여준다.

\hypertarget{binary-logistic-reg-model}{%
\subsection{회귀모형}\label{binary-logistic-reg-model}}

이분 로지스틱 회귀모형은 종속변수가 2가지 범주를 취하는 경우에 사용된다.

\(N\)개의 객체로 이루어진 학습데이터 \(\{(\mathbf{x}_i, y_i)\}_{i = 1, \cdots, N}\)를 아래와 같이 정의하자.

\begin{itemize}
\tightlist
\item
  \(\mathbf{x}_i \in \mathbb{R}^p\): \(p\)개의 독립변수로 이루어진 벡터 (\(\mathbf{x}_i = [x_{i1} \, x_{i2} \, \cdots \, x_{ip}]^\top\))
\item
  \(y_i\): 0 혹은 1의 값을 갖는 이분형 지시변수 (indicator variable)
\end{itemize}

\(\mathbf{x}_i\) 관측값을 이용하여 \(y_i\)의 기대값 \(P_i\)을 추정하는 모형을 아래와 같이 로지스틱 함수로 정의하자.

\begin{eqnarray}
P_i &=& P(y_i = 1 \,|\, \mathbf{x}_i)\\
&=& E[y_i | \mathbf{x}_i]\\ 
&=& \frac{\exp(\beta_0 + \boldsymbol\beta^\top \mathbf{x}_i)}{1 + \exp(\beta_0 + \boldsymbol\beta^\top \mathbf{x}_i)}
\label{eq:logistic-function}
\end{eqnarray}

여기에서 \(\boldsymbol\beta \in \mathbb{R}^{p}\)는 \(\mathbf{x}_i\)와 동일한 차원의 벡터이다 (\(\boldsymbol\beta = [\beta_1 \, \beta_2 \, \cdots \, \beta_p]^\top\)).

식 \eqref{eq:logistic-function}는 모든 \(\mathbf{x}_i\)값에 대해 0에서 1 사이의 값을 갖게 되므로 각 범주에 속할 확률을 추정하는 데 적합한 반면, 변수 \(\mathbf{x}\) 및 계수들에 대해 선형이 아니므로 추정이 어렵다. 그러나 아래와 같이 로짓(logit) 변환을 통해 선형회귀식으로 변환할 수 있다.

\begin{eqnarray}
logit(P_i) &=& \ln \left[ \frac{P_i}{1 - P_i} \right]\\
&=& \ln(\exp(\beta_0 + \boldsymbol\beta^\top \mathbf{x}_i))\\
&=& \beta_0 + \boldsymbol\beta^\top \mathbf{x}_i
\label{eq:logit-transform}
\end{eqnarray}

식 \eqref{eq:logit-transform}에서 확률 \(P_i\)는 직접적으로 관측되는 것이 아니고 0 또는 1을 갖는 \(y_i\)가 관측되므로, \(P_i\)를 일종의 잠재변수(latent variable)로 해석할 수 있다.

\begin{equation}
y_i = \begin{cases}
1 & \text{ if } \beta_0 + \boldsymbol\beta^\top \mathbf{x}_i + \varepsilon_i > 0 \\
0 & \text{ otherwise }
\end{cases}
\label{eq:binary-logistic-latent-interpret}
\end{equation}

식 \eqref{eq:binary-logistic-latent-interpret}에서 \(\varepsilon_i\)는 표준로지스틱분포(standard logistic distribution)을 따른다.

\hypertarget{binary-logistic-reg-estimation}{%
\subsection{회귀계수 추정}\label{binary-logistic-reg-estimation}}

로지스틱 모형에서 회귀계수의 추정을 위해서 주로 최우추정법(maximum likelihood estimation)이 사용된다. \(N\)개의 객체로 이루어진 학습데이터에 대해 우도함수는 다음과 같다.

\begin{equation*}
L = \prod_{i = 1}^{N} P_i^{y_i} (1 - P_i)^{1 - y_i}
\end{equation*}

그리고 우도함수에 자연로그를 취하면 아래와 같이 전개된다.

\begin{eqnarray}
\log L &=& \sum_{i = 1}^{N} y_i \log P_i + \sum_{i = 1}^{N} (1 - y_i) \log (1 - P_i)\\
&=& \sum_{i = 1}^{N} y_i \log \frac{P_i}{1 - P_i} + \sum_{i = 1}^{N} \log (1 - P_i)\\
&=& \sum_{i = 1}^{N} y_i (\beta_0 + \boldsymbol\beta^\top \mathbf{x}_i) - \sum_{i = 1}^{N}  \log (1 + \exp (\beta_0 + \boldsymbol\beta^\top \mathbf{x}_i) )\\
&=& \sum_{i = 1}^{N} y_i \left(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij} \right) - \sum_{i = 1}^{N}  \log \left(1 + \exp\left(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij}\right)\right)
\label{eq:binary-logistic-reg-loglik}
\end{eqnarray}

식 \eqref{eq:binary-logistic-reg-loglik}을 각 회귀계수 \(\beta_0, \beta_1, \cdots, \beta_p\)에 대해 편미분하여 최적해를 얻는다. 이를 위해 주로 뉴턴-랩슨 알고리즘(Newton-Raphson algorithm)이나 quasi-Newton 알고리즘이 사용되나 \citep{jun2012datamining}, 본 장에서는 우선 안정성은 떨어지지만 보다 간편한 방법으로 경사하강법(gradient descent)을 소개한다.

\hypertarget{binary-logistic-gradient-descent}{%
\subsubsection{경사하강법}\label{binary-logistic-gradient-descent}}

식 \eqref{eq:logistic-function}과 \(P(y_i = 0 \,|\, \mathbf{x}_i) = 1 - P_i\), 그리고

\begin{equation*}
\frac{\exp(z)}{1 + \exp(z)} = \frac{1}{1 + \exp(-z)}
\end{equation*}

임을 고려하면 아래와 같이 범주확률모형을 정의할 수 있다.

\begin{equation*}
P(y = y_i \,|\, \mathbf{x}_i, \beta_0, \boldsymbol\beta) = \frac{1}{1 + \exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}
\end{equation*}

이에 따라 로그우도함수 \eqref{eq:binary-logistic-reg-loglik}는 아래와 같이 정리된다.

\begin{equation*}
\log \prod_{i = 1}^{N} P(y = y_i \,|\, \mathbf{x}_i, \beta_0, \boldsymbol\beta) = - \sum_{i = 1}^{N} \log \left(1 + \exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)\right)
\end{equation*}

위 로그우도함수를 최대화하는 문제는 아래 함수를 최소화하는 문제와 동일하다.

\begin{equation}
f(\beta_0, \boldsymbol\beta) = \sum_{i = 1}^{N} \log \left(1 + \exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)\right)
\label{eq:binary-logistic-reg-negative-loglik}
\end{equation}

경사하강법에 따라 아래의 과정을 통해 회귀계수를 추정할 수 있다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  임의의 값으로 \(\beta_0, \beta_1, \cdots, \beta_j\)의 초기 추정값을 설정한다.
\item
  식 \eqref{eq:binary-logistic-reg-negative-loglik}을 각 회귀변수에 대해 편미분한 미분값을 구한다.
\item
  2의 값에 학습률(step size)을 곱한 만큼 회귀계수 추정값을 이동시킨다. 방향은 미분값의 반대방향.
\item
  수렴할 때까지 2-3의 과정을 반복한다.
\end{enumerate}

여기에서 식 \eqref{eq:binary-logistic-reg-negative-loglik}의 각 회귀변수에 대한 편미분식은 아래와 같다.

\begin{eqnarray*}
\frac{\partial f}{\partial \beta_0} &=& \sum_{i = 1}^{N} (1 - 2y_i) \frac{\exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}{1 + \exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}\\
&=& \sum_{i = 1}^{N} \frac{1 - 2y_i}{1 + \exp\left((2y_i - 1)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}
\end{eqnarray*}

\begin{eqnarray*}
\frac{\partial f}{\partial \beta_j} &=& \sum_{i = 1}^{N} (1 - 2y_i)x_{ij} \frac{\exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}{1 + \exp\left((1 - 2y_i)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}\\
&=& \sum_{i = 1}^{N} \frac{(1 - 2y_i)x_{ij}}{1 + \exp\left((2y_i - 1)(\beta_0 + \sum_{j = 1}^{p} \beta_j x_{ij})\right)}
\end{eqnarray*}

따라서, 회귀계수 추정값을 이동시키는 함수 \texttt{update\_beta}를 아래와 같이 구현할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{update\_beta }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, y, }\AttributeTok{beta0 =} \DecValTok{0}\NormalTok{, }\AttributeTok{beta =} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{dim}\NormalTok{(x)[}\DecValTok{2}\NormalTok{]), }\AttributeTok{alpha =} \FloatTok{0.01}\NormalTok{) \{}
  \CommentTok{\# 변미분식의 분모}
\NormalTok{  denominator }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{((}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ y }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (beta0 }\SpecialCharTok{+}\NormalTok{ (x }\SpecialCharTok{\%*\%}\NormalTok{ beta)))}

  \CommentTok{\# intercept 이동량 계산}
\NormalTok{  beta0\_numerator }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ y}
\NormalTok{  beta0\_update }\OtherTok{=} \FunctionTok{sum}\NormalTok{(beta0\_numerator }\SpecialCharTok{/}\NormalTok{ denominator)}
  
  \CommentTok{\# intercept 외 회귀계수 이동량 계산}
\NormalTok{  beta\_numerator }\OtherTok{\textless{}{-}} \FunctionTok{sweep}\NormalTok{(x, }\AttributeTok{MARGIN =} \DecValTok{1}\NormalTok{, }\AttributeTok{STATS =} \DecValTok{1} \SpecialCharTok{{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ y, }\AttributeTok{FUN =} \StringTok{"*"}\NormalTok{)}
\NormalTok{  beta\_update }\OtherTok{=} \FunctionTok{apply}\NormalTok{(beta\_numerator, }\AttributeTok{MARGIN =} \DecValTok{2}\NormalTok{, }
                      \ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{sum}\NormalTok{(x }\SpecialCharTok{/}\NormalTok{ denominator))}

  \CommentTok{\# 회귀계수 이동}
\NormalTok{  beta0 }\OtherTok{\textless{}{-}}\NormalTok{ beta0 }\SpecialCharTok{{-}}\NormalTok{ alpha }\SpecialCharTok{*}\NormalTok{ beta0\_update}
\NormalTok{  beta }\OtherTok{\textless{}{-}}\NormalTok{ beta }\SpecialCharTok{{-}}\NormalTok{ alpha }\SpecialCharTok{*}\NormalTok{ beta\_update}

  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{beta0 =}\NormalTok{ beta0, }\AttributeTok{beta =}\NormalTok{ beta))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위의 함수를 이용하여 아래 \texttt{estimate\_beta}처엄 수렴할 때까지 회귀계수 추정값을 계속 이동시킨다. 본 경사하강법은 학습률 파라미터 \texttt{alpha}값에 따라 민감한 단점이 있으며, 특히 \texttt{alpha}값을 크게 설정할 경우에는 추정값이 수렴하지 않고 오히려 실제값에서 계속 멀어지는 현상이 발생하기도 한다. 이러한 단점을 보완하기 위한 여러 방법이 있으나, 본 장에서 자세한 설명은 생략하기로 한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{caltculate\_loglik }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, y, }
                              \AttributeTok{beta0 =} \DecValTok{0}\NormalTok{, }
                              \AttributeTok{beta =} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{dim}\NormalTok{(x)[}\DecValTok{2}\NormalTok{])) \{}
  \FunctionTok{sum}\NormalTok{(y }\SpecialCharTok{*}\NormalTok{ (beta0 }\SpecialCharTok{+}\NormalTok{ (x }\SpecialCharTok{\%*\%}\NormalTok{ beta))) }\SpecialCharTok{{-}} 
    \FunctionTok{sum}\NormalTok{(}\FunctionTok{log}\NormalTok{(}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{(beta0 }\SpecialCharTok{+}\NormalTok{ (x }\SpecialCharTok{\%*\%}\NormalTok{ beta))))}
\NormalTok{\}}

\NormalTok{estimate\_beta }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, y, }
                          \AttributeTok{beta0 =} \DecValTok{0}\NormalTok{, }
                          \AttributeTok{beta =} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{dim}\NormalTok{(x)[}\DecValTok{2}\NormalTok{]), }
                          \AttributeTok{alpha =} \FloatTok{0.01}\NormalTok{, }
                          \AttributeTok{conv\_threshold =} \FloatTok{1e{-}5}\NormalTok{, }
                          \AttributeTok{max\_iter =} \FloatTok{1e+5}\NormalTok{) \{}
\NormalTok{  new\_beta0 }\OtherTok{\textless{}{-}}\NormalTok{ beta0}
\NormalTok{  new\_beta }\OtherTok{\textless{}{-}}\NormalTok{ beta}
\NormalTok{  conv }\OtherTok{\textless{}{-}} \ConstantTok{FALSE}
  
\NormalTok{  i\_iter }\OtherTok{\textless{}{-}} \DecValTok{0}
  \ControlFlowTok{while}\NormalTok{(i\_iter }\SpecialCharTok{\textless{}}\NormalTok{ max\_iter) \{}
\NormalTok{    res }\OtherTok{\textless{}{-}} \FunctionTok{update\_beta}\NormalTok{(x, y, new\_beta0, new\_beta, alpha)}
    
    \ControlFlowTok{if}\NormalTok{(}\FunctionTok{abs}\NormalTok{(}\FunctionTok{caltculate\_loglik}\NormalTok{(x, y, beta0, beta)}
           \SpecialCharTok{{-}} \FunctionTok{caltculate\_loglik}\NormalTok{(x, y, res}\SpecialCharTok{$}\NormalTok{beta0, res}\SpecialCharTok{$}\NormalTok{beta))}
       \SpecialCharTok{\textless{}}\NormalTok{ conv\_threshold) \{}
\NormalTok{      conv }\OtherTok{\textless{}{-}} \ConstantTok{TRUE}
      \ControlFlowTok{break}
\NormalTok{      \}}
    
\NormalTok{    new\_beta0 }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{beta0}
\NormalTok{    new\_beta }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{beta}
    
\NormalTok{    i\_iter }\OtherTok{\textless{}{-}}\NormalTok{ i\_iter }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{  \}}
  
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{conv =}\NormalTok{ conv, }\AttributeTok{beta0 =}\NormalTok{ new\_beta0, }\AttributeTok{beta =}\NormalTok{ new\_beta))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위에서 정의한 함수를 이용하여 Table \ref{tab:binary-logistic-reg-train-data}의 학습표본에 대한 로지스틱 회귀모형을 추정해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_beta}\NormalTok{(train\_df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.matrix}\NormalTok{(), }
\NormalTok{                     train\_df}\SpecialCharTok{$}\NormalTok{y }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.numeric}\NormalTok{() }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{,}
                     \AttributeTok{alpha =} \FloatTok{0.015}\NormalTok{,}
                     \AttributeTok{conv\_threshold =} \FloatTok{1e{-}6}\NormalTok{)}

\FunctionTok{print}\NormalTok{(res)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $conv
## [1] FALSE
## 
## $beta0
## [1] -30.39189
## 
## $beta
##       x1       x2       x3 
## 2.022808 3.457019 2.405969
\end{verbatim}

위 회귀계수 추정값은 R 함수 \texttt{glm}을 이용한 추정값(Table \ref{tab:binary-logistic-reg-coef})과 유사함을 볼 수 있다.

\hypertarget{binary-logistic-irls}{%
\subsubsection{반복재가중최소제곱법}\label{binary-logistic-irls}}

R의 \texttt{glm} 함수는 반복재가중최소제곱법(iteratively rewighted least squares; IRLS 혹은 IWLS)을 사용한다. 이는 선형회귀식

\begin{equation*}
logit(y_i) = \beta_0 + \boldsymbol\beta^\top \mathbf{x}_i + \varepsilon_i
\end{equation*}

을 추정하는 방법인데, 여기에서 \(y_i\)는 0 혹은 1이므로, \(logit(y_i)\)는 \(-\infty\) 혹은 \(\infty\)가 되어 회귀식을 추정할 수 없다. 따라서, 식 \eqref{eq:logistic-function}에 설명된 로지스틱 함수

\begin{equation*}
P = \frac{\exp(\beta_0 + \boldsymbol\beta^\top \mathbf{x})}{1 + \exp(\beta_0 + \boldsymbol\beta^\top \mathbf{x})}
\end{equation*}

와 테일러 급수(Taylor series)를 이용하여 \(logit(y)\)에 대한 근사함수를 아래와 같이 얻는다.

\begin{eqnarray*}
g(y) &=& logit(P) + (y - P) \frac{\partial logit(P)}{\partial P}\\
&=& \log \frac{P}{1 - P} + (y - P) \left( \frac{1}{P} + \frac{1}{1 - P} \right)
\end{eqnarray*}

그리고 아래 선형회귀식을 추정한다.

\begin{equation*}
g(y_i) = \beta_0 + \boldsymbol\beta^\top \mathbf{x}_i + \varepsilon_i
\end{equation*}

여기에서 오차항 \(\varepsilon_i\)의 분산은 추정된 확률 \(P_i\)에 따라 다르므로, 통상적 최소자승법(ordinary least squares; OLS) 대신 오차항의 분산이 동일해지도록 객체마다 가중치를 부여하는 가중최소자승법(weighted least squares; WLS)을 사용한다. 로지스틱 회귀모형에서 각 객체의 가중치는

\begin{equation*}
w_i = P_i (1 - P_i)
\end{equation*}

가중치와 회귀계수 추정값은 상호 영향을 미치므로, 수렴할 때까지 반복적으로 가중치와 회귀계수 추정값을 변화시키면서 최종 추정값을 찾아가는 방법이다.

우선 회귀계수 추정값이 주어졌을 때 각 객체에 대한 확률값 \(P_i\)와 가중치 \(w_i\)를 구하는 함수 \texttt{calculate\_weight}를 아래와 같이 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calculate\_weight }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, }\AttributeTok{beta0 =} \DecValTok{0}\NormalTok{, }
                             \AttributeTok{beta =} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{dim}\NormalTok{(x)[}\DecValTok{2}\NormalTok{])) \{}
  \CommentTok{\# 각 객체의 y값이 1일 확률}
\NormalTok{  P }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{+} \FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{ beta0 }\SpecialCharTok{{-}}\NormalTok{ (x }\SpecialCharTok{\%*\%}\NormalTok{ beta)))}\SpecialCharTok{\^{}}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{drop}\NormalTok{()}

  \CommentTok{\# 가중치 계산}
\NormalTok{  w }\OtherTok{\textless{}{-}}\NormalTok{ P }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ P)}

  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{P =}\NormalTok{ P, }\AttributeTok{w =}\NormalTok{ w))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

그리고 확률추정값과 가중치가 주어졌을 때 회귀계수를 구하는 함수 \texttt{calculate\_beta}를 아래와 같이 구현해보자. 여기서 회귀계수를 구하는 부분은 R의 선형회귀분석함수 \texttt{lm}을 사용한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{calculate\_beta }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, y, P, w) \{}
  \CommentTok{\# 추정확률값이 0 이나 1인 경우 }
  \CommentTok{\# 여전히 logit 함수가 정의되지 않으므로 회귀계수 결정에서 제외}
\NormalTok{  logit\_derivative }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{/}\NormalTok{P }\SpecialCharTok{+} \DecValTok{1}\SpecialCharTok{/}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ P)}
\NormalTok{  is\_good }\OtherTok{\textless{}{-}} \SpecialCharTok{!}\FunctionTok{is.nan}\NormalTok{(logit\_derivative)}
  
  \CommentTok{\# 모든 객체에 대한 추정확률이 0 이나 1인 경우 회귀계수 추정 불가능}
  \ControlFlowTok{if}\NormalTok{(}\FunctionTok{all}\NormalTok{(}\SpecialCharTok{!}\NormalTok{is\_good)) }\FunctionTok{return}\NormalTok{(}\ConstantTok{NULL}\NormalTok{)}
  
  \CommentTok{\# 테일러 급수 계산}
\NormalTok{  g\_y }\OtherTok{\textless{}{-}} \FunctionTok{log}\NormalTok{(P[is\_good]) }\SpecialCharTok{{-}} 
    \FunctionTok{log}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ P[is\_good]) }\SpecialCharTok{+} 
\NormalTok{    (y[is\_good] }\SpecialCharTok{{-}}\NormalTok{ P[is\_good]) }\SpecialCharTok{*}\NormalTok{ logit\_derivative}
  
  \CommentTok{\# 가중치최소자승법을 이용한 추정}
\NormalTok{  df }\OtherTok{\textless{}{-}} \FunctionTok{bind\_cols}\NormalTok{(}\FunctionTok{as\_tibble}\NormalTok{(x) }\SpecialCharTok{\%\textgreater{}\%} 
                    \StringTok{\textasciigrave{}}\AttributeTok{colnames\textless{}{-}}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{colnames}\NormalTok{(x)), }
                  \FunctionTok{tibble}\NormalTok{(}\AttributeTok{g\_y =}\NormalTok{ g\_y))}
  \FunctionTok{lm}\NormalTok{(g\_y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ df, }\AttributeTok{subset =}\NormalTok{ is\_good, }\AttributeTok{weights =}\NormalTok{ w)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위에서 정의한 두 함수 \texttt{calculate\_weight}과 \texttt{calculate\_beta}를 반복적으로 사용하여 Table \ref{tab:binary-logistic-reg-train-data}의 학습표본에 대한 로지스틱 회귀모형을 추정해보자. 모든 객체의 가중치 변화량이 1/10000 보다 작을 경우 모형추정이 수렴한 것으로 간주하도록 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OtherTok{\textless{}{-}}\NormalTok{ train\_df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.matrix}\NormalTok{()}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ train\_df}\SpecialCharTok{$}\NormalTok{y }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.numeric}\NormalTok{() }\SpecialCharTok{{-}} \DecValTok{1}

\NormalTok{weight }\OtherTok{\textless{}{-}} \FunctionTok{calculate\_weight}\NormalTok{(X)}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{) \{}
\NormalTok{  wls\_fit }\OtherTok{\textless{}{-}} \FunctionTok{calculate\_beta}\NormalTok{(X, y, weight}\SpecialCharTok{$}\NormalTok{P, weight}\SpecialCharTok{$}\NormalTok{w)}
  
  \ControlFlowTok{if}\NormalTok{(}\FunctionTok{is.null}\NormalTok{(wls\_fit)) \{}\ControlFlowTok{break}\NormalTok{\}}
  
\NormalTok{  new\_weight }\OtherTok{\textless{}{-}} \FunctionTok{calculate\_weight}\NormalTok{(}\AttributeTok{x =}\NormalTok{ X, }
                                 \AttributeTok{beta0 =} \FunctionTok{coef}\NormalTok{(wls\_fit)[}\DecValTok{1}\NormalTok{], }
                                 \AttributeTok{beta =} \FunctionTok{coef}\NormalTok{(wls\_fit)[}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{])}
  
  \ControlFlowTok{if}\NormalTok{(}\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(new\_weight}\SpecialCharTok{$}\NormalTok{w }\SpecialCharTok{{-}}\NormalTok{ weight}\SpecialCharTok{$}\NormalTok{w)) }\SpecialCharTok{\textless{}} \FloatTok{1e{-}4}\NormalTok{) \{}\ControlFlowTok{break}\NormalTok{\}}
  
\NormalTok{  weight }\OtherTok{\textless{}{-}}\NormalTok{ new\_weight}
\NormalTok{\}}

\FunctionTok{coef}\NormalTok{(wls\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept)          x1          x2          x3 
##  -30.510837    2.031278    3.470671    2.414387
\end{verbatim}

위 스크립트를 실행시킨 결과 7번째 반복수행에서 결과가 수렴하였으며, 해당 결과는 \texttt{glm} 함수를 사용하였을 때의 결과 (Table \ref{tab:binary-logistic-reg-coef})과 매우 근사함을 확인할 수 있다.

\hypertarget{nominal-logistic-regression}{%
\section{명목 로지스틱 회귀모형}\label{nominal-logistic-regression}}

\hypertarget{nominal-logistic-reg-basic-script}{%
\subsection{기본 R 스크립트}\label{nominal-logistic-reg-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{id, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x2, }\SpecialCharTok{\textasciitilde{}}\NormalTok{y,}
  \DecValTok{1}\NormalTok{, }\FloatTok{0.09}\NormalTok{, }\FloatTok{5.02}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{5.01}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\FloatTok{0.12}\NormalTok{, }\FloatTok{4.94}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\FloatTok{0.12}\NormalTok{, }\FloatTok{5.12}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\FloatTok{0.12}\NormalTok{, }\FloatTok{5.03}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\FloatTok{0.12}\NormalTok{, }\FloatTok{4.94}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{5.13}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{8}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{4.87}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{5.13}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{10}\NormalTok{, }\FloatTok{0.11}\NormalTok{, }\FloatTok{4.94}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{11}\NormalTok{, }\FloatTok{0.11}\NormalTok{, }\FloatTok{4.93}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{12}\NormalTok{, }\FloatTok{0.09}\NormalTok{, }\FloatTok{5.02}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{13}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{5.01}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{14}\NormalTok{, }\FloatTok{0.09}\NormalTok{, }\FloatTok{4.94}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{15}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{5.12}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{16}\NormalTok{, }\FloatTok{0.12}\NormalTok{, }\FloatTok{4.93}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{17}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{18}\NormalTok{, }\FloatTok{0.09}\NormalTok{, }\FloatTok{5.01}\NormalTok{, }\DecValTok{3}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{y =} \FunctionTok{factor}\NormalTok{(y, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)))}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
             \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
             \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}불량범주($y$)\textquotesingle{}}\NormalTok{),}
             \AttributeTok{caption =} \StringTok{\textquotesingle{}공정변수{-}불량 종류 데이터\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:nominal-logistic-reg-train-data}공정변수-불량 종류 데이터}
\centering
\begin{tabular}[t]{rrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 불량범주(\$y\$)\\
\midrule
1 & 0.09 & 5.02 & 1\\
2 & 0.10 & 5.01 & 1\\
3 & 0.12 & 4.94 & 1\\
4 & 0.12 & 5.12 & 1\\
5 & 0.12 & 5.03 & 1\\
\addlinespace
6 & 0.12 & 4.94 & 2\\
7 & 0.10 & 5.13 & 2\\
8 & 0.10 & 4.87 & 1\\
9 & 0.10 & 5.13 & 2\\
10 & 0.11 & 4.94 & 3\\
\addlinespace
11 & 0.11 & 4.93 & 3\\
12 & 0.09 & 5.02 & 3\\
13 & 0.10 & 5.01 & 3\\
14 & 0.09 & 4.94 & 3\\
15 & 0.10 & 5.12 & 2\\
\addlinespace
16 & 0.12 & 4.93 & 2\\
17 & 0.10 & 5.00 & 1\\
18 & 0.09 & 5.01 & 3\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:nominal-logistic-reg-train-data}와 같이 두 개의 독립변수 \(x_1\), \(x_2\)에 따라 세 종류의 불량 (\(y = 1, 2, 3\))\$이 발생함을 알았다면, 아래와 같이 \texttt{nnet} 패키지의 \texttt{multinom} 함수를 이용하여 공정변수에 따른 불량 종류를 분류하기 위한 로지스틱 회귀모형을 간편하게 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{multinom\_fit }\OtherTok{\textless{}{-}}\NormalTok{ nnet}\SpecialCharTok{::}\FunctionTok{multinom}\NormalTok{(}
\NormalTok{  y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, }
  \AttributeTok{data =}\NormalTok{ train\_df, }
  \AttributeTok{maxit =} \DecValTok{1000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # weights:  12 (6 variable)
## initial  value 19.775021 
## iter  10 value 17.825831
## iter  20 value 16.489924
## iter  30 value 16.116751
## iter  40 value 16.044223
## iter  50 value 16.025259
## iter  60 value 16.024629
## iter  70 value 16.016395
## final  value 16.015185 
## converged
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  multinom\_fit }\SpecialCharTok{\%\textgreater{}\%}\NormalTok{  broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{(}\AttributeTok{exponentiate =} \ConstantTok{FALSE}\NormalTok{),}
  \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{caption =} \StringTok{\textquotesingle{}위 공정변수{-}불량종류 데이터에 대한 Logistic Regression 결과\textquotesingle{}}
\CommentTok{\#  caption = \textquotesingle{}Table \textbackslash{}\textbackslash{}@ref(tab:nominal{-}logistic{-}reg{-}train{-}data)에 대한 Logistic Regression 결과\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:nominal-logistic-reg-coef}위 공정변수-불량종류 데이터에 대한 Logistic Regression 결과}
\centering
\begin{tabular}[t]{llrrrr}
\toprule
y.level & term & estimate & std.error & statistic & p.value\\
\midrule
2 & (Intercept) & -53.924661 & 45.402992 & -1.1876896 & 0.2349557\\
2 & x1 & 31.545749 & 62.162158 & 0.5074751 & 0.6118215\\
2 & x2 & 9.992311 & 8.479305 & 1.1784352 & 0.2386231\\
3 & (Intercept) & 64.191145 & 57.282533 & 1.1206059 & 0.2624556\\
3 & x1 & -101.817613 & 65.516143 & -1.5540844 & 0.1201643\\
\addlinespace
3 & x2 & -10.810865 & 10.915881 & -0.9903795 & 0.3219887\\
\bottomrule
\end{tabular}
\end{table}

\texttt{multinom} 함수는 범주 \texttt{y}의 값 1, 2, 3중 첫번째 값인 1을 기준범주(reference category)로 사용한다.

\hypertarget{baseline-category-logit-model}{%
\subsection{기준범주 로짓모형}\label{baseline-category-logit-model}}

종속변수가 셋 이상의 범주를 갖고 있으나 자연스러운 순서가 없는 경우, 기준범주 로짓모형이 널리 사용된다.

\(N\)개의 객체로 이루어진 학습데이터 \(\{(\mathbf{x}_i, y_i)\}_{i = 1, \cdots, N}\)를 아래와 같이 정의하자.

\begin{itemize}
\tightlist
\item
  \(\mathbf{x}_i \in \mathbb{R}^p\): \(p\)개의 독립변수로 이루어진 벡터 (\(\mathbf{x}_i = [x_{i1} \, x_{i2} \, \cdots \, x_{ip}]^\top\))
\item
  \(J\): 범주 수
\item
  \(y_i\): 객체 \(i\)에 대한 종속변수값 \(\in \{1, 2, \cdots, J\}\)
\end{itemize}

각 객체 \(i\)가 각 범주에 해당할 확률을 \(\pi_{ij}\)라 하자.

\begin{equation*}
\pi_{ij} = P(y_i = j \, | \, \mathbf{x}_i), \, j = 1, \cdots, J
\end{equation*}

이 때, 모든 \(i\)에 대하여

\begin{equation*}
\sum_{j = 1}^{J} \pi_{ij} = 1
\end{equation*}

이 성립한다. 여기에서 범주 1을 기준 범주(reference category 혹은 baseline category)로 간주하여 범주별로 다음과 같은 회귀모형을 정의한다 (교재 \citep{jun2012datamining}에는 범주 \(J\)를 기준 범주로 간주).

\begin{equation*}
\log \left( \frac{\pi_{ij}}{\pi_{i1}} \right) = \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i, \, j = 2, \cdots, J
\end{equation*}

이를 \(\pi_{ij}\)에 대해 풀면, 아래와 같은 해가 얻어진다 \citep{czepiel2002maximum}.

\begin{equation}
\begin{split}
\pi_{ij} &= \frac{\exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}{1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}, \, j = 2, \cdots, J\\
\pi_{i1} &= \frac{1}{1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}
\end{split}
\label{eq:multi-nominal-prob-sol}
\end{equation}

위 모수 추정을 위해 최우추정법을 사용해보자. 우선, 종속변수를 변환한 지시변수를 아래와 같이 정의한다.

\begin{equation*}
v_{ij} = \begin{cases}
1 & \text{ if } y_i = j\\
0 & \text{ otherwise }
\end{cases}
\end{equation*}

이를 이용해 우도 함수를

\begin{eqnarray*}
L &=& \prod_{i = 1}^{n} \prod_{j = 1}^{J} \left( \pi_{ij} \right)^{v_{ij}} \\
&=& \prod_{i = 1}^{n} \pi_{i1}^{1 - \sum_{j = 2}^{J} v_{ij}} \prod_{j = 2}^{J} \left( \pi_{ij} \right)^{v_{ij}}\\
&=& \prod_{i = 1}^{n} \frac{\pi_{i1}}{\pi_{i1}^{\sum_{j = 2}^{J} v_{ij}}} \prod_{j = 2}^{J} \left( \pi_{ij} \right)^{v_{ij}}\\
&=& \prod_{i = 1}^{n} \frac{\pi_{i1}}{\prod_{j = 2}^{J} \pi_{i1}^{v_{ij}}} \prod_{j = 2}^{J} \left( \pi_{ij} \right)^{v_{ij}}\\
&=& \prod_{i = 1}^{n} \pi_{i1} \prod_{j = 2}^{J} \left( \frac{\pi_{ij}}{\pi_{i1}} \right)^{v_{ij}}
\end{eqnarray*}

와 같이 표현할 수 있으며, 여기에 식 \eqref{eq:multi-nominal-prob-sol}을 이용하면 아래와 같이 정리할 수 있다.

\begin{eqnarray*}
L &=& \prod_{i = 1}^{n} \frac{1}{1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)} \prod_{j = 2}^{J} \left( \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right) \right)^{v_{ij}}\\
&=& \prod_{i = 1}^{n} \left( 1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right) \right)^{-1} \prod_{j = 2}^{J} \left( \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right) \right)^{v_{ij}}
\end{eqnarray*}

이에 따라 로그 우도함수는 다음과 같이 정의된다.

\begin{equation}
\log L = \sum_{i = 1}^{n} \left( - \log \left( 1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right) \right) + \sum_{j = 2}^{J} v_{ij} \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right) \right) 
\label{eq:multi-nominal-logit-loglik}
\end{equation}

식 \eqref{eq:multi-nominal-logit-loglik}을 각 계수에 대해 미분하면 아래와 같이 정리된다.

\begin{equation}
\begin{split}
\frac{\partial \log L}{\partial \beta_{0,j}} &= \sum_{i = 1}^{n} v_{ij} - \frac{\exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}{1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}\\
\frac{\partial \log L}{\partial \beta_{k,j}} &= \sum_{i = 1}^{n} v_{ij} x_{ik} - \frac{x_{ik} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}{1 + \sum_{j = 2}^{J} \exp \left( \beta_{0,j} + \boldsymbol\beta_{j}^\top \mathbf{x}_i \right)}, \, k = 1, \cdots, p
\end{split}
\label{eq:multi-nominal-logit-loglik-diff}
\end{equation}

따라서, 명목 로지스틱 회귀분석은 식 \eqref{eq:multi-nominal-logit-loglik-diff}이 표현하는 \((J - 1) \times (p + 1)\)개의 미분식을 모두 0으로 만드는 계수값을 찾는 문제가 된다. 이에 대한 closed form solution은 존재하지 않으므로, 각종 알고리즘을 이용하여 해를 찾아야 한다. Newton-Raphson method에 의해 해를 찾는 방법은 \citet{czepiel2002maximum} 에 보다 자세하게 설명되어 있다.

Table \ref{tab:nominal-logistic-reg-train-data}의 학습데이터에 대해 명목 로지스틱 회귀모형을 학습하여 범주를 추정한 결과는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{multinom\_fit }\OtherTok{\textless{}{-}}\NormalTok{ nnet}\SpecialCharTok{::}\FunctionTok{multinom}\NormalTok{(}
\NormalTok{  y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, }
  \AttributeTok{data =}\NormalTok{ train\_df, }
  \AttributeTok{maxit =} \DecValTok{1000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # weights:  12 (6 variable)
## initial  value 19.775021 
## iter  10 value 17.825831
## iter  20 value 16.489924
## iter  30 value 16.116751
## iter  40 value 16.044223
## iter  50 value 16.025259
## iter  60 value 16.024629
## iter  70 value 16.016395
## final  value 16.015185 
## converged
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predict\_df }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(multinom\_fit, train\_df, }\AttributeTok{type =} \StringTok{"probs"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{as\_data\_frame}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \StringTok{\textasciigrave{}}\AttributeTok{colnames\textless{}{-}}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"p1"}\NormalTok{, }\StringTok{"p2"}\NormalTok{, }\StringTok{"p3"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pred\_class =} \FunctionTok{predict}\NormalTok{(multinom\_fit, train\_df, }\AttributeTok{type =} \StringTok{"class"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: `as_data_frame()` was deprecated in tibble 2.0.0.
## Please use `as_tibble()` instead.
## The signature and semantics have changed, see `?as_tibble`.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{bind\_cols}\NormalTok{(train\_df, predict\_df) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{x1, }\SpecialCharTok{{-}}\NormalTok{x2) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}불량범주 $y\_i$\textquotesingle{}}\NormalTok{, }
                  \StringTok{\textquotesingle{}$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{pi\_\{i1\}$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{pi\_\{i2\}$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{pi\_\{i3\}$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}추정범주 $}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{hat\{y\}\_i$\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}명목 로지스틱 회귀모형 범주 추정 결과\textquotesingle{}}\NormalTok{,}
    \AttributeTok{digits =} \DecValTok{3}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:nominal-logistic-prediction}명목 로지스틱 회귀모형 범주 추정 결과}
\centering
\begin{tabular}[t]{rrrrrr}
\toprule
객체번호 & 불량범주 \$y\_i\$ & \$\textbackslash{}pi\_\{i1\}\$ & \$\textbackslash{}pi\_\{i2\}\$ & \$\textbackslash{}pi\_\{i3\}\$ & 추정범주 \$\textbackslash{}hat\{y\}\_i\$\\
\midrule
1 & 1 & 0.283 & 0.112 & 0.604 & 3\\
2 & 1 & 0.425 & 0.209 & 0.365 & 1\\
3 & 1 & 0.589 & 0.271 & 0.141 & 1\\
4 & 1 & 0.262 & 0.729 & 0.009 & 2\\
5 & 1 & 0.450 & 0.509 & 0.041 & 2\\
\addlinespace
6 & 2 & 0.589 & 0.271 & 0.141 & 1\\
7 & 2 & 0.349 & 0.570 & 0.082 & 2\\
8 & 1 & 0.199 & 0.024 & 0.777 & 3\\
9 & 2 & 0.349 & 0.570 & 0.082 & 2\\
10 & 3 & 0.501 & 0.168 & 0.331 & 1\\
\addlinespace
11 & 3 & 0.490 & 0.149 & 0.361 & 1\\
12 & 3 & 0.283 & 0.112 & 0.604 & 3\\
13 & 3 & 0.425 & 0.209 & 0.365 & 1\\
14 & 3 & 0.160 & 0.029 & 0.811 & 3\\
15 & 2 & 0.365 & 0.540 & 0.095 & 2\\
\addlinespace
16 & 2 & 0.595 & 0.247 & 0.158 & 1\\
17 & 1 & 0.416 & 0.186 & 0.398 & 1\\
18 & 3 & 0.268 & 0.096 & 0.636 & 3\\
\bottomrule
\end{tabular}
\end{table}

\texttt{nnet} 패키지 외에도 \texttt{glmnet}, \texttt{mlogit}, \texttt{VGAM} 등의 R 패키지들을 사용해 명목형 로지스틱 회귀모형을 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{VGAM}\SpecialCharTok{::}\FunctionTok{vglm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2,}
           \AttributeTok{data =}\NormalTok{ train\_df,}
           \AttributeTok{family =}\NormalTok{ VGAM}\SpecialCharTok{::}\NormalTok{multinomial)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## VGAM::vglm(formula = y ~ x1 + x2, family = VGAM::multinomial, 
##     data = train_df)
## 
## 
## Coefficients:
## (Intercept):1 (Intercept):2          x1:1          x1:2          x2:1 
##     -64.56378    -118.15274     102.65063     133.29235      10.86829 
##          x2:2 
##      20.81307 
## 
## Degrees of Freedom: 36 Total; 30 Residual
## Residual deviance: 32.03007 
## Log-likelihood: -16.01503 
## 
## This is a multinomial logit model with 3 levels
\end{verbatim}

\hypertarget{ordinal-logistic-regression}{%
\section{서열 로지스틱 회귀모형}\label{ordinal-logistic-regression}}

본 장에서는 종속변수가 3개 이상의 범주를 가지며, 각 범주 간에 서열이 있는 경우에 대한 로지스틱 회귀모형을 소개한다.

\hypertarget{ordinal-logistic-basic-script}{%
\subsection{기본 R 스크립트}\label{ordinal-logistic-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{N, }\SpecialCharTok{\textasciitilde{}}\NormalTok{L, }\SpecialCharTok{\textasciitilde{}}\NormalTok{y,}
  \DecValTok{25}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{25}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{25}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{25}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{32}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{32}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{32}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{32}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{42}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{42}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{42}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{42}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{1}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{y =} \FunctionTok{as.ordered}\NormalTok{(y))}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
             \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
             \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}잡음(N)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}손실(L)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}만족도($y$)\textquotesingle{}}\NormalTok{),}
             \AttributeTok{caption =} \StringTok{\textquotesingle{}성능변수에 따른 통신 만족도\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:ordinal-logistic-reg-train-data}성능변수에 따른 통신 만족도}
\centering
\begin{tabular}[t]{rrr}
\toprule
잡음(N) & 손실(L) & 만족도(\$y\$)\\
\midrule
25 & 5 & 3\\
25 & 10 & 3\\
25 & 20 & 2\\
25 & 30 & 1\\
32 & 5 & 3\\
\addlinespace
32 & 10 & 3\\
32 & 20 & 2\\
32 & 30 & 1\\
42 & 5 & 1\\
42 & 10 & 3\\
\addlinespace
42 & 20 & 1\\
42 & 30 & 1\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:ordinal-logistic-reg-train-data}은 벨 연구소에서 한 통신장치에 대하여 실시한 조사 결과를 나타낸 것이다. 주요 성능변수인 회선잡음(circuit noise: N)과 소리크기 손실(loudness loss: L)이 이용자의 주관적인 만족도에 미치는 영향을 분석하기 위한 것이다. 만족도는 원결과\citep{cavanaugh1976models}를 가공하여 다음과 같이 3가지로 분류하였다.

\begin{equation*}
y = \begin{cases}
1 & \mbox{good}\\
2 & \mbox{fair}\\
3 & \mbox{poor}
\end{cases}
\end{equation*}

본 장에서는 두 가지 모형을 다룬다. 우선 누적 로짓모형(cumulative logit model)은 아래와 같이 \texttt{MASS} 패키지의 \texttt{polr} 함수를 사용하여 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{MASS}\SpecialCharTok{::}\FunctionTok{polr}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ N }\SpecialCharTok{+}\NormalTok{ L, }\AttributeTok{data =}\NormalTok{ train\_df) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Re-fitting to get Hessian
\end{verbatim}

\begin{verbatim}
## # A tibble: 4 x 5
##   term  estimate std.error statistic coef.type  
##   <chr>    <dbl>     <dbl>     <dbl> <chr>      
## 1 N       -0.224     0.146     -1.53 coefficient
## 2 L       -0.300     0.137     -2.19 coefficient
## 3 1|2    -13.0       6.46      -2.02 scale      
## 4 2|3    -11.4       6.17      -1.85 scale
\end{verbatim}

인근범주 로짓모형(adjacent-categories logit model)은 아래와 같이 \texttt{VGAM} 패키지의 \texttt{vglm} 함수를 이용하여 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{VGAM}\SpecialCharTok{::}\FunctionTok{vglm}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ N }\SpecialCharTok{+}\NormalTok{ L,}
           \AttributeTok{data =}\NormalTok{ train\_df,}
           \AttributeTok{family =}\NormalTok{ VGAM}\SpecialCharTok{::}\FunctionTok{acat}\NormalTok{(}\AttributeTok{reverse =} \ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## VGAM::vglm(formula = y ~ N + L, family = VGAM::acat(reverse = TRUE), 
##     data = train_df)
## 
## 
## Coefficients:
## (Intercept):1 (Intercept):2           N:1           N:2           L:1 
##  -12.94227208   -6.10597713    0.31431599    0.04643039    0.17500408 
##           L:2 
##    0.29578067 
## 
## Degrees of Freedom: 24 Total; 18 Residual
## Residual deviance: 11.67769 
## Log-likelihood: -5.838847 
## 
## This is an adjacent categories model with 3 levels
\end{verbatim}

\hypertarget{cumulative-logit-model}{%
\subsection{누적 로짓모형}\label{cumulative-logit-model}}

객체 \(i\)가 범주 \(j\) 이하에 속할 누적확률을 \(\kappa_{ij}\)라 하자.

\begin{equation*}
\kappa_{ij} = P(y_i \leq j \, | \, \mathbf{x}_i), \, j = 1, \cdots, J
\end{equation*}

누적 로짓모형은 범주 누적확률의 로짓변환에 대한 선형 회귀모형이다.

\begin{equation}
\log \left( \frac{\kappa_{ij}}{1 - \kappa_{ij}} \right) = \beta_{0,j} + \boldsymbol\beta^\top \mathbf{x}_i, \, j = 1, \cdots, J - 1
\label{eq:cumulative-logit}
\end{equation}

식 \eqref{eq:cumulative-logit}은 독립변수에 대한 계수 \(\boldsymbol\beta\)가 모든 범주에 대해 동일하며 절편(intercept) \(\beta_{0,j}\)만 범주에 따라 다른 비례 승산 모형(proportional odds model)이다. 즉, 범주에 관계없이 각 독립변수가 한 단위 증가할 때마다 로그 승산비는 동일하게 증가한다.

모형의 추정은 \ref{baseline-category-logit-model}절과 유사하게 다항분포를 사용한 최우추정법을 사용할 수 있다. 각 객체 \(i\)가 범주 \(j\)에 속할 확률은 아래와 같다.

\begin{equation*}
\begin{split}
\pi_{ij} &= \kappa_{ij} - \kappa_{i,j-1}\\
&= \frac{\exp (\beta_{0,j} + \boldsymbol\beta^\top \mathbf{x}_i)}{1 + \exp (\beta_{0,j} + \boldsymbol\beta^\top \mathbf{x}_i)} - \frac{\exp (\beta_{0,j-1} + \boldsymbol\beta^\top \mathbf{x}_i)}{1 + \exp (\beta_{0,j-1} + \boldsymbol\beta^\top \mathbf{x}_i)}, \, j = 2, \cdots, J - 1\\
& \\
\pi_{i1} &= \kappa_{i1}\\
&= \frac{\exp (\beta_{0,1} + \boldsymbol\beta^\top \mathbf{x}_i)}{1 + \exp (\beta_{0,1} + \boldsymbol\beta^\top \mathbf{x}_i)}\\
& \\
\pi_{iJ} &= 1 - \kappa_{i,J-1}\\
&= 1 - \frac{\exp (\beta_{0,J-1} + \boldsymbol\beta^\top \mathbf{x}_i)}{1 + \exp (\beta_{0,J-1} + \boldsymbol\beta^\top \mathbf{x}_i)}
\end{split}
\label{eq:cumulative-logit-prob}
\end{equation*}

로그 우도함수는

\begin{equation*}
\sum_{i = 1}^{n} \sum_{j = 1}^{J} y_i \log \pi_{ij}
\end{equation*}

이며, 이에 위에서 정리한 \(\pi_{ij}\)식을 대입하여 전개할 수 있다. 이 로그 우도함수는 concave 함수이므로\citep{pratt1981concavity}, 각 계수에 대해 편미분하여 0이 되도록 하는 값을 구하는 방식으로 회귀모형을 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{polr\_fit }\OtherTok{\textless{}{-}}\NormalTok{ MASS}\SpecialCharTok{::}\FunctionTok{polr}\NormalTok{(y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ N }\SpecialCharTok{+}\NormalTok{ L, }\AttributeTok{data =}\NormalTok{ train\_df)}

\FunctionTok{print}\NormalTok{(polr\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## MASS::polr(formula = y ~ N + L, data = train_df)
## 
## Coefficients:
##          N          L 
## -0.2236292 -0.2998833 
## 
## Intercepts:
##       1|2       2|3 
## -13.03527 -11.39902 
## 
## Residual Deviance: 12.8825 
## AIC: 20.8825
\end{verbatim}

위와 같이 \texttt{polr} 함수 실행 시 얻어지는 각 변수들에 대한 계수들의 부호는 교재\citep{jun2012datamining}의 내용과 반대인데, 이는 \texttt{polr} 함수는 아래와 같은 모형을 추정하기 때문이다.

\begin{equation*}
\log \left( \frac{\kappa_{ij}}{1 - \kappa_{ij}} \right) = \beta_{0,j} - \boldsymbol\beta^\top \mathbf{x}_i, \, j = 1, \cdots, J - 1
\end{equation*}

위 모형에서 \texttt{polr} 함수 실행 결과 추정된 절편값은 \(\beta_{0,1} = -13.0352721\), \(\beta_{0,2} = -11.3990207\) 이며, 두 변수 \(N\), \(L\)에 대한 회귀계수는 각각 -0.2236292, -0.2998833로 추정된다.

추정된 회귀계수를 식 \eqref{eq:cumulative-logit-prob}에 대입하면 각 객체 \(i\)가 각 범주 \(j\)에 속할 확률을 Table \ref{tab:cumulative-logit-prediction}와 같이 얻을 수 있다. 아래 R 스크립트에서 사용한 \texttt{predict}라는 함수가 해당 계산을 수행한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predict\_df }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(polr\_fit, train\_df, }\AttributeTok{type =} \StringTok{"probs"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{as\_data\_frame}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \StringTok{\textasciigrave{}}\AttributeTok{colnames\textless{}{-}}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"p1"}\NormalTok{, }\StringTok{"p2"}\NormalTok{, }\StringTok{"p3"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pred\_class =} \FunctionTok{predict}\NormalTok{(polr\_fit, train\_df, }\AttributeTok{type =} \StringTok{"class"}\NormalTok{))}

\FunctionTok{bind\_cols}\NormalTok{(train\_df, predict\_df) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}잡음(N)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}손실(L)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}실제범주 $y\_i$\textquotesingle{}}\NormalTok{, }
                  \StringTok{\textquotesingle{}$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{pi\_\{i1\}$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{pi\_\{i2\}$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{pi\_\{i3\}$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}추정범주 $}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{hat\{y\}\_i$\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}위 통신 만족도 데이터에 대한 누적 로짓모형의 추정범주\textquotesingle{}}\NormalTok{,}
\CommentTok{\#    caption = \textquotesingle{}Table \textbackslash{}\textbackslash{}@ref(tab:ordinal{-}logistic{-}reg{-}train{-}data)에 대한 누적 로짓모형의 추정범주\textquotesingle{},}
    \AttributeTok{digits =} \DecValTok{4}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:cumulative-logit-prediction}위 통신 만족도 데이터에 대한 누적 로짓모형의 추정범주}
\centering
\begin{tabular}[t]{rrrrrrr}
\toprule
잡음(N) & 손실(L) & 실제범주 \$y\_i\$ & \$\textbackslash{}pi\_\{i1\}\$ & \$\textbackslash{}pi\_\{i2\}\$ & \$\textbackslash{}pi\_\{i3\}\$ & 추정범주 \$\textbackslash{}hat\{y\}\_i\$\\
\midrule
25 & 5 & 3 & 0.0026 & 0.0107 & 0.9867 & 3\\
25 & 10 & 3 & 0.0116 & 0.0452 & 0.9432 & 3\\
25 & 20 & 2 & 0.1905 & 0.3567 & 0.4528 & 3\\
25 & 30 & 1 & 0.8252 & 0.1352 & 0.0396 & 1\\
32 & 5 & 3 & 0.0124 & 0.0481 & 0.9395 & 3\\
\addlinespace
32 & 10 & 3 & 0.0531 & 0.1706 & 0.7763 & 3\\
32 & 20 & 2 & 0.5296 & 0.3230 & 0.1474 & 1\\
32 & 30 & 1 & 0.9576 & 0.0338 & 0.0085 & 1\\
42 & 5 & 1 & 0.1049 & 0.2709 & 0.6241 & 3\\
42 & 10 & 3 & 0.3443 & 0.3852 & 0.2705 & 2\\
\addlinespace
42 & 20 & 1 & 0.9133 & 0.0685 & 0.0181 & 1\\
42 & 30 & 1 & 0.9953 & 0.0038 & 0.0009 & 1\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{adjacent-categories-logit-model}{%
\subsection{인근범주 로짓모형}\label{adjacent-categories-logit-model}}

인근범주 로짓모형은 아래와 같이 인접한 두 범주의 확률 비율에 대한 회귀모형이다.

\begin{equation}
\log \left( \frac{\pi_{ij}}{\pi_{i,j+1}} \right) = \beta_{0,j} + \boldsymbol\beta^\top \mathbf{x}_i, \, j = 1, \cdots, J - 1
\label{eq:adjacent-category-logit}
\end{equation}

따라서, \(\pi_{ij}\)간에 다음과 같은 관계식이 성립한다.

\begin{equation*}
\begin{split}
\pi_{ij} &= \exp (\beta_{0,j} + \boldsymbol\beta^\top \mathbf{x}_i) \pi_{i,j+1}\\
&= \pi_{iJ} \exp \left(\sum_{k = j}^{J - 1} \beta_{0,k} + (J - j) \boldsymbol\beta^\top \mathbf{x}_i\right), \, j = 1, \cdots, J-1\\
\sum_{j = 1}^{J} \pi_{ij} &= 1
\end{split}
\end{equation*}

이를 정리하면

\begin{equation}
\begin{split}
\pi_{ij} &= \frac{\exp \left( \sum_{l = j}^{J - 1} \beta_{0,l} + (J - j) \boldsymbol\beta^\top \mathbf{x}_i \right)}{1 + \sum_{k = 1}^{J - 1} \exp \left( \sum_{l = k}^{J - 1} \beta_{0,l} + (J - k) \boldsymbol\beta^\top \mathbf{x}_i \right)}, \, j = 1, \cdots, J - 1\\
\pi_{iJ} &= \frac{1}{1 + \sum_{k = 1}^{J - 1} \exp \left( \sum_{l = k}^{J - 1} \beta_{0,l} + (J - k) \boldsymbol\beta^\top \mathbf{x}_i \right)}
\end{split}
\label{eq:adjacent-category-prob}
\end{equation}

와 같다. 이는 \ref{baseline-category-logit-model}절에서 살펴보았던 명목형 로지스틱 회귀모형에 비해 다소 복잡하지만 비슷한 형태이며, 역시 최우추정법을 이용하여 모형을 추정할 수 있다.

R에서는 \texttt{VGAM} 패키지의 \texttt{vglm} 함수를 이용할 때 파라미터 \texttt{family}의 값을 \texttt{VGAM} 패키지의 \texttt{acat} 함수를 설정함으로써 인근범주 로짓모형을 추정할 수 있다. 이 때 \texttt{acat} 함수의 \texttt{parallel} 파라미터값을 \texttt{TRUE}로 설정함으로써 식 \eqref{eq:adjacent-category-logit}에서와 같이 비례 승산 모형(proportional odds model)을 정의한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vglm\_fit }\OtherTok{\textless{}{-}}\NormalTok{ VGAM}\SpecialCharTok{::}\FunctionTok{vglm}\NormalTok{(}
\NormalTok{  y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ N }\SpecialCharTok{+}\NormalTok{ L,}
  \AttributeTok{data =}\NormalTok{ train\_df,}
  \AttributeTok{family =}\NormalTok{ VGAM}\SpecialCharTok{::}\FunctionTok{acat}\NormalTok{(}\AttributeTok{reverse =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{parallel =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  )}

\FunctionTok{print}\NormalTok{(}\FunctionTok{coef}\NormalTok{(vglm\_fit))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept):1 (Intercept):2             N             L 
##    -9.0658976    -8.9018134     0.1725867     0.2082167
\end{verbatim}

추정된 모형을 위 식 \eqref{eq:adjacent-category-prob}에 대입하면 각 객체 \(i\)가 각 범주 \(j\)에 속할 확률을 추정할 수 있다. \texttt{VGAM} 패키지의 \texttt{predictvglm} 함수가 해당 계산을 수행한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predict\_df }\OtherTok{\textless{}{-}}\NormalTok{ VGAM}\SpecialCharTok{::}\FunctionTok{predictvglm}\NormalTok{(vglm\_fit, train\_df, }\StringTok{"response"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{as\_data\_frame}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \StringTok{\textasciigrave{}}\AttributeTok{colnames\textless{}{-}}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"p1"}\NormalTok{, }\StringTok{"p2"}\NormalTok{, }\StringTok{"p3"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pred\_class =} \FunctionTok{ordered}\NormalTok{(}\FunctionTok{apply}\NormalTok{(., }\DecValTok{1}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{which.max}\NormalTok{(x))))}

\FunctionTok{bind\_cols}\NormalTok{(train\_df, predict\_df) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}잡음(N)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}손실(L)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}실제범주 $y\_i$\textquotesingle{}}\NormalTok{, }
                  \StringTok{\textquotesingle{}$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{pi\_\{i1\}$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{pi\_\{i2\}$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{pi\_\{i3\}$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}추정범주 $}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{hat\{y\}\_i$\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}위 통신 만족도 데이터에 대한 인근범주 로짓모형의 추정범주\textquotesingle{}}\NormalTok{,}
\CommentTok{\#    caption = \textquotesingle{}Table \textbackslash{}\textbackslash{}@ref(tab:ordinal{-}logistic{-}reg{-}train{-}data)에 대한 인근범주 로짓모형의 추정범주\textquotesingle{},}
    \AttributeTok{digits =} \DecValTok{4}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:adjacent-category-logit-prediction}위 통신 만족도 데이터에 대한 인근범주 로짓모형의 추정범주}
\centering
\begin{tabular}[t]{rrrrrrr}
\toprule
잡음(N) & 손실(L) & 실제범주 \$y\_i\$ & \$\textbackslash{}pi\_\{i1\}\$ & \$\textbackslash{}pi\_\{i2\}\$ & \$\textbackslash{}pi\_\{i3\}\$ & 추정범주 \$\textbackslash{}hat\{y\}\_i\$\\
\midrule
25 & 5 & 3 & 0.0007 & 0.0280 & 0.9713 & 3\\
25 & 10 & 3 & 0.0052 & 0.0751 & 0.9197 & 3\\
25 & 20 & 2 & 0.1804 & 0.3244 & 0.4952 & 3\\
25 & 30 & 1 & 0.7894 & 0.1770 & 0.0337 & 1\\
32 & 5 & 3 & 0.0072 & 0.0874 & 0.9054 & 3\\
\addlinespace
32 & 10 & 3 & 0.0474 & 0.2045 & 0.7480 & 3\\
32 & 20 & 2 & 0.5611 & 0.3015 & 0.1375 & 1\\
32 & 30 & 1 & 0.9339 & 0.0626 & 0.0036 & 1\\
42 & 5 & 1 & 0.1393 & 0.3026 & 0.5581 & 3\\
42 & 10 & 3 & 0.4411 & 0.3385 & 0.2204 & 1\\
\addlinespace
42 & 20 & 1 & 0.9063 & 0.0867 & 0.0070 & 1\\
42 & 30 & 1 & 0.9881 & 0.0118 & 0.0001 & 1\\
\bottomrule
\end{tabular}
\end{table}

비례 승산 모형(proportional odds model)이 아닌 인근범주 로짓모형은 아래와 같다.

\begin{equation}
\log \left( \frac{\pi_{ij}}{\pi_{i,j+1}} \right) = \beta_{0,j} + \boldsymbol\beta_j^\top \mathbf{x}_i, \, j = 1, \cdots, J - 1
\label{eq:adjacent-category-logit-nonproportional}
\end{equation}

해당 모형은 \texttt{acat} 함수의 \texttt{parallel} 파라미터 값을 \texttt{FALSE}로 설정함으로써 추정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vglm\_fit }\OtherTok{\textless{}{-}}\NormalTok{ VGAM}\SpecialCharTok{::}\FunctionTok{vglm}\NormalTok{(}
\NormalTok{  y }\SpecialCharTok{\textasciitilde{}}\NormalTok{ N }\SpecialCharTok{+}\NormalTok{ L,}
  \AttributeTok{data =}\NormalTok{ train\_df,}
  \AttributeTok{family =}\NormalTok{ VGAM}\SpecialCharTok{::}\FunctionTok{acat}\NormalTok{(}\AttributeTok{reverse =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{parallel =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{  )}

\FunctionTok{print}\NormalTok{(}\FunctionTok{coef}\NormalTok{(vglm\_fit))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (Intercept):1 (Intercept):2           N:1           N:2           L:1 
##  -12.94227208   -6.10597713    0.31431599    0.04643039    0.17500408 
##           L:2 
##    0.29578067
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predict\_df }\OtherTok{\textless{}{-}}\NormalTok{ VGAM}\SpecialCharTok{::}\FunctionTok{predictvglm}\NormalTok{(vglm\_fit, train\_df, }\StringTok{"response"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{as\_data\_frame}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \StringTok{\textasciigrave{}}\AttributeTok{colnames\textless{}{-}}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"p1"}\NormalTok{, }\StringTok{"p2"}\NormalTok{, }\StringTok{"p3"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pred\_class =} \FunctionTok{ordered}\NormalTok{(}\FunctionTok{apply}\NormalTok{(., }\DecValTok{1}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{which.max}\NormalTok{(x))))}

\FunctionTok{bind\_cols}\NormalTok{(train\_df, predict\_df) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}잡음(N)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}손실(L)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}실제범주 $y\_i$\textquotesingle{}}\NormalTok{, }
                  \StringTok{\textquotesingle{}$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{pi\_\{i1\}$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{pi\_\{i2\}$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{pi\_\{i3\}$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}추정범주 $}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{hat\{y\}\_i$\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}위 통신 만족도 데이터에 대한 인근범주 로짓모형의 추정범주 (비례 승산 모형이 아닌 경우)\textquotesingle{}}\NormalTok{,}
\CommentTok{\#    caption = \textquotesingle{}Table \textbackslash{}\textbackslash{}@ref(tab:ordinal{-}logistic{-}reg{-}train{-}data)에 대한 인근범주 로짓모형의 추정범주 (비례 승산 모형이 아닌 경우)\textquotesingle{},}
    \AttributeTok{digits =} \DecValTok{4}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:adjacent-category-logit-prediction-nonproportional}위 통신 만족도 데이터에 대한 인근범주 로짓모형의 추정범주 (비례 승산 모형이 아닌 경우)}
\centering
\begin{tabular}[t]{rrrrrrr}
\toprule
잡음(N) & 손실(L) & 실제범주 \$y\_i\$ & \$\textbackslash{}pi\_\{i1\}\$ & \$\textbackslash{}pi\_\{i2\}\$ & \$\textbackslash{}pi\_\{i3\}\$ & 추정범주 \$\textbackslash{}hat\{y\}\_i\$\\
\midrule
25 & 5 & 3 & 0.0004 & 0.0303 & 0.9693 & 3\\
25 & 10 & 3 & 0.0043 & 0.1200 & 0.8757 & 3\\
25 & 20 & 2 & 0.1295 & 0.6313 & 0.2392 & 2\\
25 & 30 & 1 & 0.5365 & 0.4546 & 0.0089 & 1\\
32 & 5 & 3 & 0.0055 & 0.0412 & 0.9533 & 3\\
\addlinespace
32 & 10 & 3 & 0.0488 & 0.1517 & 0.7995 & 3\\
32 & 20 & 2 & 0.5924 & 0.3200 & 0.0876 & 1\\
32 & 30 & 1 & 0.9131 & 0.0857 & 0.0012 & 1\\
42 & 5 & 1 & 0.1667 & 0.0536 & 0.7797 & 3\\
42 & 10 & 3 & 0.6335 & 0.0850 & 0.2815 & 1\\
\addlinespace
42 & 20 & 1 & 0.9734 & 0.0227 & 0.0039 & 1\\
42 & 30 & 1 & 0.9959 & 0.0040 & 0.0000 & 1\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{da}{%
\chapter{판별분석}\label{da}}

\hypertarget{da-overview}{%
\section{개요}\label{da-overview}}

판별분석(discriminant analysis)은 범주들을 가장 잘 구별하는 변수들의 하나 또는 다수의 함수를 도출하여 이를 기반으로 분류규칙을 제시한다. 본 장에서는 변수의 분포에 대한 가정이 필요 없는 피셔(Fisher) 방법과 다변량 정규분포를 가정하는 선형 및 비선형 판별분석을 설명한다.

\hypertarget{da-packages-install}{%
\section{필요 R 패키지 설치}\label{da-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.3.1\\
\hline
MASS & 7.3-54\\
\hline
mvtnorm & 1.1-2\\
\hline
\end{tabular}

\hypertarget{da-fisher}{%
\section{피셔 방법}\label{da-fisher}}

\hypertarget{da-fisher-basic-script}{%
\subsection{기본 R 스크립트}\label{da-fisher-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{id =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{9}\NormalTok{),}
  \AttributeTok{x1 =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{5}\NormalTok{),}
  \AttributeTok{x2 =} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{4}\NormalTok{),}
  \AttributeTok{class =} \FunctionTok{factor}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{)}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
             \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
             \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}범주\textquotesingle{}}\NormalTok{),}
             
             \AttributeTok{caption =} \StringTok{\textquotesingle{}판별분석 학습표본 데이터\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:da-train-data-table}판별분석 학습표본 데이터}
\centering
\begin{tabular}[t]{rrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 범주\\
\midrule
1 & 5 & 7 & 1\\
2 & 4 & 3 & 2\\
3 & 7 & 8 & 2\\
4 & 8 & 6 & 2\\
5 & 3 & 6 & 1\\
\addlinespace
6 & 2 & 5 & 1\\
7 & 6 & 6 & 1\\
8 & 9 & 6 & 2\\
9 & 5 & 4 & 2\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:da-train-data-table}와 같이 두 독립변수 \emph{x1}, \emph{x2}와 이분형 종속변수 \emph{class}의 관측값으로 이루어진 9개의 학습표본을 \emph{train\_df}라는 data frame에 저장한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fisher\_da }\OtherTok{\textless{}{-}}\NormalTok{ MASS}\SpecialCharTok{::}\FunctionTok{lda}\NormalTok{(class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, train\_df)}

\FunctionTok{print}\NormalTok{(fisher\_da)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## lda(class ~ x1 + x2, data = train_df)
## 
## Prior probabilities of groups:
##         1         2 
## 0.4444444 0.5555556 
## 
## Group means:
##    x1  x2
## 1 4.0 6.0
## 2 6.6 5.4
## 
## Coefficients of linear discriminants:
##           LD1
## x1  0.6850490
## x2 -0.7003859
\end{verbatim}

\hypertarget{uxd53cuxc154-uxd310uxbcc4uxd568uxc218}{%
\subsection{피셔 판별함수}\label{uxd53cuxc154-uxd310uxbcc4uxd568uxc218}}

각 객체는 변수벡터 \(\mathbf{x} \in \mathbb{R}^p\)와 범주 \(y \in \{1, 2\}\)로 이루어진다고 하자. 아래는 변수 \(\mathbf{x}\)의 기대치와 분산-공분산행렬(varinace-covariance matrix)을 나타낸다.

\begin{eqnarray*}
\boldsymbol\mu_1 = E(\mathbf{x} | y = 1)\\
\boldsymbol\mu_2 = E(\mathbf{x} | y = 2)\\
\boldsymbol\Sigma = Var(\mathbf{x} | y = 1) = Var(\mathbf{x} | y = 2)
\end{eqnarray*}

다음과 같이 변수들의 선형조합으로 새로운 변수 \(z\)를 형성하는 함수를 피셔 판별함수(Fisher's discriminant function)라 한다.

\begin{equation}
z = \mathbf{w}^\top \mathbf{x} \label{eq:fisher-discriminant-function}
\end{equation}

여기서 계수벡터 \(\mathbf{w} \in \mathbb{R}^p\)는 통상 아래와 같이 변수 \(z\)의 범주간 평균 차이 대 변수 \(z\)의 분산의 비율을 최대화하는 것으로 결정한다.

\begin{equation}
{\arg\!\min}_{\mathbf{w}} \frac{\mathbf{w}^\top ( \boldsymbol\mu_1 - \boldsymbol\mu_2 )}{\mathbf{w}^\top \boldsymbol\Sigma \mathbf{w}} \label{eq:fisher-discriminant-function-coef}
\end{equation}

위 식 \eqref{eq:fisher-discriminant-function-coef}의 해는

\begin{equation*}
\mathbf{w} \propto \boldsymbol\Sigma^{-1}(\boldsymbol\mu_1 - \boldsymbol\mu_2)
\end{equation*}

의 조건을 만족하며, 편의상 비례상수를 1로 두면 아래와 같은 해가 얻어진다.

\begin{equation}
\mathbf{w} = \boldsymbol\Sigma^{-1}(\boldsymbol\mu_1 - \boldsymbol\mu_2) \label{eq:fisher-discriminant-function-coef-sol}
\end{equation}

실제 모집단의 평균 및 분산을 알지 못하는 경우, 학습표본으로부터 \(\boldsymbol\mu_1, \boldsymbol\mu_2, \boldsymbol\Sigma\)의 추정치를 얻어 식 \eqref{eq:fisher-discriminant-function-coef-sol}에 대입하는 방식으로 판별계수를 추정한다. 자세한 내용은 교재 \citep{jun2012datamining} 참조.

Table \ref{tab:da-train-data-table}에 주어진 학습표본을 이용하여 피셔 판별함수를 구해보도록 하자. 우선 각 범주별 평균벡터 \(\hat{\boldsymbol\mu}_1, \hat{\boldsymbol\mu}_2\)를 아래와 같이 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mu\_hat }\OtherTok{\textless{}{-}}\NormalTok{ train\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(class) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{x1 =} \FunctionTok{mean}\NormalTok{(x1),}
            \AttributeTok{x2 =} \FunctionTok{mean}\NormalTok{(x2)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(class)}

\FunctionTok{print}\NormalTok{(mu\_hat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 3
##   class    x1    x2
##   <fct> <dbl> <dbl>
## 1 1       4     6  
## 2 2       6.6   5.4
\end{verbatim}

또한 범주별 표본 분산-공분산행렬 \(\mathbf{S}_1, \mathbf{S}_2\)를 다음과 같이 구한다. 리스트 \texttt{S\_within\_group}의 첫번째 원소는 범주 1의 분산-공분산행렬 \(\mathbf{S}_1\), 두번째 원소는 범주 2의 분산-공분산행렬 \(\mathbf{S}_2\)를 나타낸다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{S\_within\_group }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(}
  \FunctionTok{unique}\NormalTok{(train\_df}\SpecialCharTok{$}\NormalTok{class) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{sort}\NormalTok{(), }\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{    train\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(class }\SpecialCharTok{==}\NormalTok{ x) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(x1, x2) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{var}\NormalTok{()}
\NormalTok{  \}}
\NormalTok{)}

\FunctionTok{print}\NormalTok{(S\_within\_group)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
##          x1        x2
## x1 3.333333 1.0000000
## x2 1.000000 0.6666667
## 
## [[2]]
##      x1   x2
## x1 4.30 2.95
## x2 2.95 3.80
\end{verbatim}

위에서 얻은 범주별 표본 분산-공분산행렬을 이용하여 합동 분산-공분산행렬을 아래와 같이 추정한다.

\begin{equation*}
\hat{\boldsymbol\Sigma} = \mathbf{S}_p = \frac{(n_1 - 1)\mathbf{S}_1 + (n_2 - 1)\mathbf{S}_2}{n_1 + n_2 - 2}
\end{equation*}

이 때 \(n_1, n_2\)는 각각 범주 1, 2에 속한 학습표본 객체의 수를 나타낸다. 아래 R 스크립트에서는 임의의 범주 표본수 벡터 \texttt{n}과 범주별 표본 분산-공분산행렬 리스트 \texttt{S}에 대해 합동 분산-공분산행렬을 구하는 함수 \texttt{pooled\_variance}를 정의하고, 주어진 학습표본에 대한 입력값을 대입하여 합동 분산-공분산행렬 추정치 \texttt{Sigma\_hat}을 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pooled\_variance }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(n, S) \{}
  \FunctionTok{lapply}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{length}\NormalTok{(n), }\ControlFlowTok{function}\NormalTok{(i) (n[i] }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\NormalTok{S[[i]]) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{Reduce}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{+}\StringTok{\textasciigrave{}}\NormalTok{, .) }\SpecialCharTok{\%\textgreater{}\%}
    \StringTok{\textasciigrave{}}\AttributeTok{/}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{sum}\NormalTok{(n) }\SpecialCharTok{{-}} \FunctionTok{length}\NormalTok{(n))}
\NormalTok{\}}

\NormalTok{n\_obs }\OtherTok{\textless{}{-}}\NormalTok{ train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(class) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{count}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{pi =}\NormalTok{ n }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(class)}

\NormalTok{Sigma\_hat }\OtherTok{\textless{}{-}} \FunctionTok{pooled\_variance}\NormalTok{(n\_obs}\SpecialCharTok{$}\NormalTok{n, S\_within\_group)}

\FunctionTok{print}\NormalTok{(Sigma\_hat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          x1       x2
## x1 3.885714 2.114286
## x2 2.114286 2.457143
\end{verbatim}

위에서 구한 추정치들을 이용하여 아래와 같이 판별함수 계수 추정치 \(\hat{\mathbf{w}}\)를 구한다.

\begin{equation*}
\hat{\mathbf{w}} = \hat{\boldsymbol\Sigma}^{-1}(\hat{\boldsymbol\mu}_1 - \hat{\boldsymbol\mu}_2) 
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w\_hat }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(Sigma\_hat) }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(mu\_hat[}\DecValTok{1}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}x1\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}x2\textquotesingle{}}\NormalTok{)] }\SpecialCharTok{{-}}\NormalTok{ mu\_hat[}\DecValTok{2}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}x1\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}x2\textquotesingle{}}\NormalTok{)])}

\FunctionTok{print}\NormalTok{(w\_hat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         [,1]
## x1 -1.508039
## x2  1.541801
\end{verbatim}

\hypertarget{uxbd84uxb958-uxaddcuxce59}{%
\subsection{분류 규칙}\label{uxbd84uxb958-uxaddcuxce59}}

피셔 판별함수에 따른 분류 경계값은 학습표본에 대한 판별함수값의 평균으로 아래와 같이 구할 수 있다.

\begin{equation*}
\bar{z} = \frac{1}{N} \sum_i^N \hat{\mathbf{w}}^\top \mathbf{x}_i
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z\_mean }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w\_hat) }\SpecialCharTok{\%*\%}\NormalTok{ (train\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(x1, x2) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{colMeans}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{drop}\NormalTok{()}

\FunctionTok{print}\NormalTok{(z\_mean)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.526438
\end{verbatim}

위 결과를 통해, 분류규칙은 다음과 같이 주어진다.

\begin{itemize}
\tightlist
\item
  \(\hat{\mathbf{w}}^\top \mathbf{x} \ge \bar{z}\) 이면, \(\mathbf{x}\)를 범주 1로 분류
\item
  \(\hat{\mathbf{w}}^\top \mathbf{x} < \bar{z}\) 이면, \(\mathbf{x}\)를 범주 2로 분류
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_prediction\_df }\OtherTok{\textless{}{-}}\NormalTok{ train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{z =}\NormalTok{ w\_hat[}\DecValTok{1}\NormalTok{]}\SpecialCharTok{*}\NormalTok{x1 }\SpecialCharTok{+}\NormalTok{ w\_hat[}\DecValTok{2}\NormalTok{]}\SpecialCharTok{*}\NormalTok{x2,}
    \AttributeTok{predicted\_class =} \FunctionTok{factor}\NormalTok{(}\FunctionTok{if\_else}\NormalTok{(z }\SpecialCharTok{\textgreater{}=}\NormalTok{ z\_mean, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{    )}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(train\_prediction\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
             \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
             \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}실제범주\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$z$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}추정범주\textquotesingle{}}\NormalTok{),}
             \AttributeTok{caption =} \StringTok{\textquotesingle{}학습표본에 대한 피셔 분류 결과\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:fisher-da-result}학습표본에 대한 피셔 분류 결과}
\centering
\begin{tabular}[t]{rrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$z\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & 3.2524116 & 1\\
2 & 4 & 3 & 2 & -1.4067524 & 2\\
3 & 7 & 8 & 2 & 1.7781350 & 1\\
4 & 8 & 6 & 2 & -2.8135048 & 2\\
5 & 3 & 6 & 1 & 4.7266881 & 1\\
\addlinespace
6 & 2 & 5 & 1 & 4.6929260 & 1\\
7 & 6 & 6 & 1 & 0.2025723 & 2\\
8 & 9 & 6 & 2 & -4.3215434 & 2\\
9 & 5 & 4 & 2 & -1.3729904 & 2\\
\bottomrule
\end{tabular}
\end{table}

위 결과 객체 3, 7가 오분류된다.

\hypertarget{r-uxd328uxd0a4uxc9c0uxb97c-uxc774uxc6a9uxd55c-uxbd84uxb958uxaddcuxce59-uxb3c4uxcd9c}{%
\subsection{R 패키지를 이용한 분류규칙 도출}\label{r-uxd328uxd0a4uxc9c0uxb97c-uxc774uxc6a9uxd55c-uxbd84uxb958uxaddcuxce59-uxb3c4uxcd9c}}

패키지 \texttt{MASS}내의 함수 \texttt{lda} 수행 시 얻어지는 판별계수 \(\hat{\mathbf{w}}\)는 위 결과와는 사뭇 다른데, \texttt{lda} 함수의 경우 아래와 같이 1) 제약식을 포함하여 비례계수를 구하기 때문에 계수의 크기가 달라지며, 2) 목적함수를 최소화하는 대신 최대화하는 값을 찾기 때문에 부호가 달라진다.

\begin{equation*}
\begin{split}
\max \text{  } & \mathbf{w}^\top ( \boldsymbol\mu_1 - \boldsymbol\mu_2 )\\
\text{s.t. } & \mathbf{w}^\top \boldsymbol\Sigma \mathbf{w} = 1
\end{split}
\end{equation*}

이에 따른 \texttt{lda} 함수의 계수 추정 결과는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fisher\_da }\OtherTok{\textless{}{-}}\NormalTok{ MASS}\SpecialCharTok{::}\FunctionTok{lda}\NormalTok{(class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, train\_df)}

\NormalTok{w\_hat\_lda }\OtherTok{\textless{}{-}}\NormalTok{ fisher\_da}\SpecialCharTok{$}\NormalTok{scaling}
\FunctionTok{print}\NormalTok{(w\_hat\_lda)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           LD1
## x1  0.6850490
## x2 -0.7003859
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z\_mean\_lda }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(fisher\_da}\SpecialCharTok{$}\NormalTok{scaling) }\SpecialCharTok{\%*\%}\NormalTok{ (train\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(x1, x2) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{colMeans}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{drop}\NormalTok{()}
\FunctionTok{print}\NormalTok{(z\_mean\_lda)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        LD1 
## -0.2391423
\end{verbatim}

위 결과는 아래와 같은 계산을 통해 앞 장에서 보았던 결과와 동일한 분류 경계식으로 표현될 수 있음을 볼 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{scale\_adjust }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(w\_hat) }\SpecialCharTok{\%*\%}\NormalTok{ Sigma\_hat }\SpecialCharTok{\%*\%}\NormalTok{ w\_hat }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{drop}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{sqrt}\NormalTok{()}
\NormalTok{sign\_adjust }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\DecValTok{1}

\NormalTok{w\_hat }\OtherTok{\textless{}{-}}\NormalTok{ w\_hat\_lda }\SpecialCharTok{*}\NormalTok{ scale\_adjust }\SpecialCharTok{*}\NormalTok{ sign\_adjust}
\FunctionTok{print}\NormalTok{(w\_hat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          LD1
## x1 -1.508039
## x2  1.541801
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z\_mean }\OtherTok{\textless{}{-}}\NormalTok{ z\_mean\_lda }\SpecialCharTok{*}\NormalTok{ scale\_adjust }\SpecialCharTok{*}\NormalTok{ sign\_adjust }
\FunctionTok{print}\NormalTok{(z\_mean)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      LD1 
## 0.526438
\end{verbatim}

아래 스크립트는 위 \texttt{lda} 함수로부터의 경계식 추정을 기반으로 아래 수식값을 계산한다.

\begin{equation*}
\hat{\mathbf{w}}^\top \mathbf{x} - \bar{z}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{predict}\NormalTok{(fisher\_da, train\_df)}\SpecialCharTok{$}\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          LD1
## 1 -1.2383140
## 2  0.8781805
## 3 -0.5686020
## 4  1.5172187
## 5 -1.9080261
## 6 -1.8926892
## 7  0.1471208
## 8  2.2022677
## 9  0.8628436
\end{verbatim}

피셔 분류규칙에 따라 해당 값이 0보다 작으면 범주 1, 0보다 크면 범주 2로 분류한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{centered\_z =} \FunctionTok{predict}\NormalTok{(fisher\_da, .)}\SpecialCharTok{$}\NormalTok{x,}
    \AttributeTok{predicted\_class =} \FunctionTok{factor}\NormalTok{(}\FunctionTok{if\_else}\NormalTok{(centered\_z }\SpecialCharTok{\textless{}=} \DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
             \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
             \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}\NormalTok{, }
                           \StringTok{\textquotesingle{}실제범주\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$z {-} }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{bar\{z\}$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}추정범주\textquotesingle{}}\NormalTok{),}
             \AttributeTok{caption =} \StringTok{\textquotesingle{}학습표본에 대한 피셔 분류 결과 {-} \textasciigrave{}MASS::lda\textasciigrave{} 분류 경계식 기준\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:fisher-da-result-lda}학습표본에 대한 피셔 분류 결과 - `MASS::lda` 분류 경계식 기준}
\centering
\begin{tabular}[t]{rrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$z - \textbackslash{}bar\{z\}\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & -1.2383140 & 1\\
2 & 4 & 3 & 2 & 0.8781805 & 2\\
3 & 7 & 8 & 2 & -0.5686020 & 1\\
4 & 8 & 6 & 2 & 1.5172187 & 2\\
5 & 3 & 6 & 1 & -1.9080261 & 1\\
\addlinespace
6 & 2 & 5 & 1 & -1.8926892 & 1\\
7 & 6 & 6 & 1 & 0.1471208 & 2\\
8 & 9 & 6 & 2 & 2.2022677 & 2\\
9 & 5 & 4 & 2 & 0.8628436 & 2\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:fisher-da-result-lda}는 Table \ref{tab:fisher-da-result}와 동일한 범주 추정 결과를 보인다.

\hypertarget{lda}{%
\section{의사결정론에 의한 선형분류규칙}\label{lda}}

다음과 같이 객체가 각 범주에 속할 사전확률과 각 범주 내에서의 분류변수의 확률밀도함수에 대한 기호를 정의한다.

\begin{itemize}
\tightlist
\item
  \(\pi_k\): 임의의 객체가 범주 \(k\)에 속할 사전확률
\item
  \(f_k(\mathbf{x})\): 범주 \(k\)에 대한 변수의 확률밀도함수
\end{itemize}

이 때 통상적으로 \(\mathbf{x}\)는 다변량 정규분포를 따르는 것으로 가정하여 아래와 같이 평균벡터 \(\boldsymbol\mu_k\)와 분산-공분산행렬 \(\boldsymbol\Sigma\)로 확률밀도함수를 정의할 수 있다. 이 때 분산-공분산행렬 \(\boldsymbol\Sigma\)는 모든 범주에 대해 동일하다고 가정한다.

\begin{equation}
f_k(\mathbf{x}) = \frac{1}{(2\pi)^{p/2}|\boldsymbol\Sigma|^{1/2}} \exp \{ -\frac{1}{2} \left(\mathbf{x} - \boldsymbol\mu_k\right)^\top \boldsymbol\Sigma^{-1} \left(\mathbf{x} - \boldsymbol\mu_k\right) \}
\label{eq:mv-gaussian-dist}
\end{equation}

본 장에서는 두 범주(\(k = 1, 2\)) 분류 문제만 다루며, 세 범주 이상에 대한 분류 문제는 뒷 장에서 추가적으로 다루기로 한다.

\hypertarget{lda-basic-script}{%
\subsection{기본 R 스크립트}\label{lda-basic-script}}

Table \ref{tab:da-train-data-table}의 학습표본에 대해 선형판별분석을 적용하는 R 스크립트는 아래에 보이는 것처럼 피셔 판별함수를 구하기 위한 동일하며, \texttt{prior} 파라미터를 정의하지 않음으로써 \(\pi_1\)과 \(\pi_2\)를 학습표본의 범주 1, 2의 비율로 설정한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lda\_fit }\OtherTok{\textless{}{-}}\NormalTok{ MASS}\SpecialCharTok{::}\FunctionTok{lda}\NormalTok{(class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, train\_df)}

\FunctionTok{print}\NormalTok{(lda\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## lda(class ~ x1 + x2, data = train_df)
## 
## Prior probabilities of groups:
##         1         2 
## 0.4444444 0.5555556 
## 
## Group means:
##    x1  x2
## 1 4.0 6.0
## 2 6.6 5.4
## 
## Coefficients of linear discriminants:
##           LD1
## x1  0.6850490
## x2 -0.7003859
\end{verbatim}

\hypertarget{lda-function}{%
\subsection{선형판별함수}\label{lda-function}}

두 범주 문제에 있어서, 범주를 알지 못하는 변수 \(\mathbf{x}\)에 대한 확률밀도함수는 아래와 같다.

\begin{equation*}
f(\mathbf{x}) = \pi_1 f_1(\mathbf{x}) + \pi_2 f_2(\mathbf{x})
\end{equation*}

베이즈 정리(Bayes's theorem)에 따라 변수 \(\mathbf{x}\)값이 주어졌을 때 범주 \(k\)에 속할 사후확률(posterior)은 아래와 같이 구할 수 있다.

\begin{equation}
P(y = k \, | \, \mathbf{x}) = \frac{\pi_k f_k(\mathbf{x})}{f(\mathbf{x})}
\label{eq:lda-posterior}
\end{equation}

각 범주에 대한 사후확률을 계산하여, 확률이 높은 쪽으로 범주를 추정한다.

\begin{equation}
\hat{y} = \begin{cases}
    1, & \text{if } P(y = 1 \, | \, \mathbf{x}) \ge P(y = 2 \, | \, \mathbf{x})\\
    2, & \text{otherwise}
\end{cases}
\label{eq:lda-posterior-rule}
\end{equation}

이를 다시 정리하면 아래와 같다.

\begin{equation*}
\hat{y} = \begin{cases}
    1, & \text{if } \frac{f_1(\mathbf{x})}{f_2(\mathbf{x})} \ge \frac{\pi_2}{\pi_1}\\
    2, & \text{otherwise}
\end{cases}
\end{equation*}

위 분류규칙에 식 \eqref{eq:mv-gaussian-dist}을 대입하여 정리하면 다음과 같다. 보다 자세한 내용은 교재 \citep{jun2012datamining} 참조.

\begin{equation*}
\hat{y} = \begin{cases}
    1, & \text{if } \boldsymbol\mu_1^\top \boldsymbol\Sigma^{-1}\mathbf{x} - \frac{1}{2} \boldsymbol\mu_1^\top \boldsymbol\Sigma^{-1} \boldsymbol\mu_1 + \ln \pi_1 \ge \boldsymbol\mu_2^\top \boldsymbol\Sigma^{-1}\mathbf{x} - \frac{1}{2} \boldsymbol\mu_2^\top \boldsymbol\Sigma^{-1} \boldsymbol\mu_2 + \ln \pi_2  \\
    2, & \text{otherwise}
\end{cases}
\end{equation*}

따라서, 각 범주에 대한 판별함수를

\begin{equation}
u_k(\mathbf{x}) = \boldsymbol\mu_k^\top \boldsymbol\Sigma^{-1}\mathbf{x} - \frac{1}{2} \boldsymbol\mu_k^\top \boldsymbol\Sigma^{-1} \boldsymbol\mu_k + \ln \pi_k
\label{eq:lda-discriminant-function}
\end{equation}

라 하면, 아래와 같이 분류규칙을 정의할 수 있다.

\begin{equation}
\hat{y} = \begin{cases}
    1, & \text{if } u_1(\mathbf{x}) \ge u_2(\mathbf{x})  \\
    2, & \text{otherwise}
\end{cases}
\label{eq:lda-discriminant-rule}
\end{equation}

Table \ref{tab:da-train-data-table}의 학습표본에 대해 판별함수값을 계산하고 범주를 추정하면 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{discriminant\_func }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(X, mu, Sigma, pi) \{}
\NormalTok{  Sigma\_inv }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(Sigma)}
\NormalTok{  (}\FunctionTok{t}\NormalTok{(mu) }\SpecialCharTok{\%*\%}\NormalTok{ Sigma\_inv }\SpecialCharTok{\%*\%}\NormalTok{ X }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{drop}\NormalTok{()) }\SpecialCharTok{{-}}  
    \FloatTok{0.5} \SpecialCharTok{*}\NormalTok{ (}\FunctionTok{t}\NormalTok{(mu) }\SpecialCharTok{\%*\%}\NormalTok{ Sigma\_inv }\SpecialCharTok{\%*\%}\NormalTok{ mu }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{drop}\NormalTok{()) }\SpecialCharTok{+} 
    \FunctionTok{log}\NormalTok{(pi)}
\NormalTok{\}}

\NormalTok{lda\_discriminant\_result\_df }\OtherTok{\textless{}{-}}\NormalTok{ train\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{u1 =} \FunctionTok{discriminant\_func}\NormalTok{(}
\NormalTok{      .[}\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{t}\NormalTok{(),}
\NormalTok{      mu\_hat[}\DecValTok{1}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unlist}\NormalTok{(),}
\NormalTok{      Sigma\_hat,}
\NormalTok{      n\_obs}\SpecialCharTok{$}\NormalTok{pi[}\DecValTok{1}\NormalTok{]}
\NormalTok{      ),}
    \AttributeTok{u2 =} \FunctionTok{discriminant\_func}\NormalTok{(}
\NormalTok{      .[}\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{t}\NormalTok{(),}
\NormalTok{      mu\_hat[}\DecValTok{2}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unlist}\NormalTok{(),}
\NormalTok{      Sigma\_hat,}
\NormalTok{      n\_obs}\SpecialCharTok{$}\NormalTok{pi[}\DecValTok{2}\NormalTok{]}
\NormalTok{      )}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{predicted\_class =} \FunctionTok{factor}\NormalTok{(}\FunctionTok{if\_else}\NormalTok{(u1 }\SpecialCharTok{\textgreater{}=}\NormalTok{ u2, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{    )}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  lda\_discriminant\_result\_df,}
  \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{rep}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\FunctionTok{dim}\NormalTok{(lda\_discriminant\_result\_df)[}\DecValTok{2}\NormalTok{]),}
  \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}\NormalTok{,}
                \StringTok{\textquotesingle{}실제범주\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$u\_1(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$u\_2(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$\textquotesingle{}}\NormalTok{,}
                \StringTok{\textquotesingle{}추정범주\textquotesingle{}}\NormalTok{),}
  \AttributeTok{caption =} \StringTok{\textquotesingle{}학습표본에 대한 LDA 적용 결과: 판별함수값 및 추정범주\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:lda-disriminant-result}학습표본에 대한 LDA 적용 결과: 판별함수값 및 추정범주}
\centering
\begin{tabular}[t]{rrrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$u\_1(\textbackslash{}mathbf\{x\})\$ & \$u\_2(\textbackslash{}mathbf\{x\})\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & 9.2051470 & 6.971538 & 1\\
2 & 4 & 3 & 2 & -1.9363321 & 0.489223 & 2\\
3 & 7 & 8 & 2 & 11.0057900 & 10.246458 & 1\\
4 & 8 & 6 & 2 & 4.5909990 & 8.423307 & 2\\
5 & 3 & 6 & 1 & 7.4045039 & 3.696619 & 1\\
\addlinespace
6 & 2 & 5 & 1 & 5.0411598 & 1.367036 & 1\\
7 & 6 & 6 & 1 & 5.7164010 & 6.532631 & 2\\
8 & 9 & 6 & 2 & 4.0282981 & 9.368644 & 2\\
9 & 5 & 4 & 2 & 0.4270119 & 2.818805 & 2\\
\bottomrule
\end{tabular}
\end{table}

또한 식 \eqref{eq:lda-posterior}에 따른 사후확률과 식 \eqref{eq:lda-posterior-rule}에 따른 추정범주는 아래와 같이 얻어진다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lda\_posterior\_result\_df }\OtherTok{\textless{}{-}}\NormalTok{ train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{f1 =}\NormalTok{ mvtnorm}\SpecialCharTok{::}\FunctionTok{dmvnorm}\NormalTok{(}
\NormalTok{      .[}\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)],}
\NormalTok{      mu\_hat[}\DecValTok{1}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unlist}\NormalTok{(),}
\NormalTok{      Sigma\_hat),}
    \AttributeTok{f2 =}\NormalTok{ mvtnorm}\SpecialCharTok{::}\FunctionTok{dmvnorm}\NormalTok{(}
\NormalTok{      .[}\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)],}
\NormalTok{      mu\_hat[}\DecValTok{2}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unlist}\NormalTok{(),}
\NormalTok{      Sigma\_hat),}
    \AttributeTok{f =}\NormalTok{ n\_obs}\SpecialCharTok{$}\NormalTok{pi[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ f1 }\SpecialCharTok{+}\NormalTok{ n\_obs}\SpecialCharTok{$}\NormalTok{pi[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ f2}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{p1 =}\NormalTok{ n\_obs}\SpecialCharTok{$}\NormalTok{pi[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ f1 }\SpecialCharTok{/}\NormalTok{ f,}
    \AttributeTok{p2 =}\NormalTok{ n\_obs}\SpecialCharTok{$}\NormalTok{pi[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ f2 }\SpecialCharTok{/}\NormalTok{ f}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{predicted\_class =} \FunctionTok{factor}\NormalTok{(}\FunctionTok{if\_else}\NormalTok{(p1 }\SpecialCharTok{\textgreater{}=}\NormalTok{ p2, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}
\NormalTok{    id, x1, x2, class, p1, p2, predicted\_class}
\NormalTok{  )}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  lda\_posterior\_result\_df,}
  \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{rep}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\FunctionTok{dim}\NormalTok{(lda\_posterior\_result\_df)[}\DecValTok{2}\NormalTok{]),}
  \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}\NormalTok{,}
                \StringTok{\textquotesingle{}실제범주\textquotesingle{}}\NormalTok{, }
                \StringTok{\textquotesingle{}$P(y = 1 | }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$\textquotesingle{}}\NormalTok{, }
                \StringTok{\textquotesingle{}$P(y = 2 | }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$\textquotesingle{}}\NormalTok{,}
                \StringTok{\textquotesingle{}추정범주\textquotesingle{}}\NormalTok{),}
  \AttributeTok{caption =} \StringTok{\textquotesingle{}학습표본에 대한 LDA 적용 결과: 사후확률 및 추정범주\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:lda-posterior-result}학습표본에 대한 LDA 적용 결과: 사후확률 및 추정범주}
\centering
\begin{tabular}[t]{rrrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$P(y = 1 | \textbackslash{}mathbf\{x\})\$ & \$P(y = 2 | \textbackslash{}mathbf\{x\})\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & 0.9032273 & 0.0967727 & 1\\
2 & 4 & 3 & 2 & 0.0812446 & 0.9187554 & 2\\
3 & 7 & 8 & 2 & 0.6812088 & 0.3187912 & 1\\
4 & 8 & 6 & 2 & 0.0212004 & 0.9787996 & 2\\
5 & 3 & 6 & 1 & 0.9760579 & 0.0239421 & 1\\
\addlinespace
6 & 2 & 5 & 1 & 0.9752562 & 0.0247438 & 1\\
7 & 6 & 6 & 1 & 0.3065644 & 0.6934356 & 2\\
8 & 9 & 6 & 2 & 0.0047713 & 0.9952287 & 2\\
9 & 5 & 4 & 2 & 0.0838007 & 0.9161993 & 2\\
\bottomrule
\end{tabular}
\end{table}

패키지 \texttt{MASS}내의 함수 \texttt{lda}를 통해 위 Table \ref{tab:lda-posterior-result} 결과를 간편하게 얻을 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lda\_fit }\OtherTok{\textless{}{-}}\NormalTok{ MASS}\SpecialCharTok{::}\FunctionTok{lda}\NormalTok{(class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, train\_df)}

\NormalTok{train\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{bind\_cols}\NormalTok{(}
  \FunctionTok{predict}\NormalTok{(lda\_fit, train\_df)}\SpecialCharTok{$}\NormalTok{posterior }\SpecialCharTok{\%\textgreater{}\%} 
    \StringTok{\textasciigrave{}}\AttributeTok{colnames\textless{}{-}}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{"p"}\NormalTok{, }\FunctionTok{colnames}\NormalTok{(.))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as\_data\_frame}\NormalTok{()}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{predicted\_class =} \FunctionTok{predict}\NormalTok{(lda\_fit, .)}\SpecialCharTok{$}\NormalTok{class}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 9 x 7
##      id    x1    x2 class      p1     p2 predicted_class
##   <int> <dbl> <dbl> <fct>   <dbl>  <dbl> <fct>          
## 1     1     5     7 1     0.903   0.0968 1              
## 2     2     4     3 2     0.0812  0.919  2              
## 3     3     7     8 2     0.681   0.319  1              
## 4     4     8     6 2     0.0212  0.979  2              
## 5     5     3     6 1     0.976   0.0239 1              
## 6     6     2     5 1     0.975   0.0247 1              
## 7     7     6     6 1     0.307   0.693  2              
## 8     8     9     6 2     0.00477 0.995  2              
## 9     9     5     4 2     0.0838  0.916  2
\end{verbatim}

위 결과들은 교재 \citep{jun2012datamining}의 예제 결과와는 다소 차이가 있는데, 이는 교재에서는 사전확률을 학습표본 내 비율 대신 \(\pi_1 = \pi_2 = 0.5\)로 지정하였기 때문이다. 교재와 동일한 결과는 아래의 스크립트처럼 \texttt{lda} 함수 실행 시 사전확률 파리미터 \texttt{prior}의 값을 지정함으로써 얻을 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lda\_fit\_equal\_prior }\OtherTok{\textless{}{-}}\NormalTok{ MASS}\SpecialCharTok{::}\FunctionTok{lda}\NormalTok{(class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, train\_df, }\AttributeTok{prior =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{, }\DecValTok{1}\SpecialCharTok{/}\DecValTok{2}\NormalTok{))}

\NormalTok{train\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{bind\_cols}\NormalTok{(}
  \FunctionTok{predict}\NormalTok{(lda\_fit\_equal\_prior, train\_df)}\SpecialCharTok{$}\NormalTok{posterior }\SpecialCharTok{\%\textgreater{}\%} 
    \StringTok{\textasciigrave{}}\AttributeTok{colnames\textless{}{-}}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{"p"}\NormalTok{, }\FunctionTok{colnames}\NormalTok{(.))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as\_data\_frame}\NormalTok{()}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{predicted\_class =} \FunctionTok{predict}\NormalTok{(lda\_fit\_equal\_prior, .)}\SpecialCharTok{$}\NormalTok{class}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{rep}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\FunctionTok{dim}\NormalTok{(lda\_posterior\_result\_df)[}\DecValTok{2}\NormalTok{]),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}\NormalTok{,}
                \StringTok{\textquotesingle{}실제범주\textquotesingle{}}\NormalTok{, }
                \StringTok{\textquotesingle{}$P(y = 1 | }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$\textquotesingle{}}\NormalTok{, }
                \StringTok{\textquotesingle{}$P(y = 2 | }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$\textquotesingle{}}\NormalTok{,}
                \StringTok{\textquotesingle{}추정범주\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}학습표본에 대한 LDA 적용 결과: 사후확률 및 추정범주 (사전확률 = 0.5)\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:lda-posterior-result-equal-prior}학습표본에 대한 LDA 적용 결과: 사후확률 및 추정범주 (사전확률 = 0.5)}
\centering
\begin{tabular}[t]{rrrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$P(y = 1 | \textbackslash{}mathbf\{x\})\$ & \$P(y = 2 | \textbackslash{}mathbf\{x\})\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & 0.9210538 & 0.0789462 & 1\\
2 & 4 & 3 & 2 & 0.0995341 & 0.9004659 & 2\\
3 & 7 & 8 & 2 & 0.7275992 & 0.2724008 & 1\\
4 & 8 & 6 & 2 & 0.0263608 & 0.9736392 & 2\\
5 & 3 & 6 & 1 & 0.9807542 & 0.0192458 & 1\\
\addlinespace
6 & 2 & 5 & 1 & 0.9801065 & 0.0198935 & 1\\
7 & 6 & 6 & 1 & 0.3559269 & 0.6440731 & 2\\
8 & 9 & 6 & 2 & 0.0059571 & 0.9940429 & 2\\
9 & 5 & 4 & 2 & 0.1026013 & 0.8973987 & 2\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{lda-misclassification-cost}{%
\section{오분류비용을 고려한 분류규칙}\label{lda-misclassification-cost}}

위 Table \ref{tab:lda-posterior-result}의 객체 3, 7와 같이 선형분류함수가 모든 객체의 범주를 정확하게 추정하지 못하고 오분류가 발생하는 경우가 있다. 이 때 다음과 같이 두 종류의 오분류 비용이 있다고 가정하자.

\begin{itemize}
\tightlist
\item
  \(C(1 \, | \, 2)\): 범주 2를 1로 잘못 분류 시 초래 비용
\item
  \(C(2 \, | \, 1)\): 범주 1를 2로 잘못 분류 시 초래 비용
\end{itemize}

이 때 총 기대 오분류 비용은 다음과 같다.

\begin{equation}
C(1 \, | \, 2) \pi_2 \int_{\mathbf{x} \in R_1} f_2(\mathbf{x}) d\mathbf{x} + C(2 \, | \, 1) \pi_1 \int_{\mathbf{x} \in R_2} f_1(\mathbf{x}) d\mathbf{x}
\label{eq:expected-misclassification-cost}
\end{equation}

여기에서 \(R_1 \subset \mathbb{R}^p, R_2 = \mathbb{R}^p - R_{1}\)는 판별함수에 의해 각각 범주 1, 2로 분류되는 판별변수 영역을 나타낸다. 즉,

\begin{equation*}
\hat{y} = \begin{cases}
    1, & \text{if } \mathbf{x} \in R_1  \\
    2, & \text{otherwise}
\end{cases}
\end{equation*}

식 \eqref{eq:expected-misclassification-cost}을 최소화하는 영역 \(R_1, R_2\)는 아래와 같다.

\begin{eqnarray*}
R_1 &=& \left\{\mathbf{x} \in \mathbb{R}^p \, :  \, \frac{f_1(\mathbf{x})}{f_2(\mathbf{x})} \ge \frac{\pi_2}{\pi_1} \left( \frac{C(1 \, | \, 2)}{C(2 \, | \, 1)} \right) \right\}\\
R_2 &=& \left\{\mathbf{x} \in \mathbb{R}^p \, :  \, \frac{f_1(\mathbf{x})}{f_2(\mathbf{x})} < \frac{\pi_2}{\pi_1} \left( \frac{C(1 \, | \, 2)}{C(2 \, | \, 1)} \right) \right\}
\end{eqnarray*}

위 중 \(R_1\)에 대한 식을 아래와 같이 단계적으로 전개할 수 있다.

\begin{eqnarray*}
R_1 &=& \left\{\mathbf{x} \in \mathbb{R}^p \, :  \, \frac{\pi_1 f_1(\mathbf{x})}{\pi_2 f_2(\mathbf{x})} \ge \frac{C(1 \, | \, 2)}{C(2 \, | \, 1)} \right\}\\
&=& \left\{\mathbf{x} \in \mathbb{R}^p \, :  \, \frac{\frac{\pi_1 f_1(\mathbf{x})}{\pi_1 f_1(\mathbf{x}) + \pi_2 f_2(\mathbf{x})}}{\frac{\pi_2 f_2(\mathbf{x})}{\pi_1 f_1(\mathbf{x}) + \pi_2 f_2(\mathbf{x})}} \ge \frac{C(1 \, | \, 2)}{C(2 \, | \, 1)} \right\}\\
&=& \left\{\mathbf{x} \in \mathbb{R}^p \, :  \, \frac{P(y = 1 \, | \, \mathbf{x})}{P(y = 2 \, | \, \mathbf{x})} \ge \frac{C(1 \, | \, 2)}{C(2 \, | \, 1)} \right\}\\
&=& \left\{\mathbf{x} \in \mathbb{R}^p \, :  \, C(2 \, | \, 1) P(y = 1 \, | \, \mathbf{x}) \ge C(1 \, | \, 2) P(y = 2 \, | \, \mathbf{x}) \right\}
\end{eqnarray*}

따라서 오분류비용을 고려한 분류규칙은 1) 사후확률에 오분류 비용을 곱한 뒤, 2) 그 값이 큰 범주로 분류하여 오분류비용을 최소화한다.

Table \ref{tab:lda-posterior-result}에 오분류비용 \(C(1 \, | \, 2) = 1, C(2 \, | \, 1) = 5\)를 적용한 결과는 아래와 같이 구할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lda\_fit }\OtherTok{\textless{}{-}}\NormalTok{ MASS}\SpecialCharTok{::}\FunctionTok{lda}\NormalTok{(class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, train\_df)}

\NormalTok{misclassification\_cost }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{)}

\NormalTok{lda\_unequal\_cost\_result\_df }\OtherTok{\textless{}{-}}\NormalTok{ train\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{bind\_cols}\NormalTok{(}
  \FunctionTok{predict}\NormalTok{(lda\_fit, train\_df)}\SpecialCharTok{$}\NormalTok{posterior }\SpecialCharTok{\%*\%} \FunctionTok{diag}\NormalTok{(misclassification\_cost) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{as\_data\_frame}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \StringTok{\textasciigrave{}}\AttributeTok{names\textless{}{-}}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{"s"}\NormalTok{, lda\_fit}\SpecialCharTok{$}\NormalTok{lev)) }
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{predicted\_class =} \FunctionTok{factor}\NormalTok{(}\FunctionTok{if\_else}\NormalTok{(s1 }\SpecialCharTok{\textgreater{}=}\NormalTok{ s2, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{    )}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  lda\_unequal\_cost\_result\_df,}
  \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{rep}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\FunctionTok{dim}\NormalTok{(lda\_unequal\_cost\_result\_df)[}\DecValTok{2}\NormalTok{]),}
  \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}\NormalTok{,}
                \StringTok{\textquotesingle{}실제범주\textquotesingle{}}\NormalTok{, }
                \StringTok{\textquotesingle{}$C(2 }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{, | }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{, 1) P(y = 1 | }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$\textquotesingle{}}\NormalTok{, }
                \StringTok{\textquotesingle{}$C(1 }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{, | }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{, 2) P(y = 2 | }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$\textquotesingle{}}\NormalTok{,}
                \StringTok{\textquotesingle{}추정범주\textquotesingle{}}\NormalTok{),}
  \AttributeTok{caption =} \StringTok{\textquotesingle{}학습표본에 대한 오분류 비용을 고려한 LDA 적용 결과\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:lda-unequal-cost-result}학습표본에 대한 오분류 비용을 고려한 LDA 적용 결과}
\centering
\begin{tabular}[t]{rrrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$C(2 \textbackslash{}, | \textbackslash{}, 1) P(y = 1 | \textbackslash{}mathbf\{x\})\$ & \$C(1 \textbackslash{}, | \textbackslash{}, 2) P(y = 2 | \textbackslash{}mathbf\{x\})\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & 4.5161363 & 0.0967727 & 1\\
2 & 4 & 3 & 2 & 0.4062232 & 0.9187554 & 2\\
3 & 7 & 8 & 2 & 3.4060438 & 0.3187912 & 1\\
4 & 8 & 6 & 2 & 0.1060019 & 0.9787996 & 2\\
5 & 3 & 6 & 1 & 4.8802897 & 0.0239421 & 1\\
\addlinespace
6 & 2 & 5 & 1 & 4.8762808 & 0.0247438 & 1\\
7 & 6 & 6 & 1 & 1.5328222 & 0.6934356 & 1\\
8 & 9 & 6 & 2 & 0.0238567 & 0.9952287 & 2\\
9 & 5 & 4 & 2 & 0.4190033 & 0.9161993 & 2\\
\bottomrule
\end{tabular}
\end{table}

위 Table \ref{tab:lda-unequal-cost-result}에서 보는 바와 같이 오분류 객체는 3로, 이전 장의 Table \ref{tab:lda-posterior-result}에 비해 실제범주가 1인 객체를 더 정확하게 분류함을 확인할 수 있다. 범주 1인 객체를 범주 2로 분류할 때 발생하는 비용이 범주 2인 객체를 범주 1로 분류할 때 발생하는 비용보다 다섯 배나 크기 때문에, 오분류비용을 고려한 분류규칙은 실제 범주가 2인 객체를 범주 2로 정확하게 분류할 확률이 줄어든다 할지라도, 실제 범주가 1인 객체를 범주 1로 정확하게 분류하는 확률을 높이는 방향으로 학습된다.

\hypertarget{qda}{%
\section{이차판별분석}\label{qda}}

이차판별분석은 판별함수가 변수들에 대한 이차함수로 표현되는 경우인데, 각 범주에 대한 변수벡터 \(\mathbf{x}\)가 서로 다른 분산-공분산행렬을 갖는 다변량 정규분포를 따를 때 의사결정론에 의한 분류규칙으로부터 유도된다.

\hypertarget{qda-basic-script}{%
\subsection{기본 R 스크립트}\label{qda-basic-script}}

Table \ref{tab:da-train-data-table}의 학습표본에 대해 이차판별분석을 적용하는 R 스크립트는 아래에 보이는 것과 같이 \texttt{MASS} 패키지의 \texttt{qda} 함수를 사용한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qda\_fit }\OtherTok{\textless{}{-}}\NormalTok{ MASS}\SpecialCharTok{::}\FunctionTok{qda}\NormalTok{(class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, train\_df)}

\FunctionTok{print}\NormalTok{(qda\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## qda(class ~ x1 + x2, data = train_df)
## 
## Prior probabilities of groups:
##         1         2 
## 0.4444444 0.5555556 
## 
## Group means:
##    x1  x2
## 1 4.0 6.0
## 2 6.6 5.4
\end{verbatim}

\hypertarget{qda-function}{%
\subsection{이차 판별함수}\label{qda-function}}

각 범주의 확률밀도함수는 아래와 같이 다변량 정규분포로 정의된다.

\begin{equation}
f_k(\mathbf{x}) = \frac{1}{(2\pi)^{p/2}|\boldsymbol\Sigma_k|^{1/2}} \exp \{ -\frac{1}{2} \left(\mathbf{x} - \boldsymbol\mu_k\right)^\top \boldsymbol\Sigma_k^{-1} \left(\mathbf{x} - \boldsymbol\mu_k\right) \}
\label{eq:qda-mv-gaussian-dist}
\end{equation}

위 식 \eqref{eq:qda-mv-gaussian-dist}이 선형판별함수에서 사용한 식 \eqref{eq:mv-gaussian-dist}과 다른 부분은 분산-공분산분포 \(\boldsymbol\Sigma_k\)가 범주 \(k\)에 대해 각각 정의된다는 점이다.

이 경우 각 범주에 대한 판별함수는 아래와 같이 정의된다.

\begin{equation}
u_k(\mathbf{x}) = - \frac{1}{2} (\mathbf{x} - \boldsymbol\mu_k)^\top \boldsymbol\Sigma_k^{-1} (\mathbf{x} - \boldsymbol\mu_k) - \frac{1}{2} \ln \left| \boldsymbol\Sigma_k \right| + \ln \pi_k
\label{eq:qda-discriminant-function}
\end{equation}

데이터 행렬 \(X = (\mathbf{x}_1, \mathbf{x}_2, \cdots , \mathbf{x}_N)\)의 각 객체에 대한 판별함수값을 얻는 함수를 아래와 같이 구현할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qda\_discriminant\_func }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(X, mu, Sigma, pi) \{}
\NormalTok{  Sigma\_inv\_sqrt }\OtherTok{\textless{}{-}} \FunctionTok{chol}\NormalTok{(}\FunctionTok{solve}\NormalTok{(Sigma))}
  \SpecialCharTok{{-}} \FloatTok{0.5} \SpecialCharTok{*} \FunctionTok{rowSums}\NormalTok{((}\FunctionTok{t}\NormalTok{(X }\SpecialCharTok{{-}}\NormalTok{ mu) }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(Sigma\_inv\_sqrt))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{{-}} \FloatTok{0.5} \SpecialCharTok{*} \FunctionTok{log}\NormalTok{(}\FunctionTok{det}\NormalTok{(Sigma)) }\SpecialCharTok{+} \FunctionTok{log}\NormalTok{(pi)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{qda-discriminant-rule}{%
\subsection{이차판별함수에 의한 분류}\label{qda-discriminant-rule}}

분류기준은 선형판별분석과 마찬가지로 판별함수값이 큰 범주로 분류한다.

\begin{equation*}
\hat{y} = \begin{cases}
    1, & \text{if } u_1(\mathbf{x}) \ge u_2(\mathbf{x})  \\
    2, & \text{otherwise}
\end{cases}
\end{equation*}

Table \ref{tab:da-train-data-table}의 학습표본에 대해 이차판별함수값을 계산하고 범주를 추정하면 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qda\_discriminant\_result\_df }\OtherTok{\textless{}{-}}\NormalTok{ train\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mutate}\NormalTok{(}
  \AttributeTok{u1 =} \FunctionTok{qda\_discriminant\_func}\NormalTok{(}
\NormalTok{      .[}\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{t}\NormalTok{(),}
\NormalTok{      mu\_hat[}\DecValTok{1}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unlist}\NormalTok{(),}
\NormalTok{      S\_within\_group[[}\DecValTok{1}\NormalTok{]],}
\NormalTok{      n\_obs}\SpecialCharTok{$}\NormalTok{pi[}\DecValTok{1}\NormalTok{]}
\NormalTok{      ),}
  \AttributeTok{u2 =} \FunctionTok{qda\_discriminant\_func}\NormalTok{(}
\NormalTok{      .[}\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{t}\NormalTok{(),}
\NormalTok{      mu\_hat[}\DecValTok{2}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unlist}\NormalTok{(),}
\NormalTok{      S\_within\_group[[}\DecValTok{2}\NormalTok{]],}
\NormalTok{      n\_obs}\SpecialCharTok{$}\NormalTok{pi[}\DecValTok{2}\NormalTok{]}
\NormalTok{      )}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{predicted\_class =} \FunctionTok{factor}\NormalTok{(}\FunctionTok{if\_else}\NormalTok{(u1 }\SpecialCharTok{\textgreater{}=}\NormalTok{ u2, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{  )}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  qda\_discriminant\_result\_df,}
  \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{rep}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\FunctionTok{dim}\NormalTok{(qda\_discriminant\_result\_df)[}\DecValTok{2}\NormalTok{]),}
  \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}\NormalTok{,}
                \StringTok{\textquotesingle{}실제범주\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$u\_1(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$u\_2(}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$\textquotesingle{}}\NormalTok{,}
                \StringTok{\textquotesingle{}추정범주\textquotesingle{}}\NormalTok{),}
  \AttributeTok{caption =} \StringTok{\textquotesingle{}학습표본에 대한 QDA 적용 결과: 판별함수값 및 추정범주\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:qda-discriminant-result}학습표본에 대한 QDA 적용 결과: 판별함수값 및 추정범주}
\centering
\begin{tabular}[t]{rrrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$u\_1(\textbackslash{}mathbf\{x\})\$ & \$u\_2(\textbackslash{}mathbf\{x\})\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & -1.729447 & -3.950639 & 1\\
2 & 4 & 3 & 2 & -13.183993 & -2.497284 & 2\\
3 & 7 & 8 & 2 & -3.911266 & -3.145402 & 2\\
4 & 8 & 6 & 2 & -5.274902 & -1.868806 & 2\\
5 & 3 & 6 & 1 & -1.183993 & -5.764060 & 1\\
\addlinespace
6 & 2 & 5 & 1 & -1.729447 & -6.202685 & 1\\
7 & 6 & 6 & 1 & -2.002175 & -1.934273 & 2\\
8 & 9 & 6 & 2 & -7.729447 & -2.582391 & 2\\
9 & 5 & 4 & 2 & -8.274902 & -1.927726 & 2\\
\bottomrule
\end{tabular}
\end{table}

위 Table \ref{tab:qda-discriminant-result}에서 보듯이 모든 학습객체가 올바로 분류되고 있다.

또한 선형판별분석의 경우와 마찬가지로 사후확률 비교를 통한 범주 분류를 수행할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{qda\_posterior\_result\_df }\OtherTok{\textless{}{-}}\NormalTok{ train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{f1 =}\NormalTok{ mvtnorm}\SpecialCharTok{::}\FunctionTok{dmvnorm}\NormalTok{(}
\NormalTok{      .[}\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)],}
\NormalTok{      mu\_hat[}\DecValTok{1}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unlist}\NormalTok{(),}
\NormalTok{      S\_within\_group[[}\DecValTok{1}\NormalTok{]]),}
    \AttributeTok{f2 =}\NormalTok{ mvtnorm}\SpecialCharTok{::}\FunctionTok{dmvnorm}\NormalTok{(}
\NormalTok{      .[}\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)],}
\NormalTok{      mu\_hat[}\DecValTok{2}\NormalTok{, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unlist}\NormalTok{(),}
\NormalTok{      S\_within\_group[[}\DecValTok{2}\NormalTok{]]),}
    \AttributeTok{f =}\NormalTok{ n\_obs}\SpecialCharTok{$}\NormalTok{pi[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ f1 }\SpecialCharTok{+}\NormalTok{ n\_obs}\SpecialCharTok{$}\NormalTok{pi[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ f2}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{p1 =}\NormalTok{ n\_obs}\SpecialCharTok{$}\NormalTok{pi[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ f1 }\SpecialCharTok{/}\NormalTok{ f,}
    \AttributeTok{p2 =}\NormalTok{ n\_obs}\SpecialCharTok{$}\NormalTok{pi[}\DecValTok{2}\NormalTok{] }\SpecialCharTok{*}\NormalTok{ f2 }\SpecialCharTok{/}\NormalTok{ f}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{predicted\_class =} \FunctionTok{factor}\NormalTok{(}\FunctionTok{if\_else}\NormalTok{(p1 }\SpecialCharTok{\textgreater{}=}\NormalTok{ p2, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}
\NormalTok{    id, x1, x2, class, p1, p2, predicted\_class}
\NormalTok{  )}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  qda\_posterior\_result\_df,}
  \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{rep}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\FunctionTok{dim}\NormalTok{(qda\_posterior\_result\_df)[}\DecValTok{2}\NormalTok{]),}
  \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}\NormalTok{,}
                \StringTok{\textquotesingle{}실제범주\textquotesingle{}}\NormalTok{, }
                \StringTok{\textquotesingle{}$P(y = 1 | }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$\textquotesingle{}}\NormalTok{, }
                \StringTok{\textquotesingle{}$P(y = 2 | }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{x\})$\textquotesingle{}}\NormalTok{,}
                \StringTok{\textquotesingle{}추정범주\textquotesingle{}}\NormalTok{),}
  \AttributeTok{caption =} \StringTok{\textquotesingle{}학습표본에 대한 QDA 적용 결과: 사후확률 및 추정범주\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:qda-posterior-result}학습표본에 대한 QDA 적용 결과: 사후확률 및 추정범주}
\centering
\begin{tabular}[t]{rrrrrrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$ & 실제범주 & \$P(y = 1 | \textbackslash{}mathbf\{x\})\$ & \$P(y = 2 | \textbackslash{}mathbf\{x\})\$ & 추정범주\\
\midrule
1 & 5 & 7 & 1 & 0.9021365 & 0.0978635 & 1\\
2 & 4 & 3 & 2 & 0.0000228 & 0.9999772 & 2\\
3 & 7 & 8 & 2 & 0.3173746 & 0.6826254 & 2\\
4 & 8 & 6 & 2 & 0.0321055 & 0.9678945 & 2\\
5 & 3 & 6 & 1 & 0.9898499 & 0.0101501 & 1\\
\addlinespace
6 & 2 & 5 & 1 & 0.9887184 & 0.0112816 & 1\\
7 & 6 & 6 & 1 & 0.4830310 & 0.5169690 & 2\\
8 & 9 & 6 & 2 & 0.0057829 & 0.9942171 & 2\\
9 & 5 & 4 & 2 & 0.0017486 & 0.9982514 & 2\\
\bottomrule
\end{tabular}
\end{table}

이 또한 \texttt{MASS} 패키지의 \texttt{predict.qda} 함수를 통해 아래와 같이 동일한 결과값을 보다 간편하게 얻을 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{bind\_cols}\NormalTok{(}
  \FunctionTok{predict}\NormalTok{(qda\_fit, train\_df)}\SpecialCharTok{$}\NormalTok{posterior }\SpecialCharTok{\%\textgreater{}\%} 
    \StringTok{\textasciigrave{}}\AttributeTok{colnames\textless{}{-}}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(}\StringTok{"p"}\NormalTok{, }\FunctionTok{colnames}\NormalTok{(.))) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as\_data\_frame}\NormalTok{()}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{predicted\_class =} \FunctionTok{predict}\NormalTok{(qda\_fit, .)}\SpecialCharTok{$}\NormalTok{class}
\NormalTok{    )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 9 x 7
##      id    x1    x2 class        p1     p2 predicted_class
##   <int> <dbl> <dbl> <fct>     <dbl>  <dbl> <fct>          
## 1     1     5     7 1     0.902     0.0979 1              
## 2     2     4     3 2     0.0000228 1.00   2              
## 3     3     7     8 2     0.317     0.683  2              
## 4     4     8     6 2     0.0321    0.968  2              
## 5     5     3     6 1     0.990     0.0102 1              
## 6     6     2     5 1     0.989     0.0113 1              
## 7     7     6     6 1     0.483     0.517  2              
## 8     8     9     6 2     0.00578   0.994  2              
## 9     9     5     4 2     0.00175   0.998  2
\end{verbatim}

\hypertarget{da-multiclass}{%
\section{세 범주 이상의 분류}\label{da-multiclass}}

\hypertarget{mutliclass-da-basic-script}{%
\subsection{기본 R 스크립트}\label{mutliclass-da-basic-script}}

3개의 범주를 지닌 붓꽃(iris) 데이터에 대해 선형판별분석을 적용하는 R 스크립트는 아래와 같다. 본 예제에서는 각 범주별 50개 데이터 중 첫 30개 관측치만을 학습표본으로 삼아 판별함수를 유도한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris\_train\_df }\OtherTok{\textless{}{-}}\NormalTok{ datasets}\SpecialCharTok{::}\NormalTok{iris }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{x1 =}\NormalTok{ Sepal.Length,}
         \AttributeTok{x2 =}\NormalTok{ Sepal.Width,}
         \AttributeTok{x3 =}\NormalTok{ Petal.Length,}
         \AttributeTok{x4 =}\NormalTok{ Petal.Width,}
         \AttributeTok{class =}\NormalTok{ Species) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(class) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{30}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{id =} \FunctionTok{row\_number}\NormalTok{())}

\NormalTok{iris\_lda\_fit }\OtherTok{\textless{}{-}}\NormalTok{ MASS}\SpecialCharTok{::}\FunctionTok{lda}\NormalTok{(class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ . }\SpecialCharTok{{-}}\NormalTok{id, iris\_train\_df)}

\FunctionTok{print}\NormalTok{(iris\_lda\_fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## lda(class ~ . - id, data = iris_train_df)
## 
## Prior probabilities of groups:
##     setosa versicolor  virginica 
##  0.3333333  0.3333333  0.3333333 
## 
## Group means:
##                  x1       x2       x3        x4
## setosa     5.026667 3.450000 1.473333 0.2466667
## versicolor 6.070000 2.790000 4.333333 1.3533333
## virginica  6.583333 2.933333 5.603333 2.0066667
## 
## Coefficients of linear discriminants:
##           LD1        LD2
## x1  0.5711419 -1.2397647
## x2  1.8752911  3.0223980
## x3 -1.7361767  0.3159667
## x4 -3.4672646  1.3954748
## 
## Proportion of trace:
##    LD1    LD2 
## 0.9929 0.0071
\end{verbatim}

\hypertarget{mutliclass-generalized-discriminant-function}{%
\subsection{일반화된 판별함수}\label{mutliclass-generalized-discriminant-function}}

\(K (> 2)\)개의 범주가 있는 경우에 대한 판별분석은 아래와 같이 일반화된다.

\begin{itemize}
\tightlist
\item
  \(\pi_k\): 범주 \(k\)에 속할 사전확률, \(k = 1, 2, \cdots, K\)
\item
  \(C(k' \, | \, k) \ge 0\): 실제 범주 \(k\)에 속하는 데 범주 \(k'\)로 분류할 때 소요 비용 (\(C(k' \, | \, k) = 0 \text{ if } k' = k\))
\item
  \(f_k(\mathbf{x})\): 범주 \(k\)에 속하는 \(\mathbf{x}\)의 확률밀도함수
\item
  \(R_k \subset \mathbb{R}^p\): 범주 \(k\)로 분류되는 \(\mathbf{x}\)의 영역
\item
  \(P(k' \, | \, k) = \int_{\mathbf{x} \in R_{k'}} f_k(\mathbf{x}) d\mathbf{x}\): 실제범주 \(k\)에 속하는 데 범주 \(k'\)로 분류할 확률
\end{itemize}

이 때, 총 기대 오분류 비용은 아래와 같다.

\begin{equation*}
\sum_{k = 1}^{K} \pi_k \sum_{k' \neq k} C(k' \, | \, k) \int_{\mathbf{x} \in R_{k'}} f_k(\mathbf{x}) d\mathbf{x}
\end{equation*}

따라서 분류문제는 위 총 기대 오분류 비용을 최소화하는 \(R_1, \cdots, R_K\)를 찾는 것이다.

우선, 범주를 고려하지 않은 \(\mathbf{x}\)의 확률밀도함수는 아래와 같이 정의된다.

\begin{equation*}
f(\mathbf{x}) = \sum_{k=1}^{K} \pi_k f_k(\mathbf{x})
\end{equation*}

베이즈 정리에 의하여, 변수 \(\mathbf{x}\)가 주어졌을 때 범주 \(k\)에 속할 사후확률은 아래와 같다.

\begin{equation*}
P(y = k \,|\, \mathbf{x}) = \frac{\pi_k f_k(\mathbf{x})}{f(\mathbf{x})}
\end{equation*}

오분류비용이 동일한 경우에는 각 객체에 대해 위의 사후확률이 가장 큰 범주로 추정한다. 위 식에서

\begin{equation*}
P(y = k \,|\, \mathbf{x}) \propto \pi_k f_k(\mathbf{x})
\end{equation*}

이므로, 아래와 같이 범주가 추정된다.

\begin{equation*}
\hat{y} = {arg\,max}_{k} \pi_k f_k(\mathbf{x})
\end{equation*}

앞 장들에서 살펴본 것과 마찬가지로, 선형판별분석의 경우 각 범주의 확률밀도함수 \(f_k(\mathbf{x})\)가 동일 분산-공분산행렬을 가정하며, 이차판별분석의 경우 서로 다른 분산-공분산행렬을 가정한다.

아래 스크립트는 \texttt{MASS} 패키지의 \texttt{lda} 함수를 통해 각 범주에 속할 사후확률과 범주 추정값을 얻는 과정을 보여준다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris\_lda\_fit }\OtherTok{\textless{}{-}}\NormalTok{ MASS}\SpecialCharTok{::}\FunctionTok{lda}\NormalTok{(class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2 }\SpecialCharTok{+}\NormalTok{ x3 }\SpecialCharTok{+}\NormalTok{ x4, iris\_train\_df)}

\NormalTok{iris\_lda\_result }\OtherTok{\textless{}{-}}\NormalTok{ iris\_train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_cols}\NormalTok{(}
    \FunctionTok{predict}\NormalTok{(iris\_lda\_fit, .)}\SpecialCharTok{$}\NormalTok{posterior }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{as\_data\_frame}\NormalTok{()}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{predicted\_class =} \FunctionTok{predict}\NormalTok{(iris\_lda\_fit, .)}\SpecialCharTok{$}\NormalTok{class}
\NormalTok{  )}

\FunctionTok{print}\NormalTok{(iris\_lda\_result)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 90 x 10
##       x1    x2    x3    x4 class     id setosa versicolor virginica
##    <dbl> <dbl> <dbl> <dbl> <fct>  <int>  <dbl>      <dbl>     <dbl>
##  1   5.1   3.5   1.4   0.2 setosa     1   1      5.57e-22  6.34e-42
##  2   4.9   3     1.4   0.2 setosa     2   1      3.32e-17  5.67e-36
##  3   4.7   3.2   1.3   0.2 setosa     3   1      2.75e-19  2.14e-38
##  4   4.6   3.1   1.5   0.2 setosa     4   1      8.12e-17  5.62e-35
##  5   5     3.6   1.4   0.2 setosa     5   1      1.14e-22  1.25e-42
##  6   5.4   3.9   1.7   0.4 setosa     6   1      3.20e-21  4.38e-40
##  7   4.6   3.4   1.4   0.3 setosa     7   1      8.74e-19  4.07e-37
##  8   5     3.4   1.5   0.2 setosa     8   1      3.27e-20  1.62e-39
##  9   4.4   2.9   1.4   0.2 setosa     9   1.00   2.22e-15  3.42e-33
## 10   4.9   3.1   1.5   0.1 setosa    10   1      9.36e-19  4.85e-38
## # ... with 80 more rows, and 1 more variable: predicted_class <fct>
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  iris\_lda\_result }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{select}\NormalTok{(id, class, predicted\_class,}
\NormalTok{           setosa, versicolor, virginica) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{filter}\NormalTok{(class }\SpecialCharTok{!=}\NormalTok{ predicted\_class),}
  \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{rep}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\DecValTok{6}\NormalTok{),}
  \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}실제범주\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}추정범주\textquotesingle{}}\NormalTok{,}
                \StringTok{\textquotesingle{}setosa\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}versicolor\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}virginica\textquotesingle{}}\NormalTok{),}
  \AttributeTok{caption =} \StringTok{\textquotesingle{}붓꽃 학습표본에 대한 LDA 적용 결과 {-} 오분류 객체 사후 확률\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:iris-lda}붓꽃 학습표본에 대한 LDA 적용 결과 - 오분류 객체 사후 확률}
\centering
\begin{tabular}[t]{rrrrrr}
\toprule
객체번호 & 실제범주 & 추정범주 & setosa & versicolor & virginica\\
\midrule
51 & versicolor & virginica & 0 & 0.3088912 & 0.6911088\\
\bottomrule
\end{tabular}
\end{table}

아래 스크립트는 \texttt{MASS} 패키지의 \texttt{qda} 함수를 통해 각 범주에 속할 사후확률과 범주 추정값을 얻는 과정을 보여준다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iris\_qda\_fit }\OtherTok{\textless{}{-}}\NormalTok{ MASS}\SpecialCharTok{::}\FunctionTok{qda}\NormalTok{(class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2 }\SpecialCharTok{+}\NormalTok{ x3 }\SpecialCharTok{+}\NormalTok{ x4, iris\_train\_df)}

\NormalTok{iris\_qda\_result }\OtherTok{\textless{}{-}}\NormalTok{ iris\_train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_cols}\NormalTok{(}
    \FunctionTok{predict}\NormalTok{(iris\_qda\_fit, .)}\SpecialCharTok{$}\NormalTok{posterior }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{as\_data\_frame}\NormalTok{()}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{predicted\_class =} \FunctionTok{predict}\NormalTok{(iris\_qda\_fit, .)}\SpecialCharTok{$}\NormalTok{class}
\NormalTok{  )}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  iris\_qda\_result }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{select}\NormalTok{(id, class, predicted\_class,}
\NormalTok{           setosa, versicolor, virginica) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{filter}\NormalTok{(class }\SpecialCharTok{!=}\NormalTok{ predicted\_class),}
  \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{rep}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\DecValTok{6}\NormalTok{),}
  \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}실제범주\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}추정범주\textquotesingle{}}\NormalTok{,}
                \StringTok{\textquotesingle{}setosa\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}versicolor\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}virginica\textquotesingle{}}\NormalTok{),}
  \AttributeTok{caption =} \StringTok{\textquotesingle{}붓꽃 학습표본에 대한 QDA 적용 결과 {-} 오분류 객체 사후 확률\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:iris-qda}붓꽃 학습표본에 대한 QDA 적용 결과 - 오분류 객체 사후 확률}
\centering
\begin{tabular}[t]{rrrrrr}
\toprule
객체번호 & 실제범주 & 추정범주 & setosa & versicolor & virginica\\
\midrule
51 & versicolor & virginica & 0 & 0.4274712 & 0.5725288\\
\bottomrule
\end{tabular}
\end{table}

위 결과에서 선형판별분석과 이차판별분석은 동일한 객체를 오분류한다. 해당 객체의 실제 범주에 대한 사후확률은 이차판별분석 결과에서 보다 높게 나타난다.

\hypertarget{tree-based-method}{%
\chapter{트리기반 기법}\label{tree-based-method}}

\hypertarget{cart-overview}{%
\section{CART 개요}\label{cart-overview}}

CART(Classification and Regression Trees)는 \citet{breiman1984classification} 에 의하여 개발된 것인데, 각 (독립)변수를 이분화(binary split)하는 과정을 반복하여 트리 형태를 형성함으로써 분류(종속변수가 범주형일 때) 또는 회귀분석(종속변수가 연속형일 때)을 수행하는 것이다. 이 때 독립변수들은 범주형 또는 연속형 모두에 적용될 수 있다. 본 장에서는 분류를 위한 목적만을 설명하도록 한다.

\hypertarget{cart-packages-install}{%
\section{필요 R package 설치}\label{cart-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.3.1\\
\hline
rpart & 4.1-15\\
\hline
rpart.plot & 3.0.9\\
\hline
\end{tabular}

\hypertarget{cart-build}{%
\section{CART 트리 생성}\label{cart-build}}

\hypertarget{cart-basic-r-script}{%
\subsection{기본 R 스크립트}\label{cart-basic-r-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{x1 =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{),}
  \AttributeTok{x2 =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{6}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{),}
  \AttributeTok{class =} \FunctionTok{as.factor}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:tree-train-data-table}학습표본 데이터}
\centering
\begin{tabular}[t]{rrr}
\toprule
x1 & x2 & class\\
\midrule
1 & 4 & 1\\
2 & 6 & 1\\
2 & 5 & 1\\
2 & 4 & 2\\
2 & 3 & 2\\
\addlinespace
3 & 6 & 1\\
4 & 6 & 1\\
4 & 5 & 2\\
4 & 4 & 2\\
5 & 3 & 2\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:tree-train-data-table}와 같이 두 독립변수 \emph{x1}, \emph{x2}와 이분형 종속변수 \emph{class}의 관측값으로 이루어진 10개의 학습표본을 \emph{train\_df}라는 data frame에 저장한다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(rpart)}
\FunctionTok{library}\NormalTok{(rpart.plot)}
\NormalTok{cart.est }\OtherTok{\textless{}{-}} \FunctionTok{rpart}\NormalTok{(}
\NormalTok{  class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2}
\NormalTok{  , }\AttributeTok{data =}\NormalTok{ train\_df}
\NormalTok{  , }\AttributeTok{method =} \StringTok{"class"}
\NormalTok{  , }\AttributeTok{parms =} \FunctionTok{list}\NormalTok{(}\AttributeTok{split =} \StringTok{"gini"}\NormalTok{)}
\NormalTok{  , }\AttributeTok{control =} \FunctionTok{rpart.control}\NormalTok{(}\AttributeTok{minsplit =} \DecValTok{2}
\NormalTok{                            , }\AttributeTok{minbucket =} \DecValTok{1}
\NormalTok{                            , }\AttributeTok{cp =} \DecValTok{0}
\NormalTok{                            , }\AttributeTok{xval =} \DecValTok{0}
\NormalTok{                            , }\AttributeTok{maxcompete =} \DecValTok{0}\NormalTok{)}
\NormalTok{  )}
\FunctionTok{rpart.plot}\NormalTok{(cart.est)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/cart-basic-1} 

}

\caption{CART 트리}\label{fig:cart-basic}
\end{figure}

\href{https://cran.r-project.org/web/packages/rpart/}{rpart} 라는 package를 기반으로, 두 변수 x1과 x2를 이용하여 이분형 종속변수 class를 분류하는 CART 트리를 생성할 수 있으며, \href{https://cran.r-project.org/web/packages/rpart.plot/}{rpart.plot} package를 이용하여 Figure \ref{fig:cart-basic}과 같이 시각화할 수 있다.

\hypertarget{cart-notation}{%
\subsection{기호 정의}\label{cart-notation}}

본 장에서 사용될 수학적 기호는 아래와 같다.

\begin{itemize}
\tightlist
\item
  \(T\): 트리
\item
  \(A(T)\): 트리 \(T\)의 최종노드의 집합
\item
  \(J\): 범주수
\item
  \(N\): 학습표본의 총 객체수
\item
  \(N_j\): 범주 \(j\)에 속한 객체 수
\item
  \(N(t)\): 노드 \(t\)에서의 객체수
\item
  \(N_j(t)\): 노드 \(t\)에서 범주 \(j\)에 속한 객체수
\item
  \(p(j,t)\): 임의의 객체가 범주 \(j\)와 노드 \(t\)에 속할 확률
\item
  \(p(t)\): 임의의 객체가 노드 \(t\)에 속할 확률
  \[p(t) = \sum_{j=1}^{J} p(j,t)\]
\item
  \(p(j|t)\): 임의의 객체가 노드 \(t\)에 속할 때 범주 \(j\)에 속할 조건부 확률
  \[p(j|t) = \frac{p(j,t)}{p(t)}, \quad \sum_{j=1}^{J} p(j|t) = 1\]
\end{itemize}

이 때, 각 확률은 학습표본에서 아래와 같이 추정할 수 있다.
\begin{align}
p(j,t) &\approx \frac{N_j(t)}{N}\\
p(t) &\approx \frac{N(t)}{N}\\
p(j|t) &\approx \frac{N_j(t)}{N(t)}
\end{align}

\hypertarget{cart-impurity}{%
\subsection{노드 및 트리의 불순도}\label{cart-impurity}}

\hypertarget{uxb178uxb4dcuxc758-uxbd88uxc21cuxb3c4}{%
\subsubsection{노드의 불순도}\label{uxb178uxb4dcuxc758-uxbd88uxc21cuxb3c4}}

CART는 지니 지수(Gini index)를 불순도 함수로 사용한다. 총 \(J\)개의 범주별 객체비율을 \(p_1, \cdots , p_J\)라 할 때 (\(\sum_{j=1}^{J} p_j = 1\)), 지니 지수는 식 \eqref{eq:gini-index}와 같다.

\begin{equation}
G(p_1, \cdots, p_J) = \sum_{j=1}^{J} p_j(1-p_j) = 1 - \sum_{j=1}^{J}p_j^2 \label{eq:gini-index}
\end{equation}

노드 \(t\)에서의 범주별 객체비율은 \(p(1|t), \cdots, p(J|t)\)이므로, 노드 \(t\)의 불순도는 식 \eqref{eq:node-impurity}와 같이 산출된다.

\begin{equation}
\begin{split}
i(t) &= 1 - \sum_{j=1}^{J} p(j|t)^2\\
&\approx 1 - \sum_{j=1}^{J} \left[\frac{N_j(t)}{N(t)}\right]^2
\end{split}
\label{eq:node-impurity}
\end{equation}

\hypertarget{uxd2b8uxb9ac-uxbd88uxc21cuxb3c4}{%
\subsubsection{트리 불순도}\label{uxd2b8uxb9ac-uxbd88uxc21cuxb3c4}}

트리 \(T\)의 불순도는 식 \eqref{eq:tree-impurity}와 같이 최종노드들의 불순도의 가중평균으로 정의된다.

\begin{equation}
I(T) = \sum_{t \in A(T)} i(t)p(t) \label{eq:tree-impurity}
\end{equation}

여기서
\[ I(t) = i(t)p(t) \]
라 하면, 다음이 성립한다.
\[ I(T) = \sum_{t \in A(T)} I(t) \]

\hypertarget{cart-split}{%
\subsection{분지기준}\label{cart-split}}

뿌리 노드에서의 분지만을 살펴보기 위해 control parameter \emph{maxdepth}의 값을 1으로 설정한다. 이 경우, CART 알고리즘은 뿌리노드에서의 양 갈래 분지만을 선택한 뒤 종료된다. 아래 스크립트를 이용하여 뿌리노드에서 최적분지된 트리를 얻는다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cart.firstsplit }\OtherTok{\textless{}{-}} \FunctionTok{rpart}\NormalTok{(class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2}
\NormalTok{                  , }\AttributeTok{data =}\NormalTok{ train\_df}
\NormalTok{                  , }\AttributeTok{method =} \StringTok{"class"}
\NormalTok{                  , }\AttributeTok{parms =} \FunctionTok{list}\NormalTok{(}\AttributeTok{split =} \StringTok{"gini"}\NormalTok{)}
\NormalTok{                  , }\AttributeTok{control =} \FunctionTok{rpart.control}\NormalTok{(}\AttributeTok{minsplit =} \DecValTok{2}
\NormalTok{                                          , }\AttributeTok{minbucket =} \DecValTok{1}
\NormalTok{                                          , }\AttributeTok{maxdepth =} \DecValTok{1}
\NormalTok{                                          , }\AttributeTok{cp =} \DecValTok{0}
\NormalTok{                                          , }\AttributeTok{xval =} \DecValTok{0}
\NormalTok{                                          , }\AttributeTok{maxcompete =} \DecValTok{0}
\NormalTok{                                          )}
\NormalTok{                  )}
\FunctionTok{rpart.plot}\NormalTok{(cart.firstsplit)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/firstsplit-1} 

}

\caption{뿌리노드 분지}\label{fig:firstsplit}
\end{figure}

또한 분지 결과 트리는 Table \ref{tab:firstsplit-frame}와 같이 \emph{frame}이라는 이름의 data frame에 설명된다. 각 행 앞의 번호는 노드 인덱스 \(t\)를 나타내며, 각 열에 대한 설명은 아래와 같다.

\begin{itemize}
\tightlist
\item
  var: 노드 \(t\)를 분지하는 데 이용된 변수. 값이 \textless leaf\textgreater 인 경우에는 노드 \(t\)가 최종 노드임을 나타낸다.
\item
  n: 노드 내 객체 수 \(N(t)\)
\item
  wt: 가중치 적용 후 객체 수 (추후 appendix에서 설명)
\item
  dev: 오분류 객체 수
\item
  yval: 노드 \(t\)를 대표하는 범주
\item
  complexity: 노드 \(t\)에서 추가로 분지할 때 감소하는 relative error값; 본 분류트리 예제에서 error는 오분류율이며, 뿌리 노드의 relative error값을 1으로 한다.
\end{itemize}

\begin{table}

\caption{\label{tab:firstsplit-frame}뿌리노드 분지 상세 (frame)}
\centering
\begin{tabular}[t]{llrrrrrrr}
\toprule
  & var & n & wt & dev & yval & complexity & ncompete & nsurrogate\\
\midrule
1 & x2 & 10 & 10 & 5 & 1 & 0.6 & 0 & 0\\
2 & \textbackslash{}<leaf\textbackslash{}> & 3 & 3 & 0 & 1 & 0.0 & 0 & 0\\
3 & \textbackslash{}<leaf\textbackslash{}> & 7 & 7 & 2 & 2 & 0.0 & 0 & 0\\
\bottomrule
\end{tabular}
\end{table}

또한 \emph{frame}에는 트리 내 각 노드에 속한 객체와 범주에 대한 정보를 나타내는 \emph{yval2}라는 행렬이 Table \ref{tab:firstsplit-yval2}와 같이 존재한다. 실제 \emph{yval2}의 열의 개수는 전체 학습 대상 범주 수에 따라 달라지며, 본 예는 이분 분류 트리(범주개수 = 2)에 해당하는 열 구성을 보여준다. 각 행 앞의 번호는 노드 인덱스 \(t\)를 나타내며, 각 열에 대한 설명은 아래와 같다.

\begin{itemize}
\tightlist
\item
  열1: 노드 \(t\)에서의 최적 추정 범주 \(j^*\)
\item
  열2: 노드 \(t\) 내 범주 \emph{class}=1 객체 수 \(N_1(t)\)
\item
  열3: 노드 \(t\) 내 범주 \emph{class}=2 객체 수 \(N_2(t)\)
\item
  열4: 노드 \(t\) 내 범주 \emph{class}=1 관측 확률 \(p(1|t) \approx \tfrac{N_1(t)}{N(t)}\)
\item
  열5: 노드 \(t\) 내 범주 \emph{class}=2 관측 확률 \(p(2|t) \approx \tfrac{N_2(t)}{N(t)}\)
\item
  nodeprob: 노드 \(t\) 확률 \(p(t) \approx \tfrac{N(t)}{N}\)
\end{itemize}

\begin{verbatim}
## Warning: Setting row names on a tibble is deprecated.
\end{verbatim}

\begin{table}

\caption{\label{tab:firstsplit-yval2}노드 내 객체 및 범주 정보 (yval2)}
\centering
\begin{tabular}[t]{lrrrrrr}
\toprule
  & 열1 & 열2 & 열3 & 열4 & 열5 & nodeprob\\
\midrule
1 & 1 & 5 & 5 & 0.50 & 0.50 & 1.0\\
2 & 1 & 3 & 0 & 1.00 & 0.00 & 0.3\\
3 & 2 & 2 & 5 & 0.29 & 0.71 & 0.7\\
\bottomrule
\end{tabular}
\end{table}

위 CART 모델 데이터를 이용하여 트리의 불순도를 계산해보자.

우선 노드 상세 정보 행렬 \emph{yval2}의 \emph{x}번째 노드의 불순도(\(i(t)\))를 계산하는 함수 \emph{rpartNodeImpurity}를 아래와 같이 구현한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rpartNodeImpurity }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, yval2) \{}
\NormalTok{  node\_vec }\OtherTok{\textless{}{-}}\NormalTok{ yval2[x, ]}
\NormalTok{  n.columns }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(node\_vec)}
\NormalTok{  class.prob }\OtherTok{\textless{}{-}}\NormalTok{ node\_vec[((n.columns}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)}\SpecialCharTok{+}\DecValTok{1}\NormalTok{)}\SpecialCharTok{:}\NormalTok{(n.columns}\DecValTok{{-}1}\NormalTok{)]}
  \FunctionTok{return}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{sum}\NormalTok{(class.prob}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

CART tree 객체의 각 leaf node에 함수 \emph{rpartNodeImpurity}를 적용하여 노드 불순도 \(i(t)\)를 계산한 뒤, 노드 확률 \(p(t)\)을 이용한 가중합을 통해 트리 불순도 \(I(T)\)를 계산하는 함수 \emph{rpartImpurity}를 아래와 같이 구현한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rpartImpurity }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(rpart.obj) \{}
\NormalTok{  leaf.nodes }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(rpart.obj}\SpecialCharTok{$}\NormalTok{frame}\SpecialCharTok{$}\NormalTok{var}\SpecialCharTok{==}\StringTok{"\textless{}leaf\textgreater{}"}\NormalTok{)}
\NormalTok{  node.impurity }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(leaf.nodes, }
\NormalTok{                          rpartNodeImpurity, }
                          \AttributeTok{yval2 =}\NormalTok{ rpart.obj}\SpecialCharTok{$}\NormalTok{frame}\SpecialCharTok{$}\NormalTok{yval2)}
\NormalTok{  node.prob }\OtherTok{\textless{}{-}}\NormalTok{ rpart.obj}\SpecialCharTok{$}\NormalTok{frame}\SpecialCharTok{$}\NormalTok{yval2[leaf.nodes, }\StringTok{\textquotesingle{}nodeprob\textquotesingle{}}\NormalTok{]}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{sum}\NormalTok{(node.prob }\SpecialCharTok{*}\NormalTok{ node.impurity))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 함수를 이용하여 계산한 트리 Figure \ref{fig:cart-basic}의 불순도는 0.29이다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rpartImpurity}\NormalTok{(cart.firstsplit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.2857143
\end{verbatim}

분지를 추가할수록 불순도는 감소한다. 분지를 추가하기 위해서는 \emph{maxdepth}라는 control parameter 값을 증가시키면 된다.

\begin{itemize}
\tightlist
\item
  maxdepth: 뿌리노드부터 임의의 최종노드에 도달하는 최대 가능 분지 수 (default=30)
\end{itemize}

\emph{maxdepth} 파라미터의 값을 1부터 4까지 증가시키며 불순도의 변화를 살펴보자.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}

\NormalTok{tree.impurity }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{), }\ControlFlowTok{function}\NormalTok{(depth) \{}
  \FunctionTok{rpart}\NormalTok{(class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2}
\NormalTok{        , }\AttributeTok{data =}\NormalTok{ train\_df}
\NormalTok{        , }\AttributeTok{method =} \StringTok{"class"}
\NormalTok{        , }\AttributeTok{parms =} \FunctionTok{list}\NormalTok{(}\AttributeTok{split =} \StringTok{"gini"}\NormalTok{)}
\NormalTok{        , }\AttributeTok{control =} \FunctionTok{rpart.control}\NormalTok{(}\AttributeTok{minsplit =} \DecValTok{2}
\NormalTok{                                  , }\AttributeTok{minbucket =} \DecValTok{1}
\NormalTok{                                  , }\AttributeTok{maxdepth =}\NormalTok{ depth}
\NormalTok{                                  , }\AttributeTok{cp =} \DecValTok{0}
\NormalTok{                                  , }\AttributeTok{xval =} \DecValTok{0}
\NormalTok{                                  , }\AttributeTok{maxcompete =} \DecValTok{0}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rpartImpurity}\NormalTok{()}
\NormalTok{\})}

\FunctionTok{tibble}\NormalTok{(}\AttributeTok{maxdepth=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{), }\AttributeTok{impurity=}\NormalTok{tree.impurity) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{maxdepth, }\AttributeTok{y=}\NormalTok{impurity)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/impurity-trend-1} 

}

\caption{파라미터 maxdepth값에 따른 트리불순도 변화}\label{fig:impurity-trend}
\end{figure}

위 예에서, 트리의 분지가 증가함에 따라 불순도는 0.29, 0.17, 0.17, 0로 감소한다. \emph{maxdepth}값이 3일 때 불순도가 감소하지 않는 이유는, 세 번째 분지 결과가 전체적인 오분류를 감소시키지 않아 \emph{rpart} 함수가 해당 분지를 취소하기 때문이다. 여기에 작용하는 파라미터는 \emph{cp}라는 control parameter이다.

\begin{itemize}
\tightlist
\item
  cp: 노드가 분지되기 위한 최소 relative error 감소치 (default = 0.01). 값이 0일 경우 최대트리를 생성한다.
\end{itemize}

위 예제에서는 \emph{cp}값을 0으로 설정하여, 해당 분지가 트리 불순도를 감소시킨다 하더라도 전체 트리의 오분류를 감소시키는 데 기여하지 않는다면 시도하지 않도록 하였다.

\hypertarget{cart-pruning-complete}{%
\section{가지치기 및 최종 트리 선정}\label{cart-pruning-complete}}

\hypertarget{cart-pruning}{%
\subsection{가지치기}\label{cart-pruning}}

앞 장의 최대 트리 그림 \ref{fig:cart-basic}은 학습 데이터를 오분류 없이 완벽하게 분류하기 위해 복잡한 분류 구조를 형성하였다. 이러한 복잡한 분류 구조는 학습 데이터가 아닌 새로운 데이터에 대한 분류 정확도를 떨어뜨릴 수 있다. 이는 bias-variance tradeoff라 부르는 현상으로, 비단 분류트리 뿐 아니라 모든 데이터마이닝 방법에 일반적으로 적용된다.

분류 트리는 가지치기라는 방식을 통해, 분류 구조를 단순화함으로써 분류 트리가 새로운 데이터에도 정확한 분류를 제공하기를 추구한다. 가지치기란 트리 내 특정 내부노드를 기준으로 그 하위에 발생한 분지를 모두 제거하고, 해당 내부노드를 최종노드로 치환하는 방식이다.

\begin{table}

\caption{\label{tab:max-frame}최대 트리 분지 상세 (frame)}
\centering
\begin{tabular}[t]{llrrrrrrr}
\toprule
  & var & n & wt & dev & yval & complexity & ncompete & nsurrogate\\
\midrule
1 & x2 & 10 & 10 & 5 & 1 & 0.6 & 0 & 0\\
2 & \textbackslash{}<leaf\textbackslash{}> & 3 & 3 & 0 & 1 & 0.0 & 0 & 0\\
3 & x1 & 7 & 7 & 2 & 2 & 0.2 & 0 & 0\\
6 & \textbackslash{}<leaf\textbackslash{}> & 1 & 1 & 0 & 1 & 0.0 & 0 & 0\\
7 & x2 & 6 & 6 & 1 & 2 & 0.1 & 0 & 0\\
\addlinespace
14 & x1 & 2 & 2 & 1 & 1 & 0.1 & 0 & 0\\
28 & \textbackslash{}<leaf\textbackslash{}> & 1 & 1 & 0 & 1 & 0.0 & 0 & 0\\
29 & \textbackslash{}<leaf\textbackslash{}> & 1 & 1 & 0 & 2 & 0.0 & 0 & 0\\
15 & \textbackslash{}<leaf\textbackslash{}> & 4 & 4 & 0 & 2 & 0.0 & 0 & 0\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:max-frame}에서 생성 가능한 가지치기는 최종 노드(\emph{var값이 \textless leaf\textgreater{}})가 아닌 모든 노드(1, 3, 7, 14)에서 가능하며, 함수 \emph{snip.rpart}를 이용하여 가지치기 된 트리를 생성할 수 있다. 각 내부 노드에서 가지치기된 트리들은 아래와 같이 얻어진다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{internal.node.index }\OtherTok{\textless{}{-}} \FunctionTok{rownames}\NormalTok{(cart.est}\SpecialCharTok{$}\NormalTok{frame)[}\FunctionTok{which}\NormalTok{(cart.est}\SpecialCharTok{$}\NormalTok{frame}\SpecialCharTok{$}\NormalTok{var }\SpecialCharTok{!=} \StringTok{\textquotesingle{}\textless{}leaf\textgreater{}\textquotesingle{}}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as.numeric}\NormalTok{()}
\NormalTok{snipped }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(internal.node.index, }\ControlFlowTok{function}\NormalTok{(x)\{}\FunctionTok{snip.rpart}\NormalTok{(cart.est, x)\})}
\NormalTok{n.trees }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(snipped)}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{invisible}\NormalTok{(}\FunctionTok{lapply}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{n.trees), }\ControlFlowTok{function}\NormalTok{(x) \{}
  \FunctionTok{rpart.plot}\NormalTok{(snipped[[x]])\}}
\NormalTok{  ))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/snipped-1} 

}

\caption{각 내부노드 기준으로 가지치기된 트리}\label{fig:snipped}
\end{figure}

위 각 가지치기 후보 노드의 오분류 비용은 함수 \emph{nodeCost}를 아래와 같이 구현하여 계산할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nodeCost }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(node, tree) \{}
\NormalTok{  node\_vec }\OtherTok{\textless{}{-}}\NormalTok{ tree}\SpecialCharTok{$}\NormalTok{frame}\SpecialCharTok{$}\NormalTok{yval2[}\FunctionTok{as.character}\NormalTok{(node) }\SpecialCharTok{==} \FunctionTok{row.names}\NormalTok{(tree}\SpecialCharTok{$}\NormalTok{frame), ]}
\NormalTok{  n.columns }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(node\_vec)}
\NormalTok{  class.prob.max }\OtherTok{\textless{}{-}} \FunctionTok{max}\NormalTok{(node\_vec[((n.columns}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)}\SpecialCharTok{+}\DecValTok{1}\NormalTok{)}\SpecialCharTok{:}\NormalTok{(n.columns}\DecValTok{{-}1}\NormalTok{)])}
\NormalTok{  node.prob }\OtherTok{\textless{}{-}}\NormalTok{ node\_vec[n.columns]}
\NormalTok{  node.misclassification.cost }\OtherTok{\textless{}{-}}\NormalTok{ (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{class.prob.max)}\SpecialCharTok{*}\NormalTok{node.prob}
  \FunctionTok{return}\NormalTok{(node.misclassification.cost)}
\NormalTok{\}}

\FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{pruning\_node =}\NormalTok{ internal.node.index,}
  \AttributeTok{node\_cost =} \FunctionTok{sapply}\NormalTok{(internal.node.index, nodeCost, }\AttributeTok{tree=}\NormalTok{cart.est)}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r}
\hline
pruning\_node & node\_cost\\
\hline
1 & 0.5\\
\hline
3 & 0.2\\
\hline
7 & 0.1\\
\hline
14 & 0.1\\
\hline
\end{tabular}

각 가지치기 노드에 해당하는 하부 트리의 오분류비용 및 복잡도를 구하기 위해 \emph{subtreeEval}라는 함수를 아래와 같이 구현한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subtreeEval }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(node, tree) \{}
\NormalTok{  snipped }\OtherTok{\textless{}{-}} \FunctionTok{snip.rpart}\NormalTok{(tree, node)}\SpecialCharTok{$}\NormalTok{frame}
\NormalTok{  leaf.nodes }\OtherTok{\textless{}{-}} \FunctionTok{setdiff}\NormalTok{(}\FunctionTok{rownames}\NormalTok{(tree}\SpecialCharTok{$}\NormalTok{frame[tree}\SpecialCharTok{$}\NormalTok{frame}\SpecialCharTok{$}\NormalTok{var}\SpecialCharTok{==}\StringTok{"\textless{}leaf\textgreater{}"}\NormalTok{,]),}
          \FunctionTok{rownames}\NormalTok{(snipped)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{as.numeric}\NormalTok{()}

  \FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{pruning\_node =}\NormalTok{ node,}
    \AttributeTok{node.cost =} \FunctionTok{nodeCost}\NormalTok{(node, tree),}
    \AttributeTok{subtree.cost =} \FunctionTok{sapply}\NormalTok{(leaf.nodes, nodeCost, }\AttributeTok{tree=}\NormalTok{tree) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{sum}\NormalTok{(),}
    \AttributeTok{subtree.size =} \FunctionTok{length}\NormalTok{(leaf.nodes)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{alpha =}\NormalTok{ (node.cost }\SpecialCharTok{{-}}\NormalTok{ subtree.cost) }\SpecialCharTok{/}\NormalTok{ (subtree.size }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

각 노드에 대하여 알파값을 다음과 같이 계산할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.cost }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(internal.node.index, subtreeEval, }\AttributeTok{tree=}\NormalTok{cart.est) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_rows}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:first-prune-candidate-tab}내부노드 가지치기 평가 (df.cost)}
\centering
\begin{tabular}[t]{rrrrr}
\toprule
pruning\_node & node.cost & subtree.cost & subtree.size & alpha\\
\midrule
1 & 0.5 & 0 & 5 & 0.12\\
3 & 0.2 & 0 & 4 & 0.07\\
7 & 0.1 & 0 & 3 & 0.05\\
14 & 0.1 & 0 & 2 & 0.10\\
\bottomrule
\end{tabular}
\end{table}

위 Table \ref{tab:first-prune-candidate-tab} 에서 최소 알파값에 해당하는 노드 7에서 가지치기를 한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pruned.tree}\FloatTok{.1} \OtherTok{\textless{}{-}} \FunctionTok{snip.rpart}\NormalTok{(cart.est,}
\NormalTok{                            df.cost}\SpecialCharTok{$}\NormalTok{pruning\_node[}\FunctionTok{which.min}\NormalTok{(df.cost}\SpecialCharTok{$}\NormalTok{alpha)])}
\FunctionTok{rpart.plot}\NormalTok{(pruned.tree}\FloatTok{.1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/first-prune-result-1} 

}

\caption{1단계 가지치기 결과}\label{fig:first-prune-result}
\end{figure}

가지치기로 형성된 트리에서 다시 각 가지치기 노드의 오분류비용, 복잡도 및 알파값을 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df.cost }\OtherTok{\textless{}{-}} \FunctionTok{rownames}\NormalTok{(pruned.tree}\FloatTok{.1}\SpecialCharTok{$}\NormalTok{frame)[pruned.tree}\FloatTok{.1}\SpecialCharTok{$}\NormalTok{frame}\SpecialCharTok{$}\NormalTok{var}\SpecialCharTok{!=}\StringTok{"\textless{}leaf\textgreater{}"}\NormalTok{] }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{as.numeric}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{lapply}\NormalTok{(subtreeEval, }\AttributeTok{tree=}\NormalTok{pruned.tree}\FloatTok{.1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_rows}\NormalTok{()}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(df.cost)}
\end{Highlighting}
\end{Shaded}

\begin{tabular}{r|r|r|r|r}
\hline
pruning\_node & node.cost & subtree.cost & subtree.size & alpha\\
\hline
1 & 0.5 & 0.1 & 3 & 0.2\\
\hline
3 & 0.2 & 0.1 & 2 & 0.1\\
\hline
\end{tabular}

위 결과에서 다시 최소 알파값에 해당하는 노드 3에서 가지치기를 하면 아래와 같은 트리가 형성된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pruned.tree}\FloatTok{.2} \OtherTok{\textless{}{-}} \FunctionTok{snip.rpart}\NormalTok{(pruned.tree}\FloatTok{.1}\NormalTok{,}
\NormalTok{                            df.cost}\SpecialCharTok{$}\NormalTok{pruning\_node[}\FunctionTok{which.min}\NormalTok{(df.cost}\SpecialCharTok{$}\NormalTok{alpha)])}
\FunctionTok{rpart.plot}\NormalTok{(pruned.tree}\FloatTok{.2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/second-prune-result-1} 

}

\caption{2단계 가지치기 결과}\label{fig:second-prune-result}
\end{figure}

\hypertarget{cart-best-tree}{%
\subsection{최적 트리의 선정}\label{cart-best-tree}}

위 가지치기 과정에서 얻는 가지친 트리들이 최종 트리의 후보가 되며, 이 중 테스트 표본에 대한 오분류율이 가장 작은 트리를 최적 트리로 선정하게 된다.

트리를 학습할 때 사용된 학습데이터 Table \ref{tab:tree-train-data-table} 외에, Table \ref{tab:tree-test-data-table}과 같은 6개의 테스트 데이터가 있다고 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{x1 =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{),}
  \AttributeTok{x2 =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{4}\NormalTok{),}
  \AttributeTok{class =} \FunctionTok{factor}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\AttributeTok{levels=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:tree-test-data-table}테스트 데이터}
\centering
\begin{tabular}[t]{rrr}
\toprule
x1 & x2 & class\\
\midrule
1 & 5 & 1\\
0 & 5 & 1\\
3 & 4 & 2\\
4 & 3 & 2\\
2 & 7 & 1\\
\addlinespace
1 & 4 & 2\\
\bottomrule
\end{tabular}
\end{table}

테스트 데이터에 위에서 학습된 세 개의 트리, 즉 최대 트리 \emph{cart.est}와 두 개의 가지치기 트리 \emph{pruned.tree.1} \& \emph{pruned.tree.2}를 적용하여 각 트리가 각각의 테스트 데이터를 어떻게 분류하는지 살펴보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test\_pred }\OtherTok{\textless{}{-}}\NormalTok{ test\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_cols}\NormalTok{(}
    \AttributeTok{pred\_maxtree =} \FunctionTok{predict}\NormalTok{(cart.est, test\_df, }\AttributeTok{type=}\StringTok{"class"}\NormalTok{),}
    \AttributeTok{pred\_prune1 =} \FunctionTok{predict}\NormalTok{(pruned.tree}\FloatTok{.1}\NormalTok{, test\_df, }\AttributeTok{type=}\StringTok{"class"}\NormalTok{),}
    \AttributeTok{pred\_prune2 =} \FunctionTok{predict}\NormalTok{(pruned.tree}\FloatTok{.2}\NormalTok{, test\_df, }\AttributeTok{type=}\StringTok{"class"}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:tree-class-prediction-table}테스트 데이터에 대한 예측 결과}
\centering
\begin{tabular}[t]{rrllll}
\toprule
x1 & x2 & class & pred\_maxtree & pred\_prune1 & pred\_prune2\\
\midrule
1 & 5 & 1 & 1 & 1 & 2\\
0 & 5 & 1 & 1 & 1 & 2\\
3 & 4 & 2 & 2 & 2 & 2\\
4 & 3 & 2 & 2 & 2 & 2\\
2 & 7 & 1 & 1 & 1 & 1\\
\addlinespace
1 & 4 & 2 & 1 & 1 & 2\\
\bottomrule
\end{tabular}
\end{table}

결과 Table \ref{tab:tree-class-prediction-table}에서 최대트리가 오분류한 테스트 표본은 1개, 첫번째 가지치기 트리가 오분류한 테스트 표본은 1개, 그리고 두 번째 가지치기 트리가 오분류한 테스트 표본은 2개이다.

위 결과를 토대로, 최적의 트리를 선정하는 과정은 아래와 같다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  각각의 트리에 의해 오분류된 테스트 표본의 개수를 전체 테스트 표본의 개수로 나누어 오분류율 \(R^{ts}\)를 구한다.
\item
  테스트 표본 수를 \(n_{test}\)라 할 때, 오분류의 표준편차를 아래와 같이 계산한다.
  \[SE = \sqrt{\frac{R^{ts}(1 - R^{ts})}{n_{test}}}\]
\item
  1에서 구한 오분류율에 2에서 구한 표준편차를 더하여 \(R^{ts} + SE\)를 각 트리의 평가척도로 계산한다. 후보 트리들 중 해당 평가척도가 가장 작은 트리를 최종 트리로 선정한다.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{test.summary }\OtherTok{\textless{}{-}}\NormalTok{ test\_pred }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{n.test =} \FunctionTok{n}\NormalTok{(),}
            \AttributeTok{cart.est =} \FunctionTok{sum}\NormalTok{(pred\_maxtree }\SpecialCharTok{!=}\NormalTok{ class) }\SpecialCharTok{/}\NormalTok{ n.test,}
            \AttributeTok{pruned.tree.1 =} \FunctionTok{sum}\NormalTok{(pred\_prune1 }\SpecialCharTok{!=}\NormalTok{ class) }\SpecialCharTok{/}\NormalTok{ n.test,}
            \AttributeTok{pruned.tree.2 =} \FunctionTok{sum}\NormalTok{(pred\_prune2 }\SpecialCharTok{!=}\NormalTok{ class) }\SpecialCharTok{/}\NormalTok{ n.test) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{gather}\NormalTok{(}\StringTok{"tree"}\NormalTok{,}\StringTok{"R.ts"}\NormalTok{,}\SpecialCharTok{{-}}\NormalTok{n.test) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{SE =} \FunctionTok{sqrt}\NormalTok{((R.ts}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ R.ts))}\SpecialCharTok{/}\NormalTok{n.test),}
         \AttributeTok{score =}\NormalTok{ R.ts }\SpecialCharTok{+}\NormalTok{ SE) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{n.test)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:misclassification-rate-table}분류 성능}
\centering
\begin{tabular}[t]{lrrr}
\toprule
트리 & 오분류율(\$R\textasciicircum{}\{ts\}\$) & 표준편차(\$SE\$) & 척도(\$R\textasciicircum{}\{ts\} + SE\$)\\
\midrule
cart.est & 0.17 & 0.15 & 0.32\\
pruned.tree.1 & 0.17 & 0.15 & 0.32\\
pruned.tree.2 & 0.33 & 0.19 & 0.53\\
\bottomrule
\end{tabular}
\end{table}

위 결과, 최적 트리는 최대 트리 혹은 첫 번째 가지치기 트리가 된다.

위 절차를 임의의 데이터에 대해 수행하는 함수를 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rpart\_learn }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(formula, train\_df, test\_df) \{}
  \CommentTok{\# 최대 트리 생성}
\NormalTok{  max\_tree }\OtherTok{\textless{}{-}} \FunctionTok{rpart}\NormalTok{(formula}
\NormalTok{                    , }\AttributeTok{data =}\NormalTok{ train\_df}
\NormalTok{                    , }\AttributeTok{method =} \StringTok{"class"}
\NormalTok{                    , }\AttributeTok{parms =} \FunctionTok{list}\NormalTok{(}\AttributeTok{split =} \StringTok{"gini"}\NormalTok{)}
\NormalTok{                    , }\AttributeTok{control =} \FunctionTok{rpart.control}\NormalTok{(}\AttributeTok{minsplit =} \DecValTok{2}
\NormalTok{                                              , }\AttributeTok{minbucket =} \DecValTok{1}
\NormalTok{                                              , }\AttributeTok{cp =} \DecValTok{0}
\NormalTok{                                              , }\AttributeTok{xval =} \DecValTok{0}
\NormalTok{                                              , }\AttributeTok{maxcompete =} \DecValTok{0}
\NormalTok{                    )}
\NormalTok{  )}
  
  \CommentTok{\# 가지치기}
\NormalTok{  curr\_tree }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}
\NormalTok{  k }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{  curr\_tree[[k]] }\OtherTok{\textless{}{-}}\NormalTok{ max\_tree}
  \ControlFlowTok{while}\NormalTok{(}\FunctionTok{dim}\NormalTok{(curr\_tree[[k]]}\SpecialCharTok{$}\NormalTok{frame)[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{) \{}
\NormalTok{    internal.node.index }\OtherTok{\textless{}{-}} \FunctionTok{rownames}\NormalTok{(curr\_tree[[k]]}\SpecialCharTok{$}\NormalTok{frame)[}\FunctionTok{which}\NormalTok{(curr\_tree[[k]]}\SpecialCharTok{$}\NormalTok{frame}\SpecialCharTok{$}\NormalTok{var }\SpecialCharTok{!=} \StringTok{\textquotesingle{}\textless{}leaf\textgreater{}\textquotesingle{}}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{as.numeric}\NormalTok{()}
\NormalTok{    df.cost }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(internal.node.index, subtreeEval, }\AttributeTok{tree=}\NormalTok{curr\_tree[[k]]) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{bind\_rows}\NormalTok{()}
\NormalTok{    curr\_tree[[k }\SpecialCharTok{+} \DecValTok{1}\NormalTok{]] }\OtherTok{\textless{}{-}} \FunctionTok{snip.rpart}\NormalTok{(curr\_tree[[k]],}
\NormalTok{               df.cost}\SpecialCharTok{$}\NormalTok{pruning\_node[}\FunctionTok{which.min}\NormalTok{(df.cost}\SpecialCharTok{$}\NormalTok{alpha)])}
\NormalTok{    k }\OtherTok{\textless{}{-}}\NormalTok{ k }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{  \}}

  \CommentTok{\# 최적 가지치기 트리 선정}
\NormalTok{  n.test }\OtherTok{\textless{}{-}} \FunctionTok{dim}\NormalTok{(test\_df)[}\DecValTok{1}\NormalTok{]}
\NormalTok{  R.ts }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(curr\_tree, }\ControlFlowTok{function}\NormalTok{(x) \{}
    \FunctionTok{sum}\NormalTok{(}\FunctionTok{predict}\NormalTok{(x, test\_df, }\AttributeTok{type=}\StringTok{"class"}\NormalTok{) }\SpecialCharTok{!=}\NormalTok{ test\_df}\SpecialCharTok{$}\NormalTok{class) }\SpecialCharTok{/}\NormalTok{ n.test}
\NormalTok{    \}) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unlist}\NormalTok{()}
\NormalTok{  score }\OtherTok{\textless{}{-}}\NormalTok{ R.ts }\SpecialCharTok{+} \FunctionTok{sqrt}\NormalTok{((R.ts}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ R.ts))}\SpecialCharTok{/}\NormalTok{n.test)}
  \FunctionTok{return}\NormalTok{(curr\_tree[[}\FunctionTok{max}\NormalTok{(}\FunctionTok{which}\NormalTok{(score }\SpecialCharTok{==} \FunctionTok{min}\NormalTok{(score)))]])}
\NormalTok{\}}

\NormalTok{optimal\_tree }\OtherTok{\textless{}{-}} \FunctionTok{rpart\_learn}\NormalTok{(class }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, train\_df, test\_df)}
\FunctionTok{rpart.plot}\NormalTok{(optimal\_tree)}
\end{Highlighting}
\end{Shaded}

\includegraphics{data-mining-book_files/figure-latex/rpart-learn-1.png}

\hypertarget{cart-r-pkg}{%
\section{R패키지 내 분류 트리 방법}\label{cart-r-pkg}}

앞 장에서는 \emph{rpart}의 결과를 이용하여 교재 8.2 - 8.3장의 예제를 재현해보았다. 실제로 \emph{rpart} 내부의 기본 트리 방법은 교재의 예제와는 다소 다른 부분이 있다. 이 장에서는 실제 \emph{rpart} 패키지의 분류 트리 방법에 대해 알아본다.

\hypertarget{cart-r-pkg-split}{%
\subsection{트리 확장}\label{cart-r-pkg-split}}

트리 내 임의의 노드 \(t\)에 대한 불순도는 아래와 같이 정의된다.
\[i(t) = \sum_{j=1}^{J} f\left(p(j|t)\right)\]
여기에서 \(p(j|t)\)는 노드 \(t\) 내 전체 샘플 \(N(t)\) 중 범주 \(j\)의 샘플 \(N_j(t)\)의 비율로 추정된다.
\[p(j|t) \approx \frac{N_j(t)}{N(t)}\]
또한 함수 \(f\)는 concave 함수로, \(f(0) = f(1) = 0\)의 조건을 만족시켜야 한다. \emph{rpart} 에서 설정할 수 있는 함수 \(f\)의 종류에 대해서는 아래에서 좀 더 자세히 살펴보기로 한다.

트리 내 임의의 노드 \(t\)가 분지규칙 \(s\)에 따라 두 개의 노드 \(t_L\)과 \(t_R\)로 분지된다고 할 때, 불순도의 감소량은 아래와 같이 계산된다.

\begin{eqnarray}
\Delta I(s,t) &=& I(t) - I(t_L) - I(t_R)\\ &=& p(t)i(t) - p(t_L)i(t_L) - p(t_R)i(t_R) 
\end{eqnarray}

\emph{rpart}는 위 \(\Delta I(s,t)\)값이 최대가 되는 분지 기준 \(s^*\)를 찾아 노드 \(t\)를 분지하여 트리를 확장하고, 확장된 트리의 최종 노드에서 다시 최적 분지를 찾는 과정을 반복한다.

\hypertarget{uxbd84uxc9c0-uxd568uxc218}{%
\subsubsection{분지 함수}\label{uxbd84uxc9c0-uxd568uxc218}}

함수 \emph{rpart} 사용 시 \emph{parms} 파라미터에 \emph{split} 값으로 분지 방법을 설정할 수 있다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Gini index (parms=list(split=`gini'))
  교재의 예제에 사용된 방법으로, 우선 아래와 같은 함수 \(f\)를 사용한다.
  \[f(p) = p(1-p)\]
\item
  information index (parms=list(split=`information'))
  교재에 엔트로피 지수(Entropy index)로 설명된 지수로, 아래와 같은 함수를 사용한다.
  \[f(p) = -p\log(p)\]
\item
  user-defined function
  사용자가 임의로 함수를 정의하여 사용할 수 있다. 본 장에서는 자세한 설명은 생략한다.
\end{enumerate}

\hypertarget{cart-r-pkg-pruning}{%
\subsection{가지치기}\label{cart-r-pkg-pruning}}

임의의 노드 \(t\)에 대한 위험도(오분류 비용의 기대치)는 아래와 같이 계산된다.
\[r(t) = \sum_{j \neq \tau(t)} p(j|t)C\left(\tau(t)|j\right)\]
여기에서 함수 \(C(i|j)\)는 범주 \(j\)에 속하는 객체를 범주 \(i\)로 분류할 때의 오분류 비용이며, \(\tau(t)\)는 노드 \(t\) 내의 오분류 비용을 최소화하도록 노드 \(t\)에 지정된 범주값이다.

\emph{rpart}의 오분류 비용 \(C(i|j)\)의 기본값은
\[C(i|j) = 
\begin{cases} 1,  & \text{  if } i \neq j\\
              0,  & \text{  if } i = j
\end{cases} \]
으로 설정되어 있으며, \emph{parms} 파라미터에 \emph{loss} 값으로 오분류 비용 \(C(i|j)\)를 재설정할 수 있다. 본 장에서는 기본값을 사용하도록 하자.

\(A(T)\)를 트리 \(T\)의 최종 노드의 집합이라 정의하고, 트리의 최종 노드의 개수를 \(|T|\)라 할 때, 트리 \(T\)의 위험도 \(R(T)\)는 아래와 같이 정의된다.
\[R(T) = \sum_{t \in A(T)} p(t)r(t)\]

복잡도 계수(complexity parameter) \(\alpha \in [0, \infty)\)를 이용하여, 트리의 비용-복합도 척도를 다음과 같이 정의한다.
\[R_\alpha(T) = R(T) + \alpha|T|\]
이 때, 임의의 계수 \(\alpha\)에 대해 비용 \(R_\alpha(T)\)가 최소가 되게하는 가지치기 트리를 \(T_\alpha\)라 하면, 아래와 같은 관계들이 성립한다.

\begin{itemize}
\tightlist
\item
  \(T_0\): 최대 트리
\item
  \(T_\infty\): 뿌리 노드 트리 (분지 없음)
\item
  \(\alpha > \beta\)일 때, \(T_\alpha\)는 \(T_\beta\)와 동일하거나 혹은 \(T_\beta\)에서 가지치기된 트리이다.
\end{itemize}

\hypertarget{cart-r-pkg-param}{%
\subsection{파라미터값 결정}\label{cart-r-pkg-param}}

함수 \emph{rpart}를 사용할 때 여러가지 사용자 정의 파라미터값을 설정할 수 있으며, 그 파라미터 값에 따라 생성되는 트리의 결과가 달라진다. 대표적인 파라미터 값으로는 아래와 같은 것들이 있다.

\begin{itemize}
\tightlist
\item
  minsplit: 분지를 시도하기 위해 필요한 노드 내 최소 관측객체 수 (default=20)
\item
  cp: 노드가 분지되기 위한 최소 relative error 감소치 (default = 0.01). 값이 0일 경우 최대트리를 생성한다.
\item
  maxdepth: 뿌리노드부터 임의의 최종노드에 도달하는 최대 가능 분지 수 (default=30)
\end{itemize}

\hypertarget{svm}{%
\chapter{서포트 벡터 머신}\label{svm}}

\hypertarget{svm-overview}{%
\section{개요}\label{svm-overview}}

서포트 벡터 머신(suuport vector machine; 이하 SVM)은 기본적으로 두 범주를 갖는 객체들을 분류하는 방법이다. 물론 세 범주 이상의 경우로 확장이 가능하다.

\hypertarget{svm-packages-install}{%
\section{필요 R package 설치}\label{svm-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.3.1\\
\hline
e1071 & 1.7-7\\
\hline
Matrix & 1.3-4\\
\hline
quadprog & 1.5-8\\
\hline
\end{tabular}

\hypertarget{linear-svm-separable}{%
\section{선형 SVM - 분리 가능 경우}\label{linear-svm-separable}}

\hypertarget{linear-svm-separable-basic-script}{%
\subsection{기본 R 스크립트}\label{linear-svm-separable-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{x1 =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{5}\NormalTok{),}
  \AttributeTok{x2 =} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{4}\NormalTok{),}
  \AttributeTok{class =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{)}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
             \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
             \AttributeTok{caption =} \StringTok{\textquotesingle{}선형분리가능 학습표본 데이터\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:svm-train-data-table}선형분리가능 학습표본 데이터}
\centering
\begin{tabular}[t]{rrr}
\toprule
x1 & x2 & class\\
\midrule
5 & 7 & 1\\
4 & 3 & -1\\
7 & 8 & 1\\
8 & 6 & 1\\
3 & 6 & -1\\
\addlinespace
2 & 5 & -1\\
6 & 6 & 1\\
9 & 6 & 1\\
5 & 4 & -1\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:svm-train-data-table}와 같이 두 독립변수 \emph{x1}, \emph{x2}와 이분형 종속변수 \emph{class}의 관측값으로 이루어진 9개의 학습표본을 \emph{train\_df}라는 data frame에 저장한다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(e1071)}
\NormalTok{svm\_model }\OtherTok{\textless{}{-}} \FunctionTok{svm}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(class) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, }\AttributeTok{data =}\NormalTok{ train\_df, }\AttributeTok{kernel =} \StringTok{"linear"}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(svm\_model, }\AttributeTok{data =}\NormalTok{ train\_df, }\AttributeTok{formula =}\NormalTok{ x2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1, }\AttributeTok{grid =} \DecValTok{200}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/linear-svm-basic-1} 

}

\caption{선형 SVM 분리 하이퍼플레인}\label{fig:linear-svm-basic}
\end{figure}

그림 \ref{fig:linear-svm-basic}에서 각 객체의 기호는 서포트 벡터 여부(``X''이면 서포트 벡터), 각 객체의 색상은 범주값(검정 = -1, 빨강 = 1)을 나타내며, 분리 하이퍼플레인은 아래와 같다.

\[
0.6666667 x_{1} + 0.6666667 x_{2} = 7
\]

\hypertarget{linear-svm-notation}{%
\subsection{기호 정의}\label{linear-svm-notation}}

본 장에서 사용될 수학적 기호는 아래와 같다.

\begin{itemize}
\tightlist
\item
  \(\mathbf{x} \in \mathbb{R}^p\): p차원 변수벡터
\item
  \(y \in \{-1, 1\}\): 범주
\item
  \(N\): 객체 수
\item
  \((\mathbf{x}_i, y_i)\): \(i\)번째 객체의 변수벡터와 범주값
\end{itemize}

\hypertarget{linear-svm-separable-hyperplane}{%
\subsection{최적 하이퍼플레인}\label{linear-svm-separable-hyperplane}}

선형 SVM은 주어진 객체들의 두 범주를 완벽하게 분리하는 하이퍼플레인 중 각 범주의 서포트 벡터들로부터의 거리가 최대가 되는 하이퍼플레인을 찾는 문제로 귀착된다.

우선 아래와 같이 하이퍼플레인을 정의한다.

\begin{equation}
\mathbf{w}^\top \mathbf{x} + b = 0 \label{eq:linear-svm-hyperplane}
\end{equation}

여기서 \(\mathbf{w} \in \mathbb{R}^p\)와 \(b \in \mathbb{R}\)이 하이퍼플레인의 계수이다.

범주값이 1인 객체들 중 하이퍼플레인에서 가장 가까운 객체에 대해 다음과 같은 조건이 만족한다고 가정하자.

\[
H_1: \mathbf{w}^\top \mathbf{x} + b = 1 
\]

또한 범주값이 -1인 객체들 중 하이퍼플레인에서 가장 가까운 객체에 대해 다음과 같은 조건이 만족한다고 가정하자.

\[
H_2: \mathbf{w}^\top \mathbf{x} + b = -1
\]

이 때 두 하이퍼플레인 \(H_1\)과 \(H_2\) 간의 거리(margin)는 \(2 / \lVert \mathbf{w} \rVert\)이다. 선형 SVM은 아래와 같이 \(H_1\)과 \(H_2\) 간의 거리를 최대로 하는 최적화 문제가 된다.

\begin{equation*}
\begin{split}
\max \text{  } & \frac{2}{\mathbf{w}^\top \mathbf{w}}\\
\text{s.t.}& \\
& \mathbf{w}^\top \mathbf{x}_i + b \ge 1 \text{ for } y_i = 1\\
& \mathbf{w}^\top \mathbf{x}_i + b \le -1 \text{ for } y_i = -1
\end{split}
\end{equation*}

이를 간략히 정리하면

\begin{equation*}
\begin{split}
\min \text{  } & \frac{\mathbf{w}^\top \mathbf{w}}{2}\\
\text{s.t.}& \\
& y_i \left( \mathbf{w}^\top \mathbf{x}_i + b \right) \ge 1
\end{split}
\end{equation*}

과 같이 정리할 수 있으며, 각 객체 \(i\)에 대한 제약조건에 라그랑지 계수(Lagrange multiplier) \(\alpha_i \ge 0\)를 도입하여 라그랑지 함수를 유도하면 식 \eqref{eq:linear-svm-primal}과 같은 최적화 문제가 된다. 이를 원문제(primal problem)라 하자.

\begin{equation}
\begin{split}
\min \text{  } & L_P = \frac{1}{2} \mathbf{w}^\top \mathbf{w} + \sum_{i = 1}^{N} \alpha_i \left[ y_i \left( \mathbf{w}^\top \mathbf{x}_i + b \right) - 1 \right]\\
\text{s.t.  } & \alpha_i \ge 0, \text{  } i = 1, \cdots, N
\end{split}
\label{eq:linear-svm-primal}
\end{equation}

원문제 식 \eqref{eq:linear-svm-primal}에 대한 울프쌍대문제(Wolfe dual problem)는 아래 식 \eqref{eq:linear-svm-dual}과 같이 도출된다. 보다 자세한 내용은 교재\citep{jun2012datamining} 참고.

\begin{equation}
\begin{split}
\max \text{  } & L_D = \sum_{i = 1}^{N} \alpha_i - \frac{1}{2} \sum_{i = 1}^{N} \sum_{j = 1}^{N} \alpha_i \alpha_j y_i y_j \mathbf{x}_i^\top \mathbf{x}_j\\
\text{s.t. } &\\
& \sum_{i = 1}^{N} \alpha_i y_i = 0\\
& \alpha_i \ge 0, \text{  } i = 1, \cdots, N
\end{split}
\label{eq:linear-svm-dual}
\end{equation}

식 \eqref{eq:linear-svm-dual}은 이차계획(quadratic programming) 문제로, 각종 소프트웨어와 알고리즘을 이용하여 구할 수 있다. 본 장에서는 \texttt{quadprog} 패키지를 이용하여 해를 구하기로 한다. 이는 실제로 \texttt{e1071}의 \texttt{svm} 함수 호출 시 사용하는 방법은 아니며, 실제 \texttt{svm} 함수가 호출하는 알고리즘은 다음 장에서 다시 설명하기로 한다.

\texttt{quadprog}의 \texttt{solve.QP} 함수는 아래와 같은 형태로 formulation된 문제\citep{goldfarb1983numerically}에 대한 최적해를 구한다.

\begin{equation}
\begin{split}
\min \text{  } & -\mathbf{d}^{\top}\boldsymbol{\alpha} + \frac{1}{2} \boldsymbol{\alpha}^{\top}\mathbf{D}\boldsymbol{\alpha}\\
\text{s.t. } & \mathbf{A}^{\top}\boldsymbol{\alpha} \ge \mathbf{b}_0
\end{split}
\label{eq:quadprog}
\end{equation}

식 \eqref{eq:quadprog}과 식 \eqref{eq:linear-svm-dual}이 동일한 문제를 나타내도록 아래와 같이 목적함수에 필요한 벡터 및 행렬을 정의한다.

\begin{eqnarray*}
\mathbf{d} &=& \mathbf{1}_{N \times 1}\\
\mathbf{D} &=& \mathbf{y}\mathbf{y}^{\top}\mathbf{X}\mathbf{X}^{\top}
\end{eqnarray*}
where
\begin{eqnarray*}
\mathbf{y} &=& \left[ \begin{array}{c c c c} y_1 & y_2 & \cdots & y_N \end{array} \right]^\top\\
\mathbf{X} &=& \left[ \begin{array}{c c c c} \mathbf{x}_1 & \mathbf{x}_2 & \cdots & \mathbf{x}_N \end{array} \right]^{\top}
\end{eqnarray*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{dim}\NormalTok{(train\_df)[}\DecValTok{1}\NormalTok{]}
\NormalTok{X }\OtherTok{\textless{}{-}}\NormalTok{ train\_df[}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}x1\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}x2\textquotesingle{}}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.matrix}\NormalTok{()}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ train\_df[[}\StringTok{\textquotesingle{}class\textquotesingle{}}\NormalTok{]] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.numeric}\NormalTok{()}

\NormalTok{d }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, N)}
\NormalTok{D }\OtherTok{\textless{}{-}}\NormalTok{ (y }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(y)) }\SpecialCharTok{*}\NormalTok{ (X }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(X))}
\end{Highlighting}
\end{Shaded}

여기에서 행렬 \(\mathbf{D}\)의 determinant 값은 0으로, \citet{goldfarb1983numerically} 가 가정하는 symmetric positive definite matrix 조건에 위배되어 \texttt{solve.QP} 함수 실행 시 오류가 발생한다. 이를 방지하기 위해 아래 예에서는 \texttt{Matrix} 패키지의 \texttt{nearPD}함수를 이용하여 행렬 \(\mathbf{D}\)와 근사한 symmetric positive definite matrix를 아래와 같이 찾는다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{D\_pd }\OtherTok{\textless{}{-}}\NormalTok{ Matrix}\SpecialCharTok{::}\FunctionTok{nearPD}\NormalTok{(D, }\AttributeTok{doSym =}\NormalTok{ T)}\SpecialCharTok{$}\NormalTok{mat }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.matrix}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

식 \eqref{eq:quadprog}의 제약식은 모두 inequality 형태로, 식 \eqref{eq:linear-svm-dual}의 equality constraint \(\sum_{i = 1}^{N} \alpha_i y_i = 0\)를 표현하기 위해서 두 개의 제약식 \(\sum_{i = 1}^{N} \alpha_i y_i \ge 0\)와 \(\sum_{i = 1}^{N} - \alpha_i y_i \ge 0\)를 생성한다.

\begin{equation*}
\mathbf{A}^\top = \left[ 
\begin{array}{c c c c}
y_1 & y_2 & \cdots & y_N\\
-y_1 & -y_2 & \cdots & -y_N\\
1 & 0 & \cdots & 0\\
0 & 1 & \cdots & 0\\
\cdots & \cdots & \cdots & \cdots \\
0 & 0 & \cdots & 1
\end{array}
\right],
\mathbf{b}_0 = \left[ \begin{array}{c}
0 \\ 0 \\ 0 \\ 0 \\ \cdots \\ 0
\end{array}
\right]
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(}
\NormalTok{  y,}
  \SpecialCharTok{{-}}\NormalTok{y,}
  \FunctionTok{diag}\NormalTok{(N)}
\NormalTok{)}
\NormalTok{b\_zero }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{2} \SpecialCharTok{+}\NormalTok{ N)}
\end{Highlighting}
\end{Shaded}

이제 위에서 구한 행렬과 벡터들을 \texttt{solve.QP} 함수에 입력하여 최적해를 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res }\OtherTok{\textless{}{-}}\NormalTok{ quadprog}\SpecialCharTok{::}\FunctionTok{solve.QP}\NormalTok{(D\_pd, d, A, b\_zero)}
\NormalTok{alpha\_sol }\OtherTok{\textless{}{-}}\NormalTok{ res}\SpecialCharTok{$}\NormalTok{solution}
\NormalTok{obj\_val }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\NormalTok{res}\SpecialCharTok{$}\NormalTok{value}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:svm-separable-alpha}이차계획문제의 최적해}
\centering
\begin{tabular}[t]{cc}
\toprule
variable & solution\\
\midrule
alpha\_1 & 0.2234\\
alpha\_2 & 0.0000\\
alpha\_3 & 0.0000\\
alpha\_4 & 0.0000\\
alpha\_5 & 0.2228\\
\addlinespace
alpha\_6 & 0.0000\\
alpha\_7 & 0.2210\\
alpha\_8 & 0.0000\\
alpha\_9 & 0.2216\\
\bottomrule
\end{tabular}
\end{table}

표 \ref{tab:svm-separable-alpha}의 결과는 교재\citep{jun2012datamining}에 나타난 최적해와는 다소 차이가 있으나, 결과적으로 목적함수값은 0.4444로 동일하다.

위의 과정으로 최적해 \(\alpha_{i}^{*}\)를 구한 뒤, 아래와 같이 분리 하이퍼플레인의 계수를 결정할 수 있다.

\begin{eqnarray*}
\mathbf{w} &=& \sum_{i = 1}^{N} \alpha_{i}^{*} y_{i} \mathbf{x}_{i}\\
b &=& \sum_{i: \alpha_{i}^{*} > 0} \frac{1 - y_{i} \mathbf{w}^{\top} \mathbf{x}_{i}}{y_{i}} \left/ \sum_{i: \alpha_{i}^{*} > 0} 1 \right. 
\end{eqnarray*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{colSums}\NormalTok{(alpha\_sol }\SpecialCharTok{*}\NormalTok{ y }\SpecialCharTok{*}\NormalTok{ X)}
\FunctionTok{print}\NormalTok{(w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##        x1        x2 
## 0.6666658 0.6666657
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sv\_ind }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(}\FunctionTok{round}\NormalTok{(alpha\_sol, }\AttributeTok{digits =} \DecValTok{4}\NormalTok{) }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{)}
\NormalTok{b }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ y[sv\_ind] }\SpecialCharTok{*}\NormalTok{ (X[sv\_ind, ] }\SpecialCharTok{\%*\%}\NormalTok{ w)) }\SpecialCharTok{/}\NormalTok{ y[sv\_ind])}
\FunctionTok{print}\NormalTok{(b)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -6.99999
\end{verbatim}

위 결과와 같이, 분리 하이퍼플레인은 교재와 동일하게 얻어진다.

\hypertarget{linear-svm-inseparable}{%
\section{선형 SVM - 분리 불가능 경우}\label{linear-svm-inseparable}}

본 장에서는 학습표본 내의 두 범주가 어떠한 선형 하이퍼플레인으로도 완전하게 분리되지 않아 식 \eqref{eq:linear-svm-primal}이 해를 갖지 못하는 경우에 대한 문제를 다룬다.

\hypertarget{linear-svm-inseparable-basic-script}{%
\subsection{기본 R 스크립트}\label{linear-svm-inseparable-basic-script}}

앞 장에서 사용한 학습표본에 아래와 같이 하나의 객체를 추가하여 전체 학습표본이 선형 하이퍼플레인으로 분리될 수 없도록 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{inseparable\_train\_df }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(train\_df, }
                                  \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x1 =} \DecValTok{7}\NormalTok{, }\AttributeTok{x2 =} \DecValTok{6}\NormalTok{, }\AttributeTok{class =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{))}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(inseparable\_train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
             \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
             \AttributeTok{caption =} \StringTok{\textquotesingle{}선형분리불가능 학습표본 데이터\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:svm-inseparable-train-data-table}선형분리불가능 학습표본 데이터}
\centering
\begin{tabular}[t]{rrr}
\toprule
x1 & x2 & class\\
\midrule
5 & 7 & 1\\
4 & 3 & -1\\
7 & 8 & 1\\
8 & 6 & 1\\
3 & 6 & -1\\
\addlinespace
2 & 5 & -1\\
6 & 6 & 1\\
9 & 6 & 1\\
5 & 4 & -1\\
7 & 6 & -1\\
\bottomrule
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(e1071)}
\NormalTok{svm\_model }\OtherTok{\textless{}{-}} \FunctionTok{svm}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(class) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, }\AttributeTok{data =}\NormalTok{ inseparable\_train\_df, }
                 \AttributeTok{kernel =} \StringTok{"linear"}\NormalTok{, }\AttributeTok{cost =} \DecValTok{1}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(svm\_model, }\AttributeTok{data =}\NormalTok{ inseparable\_train\_df, }\AttributeTok{formula =}\NormalTok{ x2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1, }\AttributeTok{grid =} \DecValTok{200}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/linear-svm-basic-inseparable-1} 

}

\caption{선형 SVM 분리 불가능 경우의 하이퍼플레인}\label{fig:linear-svm-basic-inseparable}
\end{figure}

Figure \ref{fig:linear-svm-basic-inseparable}에서 보이듯, 하나의 검정 객체(범주 = -1)가 범주 1로 분류되는 영역에 존재하여 오분류가 발생한다. 이처럼 선형 하이퍼플레인으로 두 범주 학습표본의 분리가 불가능한 경우, 오분류 학습표본에 대한 페널티를 적용하여 최적 분리 하이퍼플레인을 도출하게 된다. 위 예에서의 최적 하이퍼플레인은 아래와 같다.

\[
0.6 x_{1} + 0.8 x_{2} = 7.6
\]

\hypertarget{linear-svm-inseparable-hyperplane}{%
\subsection{최적 하이퍼플레인}\label{linear-svm-inseparable-hyperplane}}

여유변수(slack variable) \(\xi_i\) 를 각 학습객체 \(i = 1, \cdots, N\)에 대해 아래와 같이 정의한다.

\begin{equation*}
\xi_i = \max \left\{ 0, 1 - y_i (\mathbf{w}^\top \mathbf{x}_i + b) \right\}
\end{equation*}

이는 객체가 자신의 범주의 서포트 벡터를 지나는 하이퍼플레인(범주 1인 경우 \(H_1\), 범주 -1인 경우 \(H_2\))으로 부터 다른 범주 방향으로 떨어진 거리를 나타낸다. 이 여유변수 \(\xi_i\)에 단위당 페널티 단가 \(C\)를 부여하여 아래와 같은 최적화 문제를 정의한다.

\begin{equation*}
\begin{split}
\min \text{  } & \frac{\mathbf{w}^\top \mathbf{w}}{2} + C \sum_{i = 1}^{N} \xi_i \\
\text{s.t.}& \\
& y_i \left( \mathbf{w}^\top \mathbf{x}_i + b \right) \ge 1 - \xi_i, \text{  } i = 1, \cdots, N \\
& \xi \ge 0, \text{  } i = 1, \cdots, N
\end{split}
\end{equation*}

이에 대한 울프쌍대문제를 앞 \ref{linear-svm-separable-hyperplane}장과 같은 과정으로 도출하면 아래 식 \eqref{eq:linear-svm-inseparable-dual}와 같다.

\begin{equation}
\begin{split}
\max \text{  } & L_D = \sum_{i = 1}^{N} \alpha_i - \frac{1}{2} \sum_{i = 1}^{N} \sum_{j = 1}^{N} \alpha_i \alpha_j y_i y_j \mathbf{x}_i^\top \mathbf{x}_j\\
\text{s.t. } &\\
& \sum_{i = 1}^{N} \alpha_i y_i = 0\\
& 0 \le \alpha_i \le C, \text{  } i = 1, \cdots, N
\end{split}
\label{eq:linear-svm-inseparable-dual}
\end{equation}

이는 분리 가능 경우의 식 \eqref{eq:linear-svm-dual}에 변수 \(\alpha_i\)에 대한 상한값 \(C\)의 제약이 추가된 문제로, 이는 \texttt{e1071} 패키지의 \texttt{svm} 함수가 기본 방법으로 사용하는 \texttt{LIBSVM} 라이브러리\citep{chang2011libsvm}의 \(C\)-support vector classification(\(C\)-SVC)이 사용하는 문제식이며, \texttt{LIBSVM} 라이브러리는 특정 알고리즘\citep{fan2005working}을 이용하여 해를 제공한다.

아래 \texttt{svm} 함수의 입력 변수에서 \texttt{type\ =\ "C-classification"}은 식 \eqref{eq:linear-svm-dual}를 최적화하겠다는 것을 나타내며, \texttt{cost\ =\ 1}은 페널티 단가 \(C\)의 값을 1로 설정하겠다는 것을 나타낸다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svm\_model }\OtherTok{\textless{}{-}} \FunctionTok{svm}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(class) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, }\AttributeTok{data =}\NormalTok{ inseparable\_train\_df,}
                 \AttributeTok{kernel =} \StringTok{"linear"}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{FALSE}\NormalTok{,}
                 \AttributeTok{type =} \StringTok{"C{-}classification"}\NormalTok{, }\AttributeTok{cost =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

위 결과 모델 객체 \texttt{svm\_model}의 원소 중 \texttt{index}는 학습표본 중 서포트 벡터에 해당하는 인덱스 \(i\)를 나타내며, \texttt{coefs}는 각 서포트 벡터의 \(\alpha_i y_i\) 값을 나타낸다. 따라서, \texttt{coefs}를 각 서포트 벡터의 범주값 \(y_i\)로 나누면 식 \eqref{eq:linear-svm-inseparable-dual}의 최적해를 아래와 같이 볼 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N }\OtherTok{\textless{}{-}} \FunctionTok{dim}\NormalTok{(inseparable\_train\_df)[}\DecValTok{1}\NormalTok{]}
\NormalTok{X }\OtherTok{\textless{}{-}}\NormalTok{ inseparable\_train\_df[}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}x1\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}x2\textquotesingle{}}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.matrix}\NormalTok{()}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ inseparable\_train\_df[[}\StringTok{\textquotesingle{}class\textquotesingle{}}\NormalTok{]] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.numeric}\NormalTok{()}

\NormalTok{sv\_ind }\OtherTok{\textless{}{-}}\NormalTok{ svm\_model}\SpecialCharTok{$}\NormalTok{index}
\NormalTok{alpha\_sol }\OtherTok{\textless{}{-}} \FunctionTok{vector}\NormalTok{(}\StringTok{"numeric"}\NormalTok{, N)}
\NormalTok{alpha\_sol[sv\_ind] }\OtherTok{\textless{}{-}} \FunctionTok{drop}\NormalTok{(svm\_model}\SpecialCharTok{$}\NormalTok{coefs[, }\DecValTok{1}\NormalTok{]) }\SpecialCharTok{/}\NormalTok{ y[sv\_ind]}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:svm-inseparable-alpha}이차계획문제의 최적해: 선형 분리 불가능 경우}
\centering
\begin{tabular}[t]{cc}
\toprule
variable & solution\\
\midrule
alpha\_1 & 0.8\\
alpha\_2 & 0.0\\
alpha\_3 & 0.0\\
alpha\_4 & 0.0\\
alpha\_5 & 0.8\\
\addlinespace
alpha\_6 & 0.0\\
alpha\_7 & 1.0\\
alpha\_8 & 0.0\\
alpha\_9 & 0.0\\
alpha\_10 & 1.0\\
\bottomrule
\end{tabular}
\end{table}

하이퍼플레인의 계수 \(\mathbf{w}\)는 분리 가능의 경우와 동일하게 구할 수 있다.

\begin{equation*}
\mathbf{w} = \sum_{i = 1}^{N} \alpha_{i}^{*} y_{i} \mathbf{x}_{i}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{colSums}\NormalTok{(alpha\_sol }\SpecialCharTok{*}\NormalTok{ y }\SpecialCharTok{*}\NormalTok{ X)}
\FunctionTok{print}\NormalTok{(w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  x1  x2 
## 0.6 0.8
\end{verbatim}

상수 \(b\)는 아래와 같이 \(0 < \alpha_{i}^{*} < C\)인 객체들을 이용해 산출할 수 있다.

\begin{equation*}
b = \sum_{i: 0 < \alpha_{i}^{*} < C} \frac{1 - y_{i} \mathbf{w}^{\top} \mathbf{x}_{i}}{y_{i}} \left/ \sum_{i: 0 < \alpha_{i}^{*} < C} 1 \right. 
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ind }\OtherTok{\textless{}{-}}\NormalTok{ sv\_ind[alpha\_sol[sv\_ind] }\SpecialCharTok{\textless{}}\NormalTok{ svm\_model}\SpecialCharTok{$}\NormalTok{cost]}
\NormalTok{b }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{((}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ y[ind] }\SpecialCharTok{*}\NormalTok{ (X[ind, ] }\SpecialCharTok{\%*\%}\NormalTok{ w)) }\SpecialCharTok{/}\NormalTok{ y[ind])}
\FunctionTok{print}\NormalTok{(b)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -7.6
\end{verbatim}

위와 같은 하이퍼플레인의 계수 \(\mathbf{w}\)와 상수 \(b\)값은 \texttt{svm} 객체에 원소들을 이용하여 보다 쉽게 확인할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{w }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(svm\_model}\SpecialCharTok{$}\NormalTok{coefs) }\SpecialCharTok{\%*\%}\NormalTok{ svm\_model}\SpecialCharTok{$}\NormalTok{SV}
\FunctionTok{print}\NormalTok{(w)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       x1  x2
## [1,] 0.6 0.8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{b }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\NormalTok{svm\_model}\SpecialCharTok{$}\NormalTok{rho}
\FunctionTok{print}\NormalTok{(b)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -7.6
\end{verbatim}

선형 하이퍼플레인으로 분리 불가능한 경우, 페널티 단가 \(C\)의 값에 따라 도출되는 분리 하이퍼플레인이 달라진다. \(C\)의 값이 1, 5, 100일 때의 하이퍼플레인을 비교해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svm\_models }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{100}\NormalTok{), }\ControlFlowTok{function}\NormalTok{(C)}
  \FunctionTok{svm}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(class) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, }\AttributeTok{data =}\NormalTok{ inseparable\_train\_df,}
      \AttributeTok{kernel =} \StringTok{"linear"}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{FALSE}\NormalTok{,}
      \AttributeTok{type =} \StringTok{"C{-}classification"}\NormalTok{, }\AttributeTok{cost =}\NormalTok{ C))}

\NormalTok{getHyperplane }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(model) \{}
  \FunctionTok{list}\NormalTok{(}\AttributeTok{C =}\NormalTok{ model}\SpecialCharTok{$}\NormalTok{cost,}
       \AttributeTok{w =} \FunctionTok{paste}\NormalTok{(}\FunctionTok{round}\NormalTok{(}\FunctionTok{t}\NormalTok{(model}\SpecialCharTok{$}\NormalTok{coefs) }\SpecialCharTok{\%*\%}\NormalTok{ model}\SpecialCharTok{$}\NormalTok{SV, }\AttributeTok{digits =} \DecValTok{2}\NormalTok{), }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{),}
       \AttributeTok{b =} \SpecialCharTok{{-}}\FunctionTok{round}\NormalTok{(model}\SpecialCharTok{$}\NormalTok{rho, }\AttributeTok{digits =} \DecValTok{2}\NormalTok{),}
       \AttributeTok{sv =} \FunctionTok{paste}\NormalTok{(model}\SpecialCharTok{$}\NormalTok{index, }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{),}
       \AttributeTok{misclassified =} \FunctionTok{paste}\NormalTok{(}\FunctionTok{which}\NormalTok{(model}\SpecialCharTok{$}\NormalTok{fitted }\SpecialCharTok{!=} \FunctionTok{as.factor}\NormalTok{(inseparable\_train\_df}\SpecialCharTok{$}\NormalTok{class)), }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{))}
\NormalTok{\}}

\NormalTok{svm\_summary }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(svm\_models, getHyperplane) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{bind\_rows}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:svm-inseparable-summary}페널티 단가 C에 따른 하이퍼플레인 계수 및 결과}
\centering
\begin{tabular}[t]{ccccc}
\toprule
페널티 단가 \$C\$ & \$(w\_1, w\_2)\$ & \$b\$ & 서포트 벡터 객체 & 오분류 객체\\
\midrule
1 & 0.6, 0.8 & -7.6 & 1, 7, 5, 10 & 10\\
5 & 0.4, 1.2 & -9.4 & 1, 4, 7, 5, 10 & 10\\
100 & 0.4, 1.2 & -9.4 & 1, 4, 7, 5, 10 & 10\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:svm-inseparable-summary}에서 보이는 바와 같이, 페널티 단가 \(C\)의 값이 1과 5일 때 분리 하이퍼플레인이 변하는 것을 볼 수 있다. \(C\)값이 5와 100일 때의 분리 하이퍼플레인은 거의 동일하다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(svm\_models[[}\DecValTok{2}\NormalTok{]], }\AttributeTok{data =}\NormalTok{ inseparable\_train\_df, }\AttributeTok{formula =}\NormalTok{ x2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1, }\AttributeTok{grid =} \DecValTok{200}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/linear-svm-inseparable-highcost-1} 

}

\caption{선형 SVM 분리 불가능 경우의 하이퍼플레인 ($C = 5$)}\label{fig:linear-svm-inseparable-highcost}
\end{figure}

Figure \ref{fig:linear-svm-inseparable-highcost}의 하이퍼플레인(\(C = 5\)인 경우)은 Figure \ref{fig:linear-svm-basic-inseparable}의 하이퍼플레인(\(C = 1\)인 경우)보다 오분류 객체에 가깝게 위치함을 확인할 수 있다.

\hypertarget{nonlinear-svm}{%
\section{비선형 SVM}\label{nonlinear-svm}}

본 장에서는 선형으로 분리 성능이 좋지 않은 경우에 대해 원 입력변수에 대해 비선형인 하이퍼플레인을 찾는 문제를 다룬다. 이는 원 입력변수에 대해 비선형인 기저함수 공간으로 객체를 이동시킨 후 해당 공간에서 선형 분리 하이퍼플레인을 찾는 과정이다.

\hypertarget{nonlinear-svm-basic-script}{%
\subsection{기본 R 스크립트}\label{nonlinear-svm-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nonlinear\_train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{x1 =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{9}\NormalTok{, }\DecValTok{5}\NormalTok{), }
  \AttributeTok{x2 =} \FunctionTok{c}\NormalTok{(}\DecValTok{7}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{4}\NormalTok{), }
  \AttributeTok{class =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{)}
\NormalTok{)}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(nonlinear\_train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
             \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
             \AttributeTok{caption =} \StringTok{\textquotesingle{}비선형 SVM 학습표본 데이터\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:nonlinear-svm-train-data}비선형 SVM 학습표본 데이터}
\centering
\begin{tabular}[t]{rrr}
\toprule
x1 & x2 & class\\
\midrule
5 & 7 & 1\\
4 & 3 & -1\\
7 & 8 & -1\\
8 & 6 & -1\\
3 & 6 & 1\\
\addlinespace
2 & 5 & 1\\
6 & 6 & 1\\
9 & 6 & -1\\
5 & 4 & -1\\
\bottomrule
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(e1071)}
\NormalTok{svm\_model }\OtherTok{\textless{}{-}} \FunctionTok{svm}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(class) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, }\AttributeTok{data =}\NormalTok{ nonlinear\_train\_df, }
                 \AttributeTok{kernel =} \StringTok{"polynomial"}\NormalTok{, }\AttributeTok{coef0 =} \DecValTok{1}\NormalTok{, }\AttributeTok{gamma =} \DecValTok{1}\NormalTok{, }\AttributeTok{degree =} \DecValTok{2}\NormalTok{,}
                 \AttributeTok{cost =} \DecValTok{5}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(svm\_model, }\AttributeTok{data =}\NormalTok{ nonlinear\_train\_df, }\AttributeTok{formula =}\NormalTok{ x2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1, }\AttributeTok{grid =} \DecValTok{200}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/nonlinear-svm-basic-1} 

}

\caption{비선형 SVM 하이퍼플레인}\label{fig:nonlinear-svm-basic}
\end{figure}

\hypertarget{nonlinear-svm-hyperplane}{%
\subsection{최적 하이퍼플레인}\label{nonlinear-svm-hyperplane}}

식 \eqref{eq:linear-svm-hyperplane}을 일반화한 다음과 같은 하이퍼플레인을 고려하자.

\begin{equation}
f(\mathbf{x}) = \Phi(\mathbf{x})^\top \mathbf{w} + b \label{eq:nonlinear-svm-hyperplane}
\end{equation}

여기서 벡터함수 \(\Phi: \mathbb{R}^p \rightarrow \mathbb{R}^m\)는 \(\mathbf{x}\)에 대한 새로운 특징(feature)을 추출하는 변환함수라 할 수 있는데, 통상 추출되는 특징의 차원 \(m\)이 원 변수 \(\mathbf{x}\)의 차원 \(p\)보다 높다. 이를 \(\mathbf{x}\)의 기저함수(basis function)라 부르며, 하이퍼플레인 계수 또한 \(m\)차원의 벡터가 된다 (\(\mathbf{w} \in \mathbb{R}^m\)). 이 때, 비선형 SVM 문제는 선형 SVM 문제 식 \eqref{eq:linear-svm-inseparable-dual}에서 변수를 기저변수로 치환한 형태로 아래 식 \eqref{eq:nonlinear-svm-dual}과 같이 나타낼 수 있다.

\begin{equation}
\begin{split}
\max \text{  } & L_D = \sum_{i = 1}^{N} \alpha_i - \frac{1}{2} \sum_{i = 1}^{N} \sum_{j = 1}^{N} \alpha_i \alpha_j y_i y_j \Phi(\mathbf{x}_i)^\top \Phi(\mathbf{x}_j)\\
\text{s.t. } &\\
& \sum_{i = 1}^{N} \alpha_i y_i = 0\\
& 0 \le \alpha_i \le C, \text{  } i = 1, \cdots, N
\end{split}
\label{eq:nonlinear-svm-dual}
\end{equation}

식 \eqref{eq:nonlinear-svm-dual}의 목적함수에서 기저함수의 내적 \(\Phi(\mathbf{x}_i)^\top \Phi(\mathbf{x}_j)\)을 아래와 같이 커널함수(kernel function)로 나타낼 수 있으며, 이는 두 객체 \(\mathbf{x}_i, \mathbf{x}_j\)간의 일종의 유사성 척도(similarity measure)로 해석될 수 있다.

\begin{equation*}
K(\mathbf{x}_i, \mathbf{x}_j) = \Phi(\mathbf{x}_i)^\top \Phi(\mathbf{x}_j)
\end{equation*}

널리 사용되는 커널함수로는 아래와 같은 함수들이 있다.

\begin{eqnarray*}
\text{Gaussian RBF:} & & K(\mathbf{x}_i, \mathbf{x}_j) = \exp \left( \frac{- \left\lVert \mathbf{x}_i - \mathbf{x}_j \right\rVert^2}{2 \sigma^2} \right)\\
\text{$r$-th order polynomial:} & & K(\mathbf{x}_i, \mathbf{x}_j) = \left( \mathbf{x}_i^\top \mathbf{x}_j + 1 \right)^r \\
\text{Sigmoid:} & & K(\mathbf{x}_i, \mathbf{x}_j) = \tanh \left(\kappa \mathbf{x}_i^\top \mathbf{x}_j - \delta \right)
\end{eqnarray*}

커널함수를 이용하여 분리 하이퍼플레인을 찾기 위한 식을 아래와 같이 나타낸다.

\begin{equation}
\begin{split}
\max \text{  } & L_D = \sum_{i = 1}^{N} \alpha_i - \frac{1}{2} \sum_{i = 1}^{N} \sum_{j = 1}^{N} \alpha_i \alpha_j y_i y_j k_{ij}\\
\text{s.t. } &\\
& \sum_{i = 1}^{N} \alpha_i y_i = 0\\
& 0 \le \alpha_i \le C, \text{  } i = 1, \cdots, N
\end{split}
\label{eq:nonlinear-svm-dual-kernel}
\end{equation}

이 때 \(k_{ij}\)는 \(K(\mathbf{x}_i, \mathbf{x}_j)\)를 나타낸다. 식 \eqref{eq:nonlinear-svm-dual-kernel}의 최적해 \(\boldsymbol\alpha^*\)는 선형 SVM과 마찬가지로 이차계획(quadratic programming) 소프트웨어/알고리즘을 이용하여 구할 수 있다.

Table \ref{tab:nonlinear-svm-train-data}의 학습데이터에 대해 \texttt{e1071} 패키지의 \texttt{svm} 함수를 이용하여 이차 다항 커널에 기반한 분리 하이퍼플레인을 구해보자. \texttt{svm} 함수에 파라미터값 \texttt{kernel\ =\ "polynomial"}를 설정함으로써 다항 커널을 사용할 수 있다. \texttt{svm} 함수의 다항 커널은 위에서 설명된 것보다 일반화된 형태로 아래와 같이 정의된다.

\begin{equation*}
K(\mathbf{x}_i, \mathbf{x}_j) = \left( \gamma \mathbf{x}_i^\top \mathbf{x}_j + \beta_0 \right)^r
\end{equation*}

위 커널함수의 파라미터 \(\gamma, \beta_0, r\)은 \texttt{svm} 함수에 파라미터 \texttt{gamma,\ coef0,\ degree}로 각각 정의된다. 따라서 이차 커널

\begin{equation*}
K(\mathbf{x}_i, \mathbf{x}_j) = \left( \mathbf{x}_i^\top \mathbf{x}_j + 1 \right)^2
\end{equation*}

에 기반한 SVM을 학습하기 위해서 아래와 같이 \texttt{svm} 함수를 호출한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svm\_model }\OtherTok{\textless{}{-}} \FunctionTok{svm}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(class) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, }\AttributeTok{data =}\NormalTok{ nonlinear\_train\_df, }
                 \AttributeTok{kernel =} \StringTok{"polynomial"}\NormalTok{, }\AttributeTok{coef0 =} \DecValTok{1}\NormalTok{, }\AttributeTok{gamma =} \DecValTok{1}\NormalTok{, }\AttributeTok{degree =} \DecValTok{2}\NormalTok{,}
                 \AttributeTok{scale =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

위 함수 호출 결과 서포트 벡터 객체는 1, 7, 2, 3, 9이다.

비선형 SVM의 분리 하이퍼플레인 또한 페널티 단가 \(C\)의 값에 따라 달라진다. 선형 SVM의 경우와 같이 \(C = 1, 5, 100\)에 대해 각각 비선형 SVM을 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svm\_models }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{100}\NormalTok{),}
  \ControlFlowTok{function}\NormalTok{(C)}
    \FunctionTok{svm}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(class) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, }\AttributeTok{data =}\NormalTok{ nonlinear\_train\_df,}
        \AttributeTok{kernel =} \StringTok{"polynomial"}\NormalTok{, }\AttributeTok{coef0 =} \DecValTok{1}\NormalTok{, }\AttributeTok{gamma =} \DecValTok{1}\NormalTok{, }\AttributeTok{degree =} \DecValTok{2}\NormalTok{,}
        \AttributeTok{cost =}\NormalTok{ C, }\AttributeTok{scale =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{)}

\NormalTok{getSummary }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(model) \{}
  \FunctionTok{list}\NormalTok{(}\AttributeTok{C =}\NormalTok{ model}\SpecialCharTok{$}\NormalTok{cost,}
       \AttributeTok{sv =} \FunctionTok{paste}\NormalTok{(model}\SpecialCharTok{$}\NormalTok{index, }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{),}
       \AttributeTok{misclassified =} \FunctionTok{paste}\NormalTok{(}\FunctionTok{which}\NormalTok{(model}\SpecialCharTok{$}\NormalTok{fitted }\SpecialCharTok{!=} \FunctionTok{as.factor}\NormalTok{(nonlinear\_train\_df}\SpecialCharTok{$}\NormalTok{class)), }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{))}
\NormalTok{\}}

\NormalTok{svm\_summary }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(svm\_models, getSummary) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{bind\_rows}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:nonlinear-svm-summary}페널티 단가 C에 따른 비선형 SVM 결과}
\centering
\begin{tabular}[t]{ccc}
\toprule
페널티 단가 \$C\$ & 서포트 벡터 객체 & 오분류 객체\\
\midrule
1 & 1, 7, 2, 3, 9 & 7\\
5 & 6, 7, 2, 3, 9 & \\
100 & 6, 7, 2, 3, 9 & \\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{svm-r-pkg}{%
\section{R패키지 내 SVM}\label{svm-r-pkg}}

\hypertarget{svm-kernel-function}{%
\subsection{커널함수}\label{svm-kernel-function}}

앞 장에서는 선형 커널과 다항 커널함수의 예를 살펴보았다. 본 장에서는 가우시안 커널 및 시그모이드 커널을 사용하는 법을 살펴보자.

가우시안 커널의 경우

\begin{equation*}
K(\mathbf{x}_i, \mathbf{x}_j) = \exp \left( -\gamma \left\lVert \mathbf{x}_i - \mathbf{x}_j \right\rVert^2 \right)
\end{equation*}

과 같이 \(\gamma\) 파라미터를 이용하여 함수를 정의하며, \texttt{svm} 함수에 \texttt{gamma} 파라미터값을 통해 설정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svm\_model }\OtherTok{\textless{}{-}} \FunctionTok{svm}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(class) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, }\AttributeTok{data =}\NormalTok{ nonlinear\_train\_df, }
                 \AttributeTok{kernel =} \StringTok{"radial"}\NormalTok{, }\AttributeTok{gamma =} \DecValTok{1}\NormalTok{,}
                 \AttributeTok{cost =} \DecValTok{5}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(svm\_model, }\AttributeTok{data =}\NormalTok{ nonlinear\_train\_df, }\AttributeTok{formula =}\NormalTok{ x2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1, }\AttributeTok{grid =} \DecValTok{200}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/nonlinear-svm-radial-1} 

}

\caption{가우시안 커널을 이용한 비선형 SVM 하이퍼플레인}\label{fig:nonlinear-svm-radial}
\end{figure}

시그모이드 커널의 경우

\begin{equation*}
K(\mathbf{x}_i, \mathbf{x}_j) = \tanh \left(\gamma \mathbf{x}_i^\top \mathbf{x}_j + \beta_0 \right)
\end{equation*}

와 같이 두 파라미터 \(\gamma, \beta_0\)의 값에 대응하는 \texttt{svm} 함수의 파라미터 \texttt{gamma,\ coef0} 값을 통해 설정할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svm\_model }\OtherTok{\textless{}{-}} \FunctionTok{svm}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(class) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, }\AttributeTok{data =}\NormalTok{ nonlinear\_train\_df, }
                 \AttributeTok{kernel =} \StringTok{"sigmoid"}\NormalTok{, }\AttributeTok{gamma =} \FloatTok{0.01}\NormalTok{, }\AttributeTok{coef0 =} \SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}
                 \AttributeTok{cost =} \DecValTok{5}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(svm\_model, }\AttributeTok{data =}\NormalTok{ nonlinear\_train\_df, }\AttributeTok{formula =}\NormalTok{ x2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1, }\AttributeTok{grid =} \DecValTok{200}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/nonlinear-svm-sigmoid-1} 

}

\caption{시그모이드 커널을 이용한 비선형 SVM 하이퍼플레인}\label{fig:nonlinear-svm-sigmoid}
\end{figure}

커널 함수의 종류 \texttt{kernel}, 커널 함수의 파라미터 \texttt{gamma,\ coef0,\ degree}, 페널티 단가 \texttt{cost}등의 \texttt{svm} 함수 파라미터는 학습 표본과는 별도의 테스트 데이터에 대해 오분류율을 최소화하는 값을 선택하는 것이 일반적이다.

\hypertarget{svm-nu-classification}{%
\subsection{\texorpdfstring{\(\nu\)-SVC}{\textbackslash nu-SVC}}\label{svm-nu-classification}}

\(\nu\)-support vector classification(\(\nu\)-SVC) \citep[\citet{chang2001training}]{scholkopf2000new}은 \(C\)-SVC의 이차계획식 \eqref{eq:nonlinear-svm-dual-kernel}과 다른 형태로, 페널티 단가 \(C\) 대신 \(\nu\)라는 파라미터를 이용한 아래 최적화 문제의 해를 구한다.

\begin{equation}
\begin{split}
\min \text{  } & L_D = \sum_{i = 1}^{N} \sum_{j = 1}^{N} \alpha_i \alpha_j y_i y_j k_{ij}\\
\text{s.t. } &\\
& \sum_{i = 1}^{N} \alpha_i y_i = 0\\
& 0 \le \alpha_i \le \frac{1}{N}, \text{  } i = 1, \cdots, N\\
& \sum_{i = 1}^{N} \alpha_i = \nu
\end{split}
\label{eq:nonlinear-nu-svc-dual}
\end{equation}

이 때, 각 \(\alpha_i\)의 최대값은 \(1/N\)으로, \(\nu\)를 포함한 제약식을 무시할 때 모든 객체에 대한 \(\alpha_i\)값의 합의 이론적 최대치는 1이 되며, \(\nu \in (0, 1]\)은 전체 객체 중 서포트 벡터 객체의 개수를 제한하는 개념으로 생각할 수 있다. 식 \eqref{eq:nonlinear-nu-svc-dual}이 실제로 최적해를 가지기 위한 \(\nu\)값의 범위는

\begin{equation*}
0 < \nu \le \frac{2}{N} \min \left( \sum_i I(y_i = 1), \sum_i I(y_i = -1) \right)
\end{equation*}

으로 \citep{chang2001training}, 에를 들어 범주 1에 속하는 학습표본 객체 수가
전체의 10\% 라면, \(\nu\) 값은 최대 0.2 까지 설정할 수 있다. 또한

\texttt{svm} 함수가 호출하는 \texttt{LIBSVM} 라이브러리는 위 식 \eqref{eq:nonlinear-nu-svc-dual}을 \(N\)이 큰(학습 표본 수가 매우 많은) 경우에도 안정된 결과를 얻을 수 있도록 아래와 같이 변환한 문제를 다룬다.

\begin{equation}
\begin{split}
\min \text{  } & L_D = \sum_{i = 1}^{N} \sum_{j = 1}^{N} \bar{\alpha}_i \bar{\alpha}_j y_i y_j k_{ij}\\
\text{s.t. } &\\
& \sum_{i = 1}^{N} \bar{\alpha}_i y_i = 0\\
& 0 \le \bar{\alpha}_i \le 1, \text{  } i = 1, \cdots, N\\
& \sum_{i = 1}^{N} \bar{\alpha}_i = \nu N
\end{split}
\label{eq:libsvm-nu-svc-dual}
\end{equation}

이 때 \(\bar{\alpha}_i = \alpha_i N\)이다.

\(\nu\)-SVC은 아래와 같이 \texttt{svm} 함수를 호출할 때 \texttt{type\ =\ "nu-classification"}과 파라미터 \texttt{nu} 값을 설정함으로써 학습할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{svm\_model }\OtherTok{\textless{}{-}} \FunctionTok{svm}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(class) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1 }\SpecialCharTok{+}\NormalTok{ x2, }\AttributeTok{data =}\NormalTok{ nonlinear\_train\_df, }
                 \AttributeTok{type =} \StringTok{"nu{-}classification"}\NormalTok{, }
                 \AttributeTok{kernel =} \StringTok{"radial"}\NormalTok{, }\AttributeTok{gamma =} \DecValTok{1}\NormalTok{,}
                 \AttributeTok{nu =} \FloatTok{0.5}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(svm\_model, }\AttributeTok{data =}\NormalTok{ nonlinear\_train\_df, }\AttributeTok{formula =}\NormalTok{ x2 }\SpecialCharTok{\textasciitilde{}}\NormalTok{ x1, }\AttributeTok{grid =} \DecValTok{200}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/nu-svc-radial-1} 

}

\caption{가우시안 커널을 이용한 $\nu$-SVC 하이퍼플레인}\label{fig:nu-svc-radial}
\end{figure}

\hypertarget{classifier-evaluation}{%
\chapter{분류규칙의 성능 평가}\label{classifier-evaluation}}

도출된 분류규칙에 대한 평가는 범주를 아는 학습표본이 있으므로 비교적 용이하게 이루어진다. 분류정확도 또는 분류오류율이 기본이 되나, 특히 범주가 2개인 경우에는 다양한 성능평가척도가 개발되어 사용되고 있다.

\hypertarget{classifier-evaluation-packages-install}{%
\section{필요 R 패키지 설치}\label{classifier-evaluation-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.3.1\\
\hline
caret & 6.0-88\\
\hline
\end{tabular}

\hypertarget{classifier-evaluation-misclassification-rate}{%
\section{분류오류율}\label{classifier-evaluation-misclassification-rate}}

범주를 아는 데이터 \(\{(\mathbf{x}_i, y_i)\}_{i = 1, \cdots, N}\)를 학습표본이라 한다.

\begin{itemize}
\tightlist
\item
  \(\mathbf{x}_i\): \(p\)개의 독립변수로 이루어진 \(i\)번째 객체의 변수벡터 (\(\mathbf{x}_i = [x_{i1} \, x_{i2} \, \cdots \, x_{ip}]^\top\))
\item
  \(J\): 총 범주 수
\item
  \(y_i\): \(i\)번째 객체의 범주 변수; \(y_i \in \{1, 2, \cdots, J\}\)
\end{itemize}

분류규칙 \(d(\mathbf{x})\)의 성능은 주로 분류오류율(misclassification rate)을 사용하는데, 분류규칙이 추정한 범주와 실제범주가 일치하지 않는 비율을 나타낸다.

\begin{equation}
R(d) = \frac{1}{N} \sum_{i = 1}^{N} I(d(\mathbf{x}_i) \neq y_i)
\label{eq:misclassification-rate-train}
\end{equation}

여기서 함수 지시함수 \(I(x)\)는 \(x\)가 참(true)일 때 1, 거짓(false)일 때 0의 값을 갖는다.

식 \eqref{eq:misclassification-rate-train}은 학습표본에 대한 오분류율로, 이를 최소화하려할 경우 분류규칙이 해당 학습데이터에만 과적용(overfitting)되는 문제가 발생할 수 있다. 즉, 새로운 데이터에 적용할 때도 오분류율이 최소화될 것이라는 보장이 없다.

이 때문에, 통상 관측수가 상당수 있는 데이터에 대해서는 전체 데이터를 두 부분으로 나누어, 분류규칙을 만드는 데 한 부분을 사용하고, 분류오류율을 산출하는 데 다른 한 부분을 사용하는 방안이 일반적이다. 아래와 같이 범주가 알려져있지만 분류규칙 \(d(\mathbf{x})\)를 학습하는 데 사용하지 않은 \(L\)개의 테스트 표본 \(\{(\mathbf{x}_i, y_i)\}_{i = N + 1, \cdots, N + L}\)이 있다고 하자. 이 때 테스트 표본에 대한 분류오류율을 아래와 같이 계산한다.

\begin{equation}
R^{ts}(d) = \frac{1}{L} \sum_{i = N + 1}^{N + L} I(d(\mathbf{x}_i) \neq y_i)
\label{eq:misclassification-rate-test}
\end{equation}

테스트 표본으로 분리하기에 충분하지 않은 데이터의 경우에는 cross validation 기법을 사용한다.

\hypertarget{precision-sensitivity-specificity}{%
\section{정확도, 민감도 및 특이도}\label{precision-sensitivity-specificity}}

의학 분야에서 어떤 질병에 대한 진단방법을 평가할 때 오류율 이와에 정확도, 민감도 및 특이도를 분석하는 경우가 종종 있다. 실제범주가 질병이 있는 경우(\texttt{1} 또는 \texttt{+}로 표기)와 질병이 없는 경우(\texttt{0} 또는 \texttt{-}로 표기)의 두 가지로 분류된다고 하고, 진단 방법이 양성(\texttt{1} 또는 \texttt{+}) 또는 음성(\texttt{0} 또는 \texttt{-})으로 판정할 때, 아래와 같이 네 가지 경우가 발생한다. 이와 같은 표를 정오분류표(confusion matrix)라 한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}a\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}b\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}d\textquotesingle{}}\NormalTok{), }\AttributeTok{nrow =} \DecValTok{2}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{attr}\NormalTok{(cm, }\StringTok{"dimnames"}\NormalTok{) }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{Prediction =} \FunctionTok{c}\NormalTok{(}\StringTok{"1"}\NormalTok{, }\StringTok{"0"}\NormalTok{), }\AttributeTok{Reference =} \FunctionTok{c}\NormalTok{(}\StringTok{"1"}\NormalTok{, }\StringTok{"0"}\NormalTok{))}
\FunctionTok{class}\NormalTok{(cm) }\OtherTok{\textless{}{-}} \StringTok{"table"}
\FunctionTok{print}\NormalTok{(cm)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Reference
## Prediction 1 0
##          1 a b
##          0 c d
\end{verbatim}

위 표의 문자들은 다음과 같이 정의된다.

\begin{itemize}
\tightlist
\item
  \(a\): number of true positive prediction
\item
  \(b\): number of false positive prediction
\item
  \(c\): number of false negative prediction
\item
  \(d\): number of true negative prediction
\end{itemize}

여기서 ``positive'' 또는 ``negative''는 ``양성'' 또는 ``음성''으로 추정됨을 나타내고, ``true'' 또는 ``false''는 추정의 사실 또는 거짓을 나타낸다. 이 때 분류오류율은 다음과 같이 산출된다.

\begin{equation}
\text{misclassifiction rate} = \frac{b + c}{a + b + c + d}
\label{eq:cm-misclassification-rate}
\end{equation}

정확도(accuracy)는 오류율의 반대 개념으로, 실제 범주를 제대로 추정한 전체 비율을 나타내며 아래와 같이 산출된다.

\begin{equation}
\text{accuracy} = \frac{a + d}{a + b + c + d} = 1 - \text{misclassifiction rate}
\label{eq:cm-accuracy}
\end{equation}

한편, 민감도(sensitivity)는 실제 질병이 있는 경우를 양성으로 판정하는 비율을 나타내는 것으로, 다음과 같이 산출된다.

\begin{equation}
\text{sensitivity} = \frac{a}{a + c}
\label{eq:cm-sensitivity}
\end{equation}

그리고 특이도(specificity)란 실제 질병이 없는 경우를 음성으로 판정하는 비율을 나타내는 것으로 다음과 같다.

\begin{equation}
\text{specificity} = \frac{d}{b + d}
\label{eq:cm-specificity}
\end{equation}

정확도를 민감도 및 특이도로 표현하면 다음과 같다.

\begin{equation*}
\text{accuracy} = \frac{a + c}{a + b + c + d}\text{sensitivity} + \frac{b + d}{a + b + c + d}\text{specificity}
\end{equation*}

민감도 및 특이도를 별도로 산출하여 분석하는 이유 중 하나는, 동일한 정확도를 갖는다 하더라도 민감도와 특이도는 다를 수 있기 때문이다. 경우에 따라서는 높은 민감도를 원하거나 높은 특이도를 원할 수 있다.

\hypertarget{confusion-matrix-r-package}{%
\subsection{R 패키지 내 정오분류표}\label{confusion-matrix-r-package}}

100개의 객체에 대한 실제범주와 추정범주가 아래와 같이 주어진다고 하자.

\begin{eqnarray*}
y_i &=& \begin{cases}
1 & i = 1, \cdots, 20\\
0 & i = 21, \cdots, 100
\end{cases},\\
\hat{y}_i &=& \begin{cases}
1 & i = 1, \cdots, 15, 91, \cdots, 100\\
0 & i = 16, \cdots, 90
\end{cases}
\end{eqnarray*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{20}\NormalTok{), }\FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{80}\NormalTok{)), }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\NormalTok{y\_hat }\OtherTok{\textless{}{-}}\FunctionTok{factor}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{15}\NormalTok{), }\FunctionTok{rep}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{75}\NormalTok{), }\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{)), }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

해당 추정결과에 대한 정오분류표 및 각종 평가지표를 얻기 위해 \texttt{caret} 패키지의 \texttt{confusionMatrix} 함수를 이용한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm }\OtherTok{\textless{}{-}}\NormalTok{ caret}\SpecialCharTok{::}\FunctionTok{confusionMatrix}\NormalTok{(}\AttributeTok{data =}\NormalTok{ y\_hat, }\AttributeTok{reference =}\NormalTok{ y)}
\end{Highlighting}
\end{Shaded}

우선 정오분류표는 결과 객체의 \texttt{table} component에 저장된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm}\SpecialCharTok{$}\NormalTok{table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Reference
## Prediction  1  0
##          1 15 10
##          0  5 70
\end{verbatim}

정확도를 비롯한 각종 전반적인 지표는 \texttt{overall}이라는 component에 벡터 형태로 저장된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm}\SpecialCharTok{$}\NormalTok{overall}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       Accuracy          Kappa  AccuracyLower  AccuracyUpper   AccuracyNull 
##      0.8500000      0.5714286      0.7646925      0.9135456      0.8000000 
## AccuracyPValue  McnemarPValue 
##      0.1285055      0.3016996
\end{verbatim}

또한, 민감도, 특이도를 비롯한 몇 가지 분류성능 지표들은 \texttt{byClass}라는 component에 역시 벡터 형태로 저장된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm}\SpecialCharTok{$}\NormalTok{byClass}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          Sensitivity          Specificity       Pos Pred Value 
##            0.7500000            0.8750000            0.6000000 
##       Neg Pred Value            Precision               Recall 
##            0.9333333            0.6000000            0.7500000 
##                   F1           Prevalence       Detection Rate 
##            0.6666667            0.2000000            0.1500000 
## Detection Prevalence    Balanced Accuracy 
##            0.2500000            0.8125000
\end{verbatim}

\hypertarget{roc-curve}{%
\section{ROC 곡선}\label{roc-curve}}

일반적으로 민감도와 특이도를 동시에 증가시키는 것은 불가능하다. 다시 말하면, 민감도를 높이면 특이도가 감소하고, 또한 반대가 성립하게 된다.

예를 들어 다음과 같이 10개의 객체로 이루어진 학습표본이 있다고 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{x, }\SpecialCharTok{\textasciitilde{}}\NormalTok{y,}
  \DecValTok{24}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{35}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{37}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{42}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{49}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{54}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{56}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{68}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{72}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{73}\NormalTok{, }\DecValTok{1}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{y =} \FunctionTok{factor}\NormalTok{(y, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

분류기준이 만약 \(x < 40\)이면 범주 \texttt{0}, \(x \geq 40\)이면 범주 \texttt{1}로 추정할 때, 정오분류표는 다음과 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm40 }\OtherTok{\textless{}{-}}\NormalTok{ caret}\SpecialCharTok{::}\FunctionTok{confusionMatrix}\NormalTok{(}
  \FunctionTok{factor}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(train\_df}\SpecialCharTok{$}\NormalTok{x }\SpecialCharTok{\textgreater{}=} \DecValTok{40}\NormalTok{), }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)),}
\NormalTok{  train\_df}\SpecialCharTok{$}\NormalTok{y}
\NormalTok{)}

\NormalTok{cm40}\SpecialCharTok{$}\NormalTok{table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Reference
## Prediction 1 0
##          1 5 2
##          0 1 2
\end{verbatim}

이 때 구해지는 민감도 및 특이도는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm40}\SpecialCharTok{$}\NormalTok{byClass[}\FunctionTok{c}\NormalTok{(}\StringTok{"Sensitivity"}\NormalTok{, }\StringTok{"Specificity"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Sensitivity Specificity 
##   0.8333333   0.5000000
\end{verbatim}

한편, 분류기준이 만약 \(x < 50\)이면 범주 \texttt{0}, \(x \geq 50\)이면 범주 \texttt{1}로 추정할 때, 정오분류표는 다음과 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm50 }\OtherTok{\textless{}{-}}\NormalTok{ caret}\SpecialCharTok{::}\FunctionTok{confusionMatrix}\NormalTok{(}
  \FunctionTok{factor}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(train\_df}\SpecialCharTok{$}\NormalTok{x }\SpecialCharTok{\textgreater{}=} \DecValTok{50}\NormalTok{), }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)),}
\NormalTok{  train\_df}\SpecialCharTok{$}\NormalTok{y}
\NormalTok{)}

\NormalTok{cm50}\SpecialCharTok{$}\NormalTok{table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           Reference
## Prediction 1 0
##          1 4 1
##          0 2 3
\end{verbatim}

또한, 이 때 구해지는 민감도 및 특이도는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cm50}\SpecialCharTok{$}\NormalTok{byClass[}\FunctionTok{c}\NormalTok{(}\StringTok{"Sensitivity"}\NormalTok{, }\StringTok{"Specificity"}\NormalTok{)]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Sensitivity Specificity 
##   0.6666667   0.7500000
\end{verbatim}

위 \(x\)값 40을 기준으로 분류를 하는 경우와 비교하여 민감도는 감소하고 특이도는 증가함을 관찰할 수 있다.

분류를 위한 \(x\) 기준값(threshold)을 증가시켜가면서 민감도와 특이도가 어떻게 변하는 지 살펴보도록 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{univariate\_binary\_rule }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, y, th) \{}
\NormalTok{  cm }\OtherTok{\textless{}{-}}\NormalTok{ caret}\SpecialCharTok{::}\FunctionTok{confusionMatrix}\NormalTok{(}
    \FunctionTok{factor}\NormalTok{(}\FunctionTok{as.integer}\NormalTok{(x }\SpecialCharTok{\textgreater{}=}\NormalTok{ th), }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)),}
\NormalTok{    y}
\NormalTok{  )}
  
  \FunctionTok{tibble}\NormalTok{(}\AttributeTok{threshold =}\NormalTok{ th, }
         \AttributeTok{sensitivity =}\NormalTok{ cm}\SpecialCharTok{$}\NormalTok{byClass[}\StringTok{"Sensitivity"}\NormalTok{],}
         \AttributeTok{specificity =}\NormalTok{ cm}\SpecialCharTok{$}\NormalTok{byClass[}\StringTok{"Specificity"}\NormalTok{])}
\NormalTok{\}}

\NormalTok{th }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{sort}\NormalTok{(train\_df}\SpecialCharTok{$}\NormalTok{x), }\ConstantTok{Inf}\NormalTok{)}

\NormalTok{roc\_df }\OtherTok{\textless{}{-}} \FunctionTok{map\_dfr}\NormalTok{(th, univariate\_binary\_rule, }\AttributeTok{x =}\NormalTok{ train\_df}\SpecialCharTok{$}\NormalTok{x, }\AttributeTok{y =}\NormalTok{ train\_df}\SpecialCharTok{$}\NormalTok{y)}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  roc\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
  \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}분류기준값($x$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}민감도(sensitivity)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}특이도(specificity)\textquotesingle{}}\NormalTok{),}
  \AttributeTok{caption =} \StringTok{\textquotesingle{}분류기준별 민감도 및 특이도\textquotesingle{}}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:roc-data}분류기준별 민감도 및 특이도}
\centering
\begin{tabular}[t]{rrr}
\toprule
분류기준값(\$x\$) & 민감도(sensitivity) & 특이도(specificity)\\
\midrule
24 & 1.0000000 & 0.00\\
35 & 1.0000000 & 0.25\\
37 & 1.0000000 & 0.50\\
42 & 0.8333333 & 0.50\\
49 & 0.8333333 & 0.75\\
\addlinespace
54 & 0.6666667 & 0.75\\
56 & 0.5000000 & 0.75\\
68 & 0.5000000 & 1.00\\
72 & 0.3333333 & 1.00\\
73 & 0.1666667 & 1.00\\
\addlinespace
Inf & 0.0000000 & 1.00\\
\bottomrule
\end{tabular}
\end{table}

민감도와 특이도를 동시에 그래프로 나타낸 것 중 ROC(receiver operating characteristic) 곡선이 널리 사용되는데, 이는 분류기의 경계치를 조정하여 가면서 (1 - 특이도)(또는 false positive rate)을 \(x\)축에, 민감도를 \(y\)축에 도식화한 것이다.

위 Table \ref{tab:roc-data}를 바탕으로 ROC 곡선을 작성해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{roc\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ specificity, }\AttributeTok{y =}\NormalTok{ sensitivity)) }\SpecialCharTok{+}
  \FunctionTok{geom\_path}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/roc-example-1} 

}

\caption{ROC 곡선}\label{fig:roc-example}
\end{figure}

\hypertarget{gain-chart}{%
\section{이익도표}\label{gain-chart}}

이익도표는 마케팅을 위하여 수익을 창출하는 목표고객(target)을 추출할 목적으로 사용되는데, 단순히 분류를 위한 여러 모형을 비교하기 위한 목적으로도 종종 사용되고 있다. 목표 마케팅의 목적에서는, 특정 범주의 고객을 목표고객으로 할 때, 이러한 목표고객의 비율이 상대적으로 높은 서브그룹을 찾고자 하는 것이다. 이를 위해, 우선 전체 데이터를 특정 범주의 사후확률의 순서로 정렬한 후, \(K\)개(주로 \(K = 10\)을 사용)의 집단으로 구분하고, 각 집단별로 다음과 같은 통계량을 산출한다.

\(k\)번째 집단 내에서 범주 \(j\)에 속한 객체의 수를 \(n_{kj}\)라 할 때, 다음과 같은 범주 \(j\)에 대한 \(k\)번째 집단의 통계량들을 산출할 수 있다. (본 장에서 \(K\)개의 집단은 동일한 크기라 가정하자. 즉, 모든 집단 \(k\)에 대해 \(\sum_{j = 1}^{J} n_{kj} = \frac{N}{K}\)가 성립한다고 하자.)

\begin{eqnarray*}
\text{$\%$ captured response} &=& \frac{n_{kj}}{\sum_{k = 1}^{K} n_{kj}} \times 100\\
\text{cumulative $\%$ captured response} &=& \frac{\sum_{l = 1}^{k} n_{lj}}{\sum_{k = 1}^{K} n_{kj}} \times 100\\
\text{$\%$ response} &=& \frac{n_{kj}}{\sum_{j = 1}^{J} n_{kj}} \times 100\\
\text{lift} &=& \frac{n_{kj}}{\frac{1}{K} \sum_{k = 1}^{K} n_{kj}}
\end{eqnarray*}

1,000개의 객체로 이루어진 어떤 데이터의 실제 범주별 빈도가 다음과 같다고 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_freq }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{y, }\SpecialCharTok{\textasciitilde{}}\NormalTok{n,}
  \DecValTok{1}\NormalTok{, }\DecValTok{437}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{348}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{215}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{y =} \FunctionTok{factor}\NormalTok{(y, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)))}

\NormalTok{y\_freq}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##   y         n
##   <fct> <dbl>
## 1 1       437
## 2 2       348
## 3 3       215
\end{verbatim}

한편, 어떤 분류모형을 사용하여 각 객체의 범주 \texttt{1}(특정 범주)에 대한 사후확률을 산출한 후, 전체 객체를 사후확률의 내림차순으로 정렬한 뒤 100개 객체씩 한 집단으로 구분하였다. 각 집단에 속하는 범주 \texttt{1}의 빈도는 다음과 같았다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{freq\_within\_group }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{k, }\SpecialCharTok{\textasciitilde{}}\NormalTok{n,}
  \DecValTok{1}\NormalTok{, }\DecValTok{92}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{78}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{64}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{57}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{43}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\DecValTok{35}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\DecValTok{29}\NormalTok{,}
  \DecValTok{8}\NormalTok{, }\DecValTok{22}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\DecValTok{7}\NormalTok{,}
  \DecValTok{10}\NormalTok{, }\DecValTok{10}
\NormalTok{)}

\NormalTok{freq\_within\_group}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##        k     n
##    <dbl> <dbl>
##  1     1    92
##  2     2    78
##  3     3    64
##  4     4    57
##  5     5    43
##  6     6    35
##  7     7    29
##  8     8    22
##  9     9     7
## 10    10    10
\end{verbatim}

이를 바탕으로 각 집단 별 범주 \texttt{1}에 대한 통계량을 산출해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stat\_df }\OtherTok{\textless{}{-}}\NormalTok{ freq\_within\_group }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{cum\_n =} \FunctionTok{cumsum}\NormalTok{(n)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{captured\_response\_pct =}\NormalTok{ n }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{,}
    \AttributeTok{cum\_captured\_response\_pct =}\NormalTok{ cum\_n }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{,}
    \AttributeTok{response\_pct =}\NormalTok{ n }\SpecialCharTok{/} \DecValTok{100} \SpecialCharTok{*} \DecValTok{100}\NormalTok{,}
    \AttributeTok{lift =}\NormalTok{ n }\SpecialCharTok{/} \FunctionTok{mean}\NormalTok{(n)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{cum\_n)}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
\NormalTok{  stat\_df,}
  \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
  \AttributeTok{align =} \FunctionTok{rep}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\DecValTok{6}\NormalTok{),}
  \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}집단\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}범주 1의 빈도\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\% captured response\textquotesingle{}}\NormalTok{, }
                \StringTok{\textquotesingle{}cum. \% captured response\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}\% response\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}lift\textquotesingle{}}\NormalTok{),}
  \AttributeTok{caption =} \StringTok{\textquotesingle{}이익도표를 위한 통계량\textquotesingle{}}\NormalTok{,}
  \AttributeTok{digits =} \DecValTok{2}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:gain-chart-stat}이익도표를 위한 통계량}
\centering
\begin{tabular}[t]{rrrrrr}
\toprule
집단 & 범주 1의 빈도 & \% captured response & cum. \% captured response & \% response & lift\\
\midrule
1 & 92 & 21.05 & 21.05 & 92 & 2.11\\
2 & 78 & 17.85 & 38.90 & 78 & 1.78\\
3 & 64 & 14.65 & 53.55 & 64 & 1.46\\
4 & 57 & 13.04 & 66.59 & 57 & 1.30\\
5 & 43 & 9.84 & 76.43 & 43 & 0.98\\
\addlinespace
6 & 35 & 8.01 & 84.44 & 35 & 0.80\\
7 & 29 & 6.64 & 91.08 & 29 & 0.66\\
8 & 22 & 5.03 & 96.11 & 22 & 0.50\\
9 & 7 & 1.60 & 97.71 & 7 & 0.16\\
10 & 10 & 2.29 & 100.00 & 10 & 0.23\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:gain-chart-stat}를 바탕으로 네 가지 이익도표를 작성해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{stat\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{gather}\NormalTok{(}\AttributeTok{key =} \StringTok{"stat"}\NormalTok{, }\AttributeTok{value =} \StringTok{"value"}\NormalTok{,}
\NormalTok{         captured\_response\_pct}\SpecialCharTok{:}\NormalTok{lift) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ k, }\AttributeTok{y =}\NormalTok{ value)) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\FunctionTok{vars}\NormalTok{(stat), }\AttributeTok{nrow =} \DecValTok{2}\NormalTok{, }\AttributeTok{ncol =} \DecValTok{2}\NormalTok{, }\AttributeTok{scales =} \StringTok{"free\_y"}\NormalTok{,}
             \AttributeTok{labeller =} \FunctionTok{as\_labeller}\NormalTok{(}
               \FunctionTok{c}\NormalTok{(}\StringTok{"captured\_response\_pct"} \OtherTok{=} \StringTok{"\% captured response"}\NormalTok{,}
                 \StringTok{"cum\_captured\_response\_pct"} \OtherTok{=} \StringTok{"cum. \% captured response"}\NormalTok{,}
                 \StringTok{"response\_pct"} \OtherTok{=} \StringTok{"\% response"}\NormalTok{,}
                 \StringTok{"lift"} \OtherTok{=} \StringTok{"lift"}\NormalTok{)}
\NormalTok{             )) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"group"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"statistics"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/gain-chart-plot-1} 

}

\caption{이익도표}\label{fig:gain-chart-plot}
\end{figure}

\hypertarget{part-3uxbd80---uxad70uxc9d1uxbd84uxc11d}{%
\part{3부 - 군집분석}\label{part-3uxbd80---uxad70uxc9d1uxbd84uxc11d}}

\hypertarget{clustering-overview}{%
\chapter{군집분석 개요}\label{clustering-overview}}

하나의 객체(object)가 여러 속성(attribute)을 갖는다 하고, 이러한 객체가 다수 있다고 하자. 군집분석이란 유사한 속성들을 갖는 객체들을 묶어 전체의 객체들을 몇 개의 그룹 또는 군집(cluster)으로 나누는 것을 말한다.

\hypertarget{clustering-overview-packages-install}{%
\section{필요 R 패키지 설치}\label{clustering-overview-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.3.1\\
\hline
stats & 4.1.0\\
\hline
corrr & 0.4.3\\
\hline
cluster & 2.1.2\\
\hline
\end{tabular}

\hypertarget{clustering-method}{%
\section{군집분석 기법}\label{clustering-method}}

전체 객체의 개수를 \(n\)이라 하고, \(i\)번째 객체를 \(O_i\)라 할 때, 전체 객체의 집합 \(S\)는 다음과 같다.

\begin{equation*}
S = \{O_1, \cdots, O_n\}
\end{equation*}

군집분석이란 집합 \(S\)를 서로 배타적인 \(K\)개의 부분집합 \(C_1, \cdots, C_K\)로 나누는 것이다. 따라서 다음이 성립한다.

\begin{equation*}
\begin{split}
C_i \cap C_j &= \emptyset, \, 1 \leq i \neq j \leq K\\
\cup_{i = 1}^{K} C_i &= S
\end{split}
\end{equation*}

이 때, \(C_j\)를 \(j\)번째 군집(또는 군집 \(j\))이라 한다. 각 객체는 한 군집에만 속하여야 하며, 한 군집에는 적어도 하나의 객체를 포함하여야 한다. 군집들을 다음과 같이 모아놓은 것을 군집결과(clustering result) 또는 군집해(clustering solution)라 한다.

\begin{equation*}
C = \{C_1, \cdots, C_K\}
\end{equation*}

군집방법(clustering method)은 무수히 많다. 다음 장들에서 아래에 분류된 방법들을 보다 자세히 다룬다.

\begin{itemize}
\tightlist
\item
  계층적 방법(hierarchical method)

  \begin{itemize}
  \tightlist
  \item
    집괴법(agglomerative method)
  \item
    분리법(divisive method)
  \end{itemize}
\item
  비계층적 방법(non-hierarchical method)
\end{itemize}

\hypertarget{object-similarity-metric}{%
\section{객체 간의 유사성 척도}\label{object-similarity-metric}}

\hypertarget{object-distance-metric}{%
\subsection{거리 관련 척도}\label{object-distance-metric}}

각 객체가 \(p\)개의 속성 또는 변수(variable)를 갖는다 하고, \(j\)번째 변수의 객체 \(i\)에 대한 관측치를 \(x_{ji}\)라 하면, 객체 \(i\)의 \(p\)차원 공간에서의 좌표는 아래와 같은 열벡터로 표현된다.

\begin{equation*}
\mathbf{x}_{i} = [x_{1i} \, x_{2i} \, \cdots \, x_{pi}]^\top
\end{equation*}

이 때, 객체 \(i\)와 객체 \(j\)의 거리를 나타내는 척도들은 아래와 같은 것들이 있다.

\begin{itemize}
\tightlist
\item
  유클리드 거리(Euclidean distance)
\end{itemize}

\begin{eqnarray*}
d(\mathbf{x}_i, \mathbf{x}_j) &=& \sqrt{\sum_{a = 1}^{p} \left(x_{ai} - x_{aj}\right)^2}\\
&=& \sqrt{(\mathbf{x}_i - \mathbf{x}_j)^\top (\mathbf{x}_i - \mathbf{x}_j)}
\end{eqnarray*}

\begin{itemize}
\tightlist
\item
  맨하탄 거리(Manhattan distance)
\end{itemize}

\begin{equation*}
d(\mathbf{x}_i, \mathbf{x}_j) = \sum_{a = 1}^{p} \left| x_{ai} - x_{aj} \right|
\end{equation*}

\begin{itemize}
\tightlist
\item
  민코프스키 거리(Minkowski distance)
\end{itemize}

\begin{equation*}
d(\mathbf{x}_i, \mathbf{x}_j) = \left( \sum_{a = 1}^{p} \left| x_{ai} - x_{aj} \right|^m \right)^\frac{1}{m}
\end{equation*}

\begin{itemize}
\tightlist
\item
  표준 유클리드 거리(standardized Euclidean distance)
\end{itemize}

\begin{eqnarray*}
d(\mathbf{x}_i, \mathbf{x}_j) &=& \sqrt{\sum_{a = 1}^{p} \left(\frac{x_{ai} - x_{aj}}{s_a}\right)^2}\\
&=& \sqrt{(\mathbf{x}_i - \mathbf{x}_j)^\top \mathbf{S}_d^{-1} (\mathbf{x}_i - \mathbf{x}_j)}
\end{eqnarray*}

여기서

\begin{eqnarray*}
\mathbf{S}_d &=& \begin{bmatrix}
s_1^2 & 0 & \dots & 0\\
0 & s_2^2 & \dots & 0\\
\vdots & \vdots & \ddots & \vdots\\
0 & 0 & \dots & s_p^2
\end{bmatrix}\\
s_a &=& \sqrt{\frac{\sum_{i = 1}^{n} \left(x_{ai} - \bar{x}_a \right)^2}{n - 1}}\\
\bar{x}_a &=& \frac{1}{n} \sum_{i = 1}^{n} x_{ai}
\end{eqnarray*}

\begin{itemize}
\tightlist
\item
  마할라노비스 거리(Mahalanobis distance)
\end{itemize}

\begin{equation*}
d(\mathbf{x}_i, \mathbf{x}_j) = \sqrt{(\mathbf{x}_i - \mathbf{x}_j)^\top \mathbf{S}^{-1} (\mathbf{x}_i - \mathbf{x}_j)}
\end{equation*}

여기서

\begin{eqnarray*}
\mathbf{S} &=& \begin{bmatrix}
s_1^2 & s_{12} & \dots & s_{1p}\\
s_{21} & s_2^2 & \dots & s_{2p}\\
\vdots & \vdots & \ddots & \vdots\\
s_{p1} & s_{p2} & \dots & s_p^2
\end{bmatrix}\\
s_{ab} &=& \frac{\sum_{i = 1}^{n} (x_{ai} - \bar{x}_a)(x_{bi} - \bar{x}_b)}{n - 1}\\
\bar{x}_a &=& \frac{1}{n} \sum_{i = 1}^{n} x_{ai}
\end{eqnarray*}

위와 같은 거리 척도들을 이용하여 객체들의 모든 쌍에 대한 거리를 다음과 같이 \((n \times n)\) 행렬 \(\mathbf{D}\)로 나타낼 수 있다.

\begin{equation*}
\mathbf{D} = \begin{bmatrix}
0 & d(\mathbf{x}_1, \mathbf{x}_2) & \dots & d(\mathbf{x}_1, \mathbf{x}_n)\\
d(\mathbf{x}_2, \mathbf{x}_1) & 0 & \dots & d(\mathbf{x}_2, \mathbf{x}_n)\\
\vdots & \vdots & \ddots & \vdots \\
d(\mathbf{x}_n, \mathbf{x}_1) & d(\mathbf{x}_n, \mathbf{x}_2) & \dots & 0
\end{bmatrix}
\end{equation*}

아래 표는 가정에서 PC를 사용하는 10명에 대한 나이(\(x_1\)), PC 경험연수(\(x_2\)), 주당 사용시간(\(x_3\))을 나타낸 것이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{id, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x2, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x3,}
  \DecValTok{1}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{14}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{28}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{13}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{42}\NormalTok{, }\DecValTok{14}\NormalTok{, }\DecValTok{6}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{35}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{7}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{7}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{15}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\DecValTok{45}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{6}\NormalTok{,}
  \DecValTok{8}\NormalTok{, }\DecValTok{46}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\DecValTok{51}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{10}\NormalTok{, }\DecValTok{41}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}
\NormalTok{)}

\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}나이($x\_1$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}PC 경험연수($x\_2$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}주당 사용시간($x\_3$)\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}PC 사용 데이터\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:pc-user}PC 사용 데이터}
\centering
\begin{tabular}[t]{rrrr}
\toprule
객체번호 & 나이(\$x\_1\$) & PC 경험연수(\$x\_2\$) & 주당 사용시간(\$x\_3\$)\\
\midrule
1 & 20 & 6 & 14\\
2 & 28 & 8 & 13\\
3 & 42 & 14 & 6\\
4 & 35 & 12 & 7\\
5 & 30 & 15 & 7\\
\addlinespace
6 & 30 & 7 & 15\\
7 & 45 & 13 & 6\\
8 & 46 & 4 & 2\\
9 & 51 & 3 & 3\\
10 & 41 & 3 & 2\\
\bottomrule
\end{tabular}
\end{table}

R 함수 \texttt{dist}를 이용하여 다양한 거리를 계산할 수 있다.

우선 객체 2로부터 객체 4, 5까지의 유클리드 거리는 아래와 같이 계산된다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dist}\NormalTok{(df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{)], }\AttributeTok{upper =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}
\NormalTok{    item1 }\SpecialCharTok{==} \DecValTok{2}\NormalTok{,}
\NormalTok{    item2 }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호(from)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}객체번호(to)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}거리\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}유클리드 거리\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:euclidean-dist}유클리드 거리}
\centering
\begin{tabular}[t]{rrr}
\toprule
객체번호(from) & 객체번호(to) & 거리\\
\midrule
2 & 4 & 10.049876\\
2 & 5 & 9.433981\\
\bottomrule
\end{tabular}
\end{table}

위 표에서 나타나는 바와 같이, 객체 2를 기준으로 할 때, 객체 4가 객체 5보다 멀리 떨어져있다고 할 수 있다.

표준화된 거리를 계산하기 위해서는 데이터를 함수 \texttt{scale}을 이용하여 데이터를 표준화한 뒤 \texttt{dist}함수를 적용한다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dist}\NormalTok{(}\FunctionTok{scale}\NormalTok{(df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{)]), }\AttributeTok{upper =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}
\NormalTok{    item1 }\SpecialCharTok{==} \DecValTok{2}\NormalTok{,}
\NormalTok{    item2 }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호(from)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}객체번호(to)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}거리\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}표준 유클리드 거리\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:std-euclidean-dist}표준 유클리드 거리}
\centering
\begin{tabular}[t]{rrr}
\toprule
객체번호(from) & 객체번호(to) & 거리\\
\midrule
2 & 4 & 1.663576\\
2 & 5 & 1.954486\\
\bottomrule
\end{tabular}
\end{table}

표준화된 거리로는 객체 5가 객체 4보다 객체 2에서 멀리 떨어짐을 알 수 있다.

유클리드 거리 외에 민코프스키 거리, 마할라노비스 거리 등은 \texttt{dist}함수의 파라미터 \texttt{method} 및 \texttt{p}값을 설정하여 계산할 수 있다.

\hypertarget{object-correlation-metric}{%
\subsection{상관계수 관련 척도}\label{object-correlation-metric}}

또 다른 유사성 척도로 다음과 같은 객체 간의 상관계수를 사용할 수 있다.

\begin{equation}
sim(\mathbf{x}_i, \mathbf{x}_j) = r_{ij} = \frac{\sum_{a = 1}^{p} (x_{ai} - m_{i})(x_{aj} - m_{j})}{\sqrt{\sum_{a = 1}^{p} (x_{ai} - m_{i})^2} \sqrt{\sum_{a = 1}^{p} (x_{aj} - m_{j})^2}}
\label{eq:object-correlation}
\end{equation}

여기서 \(m_i\)는 객체 \(i\)의 평균값으로 다음과 같다.

\begin{equation*}
m_{i} = \frac{1}{p} \sum_{a = 1}^{p} x_{ai}
\end{equation*}

식 \eqref{eq:object-correlation}은 -1에서 1 사이의 값을 가지며, 값이 클수록 두 객체의 유사성이 크다고 할 수 있다. 여기서도 데이터를 변수별로 표준화한 후 상관계수를 산출함을 추천한다.

아래는 Table \ref{tab:pc-user}의 객체 1과 객체 6, 8간의 상관계수를 계산한 것이다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t}\NormalTok{(}\FunctionTok{scale}\NormalTok{(df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{)])) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  corrr}\SpecialCharTok{::}\FunctionTok{correlate}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  corrr}\SpecialCharTok{::}\FunctionTok{stretch}\NormalTok{(}\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{x =} \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{gsub}\NormalTok{(}\StringTok{"V"}\NormalTok{, }\StringTok{""}\NormalTok{, x)),}
    \AttributeTok{y =} \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{gsub}\NormalTok{(}\StringTok{"V"}\NormalTok{, }\StringTok{""}\NormalTok{, y))}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}
\NormalTok{    x }\SpecialCharTok{==} \DecValTok{1}\NormalTok{,}
\NormalTok{    y }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호(from)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}객체번호(to)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}상관계수\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}객체 간 상관계수\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Correlation method: 'pearson'
## Missing treated using: 'pairwise.complete.obs'
\end{verbatim}

\begin{table}

\caption{\label{tab:std-correlation-similarity}객체 간 상관계수}
\centering
\begin{tabular}[t]{rrr}
\toprule
객체번호(from) & 객체번호(to) & 상관계수\\
\midrule
1 & 6 & 0.9718362\\
1 & 8 & -0.8348917\\
\bottomrule
\end{tabular}
\end{table}

한편, 상관계수로부터 거리 개념의 비유사성 척도를 원하면 다음의 척도를 사용할 수 있다.

\begin{equation*}
d(\mathbf{x}_i, \mathbf{x}_j) = 1 - r_{ij}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t}\NormalTok{(}\FunctionTok{scale}\NormalTok{(df[, }\FunctionTok{c}\NormalTok{(}\StringTok{"x1"}\NormalTok{, }\StringTok{"x2"}\NormalTok{, }\StringTok{"x3"}\NormalTok{)])) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  corrr}\SpecialCharTok{::}\FunctionTok{correlate}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{  corrr}\SpecialCharTok{::}\FunctionTok{stretch}\NormalTok{(}\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{x =} \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{gsub}\NormalTok{(}\StringTok{"V"}\NormalTok{, }\StringTok{""}\NormalTok{, x)),}
    \AttributeTok{y =} \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{gsub}\NormalTok{(}\StringTok{"V"}\NormalTok{, }\StringTok{""}\NormalTok{, y)),}
    \AttributeTok{d =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ r}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{r) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}
\NormalTok{    x }\SpecialCharTok{==} \DecValTok{1}\NormalTok{,}
\NormalTok{    y }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호(from)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}객체번호(to)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}거리\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}상관계수 기반 비유사성 척도\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Correlation method: 'pearson'
## Missing treated using: 'pairwise.complete.obs'
\end{verbatim}

\begin{table}

\caption{\label{tab:std-correlation-dissimilarity}상관계수 기반 비유사성 척도}
\centering
\begin{tabular}[t]{rrr}
\toprule
객체번호(from) & 객체번호(to) & 거리\\
\midrule
1 & 6 & 0.0281638\\
1 & 8 & 1.8348917\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{category-similarity-metric}{%
\section{범주형 객체의 유사성 척도}\label{category-similarity-metric}}

객체의 변수(속성)들 중 일부 또는 전체가 범주형인 경우에는 유사성 척도를 다소 다르게 정의할 필요가 있다. 범주형 변수는 다시 이분형(binary), 서열형(ordinal), 명목형(nominal)으로 구분된다. 이분형은 서열형 또는 명목형에 속할 수도 있으나, 통상적으로 별도로 구분하고 있다.

\hypertarget{binary-similarity-metric}{%
\subsection{이분형 변수의 경우}\label{binary-similarity-metric}}

이분형 변수란 변수가 취하는 값이 두 개인 것을 의미하며, 통상 0과 1을 부여한다. 이 경우 사용되는 유사성 척도는 다양하나, 단순매칭(simple matching)과 자카드(Jaccard) 척도가 주로 사용된다.

\begin{itemize}
\tightlist
\item
  단순매칭
\end{itemize}

객체 \(\mathbf{x}_i\)와 \(\mathbf{x}_j\)에 대하여 \(k\)번째 변수가 이분형일 때, 해당 변수값에 대한 유사성을 아래와 같이 계산한다.

\begin{equation*}
sim(x_{ki}, x_{kj}) = \begin{cases}
1 & \text{if } x_{ki} = x_{kj}\\
0 & \text{if } x_{ki} \neq x_{kj}
\end{cases}
\end{equation*}

객체의 \(p\)개의 모든 변수가 이분형일 때, 두 객체의 유사성은 아래와 같이 변수별 유사성의 평균으로 계산한다.

\begin{equation*}
sim(\mathbf{x}_i, \mathbf{x}_j) = \frac{1}{p} \sum_{k = 1}^{p} sim(x_{ki}, x_{kj})
\end{equation*}

\begin{itemize}
\tightlist
\item
  자카드(Jaccard) 척도
\end{itemize}

자카드 척도에서는 변수값을 특정 속성이 나타나는(presence) 경우에 1, 나타나지 않는(absence) 경우 0으로 표현할 때, 두 객체에서 모두 나타나는 경우에만 유사한 것으로 평가한다. 결국, 이 척도에서는 두 객체에서 특정 속성이 0인 경우에는 전반적 유사성 척도 산출에 포함되지 않고 무시된다.

\begin{equation*}
sim(x_{ki}, x_{kj}) = \begin{cases}
1 & \text{if } x_{ki} = x_{kj} = 1\\
\text{ignored} & \text{if } x_{ki} = x_{kj} = 0\\
0 & \text{if } x_{ki} \neq x_{kj}
\end{cases}
\end{equation*}

따라서, 객체의 \(p\)개의 모든 변수가 이분형일 때, 두 객체의 유사성은 아래와 같이 계산한다.

\begin{equation*}
sim(\mathbf{x}_i, \mathbf{x}_j) = \frac{\sum_{k: x_{ki} + x_{kj} > 0} sim(x_{ki}, x_{kj})}{\sum_{k: x_{ki} + x_{kj} > 0} 1}
\end{equation*}

다음은 3명에 대한 건강 관련 문진에 대한 답을 나타낸 자료이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{id, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x2, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x3, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x4, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x5,}
  \DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}
\NormalTok{)}

\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}운동여부($x\_1$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}음주여부($x\_2$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}흡연여부($x\_3$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}가족력여부($x\_4$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}고혈압여부($x\_5$)\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}건강 문진\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:health-question-df}건강 문진}
\centering
\begin{tabular}[t]{rrrrrr}
\toprule
객체번호 & 운동여부(\$x\_1\$) & 음주여부(\$x\_2\$) & 흡연여부(\$x\_3\$) & 가족력여부(\$x\_4\$) & 고혈압여부(\$x\_5\$)\\
\midrule
1 & 1 & 1 & 1 & 0 & 1\\
2 & 1 & 0 & 1 & 0 & 0\\
3 & 0 & 1 & 0 & 1 & 0\\
\bottomrule
\end{tabular}
\end{table}

객체 1과 2의 단순매칭에 의한 유사성은 다음과 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{similarity\_simplematching }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(vec\_1, vec\_2) \{}
  \FunctionTok{sum}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{abs}\NormalTok{(vec\_1 }\SpecialCharTok{{-}}\NormalTok{ vec\_2)) }\SpecialCharTok{/} \FunctionTok{length}\NormalTok{(vec\_1)}
\NormalTok{\}}

\NormalTok{df\_pairs }\OtherTok{\textless{}{-}}\NormalTok{ df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(id) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{expand}\NormalTok{(}\AttributeTok{id\_1 =}\NormalTok{ id, }\AttributeTok{id\_2 =}\NormalTok{ id) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(id\_1 }\SpecialCharTok{!=}\NormalTok{ id\_2)}

\NormalTok{df\_pairs}\SpecialCharTok{$}\NormalTok{similarity }\OtherTok{\textless{}{-}}\NormalTok{ df\_pairs }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{inner\_join}\NormalTok{(df, }\AttributeTok{by=}\FunctionTok{c}\NormalTok{(}\StringTok{"id\_1"} \OtherTok{=} \StringTok{"id"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(df, }\AttributeTok{by=}\FunctionTok{c}\NormalTok{(}\StringTok{"id\_2"} \OtherTok{=} \StringTok{"id"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rowwise}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{do}\NormalTok{(}\AttributeTok{similarity =} \FunctionTok{similarity\_simplematching}\NormalTok{(}
\NormalTok{    .[}\FunctionTok{c}\NormalTok{(}\StringTok{"x1.x"}\NormalTok{, }\StringTok{"x2.x"}\NormalTok{, }\StringTok{"x3.x"}\NormalTok{, }\StringTok{"x4.x"}\NormalTok{, }\StringTok{"x5.x"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unlist}\NormalTok{(),}
\NormalTok{    .[}\FunctionTok{c}\NormalTok{(}\StringTok{"x1.y"}\NormalTok{, }\StringTok{"x2.y"}\NormalTok{, }\StringTok{"x3.y"}\NormalTok{, }\StringTok{"x4.y"}\NormalTok{, }\StringTok{"x5.y"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unlist}\NormalTok{())) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{unlist}\NormalTok{()}

\NormalTok{df\_pairs }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}
\NormalTok{    id\_1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{,}
\NormalTok{    id\_2 }\SpecialCharTok{==} \DecValTok{2}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호(from)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}객체번호(to)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}유사도\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}단순매칭 유사성 척도\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:binary-simplematching}단순매칭 유사성 척도}
\centering
\begin{tabular}[t]{rrr}
\toprule
객체번호(from) & 객체번호(to) & 유사도\\
\midrule
1 & 2 & 0.6\\
\bottomrule
\end{tabular}
\end{table}

한편 자카드 유사성은 아래와 같이 함수 \texttt{dist}를 이용하여 구할 수 있다. 함수 \texttt{dist}는 거리 척도 함수로, 자카드 기반 거리의 경우 \(d(\mathbf{x}_i, \mathbf{x}_j) = 1 - sim(\mathbf{x}_i, \mathbf{x}_j)\)를 계산한다. 따라서, 거리값에 기반하여 자카드 유사성을 구하고 싶은 경우, \(sim(\mathbf{x}_i, \mathbf{x}_j) = 1 - d(\mathbf{x}_i, \mathbf{x}_j)\)를 계산하면 된다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dist}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{method =} \StringTok{"binary"}\NormalTok{, }\AttributeTok{upper =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{similarity =} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ distance) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{distance) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}
\NormalTok{    item1 }\SpecialCharTok{==} \DecValTok{1}\NormalTok{,}
\NormalTok{    item2 }\SpecialCharTok{==} \DecValTok{2}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호(from)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}객체번호(to)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}유사도\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}자카드 유사성 척도\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:binary-jaccard}자카드 유사성 척도}
\centering
\begin{tabular}[t]{rrr}
\toprule
객체번호(from) & 객체번호(to) & 유사도\\
\midrule
1 & 2 & 0.5\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{ordinal-similarity-metric}{%
\subsection{서열형 변수의 경우}\label{ordinal-similarity-metric}}

객체의 \(k\)번째 변수가 서열형이고 \(1, 2, \cdots, M_k\) 중 한 값을 갖는다고 할 때, 거리척도로는 우선 아래와 같은 직접적 방법이 있다.

\begin{equation*}
d(x_{ki}, x_{kj}) = \frac{|x_{ki} - x_{kj}|}{M_k - 1}
\end{equation*}

위에서 분모는 해당 변수가 취할 수 있는 범위(range)를 나타내며, 따라서 위의 값은 0에서 1 사이 값을 갖는다. 이 방법을 사용할 경우, 객체의 모든 변수가 서열형이면 두 객 체의 거리는 다음과 같다.

\begin{equation*}
d(\mathbf{x}_i, \mathbf{x}_j) = \sum_{k = 1}^{p} d(x_{ki}, x_{kj}) = \sum_{k = 1}^{p} \frac{|x_{ki} - x_{kj}|}{M_k - 1}
\end{equation*}

또 다른 방법은 우선 각 변수를 0에서 1 사이의 값으로 변환한 후, 연속형 변수의 경우와 같이 거리척도를 산출하는 것이다. 이 경우 객체 \(i\)의 \(k\)번째 변수는 다음과 같이 변환한다.

\begin{equation*}
x_{ki}' = \frac{x_{ki} - 1}{M_k - 1}
\end{equation*}

\hypertarget{nominal-similarity-metric}{%
\subsection{명목형 변수의 경우}\label{nominal-similarity-metric}}

두 객체에 대한 \(k\)번째 변수가 명목형인 경우, 이분형 변수의 경우와 같이 두 변수가 일치하면 1, 그렇지 않으면 0으로 유사성을 평가한다. 즉,

\begin{equation*}
sim(x_{ki}, x_{kj}) = \begin{cases}
1 & \text{if } x_{ki} = x_{kj}\\
0 & \text{if } x_{ki} \neq x_{kj}
\end{cases}
\end{equation*}

\(p\)개의 모든 변수가 명목형인 경우, 두 객체 간유사성은 다음과 같다.

\begin{equation*}
sim(\mathbf{x}_i, \mathbf{x}_j) = \frac{1}{p} \sum_{k: x_{ki} = x_{kj}} 1
\end{equation*}

\hypertarget{mixed-similarity-metric}{%
\subsection{혼합형의 경우}\label{mixed-similarity-metric}}

두 객체의 유사성 또는 비유사성을 산출하는 데 각 변수의 형태가 연속형, 이분형, 서열형, 명목형 등으로 다른 경우에는, 각 변수의 형태에 따라 위에서 언급한 바와 같이 각기 다른 방법으로 유사성 또는 비유사성을 평가한 후, 최종적으로 합 또는 평균으로 도출하게 된다. 따라서 편의상 각 변수에 대하여 0에서 1 사이의 값을 갖는 척도를 사용하고 있다. 위에서 언급한 이분형, 서열형, 명목형인 경우에는 이미 0에서 1 사이의 유사성 척도가 제시되었다.

연속형의 경우, 0에서 1 사이의 값을 갖는 거리(비유사성)의 척도로는 아래와 같이 각 변수의 범위를 활용하는 방법을 사용한다.

\begin{equation*}
d(x_{ki}, x_{kj}) = \frac{|x_{ki} - x_{kj}|}{R_k}
\end{equation*}

여기서 \(R_k\)는 \(k\)번째 변수의 범위(=최대값 - 최소값)를 의미한다. 유사성 척도를 원할 경우에는 다음과 같이 산출할 수 있다.

\begin{equation*}
sim(x_{ki}, x_{kj}) = 1 - d(x_{ki}, x_{kj})
\end{equation*}

결국, 여러 형태의 변수가 혼합되어 있는 경우, 각 변수에 대한 유사성 척도가 산출되어 있을 때, 두 객체의 유사성은 다음과 같이 계산한다.

\begin{equation*}
sim(\mathbf{x}_i, \mathbf{x}_j) = \frac{1}{p} \sum_{k = 1}^{p} sim(x_{ki}, x_{kj})
\end{equation*}

또는 각 변수의 거리가 산출도니 경우, 두 객체의 거리는 다음과 같다.

\begin{equation*}
d(\mathbf{x}_i, \mathbf{x}_j) = \frac{1}{p} \sum_{k = 1}^{p} d(x_{ki}, x_{kj})
\end{equation*}

위에 설명한 혼합형 거리 척도는 \citet{gower1971general} 에 기반하며, R에서는 \texttt{cluster} 패키지의 \texttt{daisy} 함수를 이용하여 구할 수 있다. \texttt{daisy} 함수는 연속형 및 서열형 변수의 경우 입력 데이터에 기반하여 range를 계산하므로, 입력 데이터의 최소값, 최대값이 아닌 이론적 최소값, 최대값에 의하여 range를 계산하고 싶은 경우에는 명시적으로 각 변수의 최소값과 최대값을 나타내는 데이터를 입력 데이터에 추가하여야 한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{id, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x2, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x3, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x4, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x5,}
  \DecValTok{1}\NormalTok{, }\StringTok{"남"}\NormalTok{, }\DecValTok{46}\NormalTok{, }\StringTok{"공무원"}\NormalTok{, }\DecValTok{35000}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\StringTok{"여"}\NormalTok{, }\DecValTok{28}\NormalTok{, }\StringTok{"은행원"}\NormalTok{, }\DecValTok{51000}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\StringTok{"여"}\NormalTok{, }\DecValTok{32}\NormalTok{, }\StringTok{"주부"}\NormalTok{, }\DecValTok{46000}\NormalTok{, }\DecValTok{4}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{x1 =} \FunctionTok{factor}\NormalTok{(x1, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{"남"}\NormalTok{, }\StringTok{"여"}\NormalTok{)),}
    \AttributeTok{x3 =} \FunctionTok{factor}\NormalTok{(x3),}
    \AttributeTok{x5 =} \FunctionTok{factor}\NormalTok{(x5, }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{), }\AttributeTok{ordered =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  )}

\NormalTok{n\_obs }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}

\NormalTok{range\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{x2 =} \FunctionTok{c}\NormalTok{(}\DecValTok{25}\NormalTok{, }\DecValTok{70}\NormalTok{),}
    \AttributeTok{x4 =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{150000}\NormalTok{),}
    \AttributeTok{x5 =} \FunctionTok{factor}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{), }\AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{5}\NormalTok{), }\AttributeTok{ordered =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  )}

\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_rows}\NormalTok{(range\_df) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{id) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  cluster}\SpecialCharTok{::}\FunctionTok{daisy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as.dist}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}
\NormalTok{    item1 }\SpecialCharTok{\textless{}=}\NormalTok{ n\_obs,}
\NormalTok{    item2 }\SpecialCharTok{\textless{}=}\NormalTok{ n\_obs}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호(from)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}객체번호(to)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}거리\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}혼합형 Gower 거리\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in Ops.factor(item1, n_obs): '<=' not meaningful for factors
\end{verbatim}

\begin{verbatim}
## Warning in Ops.factor(item2, n_obs): '<=' not meaningful for factors
\end{verbatim}

\begin{table}

\caption{\label{tab:mixed-gower}혼합형 Gower 거리}
\centering
\begin{tabular}[t]{rrr}
\toprule
객체번호(from) & 객체번호(to) & 거리\\


\bottomrule
\end{tabular}
\end{table}

\hypertarget{hierarchical-clustering}{%
\chapter{계층적 군집방법}\label{hierarchical-clustering}}

계층적 군집방법에는 집괴법과 분리법이 있으나 주로 집괴법이 사용된다. 본 장에서는 집괴법으로는 연결법을 소개하고, 분리법으로는 다이아나(DIANA)를 소개한다.

\hypertarget{hierarchical-clustering-packages-install}{%
\section{필요 R 패키지 설치}\label{hierarchical-clustering-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.3.1\\
\hline
stats & 4.1.0\\
\hline
cluster & 2.1.2\\
\hline
\end{tabular}

\hypertarget{distance-between-clusters}{%
\section{군집 간 거리척도 및 연결법}\label{distance-between-clusters}}

계층적 군집방법에서는 유사한 객체들을 군집으로 묶고, 다시 유사한 군집을 새로운 군집으로 묶는 등 단계적 절차를 사용한다. 이를 위해서는 군집 간의 유사성 척도 혹은 비유사성 척도가 필요하다.

\begin{itemize}
\tightlist
\item
  \(C_i\): \(i\)번째 군집(군집 \(i\))
\item
  \(|C_i|\): 군집 \(i\)의 객체수
\item
  \(\mathbf{c}_i = \left( \bar{x}_1^{(i)}, \bar{x}_2^{(i)}, \cdots, \bar{x}_p^{(i)} \right)\): 군집 \(i\)의 중심좌표(centroid) (\(\bar{x}_a^{(i)} = \frac{1}{|C_i|} \sum_{j \in C_i} x_{aj}\))
\item
  \(d(u, v) = d(\mathbf{x}_u, \mathbf{x}_v)\): 객체 \(u\)와 객체 \(v\)의 거리(또는 비유사성 척도)
\item
  \(D(C_i, C_j)\): 군집 \(i\)와 군집 \(j\)의 거리(또는 비유사성 척도)
\end{itemize}

군집과 군집 간의 거리척도를 평가하는 방법에 따라 다양한 연결법(linkage method)이 존재한다. 아래에 대표적인 연결법과 군집 간 거리척도를 소개한다.

\begin{table}

\caption{\label{tab:linkage-method}연결법 종류}
\centering
\begin{tabular}[t]{cc}
\toprule
연결법 & 군집거리 \$D(C\_i, C\_j)\$\\
\midrule
단일연결법(single linkage method) & \$\textbackslash{}min\_\{u \textbackslash{}in C\_i, \textbackslash{}, v \textbackslash{}in C\_j\} d(u, v)\$\\
완전연결법(complete linkage method) & \$\textbackslash{}max\_\{u \textbackslash{}in C\_i, \textbackslash{}, v \textbackslash{}in C\_j\} d(u, v)\$\\
평균연결법(average linkage method) & \$\textbackslash{}frac\{1\}\{|C\_i||C\_j|\} \textbackslash{}sum\_\{u \textbackslash{}in C\_i, \textbackslash{}, v \textbackslash{}in C\_j\} d(u, v)\$\\
중심연결법(centroid linkage method) & \$d(\textbackslash{}mathbf\{c\}\_i, \textbackslash{}mathbf\{c\}\_j)\$\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{linkage-method}{%
\section{연결법의 군집 알고리즘}\label{linkage-method}}

\hypertarget{linkage-method-basic-script}{%
\subsection{기본 R 스크립트}\label{linkage-method-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{id =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{),}
  \AttributeTok{x1 =} \FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{14}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{),}
  \AttributeTok{x2 =} \FunctionTok{c}\NormalTok{(}\DecValTok{14}\NormalTok{,}\DecValTok{13}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{)}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
             \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
             \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}PC 경력(년, $x\_1$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}사용시간(시간, $x\_2$)\textquotesingle{}}\NormalTok{),}
             \AttributeTok{caption =} \StringTok{\textquotesingle{}PC 사용자 데이터\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:pc-user-data}PC 사용자 데이터}
\centering
\begin{tabular}[t]{rrr}
\toprule
객체번호 & PC 경력(년, \$x\_1\$) & 사용시간(시간, \$x\_2\$)\\
\midrule
1 & 6 & 14\\
2 & 8 & 13\\
3 & 14 & 6\\
4 & 11 & 8\\
5 & 15 & 7\\
\addlinespace
6 & 7 & 15\\
7 & 13 & 6\\
8 & 5 & 4\\
9 & 3 & 3\\
10 & 3 & 2\\
\bottomrule
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{theme\_set}\NormalTok{(}\FunctionTok{theme\_gray}\NormalTok{(}\AttributeTok{base\_family=}\StringTok{\textquotesingle{}NanumGothic\textquotesingle{}}\NormalTok{))}
\FunctionTok{ggplot}\NormalTok{(train\_df, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x1, }\AttributeTok{y =}\NormalTok{ x2)) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{label =}\NormalTok{ id)) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"PC 경력"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"사용시간"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/pc-user-data-plot-1} 

}

\caption{PC 사용자 데이터}\label{fig:pc-user-data-plot}
\end{figure}

Table \ref{tab:pc-user-data}는 10명의 사람(객체)에 대한 PC 사용경력과 주당 PC 사용시간을 나타낸 것이다. 각 객체가 두 변수로 이루어져 있으며, Figure \ref{fig:pc-user-data-plot}에서 보는 바와 같이 세 개의 군집(\{1, 2, 6\}, \{3, 4, 5, 7\}, \{8, 9, 10\})으로 이루어져 있다고 볼 수 있다.

본 장에서 평균연결법에 의한 군집화 과정을 살펴보기로 하자. 우선 R 패키지를 이용해서 간단하게 군집해를 구하는 과정은 아래와 같다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{stats} 패키지의 함수 \texttt{dist}를 이용하여 객체간 거리를 계산한다.
\item
  1에서 얻은 거리 행렬을 \texttt{stats} 패키지의 \texttt{hclust} 함수에 입력하여 데이터 군집을 분석한다. 이 때, 파라미터 \texttt{method}의 값을 ``average''로 설정하면 평균연결법을 이용한다.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dist}\NormalTok{(train\_df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{hclust}\NormalTok{(}\AttributeTok{method =} \StringTok{"average"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{plot}\NormalTok{(}
    \AttributeTok{main =} \ConstantTok{NULL}\NormalTok{,}
    \AttributeTok{ylab =} \StringTok{"distance"}\NormalTok{,}
    \AttributeTok{xlab =} \StringTok{"observation"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/pc-user-average-linkage-1} 

}

\caption{PC 사용자 데이터에 대한 평균연결법 덴드로그램}\label{fig:pc-user-average-linkage}
\end{figure}

\hypertarget{linkage-method-algorithm}{%
\subsection{연결법 군집 알고리즘}\label{linkage-method-algorithm}}

각 연결법들은 군집간 유사성 척도 평가 방법이 다를 뿐, 군집화를 위한 알고리즘은 동일하게 아래와 같이 진행된다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{-1}
\tightlist
\item
  단계0: 초기화

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    연결법을 선정한다.
  \item
    각 객체를 하나의 군집으로 간주한다.
  \item
    \(k \leftarrow n\)
  \end{enumerate}
\item
  단계1: 군집

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    현재의 군집결과에 있는 모든 군집 간의 쌍에 대하여 \(D(C_i, C_j)\)를 산출하여, 이 중 최소가 되는 군집 \(i\)와 \(j\)를 묶어 하나의 군집으로 만든 후 군집결과를 수정한다.
  \item
    \(k \leftarrow k - 1\)
  \end{enumerate}
\item
  단계2: \(k = 1\)이면 Stop, 그렇지 않으면 단계 1을 반복한다.
\end{enumerate}

단계1은 객체 수 \(n\)만큼 반복된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration }\OtherTok{\textless{}{-}} \FunctionTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\AttributeTok{length =} \FunctionTok{nrow}\NormalTok{(train\_df))}
\end{Highlighting}
\end{Shaded}

임의의 군집해에 대하여, 단계1을 수행하는 함수를 아래와 같이 구현해보자. 아래 함수 \texttt{merge\_cluster}는 아래와 같은 두 개의 입력변수를 사용한다.

\begin{itemize}
\tightlist
\item
  \texttt{df}: 객체 데이터 프레임. 열 이름이 \texttt{id}인 열은 객체번호를 나타내어, 객체간 거리 계산에 포함하지 않는다.
\item
  \texttt{cluster\_label}: 두 개의 열로 이루어진 데이터 프레임. 열 \texttt{id}는 객체번호를 나타내며, 열 \texttt{cluster}는 군집 이름을 나타낸다. 하나의 객체는 하나의 군집에만 속할 수 있으나, 하나의 군집은 여러 개의 객체를 포함할 수 있다.
\end{itemize}

함수 수행 결과, 아래와 같은 세 개의 원소를 지닌 리스트를 리턴한다.

\begin{itemize}
\tightlist
\item
  \texttt{cluster\_dist}: 군집 간 거리를 나타낸 데이터 프레임. 평균연결법에 기반한 거리.
\item
  \texttt{closest\_clusters}: 입력된 군집해 내에서 가장 가까운 두 군집을 나타낸 데이터 프레임. 두 열 \texttt{item1}과 \texttt{item2}는 각각 군집 이름을 나타내며, \texttt{distance}는 해당 두 군집간의 거리를 나타낸다.
\item
  \texttt{new\_cluster\_label}: \texttt{closest\_clusters}에 포함된 두 군집을 하나로 묶어 새로운 군집을 만든 후 얻어진 군집해.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{merge\_cluster }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, cluster\_label) \{}
  \CommentTok{\# 군집간 거리 계산한다. {-} 유클리드 거리 및 평균연결법 기반}
\NormalTok{  cluster\_dist }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(}\FunctionTok{subset}\NormalTok{(df, }\AttributeTok{select =} \SpecialCharTok{{-}}\NormalTok{id), }\AttributeTok{upper =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{    broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate\_if}\NormalTok{(is.factor, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(.))) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{inner\_join}\NormalTok{(}
\NormalTok{      cluster\_label }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{rename}\NormalTok{(}
        \AttributeTok{item1 =}\NormalTok{ id, }\AttributeTok{cluster1 =}\NormalTok{ cluster}
\NormalTok{        ),}
      \AttributeTok{by =} \StringTok{"item1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{inner\_join}\NormalTok{(}
\NormalTok{      cluster\_label }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{rename}\NormalTok{(}
        \AttributeTok{item2 =}\NormalTok{ id, }\AttributeTok{cluster2 =}\NormalTok{ cluster}
\NormalTok{        ),}
      \AttributeTok{by =} \StringTok{"item2"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(cluster1 }\SpecialCharTok{!=}\NormalTok{ cluster2) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(cluster1, cluster2) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarize}\NormalTok{(}\AttributeTok{distance =} \FunctionTok{mean}\NormalTok{(distance)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ungroup}\NormalTok{()}
  
  \CommentTok{\# 서로 가장 가깝게 위치하는 두 군집을 찾는다.}
\NormalTok{  closest\_clusters }\OtherTok{\textless{}{-}}\NormalTok{ cluster\_dist }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(distance) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{)}
  
  \CommentTok{\# 군집해를 업데이트한다.}
\NormalTok{  cluster\_label[}
\NormalTok{    cluster\_label}\SpecialCharTok{$}\NormalTok{cluster }\SpecialCharTok{\%in\%}\NormalTok{ (}
\NormalTok{      closest\_clusters[, }\FunctionTok{c}\NormalTok{(}\StringTok{"cluster1"}\NormalTok{, }\StringTok{"cluster2"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unlist}\NormalTok{()}
\NormalTok{    ),}
    \StringTok{"cluster"}
\NormalTok{  ] }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}
\NormalTok{    closest\_clusters[, }\FunctionTok{c}\NormalTok{(}\StringTok{"cluster1"}\NormalTok{, }\StringTok{"cluster2"}\NormalTok{)] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unlist}\NormalTok{(),}
    \AttributeTok{collapse =} \StringTok{","}
\NormalTok{    )}
  
  \FunctionTok{list}\NormalTok{(}\AttributeTok{cluster\_dist =}\NormalTok{ cluster\_dist, }
       \AttributeTok{closest\_clusters =}\NormalTok{ closest\_clusters, }
       \AttributeTok{new\_cluster\_label =}\NormalTok{ cluster\_label)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

우선 단계 0에서 얻어지는 군집해에 대한 데이터를 아래와 같이 생성한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{init\_cluster }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{id =}\NormalTok{ train\_df}\SpecialCharTok{$}\NormalTok{id,}
  \AttributeTok{cluster =} \FunctionTok{as.character}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(train\_df))}
\NormalTok{)}

\FunctionTok{print}\NormalTok{(}\FunctionTok{unique}\NormalTok{(init\_cluster}\SpecialCharTok{$}\NormalTok{cluster))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] "1"  "2"  "3"  "4"  "5"  "6"  "7"  "8"  "9"  "10"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(init\_cluster}\SpecialCharTok{$}\NormalTok{cluster))}

\FunctionTok{print}\NormalTok{(k)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10
\end{verbatim}

위와 같이, 초기 군집해에서 군집 수는 전체 객체수와 같은 10개이다.

위 초기해로부터 단계1을 아래와 같이 수행해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration[[}\DecValTok{1}\NormalTok{]] }\OtherTok{\textless{}{-}} \FunctionTok{merge\_cluster}\NormalTok{(train\_df, init\_cluster)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'cluster1'. You can override using the `.groups` argument.
\end{verbatim}

찾아진 가장 가까운 두 군집은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration[[}\DecValTok{1}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{closest\_cluster}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
##   cluster1 cluster2 distance
##   <chr>    <chr>       <dbl>
## 1 10       9               1
\end{verbatim}

위 두 군집을 하나로 묶은 새로운 군집해는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration[[}\DecValTok{1}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{new\_cluster\_label}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##       id cluster
##    <int> <chr>  
##  1     1 1      
##  2     2 2      
##  3     3 3      
##  4     4 4      
##  5     5 5      
##  6     6 6      
##  7     7 7      
##  8     8 8      
##  9     9 10,9   
## 10    10 10,9
\end{verbatim}

위 새로운 군집해의 군집 수는 9이다. 이는 아직 1보다 크므로, 새로 얻어진 군집해로부터 단계 1을 반복한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration[[}\DecValTok{2}\NormalTok{]] }\OtherTok{\textless{}{-}} \FunctionTok{merge\_cluster}\NormalTok{(}
\NormalTok{  train\_df,}
\NormalTok{  iteration[[}\DecValTok{1}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{new\_cluster\_label}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'cluster1'. You can override using the `.groups` argument.
\end{verbatim}

이번에 찾아진 가장 가까운 두 군집은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration[[}\DecValTok{2}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{closest\_cluster}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
##   cluster1 cluster2 distance
##   <chr>    <chr>       <dbl>
## 1 3        7               1
\end{verbatim}

위 두 군집을 하나로 묶은 새로운 군집해는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration[[}\DecValTok{2}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{new\_cluster\_label}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##       id cluster
##    <int> <chr>  
##  1     1 1      
##  2     2 2      
##  3     3 3,7    
##  4     4 4      
##  5     5 5      
##  6     6 6      
##  7     7 3,7    
##  8     8 8      
##  9     9 10,9   
## 10    10 10,9
\end{verbatim}

위 군집해에 기반하여 단계 1을 다시 반복해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iteration[[}\DecValTok{3}\NormalTok{]] }\OtherTok{\textless{}{-}} \FunctionTok{merge\_cluster}\NormalTok{(}
\NormalTok{  train\_df,}
\NormalTok{  iteration[[}\DecValTok{2}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{new\_cluster\_label}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'cluster1'. You can override using the `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(iteration[[}\DecValTok{3}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{closest\_cluster)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
##   cluster1 cluster2 distance
##   <chr>    <chr>       <dbl>
## 1 1        6            1.41
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(iteration[[}\DecValTok{3}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{new\_cluster\_label)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##       id cluster
##    <int> <chr>  
##  1     1 1,6    
##  2     2 2      
##  3     3 3,7    
##  4     4 4      
##  5     5 5      
##  6     6 1,6    
##  7     7 3,7    
##  8     8 8      
##  9     9 10,9   
## 10    10 10,9
\end{verbatim}

위와 같은 과정을 전체 객체가 하나의 군집으로 묶일 때까지 아래와 같이 반복하며 군집결과를 출력해보자.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#단계0}
\NormalTok{init\_cluster }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{id =}\NormalTok{ train\_df}\SpecialCharTok{$}\NormalTok{id,}
  \AttributeTok{cluster =} \FunctionTok{as.character}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(train\_df))}
\NormalTok{)}

\NormalTok{i }\OtherTok{\textless{}{-}}\NormalTok{ 0L}
\NormalTok{current\_clusters }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(init\_cluster}\SpecialCharTok{$}\NormalTok{cluster)}
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(current\_clusters)}

\NormalTok{print\_clusters }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(i, k, clusters) \{}
  \FunctionTok{cat}\NormalTok{(}\StringTok{"Iteration: "}\NormalTok{, i, }\StringTok{", k = "}\NormalTok{, k, }\StringTok{", clusters = "}\NormalTok{, }\FunctionTok{paste0}\NormalTok{(}\StringTok{"\{"}\NormalTok{, clusters, }\StringTok{"\}"}\NormalTok{), }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{\}}

\FunctionTok{print\_clusters}\NormalTok{(i, k, current\_clusters)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Iteration:  0 , k =  10 , clusters =  {1} {2} {3} {4} {5} {6} {7} {8} {9} {10}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#단계1}
\NormalTok{iteration }\OtherTok{\textless{}{-}} \FunctionTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\AttributeTok{length =} \FunctionTok{nrow}\NormalTok{(train\_df) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\ControlFlowTok{while}\NormalTok{(k }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  i }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{+} \DecValTok{1}
  \ControlFlowTok{if}\NormalTok{(i }\SpecialCharTok{==} \DecValTok{1}\NormalTok{) \{}
\NormalTok{    iteration[[i]] }\OtherTok{\textless{}{-}} \FunctionTok{merge\_cluster}\NormalTok{(}
\NormalTok{      train\_df,}
\NormalTok{      init\_cluster}
\NormalTok{    )}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    iteration[[i]] }\OtherTok{\textless{}{-}} \FunctionTok{merge\_cluster}\NormalTok{(}
\NormalTok{      train\_df,}
\NormalTok{      iteration[[i}\DecValTok{{-}1}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{new\_cluster\_label}
\NormalTok{    )}
\NormalTok{  \}}

\NormalTok{  current\_clusters }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(iteration[[i]]}\SpecialCharTok{$}\NormalTok{new\_cluster\_label}\SpecialCharTok{$}\NormalTok{cluster)}
\NormalTok{  k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(current\_clusters)}
  
  \FunctionTok{print\_clusters}\NormalTok{(i, k, current\_clusters)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Iteration:  1 , k =  9 , clusters =  {1} {2} {3} {4} {5} {6} {7} {8} {10,9} 
## Iteration:  2 , k =  8 , clusters =  {1} {2} {3,7} {4} {5} {6} {8} {10,9} 
## Iteration:  3 , k =  7 , clusters =  {1,6} {2} {3,7} {4} {5} {8} {10,9} 
## Iteration:  4 , k =  6 , clusters =  {1,6} {2} {3,7,5} {4} {8} {10,9} 
## Iteration:  5 , k =  5 , clusters =  {1,6,2} {3,7,5} {4} {8} {10,9} 
## Iteration:  6 , k =  4 , clusters =  {1,6,2} {3,7,5} {4} {10,9,8} 
## Iteration:  7 , k =  3 , clusters =  {1,6,2} {3,7,5,4} {10,9,8} 
## Iteration:  8 , k =  2 , clusters =  {1,6,2,3,7,5,4} {10,9,8} 
## Iteration:  9 , k =  1 , clusters =  {1,6,2,3,7,5,4,10,9,8}
\end{verbatim}

\hypertarget{hclust}{%
\subsection{R 패키지 내 연결법}\label{hclust}}

R에서는 \texttt{stats} 패키지의 \texttt{hclust} 함수를 이용하여 군집해를 구할 수 있다.

우선, 객체간 거리 행렬을 함수 \texttt{dist}를 이용하여 구한다. 아래는 유클리드 거리를 구하는 예이며, 상황에 따라 다른 거리 척도를 이용할 수도 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{distance\_matrix }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(train\_df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

객체간 거리를 구한 후, 함수 \texttt{hclust}를 이용하여 군집분석을 수행한다. 기본설정은 완전연결법이며, 파라미터 \texttt{method}의 값을 설정함으로써 단일연결법, 평균연결법, 중심연결법을 수행할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster\_solution }\OtherTok{\textless{}{-}} \FunctionTok{hclust}\NormalTok{(distance\_matrix, }\AttributeTok{method =} \StringTok{"average"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

결과 객체 \texttt{cluster\_solution}는 아래와 같은 컴포넌트(components)를 지닌 리스트(list) 객체이다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(cluster\_solution)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "merge"       "height"      "order"       "labels"      "method"     
## [6] "call"        "dist.method"
\end{verbatim}

이 중, \texttt{merge}는 2개의 열과 \(n - 1\)개의 행으로 이루어진 행렬로, 연결법 알고리즘의 단계1 iteration에서 묶어지는 두 군집을 기록한 것이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster\_solution}\SpecialCharTok{$}\NormalTok{merge}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       [,1] [,2]
##  [1,]   -3   -7
##  [2,]   -9  -10
##  [3,]   -1   -6
##  [4,]   -5    1
##  [5,]   -2    3
##  [6,]   -8    2
##  [7,]   -4    4
##  [8,]    5    7
##  [9,]    6    8
\end{verbatim}

위에서 각 행은 iteration을 나타내며, 두 열은 묶어지는 두 군집을 나타낸다. 값이 0보다 작은 경우에는 번호가 원 객체 번호를 나타내며, 값이 0보다 큰 경우에는 해당 번호의 iteration에서 묶어진 군집을 나타낸다. 예를 들어, 위 결과의 6번째 행 (-8, 2) 은 객체 8과 두 번째 iteration에서 얻어진 군집 (객체 9와 10이 묶여진 군집)이 묶여 하나의 군집(객체 8, 9, 10)을 이루게 됨을 나타낸다.

\texttt{height}는 각 iteration에서 묶이는 두 군집간의 거리를 나타내며, 위 Figure \ref{fig:pc-user-average-linkage}의 덴드로그램에서 세로선의 높이를 나타낸다. Iteration이 증가함에 따라 묶이는 두 군집간의 거리도 증가한다. 일반적으로 이 거리값이 크게 증가하는 iteration에서 두 군집을 묶지 않고 최종 군집해를 도출한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster\_solution}\SpecialCharTok{$}\NormalTok{height}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1.000000  1.000000  1.414214  1.825141  2.236068  2.532248  3.519028
## [8]  9.635217 10.881878
\end{verbatim}

위 결과의 경우 iteration 8에서 거리값이 크게 증가한다. 이는 위 Figure \ref{fig:pc-user-average-linkage}의 덴드로그램에서 3개의 군집에서 2개의 군집으로 묶이는 과정에서 세로선의 높이가 현격히 증가하는 지점이다. 따라서, iteration 7에서 얻어진 3개의 군집이 적절한 군집해라 판단할 수 있겠다.

\hypertarget{ward-method}{%
\section{워드 방법}\label{ward-method}}

워드방법(Ward's method) 역시 각 객체를 하나의 군집으로 간주함을 시작으로 군집들을 묶어 단계적으로 그 수를 하나가 돌 때까지 줄여나가는 것인데, 군집의 제곱합을 활용한다.

\hypertarget{ward-method-basic-script}{%
\subsection{기본 R 스크립트}\label{ward-method-basic-script}}

아래 Table \ref{tab:driver-data}는 8명의 운전자에 대한 운전경력과 교통위반 횟수를 나타낸 것이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{id =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{8}\NormalTok{),}
  \AttributeTok{x1 =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{17}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{18}\NormalTok{),}
  \AttributeTok{x2 =} \FunctionTok{c}\NormalTok{(}\DecValTok{15}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{17}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{6}\NormalTok{)}
\NormalTok{)}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
             \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
             \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}운전경력($x\_1$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}위반횟수($x\_2$)\textquotesingle{}}\NormalTok{),}
             \AttributeTok{caption =} \StringTok{\textquotesingle{}운전경력에 따른 교통위반 횟수\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:driver-data}운전경력에 따른 교통위반 횟수}
\centering
\begin{tabular}[t]{rrr}
\toprule
객체번호 & 운전경력(\$x\_1\$) & 위반횟수(\$x\_2\$)\\
\midrule
1 & 4 & 15\\
2 & 20 & 13\\
3 & 3 & 13\\
4 & 19 & 4\\
5 & 17 & 17\\
\addlinespace
6 & 8 & 11\\
7 & 19 & 12\\
8 & 18 & 6\\
\bottomrule
\end{tabular}
\end{table}

앞 절의 연결법에서 사용했던 \texttt{hclust} 함수를 이용하여 워드 방법에 의한 군집해도 구할 수 있으며, 이 때 파라미터 \texttt{method}의 값으로 ``ward.D2''를 사용한다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dist}\NormalTok{(train\_df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{hclust}\NormalTok{(}\AttributeTok{method =} \StringTok{"ward.D2"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{plot}\NormalTok{(}
    \AttributeTok{main =} \ConstantTok{NULL}\NormalTok{,}
    \AttributeTok{xlab =} \StringTok{"observation"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/ward-dendrogram-1} 

}

\caption{운전자 데이터에 대한 워드 방법 덴드로그램}\label{fig:ward-dendrogram}
\end{figure}

\hypertarget{ward-method-algorithm}{%
\subsection{워드 군집 알고리즘}\label{ward-method-algorithm}}

군집결과가 \(\mathbf{C} = \{ C_1, C_2, \cdots, C_k \}\)일 때, 군집 \(C_i\) 내의 제곱합(within sum of squares)은 다음과 같이 산출된다.

\begin{equation*}
SS(C_i) = \sum_{u \in C_i} \left(\mathbf{x}_u - \mathbf{c}_i\right)^\top\left(\mathbf{x}_u - \mathbf{c}_i\right)
\end{equation*}

이 때, 전체 군집 내 제곱합을 \(SSW\)라 할 때, 이는 다음과 같다.

\begin{equation*}
SSW = \sum_{i = 1}^{k} SS(C_i)
\end{equation*}

다음으로, 현 군집의 각 쌍을 묶는다고 할 때의 새로운 \(SSW\)를 산출한 후, 이 값이 가장 작게 되는 군집 쌍을 묶는다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  단계0

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    각 객체를 하나의 군집으로 간주한다.
  \item
    \(k \leftarrow n\)
  \end{enumerate}
\item
  단계1

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    현재의 군집 결과에 있는 모든 군집간의 쌍에 대하여 묶을 경우 전체제곱합(SSW)을 산출하고, 이 중 최소가 되는 군집 \(i\)와 군집 \(j\)를 묶어 하나의 군집으로 만든 후, 군집 결과를 수정한다.
  \item
    \(k \leftarrow k - 1\)
  \end{enumerate}
\item
  단계2: \(k = 1\)이면 Stop, 그렇지 않으면 단계1을 반복한다.
\end{enumerate}

워드 군집 알고리즘을 R script로 구현해보자. 우선, 객체 데이터 \(SSW\)를 계산하는 사용자 정의 함수 \texttt{calculate\_ssw}를 아래와 같이 두 입력변수 \texttt{df} 및 \texttt{cluster\_label}를 이용하여 구현하자.

\begin{itemize}
\tightlist
\item
  \texttt{df}: 객체 데이터 프레임. 열 이름이 \texttt{id}인 열은 객체번호를 나타내어, 객체간 거리 계산에 포함하지 않는다.
\item
  \texttt{cluster\_label}: 두 개의 열로 이루어진 데이터 프레임. 열 \texttt{id}는 객체번호를 나타내며, 열 \texttt{cluster}는 군집 이름을 나타낸다. 하나의 객체는 하나의 군집에만 속할 수 있으나, 하나의 군집은 여러 개의 객체를 포함할 수 있다.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# SSW 계산}
\NormalTok{calculate\_ssw }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, cluster\_label) \{}
\NormalTok{  df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{inner\_join}\NormalTok{(cluster\_label, }\AttributeTok{by =} \StringTok{"id"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(cluster) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{id) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarize\_all}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{sum}\NormalTok{((x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{ss =} \FunctionTok{rowSums}\NormalTok{(}\FunctionTok{subset}\NormalTok{(., }\AttributeTok{select =} \SpecialCharTok{{-}}\NormalTok{cluster))) }\SpecialCharTok{\%\textgreater{}\%}
    \StringTok{\textasciigrave{}}\AttributeTok{[[}\StringTok{\textasciigrave{}}\NormalTok{(}\StringTok{"ss"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{sum}\NormalTok{()}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

워드 군집 알고리즘은 현재 군집해 내의 모든 군집쌍에 대하여 두 군집을 하나의 군집으로 묶을 경우의 \(SSW\)를 계산해야 한다. 따라서, 우선 고려할 모든 군집해를 생성하는 사용자 정의 함수 \texttt{generate\_clusters}를 아래와 같이 구현한다.

아래 사용자 정의 함수 \texttt{generate\_clusters}는 임의의 군집해 \texttt{cluster\_label}을 입력변수로 사용하며, 해당 입력변수에 대한 설명은 위 함수 \texttt{calculate\_ssw}에서와 같다. 함수 수행 결과, 가능한 각각의 군집쌍 결합의 결과물인 군집해 데이터 프레임을 리스트(list) 형태로 출력한다.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 임의의 군집해로부터 가능한 다음단계 군집해 생성}
\NormalTok{generate\_clusters }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(cluster\_label) \{}
\NormalTok{  unique\_clusters }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(cluster\_label}\SpecialCharTok{$}\NormalTok{cluster)}
  
\NormalTok{  potential\_pairs }\OtherTok{\textless{}{-}} \FunctionTok{crossing}\NormalTok{(}\AttributeTok{cluster1 =}\NormalTok{ unique\_clusters, }
           \AttributeTok{cluster2 =}\NormalTok{ unique\_clusters) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(cluster1 }\SpecialCharTok{\textless{}}\NormalTok{ cluster2) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{cluster =} \FunctionTok{paste}\NormalTok{(cluster1, cluster2, }\AttributeTok{sep =} \StringTok{","}\NormalTok{))}
  
\NormalTok{  candidate\_solutions }\OtherTok{\textless{}{-}}\NormalTok{ potential\_pairs }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{rowwise}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{do}\NormalTok{(}\AttributeTok{candidate\_solution =} \FunctionTok{merge\_cluster}\NormalTok{(cluster\_label, .)) }\SpecialCharTok{\%\textgreater{}\%}
    \StringTok{\textasciigrave{}}\AttributeTok{[[}\StringTok{\textasciigrave{}}\NormalTok{(}\StringTok{"candidate\_solution"}\NormalTok{)}
  
\NormalTok{  candidate\_solutions}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위에서 보이는 바와 같이, 함수 \texttt{generate\_clusters}는 또 다른 사용자 정의함수 \texttt{merge\_cluster}를 호출한다. 이 함수는 두 입력변수 \texttt{cluster\_label} 및 \texttt{cluster\_merge}를 사용하는데, \texttt{cluster\_label}에 대한 설명은 위 다른 사용자 정의 함수에서와 동일하며, \texttt{cluster\_merge}에 대한 설명은 아래와 같다.

\begin{itemize}
\tightlist
\item
  \texttt{cluster\_merge}: 3차원 character 벡터. 첫 두 element는 현재 \texttt{cluster\_label}에 존재하는 군집 중 하나의 군집으로 묶일 두 군집의 이름을 나타내며, 세 번째 element는 그 결과 나타나는 군집 이름을 나타낸다.
\end{itemize}

함수 수행 결과, 입력된 \texttt{cluster\_label}에서 군집이름이 \texttt{cluster\_merge{[}1{]}} 혹은 \texttt{cluster\_merge{[}2{]}}에 해당하는 객체들은, 출력된 군집해에서는 군집이름 \texttt{cluster\_merge{[}3{]}}을 지닌다.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 임의의 군집 결합 규칙 cluster\_merge에 따른 군집해}
\NormalTok{merge\_cluster }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(cluster\_label, cluster\_merge) \{}
\NormalTok{  idx }\OtherTok{\textless{}{-}}\NormalTok{ cluster\_label}\SpecialCharTok{$}\NormalTok{cluster }\SpecialCharTok{\%in\%}\NormalTok{ cluster\_merge[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{]}
\NormalTok{  cluster\_label[idx, }\StringTok{"cluster"}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ cluster\_merge[}\DecValTok{3}\NormalTok{]}
\NormalTok{  cluster\_label}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

마지막으로, 현재 군집해로부터 가장 최적의 다음단계 군집해를 얻는 사용자 함수 \texttt{best\_merge\_cluster}를 아래와 같이 구현해보자.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{generate\_clusters}를 실행하여 다음 단계에 가능한 모든 군집해를 구한다.
\item
  1의 각 군집해에 함수 \texttt{calculate\_ssw}를 적용하여 \(SSW\)값을 구한다.
\item
  \(SSW\)값이 최소인 군집해를 최적 군집해로 선정한다.
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 최적 군집 결합}
\NormalTok{best\_merge\_cluster }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, cluster\_label) \{}
\NormalTok{  candidate\_solutions }\OtherTok{\textless{}{-}} \FunctionTok{generate\_clusters}\NormalTok{(cluster\_label)}
\NormalTok{  ssw }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(candidate\_solutions, }\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{calculate\_ssw}\NormalTok{(df, x))}
  \FunctionTok{list}\NormalTok{(}
    \AttributeTok{new\_cluster\_label =}\NormalTok{ candidate\_solutions[[}\FunctionTok{which.min}\NormalTok{(ssw)]],}
    \AttributeTok{new\_ssw =} \FunctionTok{min}\NormalTok{(ssw)}
\NormalTok{  )}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 사용자 함수들을 이용하여 Table \ref{tab:driver-data}에 대한 워드 군집 분석을 수행해보자.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#단계0}
\NormalTok{init\_cluster }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{id =}\NormalTok{ train\_df}\SpecialCharTok{$}\NormalTok{id,}
  \AttributeTok{cluster =} \FunctionTok{as.character}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(train\_df))}
\NormalTok{)}
\NormalTok{i }\OtherTok{\textless{}{-}}\NormalTok{ 0L}
\NormalTok{current\_clusters }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(init\_cluster}\SpecialCharTok{$}\NormalTok{cluster)}
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(current\_clusters)}
\NormalTok{ssw }\OtherTok{\textless{}{-}} \FunctionTok{calculate\_ssw}\NormalTok{(train\_df, init\_cluster)}

\NormalTok{print\_clusters }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(i, k, clusters, ssw) \{}
  \FunctionTok{cat}\NormalTok{(}\StringTok{"Iteration: "}\NormalTok{, i, }\StringTok{", k = "}\NormalTok{, k, }\StringTok{", clusters = "}\NormalTok{, }\FunctionTok{paste0}\NormalTok{(}\StringTok{"\{"}\NormalTok{, clusters, }\StringTok{"\}"}\NormalTok{), }\StringTok{", SSW ="}\NormalTok{, ssw, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{\}}

\FunctionTok{print\_clusters}\NormalTok{(i, k, current\_clusters, ssw)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Iteration:  0 , k =  8 , clusters =  {1} {2} {3} {4} {5} {6} {7} {8} , SSW = 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#단계1}
\NormalTok{iteration }\OtherTok{\textless{}{-}} \FunctionTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\AttributeTok{length =} \FunctionTok{nrow}\NormalTok{(train\_df) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\ControlFlowTok{while}\NormalTok{(k }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  i }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{+} \DecValTok{1}
  \ControlFlowTok{if}\NormalTok{(i }\SpecialCharTok{==} \DecValTok{1}\NormalTok{) \{}
\NormalTok{    iteration[[i]] }\OtherTok{\textless{}{-}} \FunctionTok{best\_merge\_cluster}\NormalTok{(}
\NormalTok{      train\_df,}
\NormalTok{      init\_cluster}
\NormalTok{    )}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    iteration[[i]] }\OtherTok{\textless{}{-}} \FunctionTok{best\_merge\_cluster}\NormalTok{(}
\NormalTok{      train\_df,}
\NormalTok{      iteration[[i}\DecValTok{{-}1}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{new\_cluster\_label}
\NormalTok{    )}
\NormalTok{  \}}

\NormalTok{  current\_clusters }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(iteration[[i]]}\SpecialCharTok{$}\NormalTok{new\_cluster\_label}\SpecialCharTok{$}\NormalTok{cluster)}
\NormalTok{  k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(current\_clusters)}
\NormalTok{  ssw }\OtherTok{\textless{}{-}}\NormalTok{ iteration[[i]]}\SpecialCharTok{$}\NormalTok{new\_ssw}
  
  \FunctionTok{print\_clusters}\NormalTok{(i, k, current\_clusters, ssw)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Iteration:  1 , k =  7 , clusters =  {1} {2,7} {3} {4} {5} {6} {8} , SSW = 1 
## Iteration:  2 , k =  6 , clusters =  {1,3} {2,7} {4} {5} {6} {8} , SSW = 3.5 
## Iteration:  3 , k =  5 , clusters =  {1,3} {2,7} {4,8} {5} {6} , SSW = 6 
## Iteration:  4 , k =  4 , clusters =  {1,3} {2,7,5} {4,8} {6} , SSW = 23.66667 
## Iteration:  5 , k =  3 , clusters =  {1,3,6} {2,7,5} {4,8} , SSW = 43.16667 
## Iteration:  6 , k =  2 , clusters =  {1,3,6} {2,7,5,4,8} , SSW = 140.4 
## Iteration:  7 , k =  1 , clusters =  {1,3,6,2,7,5,4,8} , SSW = 499.875
\end{verbatim}

\hypertarget{ward-rpackages}{%
\subsection{R 패키지 내 워드 방법}\label{ward-rpackages}}

R 패키지로 구현된 워드 군집은 위에서 구현한 \(SSW\)와는 다소 다른 metric을 이용하여 군집해를 구한다. 따라서, 우선 워드 방법이 제안된 논문들을 살펴볼 필요가 있다.

우선 원 논문 \citet{ward1963hierarchical} 는 \(ESS\)(error sum of squares)를 아래와 같이 정의하였으며, 이는 위에서 사용한 \(SSW\)와 일치한다.

\begin{equation*}
\begin{split}
ESS(\{C_1, \cdots, C_k \}) &= \sum_{i = 1}^{k} ESS(C_i)\\
&= \sum_{i = 1}^{k} \sum_{u \in C_i} \mathbf{x}_u^\top \mathbf{x}_u - |C_i| \mathbf{c}_i^\top \mathbf{c}_i\\
&= SSW
\end{split}
\end{equation*}

위 식에서 임의의 두 군집 \(C_i\), \(C_j\)를 하나의 군집으로 묶을 때 \(SSW\)의 변화는 아래와 같다. \(C_i\)와 \(C_j\) 외의 군집은 \(SSW\)의 변화에 영향을 미치지 않으므로, \(SSW\) 변화량은 아래와 같이 군집 \(C_i\)와 \(C_j\)에 속하는 객체만을 이용하여 구할 수 있으며, 결과적으로 \(C_i\)와 \(C_j\)의 군집 크기 \(|C_i|\)와 \(|C_j|\)및 군집 중심벡터 \(\mathbf{c}_i\)와 \(\mathbf{c}_j\)를 이용하여 구할 수 있다.

\begin{equation}
\begin{split}
\Delta SSW =& ESS(C_i \cup C_j) - ESS(C_i) - ESS(C_j)\\
=& \sum_{u \in C_i \cup C_j} \mathbf{x}_u^\top \mathbf{x}_u - (|C_i| + |C_j|)\left[\frac{|C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j}{|C_i| + |C_j|}\right]^\top \left[\frac{|C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j}{|C_i| + |C_j|}\right]\\
& - \left( \sum_{u \in C_i} \mathbf{x}_u^\top \mathbf{x}_u - |C_i| \mathbf{c}_i^\top \mathbf{c}_i \right) - \left( \sum_{u \in C_j} \mathbf{x}_u^\top \mathbf{x}_u - |C_j| \mathbf{c}_j^\top \mathbf{c}_j \right)\\
=& -\frac{1}{|C_i| + |C_j|} \left( |C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j \right)^\top \left( |C_i|\mathbf{c}_i + |C_j|\mathbf{c}_j \right) + |C_i| \mathbf{c}_i^\top \mathbf{c}_i + |C_j| \mathbf{c}_j^\top \mathbf{c}_j\\
=& \frac{|C_i||C_j|}{|C_i| + |C_j|} \left(\mathbf{c}_i - \mathbf{c}_j\right)^\top \left(\mathbf{c}_i - \mathbf{c}_j\right)
\end{split}
\label{eq:ward-minimand}
\end{equation}

따라서 워드 방법은 각 iteration에서 식 \eqref{eq:ward-minimand}를 최소화하는 두 군집 \(C_i\), \(C_j\)를 선택하여 두 군집을 하나로 묶는 방법이다.

한편, \(SS(C_i)\)는 아래와 같이 군집 \(C_i\)내 객체들 간의 제곱 유클리드 거리로 나타낼 수 있다.

\begin{equation}
\begin{split}
D^2(C_i) =& \sum_{u, v \in C_i} (\mathbf{x}_u - \mathbf{x}_v)^\top (\mathbf{x}_u - \mathbf{x}_v)\\
=& \sum_{u, v \in C_i} \left((\mathbf{x}_u - \mathbf{c}_i) - (\mathbf{x}_v - \mathbf{c}_i)\right)^\top \left((\mathbf{x}_u - \mathbf{c}_i) - (\mathbf{x}_v - \mathbf{c}_i)\right)\\
=& 2 \sum_{u \in C_i} (\mathbf{x}_u - \mathbf{c}_i)^\top (\mathbf{x}_u - \mathbf{c}_i) - 2 \sum_{u, v \in C_i} (\mathbf{x}_u - \mathbf{c}_i)^\top (\mathbf{x}_v - \mathbf{c}_i)\\
=& 2 \sum_{u \in C_i} (\mathbf{x}_u - \mathbf{c}_i)^\top (\mathbf{x}_u - \mathbf{c}_i)\\
=& 2 SS(C_i)
\end{split}
\label{eq:squared-euclidean-within-cluster}
\end{equation}

위 식 \eqref{eq:squared-euclidean-within-cluster}을 달리 표현하면, 객체간의 제곱 유클리드 거리를 표현한 행렬에서 군집 \(i\)에 속한 객체들에 해당하는 부분행렬(submatrix)를 뽑아 행렬의 원소값을 모두 더하면, 그 값이 \(2 SS(C_i)\)와 같다. 이를 통해 각 군집의 중심벡터를 계산하지 않고도 각 iteration에서 SSW를 최소화하는 군집 결합을 찾을 수 있다.

R 패키지 \texttt{stats} 내의 \texttt{hclust} 함수는 워드 방법으로 \texttt{method} 파라미터의 값을 ``ward.D'' 혹은 ``ward.D2''로 설정할 수 있다. 이 두 방법의 차이는 입력 거리행렬을 제곱 유클리드 거리로 사용하는지 일반 유클리드 거리로 사용하는지의 차이로, 아래에서 R 스크립트 예제와 함께 설명하기로 한다.

우선 \texttt{method}값을 ``ward.D2''로 설정하는 경우, \texttt{dist} 함수의 결과를 입력 거리행렬로 그대로 사용하면 된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_ward.D2 }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(train\_df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{hclust}\NormalTok{(}\AttributeTok{method =} \StringTok{"ward.D2"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

이 때, 결과 데이터 \texttt{res\_ward.D2}에서 워드 방법의 criterion을 나타내는 \texttt{height} 원소(component)가 표현하는 값은 위에서 계산하였던 \(SSW\)와 다르다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_ward.D2}\SpecialCharTok{$}\NormalTok{height}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1.414214  2.236068  2.236068  5.944185  6.244998 13.945131 26.813243
\end{verbatim}

이는 \texttt{height}에서 표현하는 값은 전체 \(SSW\)가 아니라, 두 군집 \(i\)와 \(j\)를 하나로 묶을 때 추가로 증가하는 \(SSW\) 수치의 변환으로, 아래와 같이 계산되기 때문이다.

\begin{equation}
height = \sqrt{D^2(C_i \cup C_j) - \left(D^2(C_i) + D^2(C_j)\right)}
\label{eq:hclust-height}
\end{equation}

따라서, 군집 \(i\)와 \(j\)를 하나로 묶을 때 증가하는 \(SSW\)의 수치 \(\Delta SSW\)는 아래와 같이 표현된다.

\begin{equation}
\Delta SSW = \frac{1}{2} height^2
\end{equation}

각 iteration에서 발생하는 \(\Delta SSW\)의 누적합이 위 \ref{ward-method-algorithm}절에서 보였던 \(SSW\) 결과와 동일함을 아래와 같이 확인해보자.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{iteration =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(train\_df) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)),}
  \AttributeTok{height =}\NormalTok{ res\_ward.D2}\SpecialCharTok{$}\NormalTok{height}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{delta\_ssw =}\NormalTok{ height }\SpecialCharTok{\^{}} \DecValTok{2} \SpecialCharTok{/} \DecValTok{2}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{ssw =} \FunctionTok{cumsum}\NormalTok{(delta\_ssw)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}iteration\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$height$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{Delta SSW = }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{frac\{1\}\{2\} height \^{} 2$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$SSW = }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{sum }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{Delta SSW$\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}hclust 함수 ward.D2 방법의 height와 SSW 관계\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:ward-D2-height-ssw}hclust 함수 ward.D2 방법의 height와 SSW 관계}
\centering
\begin{tabular}[t]{rrrr}
\toprule
iteration & \$height\$ & \$\textbackslash{}Delta SSW = \textbackslash{}frac\{1\}\{2\} height \textasciicircum{} 2\$ & \$SSW = \textbackslash{}sum \textbackslash{}Delta SSW\$\\
\midrule
1 & 1.414214 & 1.00000 & 1.00000\\
2 & 2.236068 & 2.50000 & 3.50000\\
3 & 2.236068 & 2.50000 & 6.00000\\
4 & 5.944185 & 17.66667 & 23.66667\\
5 & 6.244998 & 19.50000 & 43.16667\\
\addlinespace
6 & 13.945131 & 97.23333 & 140.40000\\
7 & 26.813243 & 359.47500 & 499.87500\\
\bottomrule
\end{tabular}
\end{table}

우선 \texttt{method}값을 ``ward.D''로 설정하는 경우, \texttt{dist} 함수의 결과를 입력 거리행렬로 그대로 사용하면 아래와 같이 위 ``ward.D2''와는 다른 \texttt{height}값을 출력하며, 이는 워드 방법의 criterion을 정확히 반영하지 못한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_ward.D }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(train\_df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{hclust}\NormalTok{(}\AttributeTok{method =} \StringTok{"ward.D"}\NormalTok{)}

\NormalTok{res\_ward.D}\SpecialCharTok{$}\NormalTok{height}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1.414214  2.236068  2.236068  6.452039  6.615990 17.358484 39.311447
\end{verbatim}

이는 ``ward.D2''는 워드 방법 수행 전 입력된 유클리드 거리행렬을 내부적으로 제곱하는 반면, ``ward.D'' 방법은 제곱 유클리드 거리행렬이 입력되는 것을 가정하기 때문이다.

\citet{lance1967general} 은 군집 \(i\)와 \(j\)를 하나로 묶을 때, 새로 생성된 군집과 다른 군집들간의 거리는 원 두 군집들과 다른 군집들간의 거리로 아래와 같이 표현됨을 보였다. 이를 Lance-Williams update 공식이라 한다.

\begin{equation}
D(C_i \cup C_j, C_{h \notin \{i, j\}}) = \alpha_i D(C_i, C_h) + \alpha_j D(C_j, C_h) + \beta D(C_i, C_j) + \gamma |D(C_i, C_h) - D(C_j, C_h)|
\label{eq:lance-williams-update}
\end{equation}

이후 \citet{wishart1969256} 에서 워드 방법을 위 Lance-Williams update 공식으로 표현하였다.

\begin{equation}
\begin{split}
\alpha_i =& \frac{|C_i| + |C_h|}{|C_i| + |C_j| + |C_h|}\\
\alpha_j =& \frac{|C_j| + |C_h|}{|C_i| + |C_j| + |C_h|}\\
\beta =& - \frac{|C_h|}{|C_i| + |C_j| + |C_h|}\\
\gamma =& 0
\end{split}
\label{eq:wishart}
\end{equation}

이 때, 식 \eqref{eq:wishart}가 기반한 식 \eqref{eq:lance-williams-update}에서의 거리함수 \(D\)는 제곱 유클리드 거리를 사용한다.

``ward.D'' 방법은 제곱 유클리드 거리의 입력을 가정하며, 위의 경우와 같이 제곱 유클리드 거리가 아닌 일반 유클리드 거리행렬을 입력하였을 때, 오류 메시지를 출력하는 대신, 입력된 거리행렬이 제곱 유클리드 거리를 나타낸다 가정하고 Lance-Williams update를 수행한다. 따라서, 이 경우 \texttt{height}는 워드 방법의 criterion을 정확히 표현하지 못한다.

제곱 유클리드 거리를 ``ward.D'' 방법의 입력 거리행렬로 설정하고, 구해진 \texttt{height}를 출력해보자

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_ward.D }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(train\_df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{])}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{hclust}\NormalTok{(}\AttributeTok{method =} \StringTok{"ward.D"}\NormalTok{)}

\NormalTok{res\_ward.D}\SpecialCharTok{$}\NormalTok{height}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]   2.00000   5.00000   5.00000  35.33333  39.00000 194.46667 718.95000
\end{verbatim}

위 \texttt{height}값은 ``ward.D2'' 방법에서 출력된 값보다 크다. 위 값의 제곱근(square root)를 구하면 ``ward.D2''에서의 \texttt{height}값과 동일한 값을 얻을 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sqrt}\NormalTok{(res\_ward.D}\SpecialCharTok{$}\NormalTok{height)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1.414214  2.236068  2.236068  5.944185  6.244998 13.945131 26.813243
\end{verbatim}

제곱 유클리드 거리행렬을 입력한 ``ward.D'' 방법의 결과로 출력된 criterion \texttt{height}는 \(2 \Delta SSW\)의 값에 해당하는 수치이며, 각 iteration 당 \(\sum_i D(C_i)\)의 값의 변화량이라고 볼 수 있다. (식 \eqref{eq:squared-euclidean-within-cluster} 참조)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{iteration =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(train\_df) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)),}
  \AttributeTok{height =}\NormalTok{ res\_ward.D}\SpecialCharTok{$}\NormalTok{height}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{delta\_ssw =}\NormalTok{ height }\SpecialCharTok{/} \DecValTok{2}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{ssw =} \FunctionTok{cumsum}\NormalTok{(delta\_ssw)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}iteration\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$height$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{Delta SSW = }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{frac\{1\}\{2\} height$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$SSW = }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{sum }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{Delta SSW$\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}hclust 함수 ward.D 방법의 height와 SSW 관계\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:ward-D-height-ssw}hclust 함수 ward.D 방법의 height와 SSW 관계}
\centering
\begin{tabular}[t]{rrrr}
\toprule
iteration & \$height\$ & \$\textbackslash{}Delta SSW = \textbackslash{}frac\{1\}\{2\} height\$ & \$SSW = \textbackslash{}sum \textbackslash{}Delta SSW\$\\
\midrule
1 & 2.00000 & 1.00000 & 1.00000\\
2 & 5.00000 & 2.50000 & 3.50000\\
3 & 5.00000 & 2.50000 & 6.00000\\
4 & 35.33333 & 17.66667 & 23.66667\\
5 & 39.00000 & 19.50000 & 43.16667\\
\addlinespace
6 & 194.46667 & 97.23333 & 140.40000\\
7 & 718.95000 & 359.47500 & 499.87500\\
\bottomrule
\end{tabular}
\end{table}

즉, ``ward.D2''와 ``ward.D''의 가장 큰 차이는 입력될 거리행렬이 유클리드 거리(ward.D2)인지 제곱 유클리드 거리(ward.D)인지의 차이이다.

참고로, \texttt{cluster} 패키지의 \texttt{agnes}함수도 워드 방법을 지원하며, 이 경우 파라미터 \texttt{method}의 값을 ``ward''로 설정한 결과가 \texttt{hclust}함수의 ``ward.D2''의 경우와 동일하다. 본 절에서는 해당 함수의 자세한 사용법은 생략한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_agnes\_ward }\OtherTok{\textless{}{-}}\NormalTok{ cluster}\SpecialCharTok{::}\FunctionTok{agnes}\NormalTok{(train\_df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{method =} \StringTok{"ward"}\NormalTok{)}

\FunctionTok{sort}\NormalTok{(res\_agnes\_ward}\SpecialCharTok{$}\NormalTok{height)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  1.414214  2.236068  2.236068  5.944185  6.244998 13.945131 26.813243
\end{verbatim}

\hypertarget{diana}{%
\section{분리적 방법 - 다이아나}\label{diana}}

다이아나는 분리적 방법의 하나로, \citet{kaufman1990finding} 에 의하여 제안된 것이다. 이는 전체의 객체를 하나의 군집으로 시작하여 매번 이분화하는 등 모든 군집이 단독 객체로 구성될 때까지 진행하는 방법이다. 이 때, 비유사성 척도로는 평균거리를 사용한다.

\hypertarget{diana-basic-script}{%
\subsection{기본 R 스크립트}\label{diana-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{id =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{7}\NormalTok{),}
  \AttributeTok{x1 =} \FunctionTok{c}\NormalTok{(}\DecValTok{30}\NormalTok{, }\DecValTok{45}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{40}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{42}\NormalTok{),}
  \AttributeTok{x2 =} \FunctionTok{c}\NormalTok{(}\DecValTok{15}\NormalTok{, }\DecValTok{22}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{24}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\NormalTok{)}

\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(train\_df, }\AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
             \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
             \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}\NormalTok{),}
             \AttributeTok{caption =} \StringTok{\textquotesingle{}DIANA 군집 대상 객체 데이터\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:diana-data}DIANA 군집 대상 객체 데이터}
\centering
\begin{tabular}[t]{rrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$\\
\midrule
1 & 30 & 15\\
2 & 45 & 22\\
3 & 25 & 12\\
4 & 40 & 24\\
5 & 50 & 25\\
\addlinespace
6 & 20 & 10\\
7 & 42 & 9\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:diana-data}와 같이 두 변수 \(x_1\), \(x_2\)로 이루어진 7개의 객체 데이터에 대해 DIANA 방법에 의해 군집해를 아래와 같이 \texttt{cluster} 패키지의 \texttt{diana} 함수를 이용하여 간단히 구할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_diana }\OtherTok{\textless{}{-}}\NormalTok{ cluster}\SpecialCharTok{::}\FunctionTok{diana}\NormalTok{(train\_df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{])}
\NormalTok{cluster}\SpecialCharTok{::}\FunctionTok{pltree}\NormalTok{(res\_diana,}
                \AttributeTok{main =} \ConstantTok{NULL}\NormalTok{,}
                \AttributeTok{xlab =} \StringTok{"observation"}
\NormalTok{                )}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/diana-result-plot-1} 

}

\caption{DIANA 방법에 의한 군집 덴드로그램}\label{fig:diana-result-plot}
\end{figure}

\hypertarget{diana-algorithm}{%
\subsection{다이아나 알고리즘}\label{diana-algorithm}}

가장 처음 이분화가 이루어질 때, 우선 타 객체와의 평균거리가 가장 큰 객체가 분파되어 새로운 군집을 형성한다. 그리고 다른 객체에 대하여, 군집에 남아있을 때의 평균거리와 새로운 군집으로 분리될 때의 평균거리를 산출하여, 현 군집에 잔류 또는 새로운 군집으로의 합류를 결정한다.

여기서 객체 \(i\)와 군집 \(C\)간의 평균거리는 다음과 같이 산출된다.

\begin{equation*}
\bar{d}(i, C) = \begin{cases}
\frac{1}{|C| - 1} \sum_{j \in C} d(i, j) & \text{ if } i \in C\\
\frac{1}{|C|} \sum_{j \in C} d(i, j) & \text{ if } i \notin C
\end{cases}
\end{equation*}

본 방법의 알고리즘은 다음과 같다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  단계0: \(n\)개의 객체를 하나의 군집으로 간주한다. (\(k = 1\))
\item
  단계1: 객체 간 거리가 가장 큰 두 객체를 포함한 군집을 이분화 대상으로 선정한다. (이를 \(A\)라 하고, \(B \leftarrow \emptyset\)로 둔다.)
\item
  단계2: 다음 과정을 통하여 군집 \(A\)를 이분화한다.

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    단계2-1: \(i \leftarrow \arg\,\max_{i'} \bar{d}(i', A)\)
  \item
    단계2-2: \(A \leftarrow A - \{i\}\), \(B \leftarrow B \cup \{i\}\)
  \item
    단계2-3: \(i \leftarrow \arg\,\max_{i' \in A} e(i') = \bar{d}(i', A) - \bar{d}(i', B)\)
  \item
    단계2-4: \(e(i) > 0\)이면 단계2-2로, \(e(i) \le 0\)이면 단계3으로
  \end{enumerate}
\item
  단계3

  \begin{enumerate}
  \def\labelenumii{\arabic{enumii}.}
  \tightlist
  \item
    \(k \leftarrow k + 1\)
  \item
    \(k < n\)이면 단계1로, \(k = n\)이면 Stop.
  \end{enumerate}
\end{enumerate}

DIANA 알고리즘을 R script로 구현해보자.

우선, 단계1의 군집을 찾는 함수 \texttt{max\_distance\_cluster}를 구현하자. 이 함수는 아래 두 개의 데이터 프레임을 입력받는다.

\begin{itemize}
\tightlist
\item
  입력

  \begin{itemize}
  \tightlist
  \item
    \texttt{df}: 관측 데이터. 각 열의 설명은 아래와 같다.

    \begin{itemize}
    \tightlist
    \item
      \texttt{id}: 객체번호
    \item
      나머지 열: 숫자형 변수
    \end{itemize}
  \item
    \texttt{cluster\_label}: 각 객체의 현재 소속 군집을 나타내는 데이터 프레임

    \begin{itemize}
    \tightlist
    \item
      \texttt{id}: 객체번호
    \item
      \texttt{cluster}: 군집명
    \end{itemize}
  \end{itemize}
\item
  함수값

  \begin{itemize}
  \tightlist
  \item
    \texttt{cluster}: 객체간 거리가 가장 큰 두 객체를 포함한 군집명
  \item
    \texttt{distance}: 군집 내 객체간 최대 거리
  \end{itemize}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{max\_distance\_cluster }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, cluster\_label) \{}
\NormalTok{  unique\_cluster }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(cluster\_label}\SpecialCharTok{$}\NormalTok{cluster)}
  
\NormalTok{  cluster\_df }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(unique\_cluster, }\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{    cluster\_label }\SpecialCharTok{\%\textgreater{}\%} 
      \FunctionTok{filter}\NormalTok{(cluster }\SpecialCharTok{==}\NormalTok{ x) }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{inner\_join}\NormalTok{(df, }\AttributeTok{by =} \StringTok{"id"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{cluster, }\SpecialCharTok{{-}}\NormalTok{id)}
\NormalTok{    \})}
  
\NormalTok{  max\_distance }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(cluster\_df, }
                         \ControlFlowTok{function}\NormalTok{(x) \{}
                           \ControlFlowTok{if}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(x) }\SpecialCharTok{==} \DecValTok{1}\NormalTok{) }\FunctionTok{return}\NormalTok{(}\DecValTok{0}\NormalTok{)}
                           \FunctionTok{max}\NormalTok{(}\FunctionTok{dist}\NormalTok{(x))}
\NormalTok{                         \}}
\NormalTok{                         )}

  \FunctionTok{list}\NormalTok{(}
    \AttributeTok{cluster =}\NormalTok{ unique\_cluster[}\FunctionTok{which.max}\NormalTok{(max\_distance)],}
    \AttributeTok{distance =} \FunctionTok{max}\NormalTok{(max\_distance)}
\NormalTok{  )}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

단계 2-1에서 군집 내 평균거리가 가장 큰 객체를 찾는 함수 \texttt{max\_within\_distance}를 아래와 같이 구현해보자. 이 때 입력변수인 \texttt{cluster\_df}는 해당 군집의 객체 데이터로, 객체 번호를 나타내는 열 \texttt{id}와 객체의 각 숫자형 변수를 표현하는 열들로 구성된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{max\_within\_distance }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(cluster\_df) \{}
\NormalTok{  idx }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(}\FunctionTok{subset}\NormalTok{(cluster\_df, }\AttributeTok{select =} \SpecialCharTok{{-}}\NormalTok{id), }\AttributeTok{upper =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarize}\NormalTok{(}\AttributeTok{mean\_distance =} \FunctionTok{mean}\NormalTok{(distance)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{mean\_distance) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    .[[}\StringTok{"item1"}\NormalTok{]] }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    .[}\DecValTok{1}\NormalTok{]}
  
\NormalTok{  cluster\_df}\SpecialCharTok{$}\NormalTok{id[idx]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

이후 단계2-3에서 정의한 \(e(i') = \bar{d}(i', A) - \bar{d}(i', B)\)를 계산하는 함수 \texttt{e\_score}를 아래와 같이 구현한다.

\begin{itemize}
\tightlist
\item
  \texttt{object}: 객체 번호(\texttt{id})
\item
  \texttt{A}(\texttt{B}): 군집 \(A\)(\(B\))의 객체 데이터. 행은 객체를 나타내며, \texttt{id} 열은 객체 번호, 이외의 열들은 변수를 나타낸다.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e\_score }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(object, A, B) \{}
\NormalTok{  d\_from\_A }\OtherTok{\textless{}{-}}\NormalTok{ proxy}\SpecialCharTok{::}\FunctionTok{dist}\NormalTok{(}\FunctionTok{subset}\NormalTok{(A, id }\SpecialCharTok{==}\NormalTok{ object, }\SpecialCharTok{{-}}\NormalTok{id), }
                          \FunctionTok{subset}\NormalTok{(A, id }\SpecialCharTok{!=}\NormalTok{ object, }\SpecialCharTok{{-}}\NormalTok{id)) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{mean}\NormalTok{()}
\NormalTok{  d\_from\_B }\OtherTok{\textless{}{-}}\NormalTok{ proxy}\SpecialCharTok{::}\FunctionTok{dist}\NormalTok{(}\FunctionTok{subset}\NormalTok{(A, id }\SpecialCharTok{==}\NormalTok{ object, }\SpecialCharTok{{-}}\NormalTok{id), }
\NormalTok{                          B }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{id)) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{mean}\NormalTok{()}
  \FunctionTok{return}\NormalTok{(d\_from\_A }\SpecialCharTok{{-}}\NormalTok{ d\_from\_B)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 두 함수 \texttt{max\_within\_distance}와 \texttt{e\_score}를 이용하여, 주어진 데이터 프레임을 두 군집으로 나누는 함수 \texttt{split\_cluster}를 구현해보자.

\begin{itemize}
\tightlist
\item
  입력: 객체 데이터를 나타내는 데이터 프레임 \texttt{cluster\_df}. 행은 객체를 나타내며, 객체 번호를 나타내는 열 \texttt{id}와 객체의 각 숫자형 변수를 표현하는 열들로 구성된다.
\item
  함수값: 아래 두 개의 component를 지닌 리스트.

  \begin{itemize}
  \tightlist
  \item
    \texttt{idx\_A}: 객체 데이터에서 행렬 \(A\)에 속하는 객체 번호
  \item
    \texttt{idx\_B}: 객체 데이터에서 행렬 \(B\)에 속하는 객체 번호
  \end{itemize}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{split\_cluster }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(cluster\_df) \{}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(cluster\_df)}
  
\NormalTok{  idx\_A }\OtherTok{\textless{}{-}}\NormalTok{ cluster\_df}\SpecialCharTok{$}\NormalTok{id}
\NormalTok{  idx\_B }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
  
  \CommentTok{\# 단계2{-}1}
\NormalTok{  max\_object }\OtherTok{\textless{}{-}} \FunctionTok{max\_within\_distance}\NormalTok{(cluster\_df)}
\NormalTok{  e\_i }\OtherTok{\textless{}{-}} \ConstantTok{Inf}

  \ControlFlowTok{while}\NormalTok{(e\_i }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{) \{}
    \CommentTok{\# 단계2{-}2}
\NormalTok{    idx\_B }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(idx\_B, max\_object)}
\NormalTok{    idx\_A }\OtherTok{\textless{}{-}} \FunctionTok{setdiff}\NormalTok{(idx\_A, max\_object)}
    
\NormalTok{    A }\OtherTok{\textless{}{-}}\NormalTok{ cluster\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(id }\SpecialCharTok{\%in\%}\NormalTok{ idx\_A)}
\NormalTok{    B }\OtherTok{\textless{}{-}}\NormalTok{ cluster\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(id }\SpecialCharTok{\%in\%}\NormalTok{ idx\_B)}

    \CommentTok{\# 단계2{-}3}
    \ControlFlowTok{if}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(A) }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{) \{}
\NormalTok{      e\_is }\OtherTok{\textless{}{-}} \FunctionTok{sapply}\NormalTok{(A}\SpecialCharTok{$}\NormalTok{id, }\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{e\_score}\NormalTok{(x, A, B))}
\NormalTok{      max\_object }\OtherTok{\textless{}{-}}\NormalTok{ A}\SpecialCharTok{$}\NormalTok{id[}\FunctionTok{which.max}\NormalTok{(e\_is)]}
\NormalTok{      e\_i }\OtherTok{\textless{}{-}} \FunctionTok{max}\NormalTok{(e\_is)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{      e\_i }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\ConstantTok{Inf}
\NormalTok{    \}}
\NormalTok{  \}}
  
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{idx\_A =}\NormalTok{ idx\_A, }\AttributeTok{idx\_B =}\NormalTok{ idx\_B))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

단계1 함수 \texttt{max\_distance\_cluster}와 단계2 함수 \texttt{split\_cluster}를 반복적으로 수행하며 각각의 객체가 군집에 될 때까지 군집을 분리해간다.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 단계0}
\NormalTok{current\_cluster }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{id =}\NormalTok{ train\_df}\SpecialCharTok{$}\NormalTok{id}
\NormalTok{)}
\NormalTok{current\_cluster}\SpecialCharTok{$}\NormalTok{cluster }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(current\_cluster), }\AttributeTok{collapse =} \StringTok{","}\NormalTok{)}
\NormalTok{i }\OtherTok{\textless{}{-}}\NormalTok{ 0L}
\NormalTok{k }\OtherTok{\textless{}{-}}\NormalTok{ 1L}

\ControlFlowTok{while}\NormalTok{(k }\SpecialCharTok{\textless{}} \FunctionTok{nrow}\NormalTok{(train\_df)) \{}
\NormalTok{  i }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{+}\NormalTok{ 1L}
  
  \CommentTok{\# 단계1}
\NormalTok{  max\_cluster }\OtherTok{\textless{}{-}} \FunctionTok{max\_distance\_cluster}\NormalTok{(train\_df, current\_cluster)}

  \CommentTok{\# 단계2}
\NormalTok{  new\_split }\OtherTok{\textless{}{-}}\NormalTok{ current\_cluster }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(cluster }\SpecialCharTok{==}\NormalTok{ max\_cluster}\SpecialCharTok{$}\NormalTok{cluster) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{inner\_join}\NormalTok{(train\_df, }\AttributeTok{by =} \StringTok{"id"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{cluster) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{split\_cluster}\NormalTok{()}

  \CommentTok{\# 군집해 업데이트}
\NormalTok{  current\_cluster[}
\NormalTok{    current\_cluster}\SpecialCharTok{$}\NormalTok{id }\SpecialCharTok{\%in\%}\NormalTok{ new\_split}\SpecialCharTok{$}\NormalTok{idx\_A, }
    \StringTok{"cluster"}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(new\_split}\SpecialCharTok{$}\NormalTok{idx\_A, }\AttributeTok{collapse =} \StringTok{","}\NormalTok{)}
\NormalTok{  current\_cluster[}
\NormalTok{    current\_cluster}\SpecialCharTok{$}\NormalTok{id }\SpecialCharTok{\%in\%}\NormalTok{ new\_split}\SpecialCharTok{$}\NormalTok{idx\_B, }
    \StringTok{"cluster"}\NormalTok{] }\OtherTok{\textless{}{-}} \FunctionTok{paste}\NormalTok{(new\_split}\SpecialCharTok{$}\NormalTok{idx\_B, }\AttributeTok{collapse =} \StringTok{","}\NormalTok{)}
  
  \CommentTok{\# 군집해 출력}
\NormalTok{  k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(current\_cluster}\SpecialCharTok{$}\NormalTok{cluster))}
  \FunctionTok{cat}\NormalTok{(}\StringTok{"Iteration: "}\NormalTok{, i, }\StringTok{", k = "}\NormalTok{, k, }\StringTok{", clusters = "}\NormalTok{, }
      \FunctionTok{paste0}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{unique}\NormalTok{(current\_cluster}\SpecialCharTok{$}\NormalTok{cluster), }\StringTok{"\}"}\NormalTok{),}
      \StringTok{", height = "}\NormalTok{, max\_cluster}\SpecialCharTok{$}\NormalTok{distance, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Iteration:  1 , k =  2 , clusters =  {6,3,1} {2,4,5,7} , height =  33.54102 
## Iteration:  2 , k =  3 , clusters =  {6,3,1} {2,4,5} {7} , height =  17.88854 
## Iteration:  3 , k =  4 , clusters =  {1} {2,4,5} {3,6} {7} , height =  11.18034 
## Iteration:  4 , k =  5 , clusters =  {1} {2,4} {3,6} {5} {7} , height =  10.04988 
## Iteration:  5 , k =  6 , clusters =  {1} {2} {3,6} {4} {5} {7} , height =  5.385165 
## Iteration:  6 , k =  7 , clusters =  {1} {2} {3} {4} {5} {6} {7} , height =  5.385165
\end{verbatim}

위 출력 결과에서 \texttt{height}는 해당 iteration에서 분리된 군집의 분리 전 지름(diameter)으로, 함수 \texttt{max\_distance\_cluster}에서 계산한 군집 내 객체간 최대 거리를 나타내며, 이는 R 패키지 \texttt{cluster}의 \texttt{diana} 함수 수행 시 함수값으로 출력되는 \texttt{height}값이다. Iteration이 진행됨에 따라 \texttt{height}의 값이 감소하는 것을 확인할 수 있다.

\hypertarget{hierarchical-cluster-number}{%
\section{군집수의 결정}\label{hierarchical-cluster-number}}

최적의 군집수를 결정하는 객관적인 방법은 존재하지 않는다. 계층적 군집방법에서는 덴드로그램을 참조하여 군집 간의 거리가 급격히 증가하는 계층에서 수평으로 절단하여, 그 이하의 그룹들을 하나의 군집으로 형성하는 방안을 널리 사용하고 있다. 이외에 군집수를 결정하는 데 통계량으로 다음과 같은 통계량들이 부수적으로 사용된다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  새 군집의 RMS 표준편차(root-mean-square standard deviation of the new cluster; RMSSTD)
\end{enumerate}

\begin{equation*}
RMSSTD(C_i, C_j) = \sqrt{\frac{SS(C_i \cup C_j)}{p(|C_i| + |C_j| - 1)}}
\end{equation*}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Semipartial R-squared(SPR)
\end{enumerate}

\begin{equation*}
SPR(C_i, C_j) = \frac{SS(C_i \cup C_j) - (SS(C_i) + SS(C_j))}{SST}
\end{equation*}

where

\begin{equation*}
SST = \sum_{i = 1}^{n} \sum_{j = 1}^{p} \left( x_{ji} - \frac{1}{n} \sum_{a = 1}^{n} x_{ja} \right)^2
\end{equation*}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  R-squared(\(R^2\))
\end{enumerate}

\begin{equation*}
1 - \frac{\sum_{i = 1}^{k} SS(C_i)}{SST}
\end{equation*}

위 \ref{ward-method-algorithm}절에서 워드 군집 알고리즘으로 구현한 군집 과정에 대해 위 통계량을 계산해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{id =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{8}\NormalTok{),}
  \AttributeTok{x1 =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{17}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{18}\NormalTok{),}
  \AttributeTok{x2 =} \FunctionTok{c}\NormalTok{(}\DecValTok{15}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{17}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{6}\NormalTok{)}
\NormalTok{)}

\NormalTok{sst }\OtherTok{\textless{}{-}}\NormalTok{ train\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{id) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{sapply}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{sum}\NormalTok{((x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{sum}\NormalTok{()}

\CommentTok{\#단계0}
\NormalTok{init\_cluster }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{id =}\NormalTok{ train\_df}\SpecialCharTok{$}\NormalTok{id,}
  \AttributeTok{cluster =} \FunctionTok{as.character}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(train\_df))}
\NormalTok{)}
\NormalTok{i }\OtherTok{\textless{}{-}}\NormalTok{ 0L}
\NormalTok{current\_clusters }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(init\_cluster}\SpecialCharTok{$}\NormalTok{cluster)}
\NormalTok{k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(current\_clusters)}
\NormalTok{ssw }\OtherTok{\textless{}{-}} \FunctionTok{calculate\_ssw}\NormalTok{(train\_df, init\_cluster)}
\NormalTok{old\_ssw }\OtherTok{\textless{}{-}} \ConstantTok{NA\_real\_}

\CommentTok{\#단계1}
\NormalTok{iteration }\OtherTok{\textless{}{-}} \FunctionTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\AttributeTok{length =} \FunctionTok{nrow}\NormalTok{(train\_df) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\ControlFlowTok{while}\NormalTok{(k }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  i }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{+} \DecValTok{1}
\NormalTok{  old\_ssw }\OtherTok{\textless{}{-}}\NormalTok{ ssw}
  
  \ControlFlowTok{if}\NormalTok{(i }\SpecialCharTok{==} \DecValTok{1}\NormalTok{) \{}
\NormalTok{    old\_cluster }\OtherTok{\textless{}{-}}\NormalTok{ init\_cluster}
\NormalTok{  \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{    old\_cluster }\OtherTok{\textless{}{-}}\NormalTok{ iteration[[i}\DecValTok{{-}1}\NormalTok{]]}\SpecialCharTok{$}\NormalTok{new\_cluster\_label}
\NormalTok{  \}}
  
\NormalTok{  iteration[[i]] }\OtherTok{\textless{}{-}} \FunctionTok{best\_merge\_cluster}\NormalTok{(}
\NormalTok{    train\_df,}
\NormalTok{    old\_cluster}
\NormalTok{  )}
  
\NormalTok{  merged }\OtherTok{\textless{}{-}}\NormalTok{ old\_cluster }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{anti\_join}\NormalTok{(iteration[[i]]}\SpecialCharTok{$}\NormalTok{new\_cluster\_label, }\AttributeTok{by =} \StringTok{"cluster"}\NormalTok{)}
  
\NormalTok{  current\_clusters }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(iteration[[i]]}\SpecialCharTok{$}\NormalTok{new\_cluster\_label}\SpecialCharTok{$}\NormalTok{cluster)}
\NormalTok{  k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(current\_clusters)}
\NormalTok{  ssw }\OtherTok{\textless{}{-}}\NormalTok{ iteration[[i]]}\SpecialCharTok{$}\NormalTok{new\_ssw}
  
\NormalTok{  iteration[[i]]}\SpecialCharTok{$}\NormalTok{rmsstd }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}
\NormalTok{    merged }\SpecialCharTok{\%\textgreater{}\%} 
      \FunctionTok{inner\_join}\NormalTok{(train\_df, }\AttributeTok{by =} \StringTok{"id"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{id, }\SpecialCharTok{{-}}\NormalTok{cluster) }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{sapply}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(x) }\FunctionTok{sum}\NormalTok{((x }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x))}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{sum}\NormalTok{() }\SpecialCharTok{/}\NormalTok{ (}\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\FunctionTok{nrow}\NormalTok{(merged) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{))}
\NormalTok{  )}
  
\NormalTok{  iteration[[i]]}\SpecialCharTok{$}\NormalTok{iter }\OtherTok{\textless{}{-}}\NormalTok{ i}
\NormalTok{  iteration[[i]]}\SpecialCharTok{$}\NormalTok{merge }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{unique}\NormalTok{(merged}\SpecialCharTok{$}\NormalTok{cluster), }\StringTok{"\}"}\NormalTok{, }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{)}
\NormalTok{  iteration[[i]]}\SpecialCharTok{$}\NormalTok{sol }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{unique}\NormalTok{(current\_clusters), }\StringTok{"\}"}\NormalTok{, }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{)}
\NormalTok{  iteration[[i]]}\SpecialCharTok{$}\NormalTok{spr }\OtherTok{\textless{}{-}}\NormalTok{ (ssw }\SpecialCharTok{{-}}\NormalTok{ old\_ssw) }\SpecialCharTok{/}\NormalTok{ sst}
\NormalTok{  iteration[[i]]}\SpecialCharTok{$}\NormalTok{r\_sq }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ ssw }\SpecialCharTok{/}\NormalTok{ sst}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster\_statistic }\OtherTok{\textless{}{-}} \FunctionTok{lapply}\NormalTok{(iteration, }\ControlFlowTok{function}\NormalTok{(x) x[}
  \FunctionTok{c}\NormalTok{(}\StringTok{"iter"}\NormalTok{, }\StringTok{"merge"}\NormalTok{, }\StringTok{"sol"}\NormalTok{, }\StringTok{"rmsstd"}\NormalTok{, }\StringTok{"spr"}\NormalTok{, }\StringTok{"r\_sq"}\NormalTok{)]) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_rows}\NormalTok{(}
    \FunctionTok{tibble}\NormalTok{(}
      \AttributeTok{iter =} \DecValTok{0}\NormalTok{,}
      \AttributeTok{sol =} \FunctionTok{paste0}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{unique}\NormalTok{(init\_cluster}\SpecialCharTok{$}\NormalTok{cluster), }\StringTok{"\}"}\NormalTok{, }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{),}
      \AttributeTok{r\_sq =} \DecValTok{1}
\NormalTok{    )}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(iter)}

\NormalTok{cluster\_statistic }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}Iteration\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}통합대상군집\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}통합 후 군집\textquotesingle{}}\NormalTok{,}
                  \StringTok{\textquotesingle{}$RMSSTD$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$SPR$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$R\^{}2$\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}군집 과정에 따른 여러 통계량\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:cluster-statistic}군집 과정에 따른 여러 통계량}
\centering
\begin{tabular}[t]{rllrrr}
\toprule
Iteration & 통합대상군집 & 통합 후 군집 & \$RMSSTD\$ & \$SPR\$ & \$R\textasciicircum{}2\$\\
\midrule
0 & NA & \{1\}, \{2\}, \{3\}, \{4\}, \{5\}, \{6\}, \{7\}, \{8\} & NA & NA & 1.0000000\\
1 & \{2\}, \{7\} & \{1\}, \{2,7\}, \{3\}, \{4\}, \{5\}, \{6\}, \{8\} & 0.7071068 & 0.0020005 & 0.9979995\\
2 & \{1\}, \{3\} & \{1,3\}, \{2,7\}, \{4\}, \{5\}, \{6\}, \{8\} & 1.1180340 & 0.0050013 & 0.9929982\\
3 & \{4\}, \{8\} & \{1,3\}, \{2,7\}, \{4,8\}, \{5\}, \{6\} & 1.1180340 & 0.0050013 & 0.9879970\\
4 & \{2,7\}, \{5\} & \{1,3\}, \{2,7,5\}, \{4,8\}, \{6\} & 2.1602469 & 0.0353422 & 0.9526548\\
\addlinespace
5 & \{1,3\}, \{6\} & \{1,3,6\}, \{2,7,5\}, \{4,8\} & 2.3452079 & 0.0390098 & 0.9136451\\
6 & \{2,7,5\}, \{4,8\} & \{1,3,6\}, \{2,7,5,4,8\} & 3.8470768 & 0.1945153 & 0.7191298\\
7 & \{1,3,6\}, \{2,7,5,4,8\} & \{1,3,6,2,7,5,4,8\} & 5.9753960 & 0.7191298 & 0.0000000\\
\bottomrule
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster\_statistic }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{rmsstd =} \FunctionTok{if\_else}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(rmsstd), }\DecValTok{0}\NormalTok{, rmsstd),}
    \AttributeTok{spr =} \FunctionTok{if\_else}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(spr), }\DecValTok{0}\NormalTok{, spr)}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ iter)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ rmsstd, }\AttributeTok{color =} \StringTok{"RMSSTD"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ spr }\SpecialCharTok{*} \DecValTok{6}\NormalTok{, }\AttributeTok{color =} \StringTok{"SPR"}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y =}\NormalTok{ r\_sq }\SpecialCharTok{*} \DecValTok{6}\NormalTok{, }\AttributeTok{color =} \StringTok{"R2"}\NormalTok{)) }\SpecialCharTok{+} 
  \FunctionTok{scale\_y\_continuous}\NormalTok{(}\AttributeTok{sec.axis =} \FunctionTok{sec\_axis}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ . }\SpecialCharTok{/} \DecValTok{6}\NormalTok{, }\AttributeTok{name =} \StringTok{"SPR, R2"}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{ylab}\NormalTok{(}\StringTok{"RMSSTD"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{xlab}\NormalTok{(}\StringTok{"Iteration"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/cluster-statistic-1} 

}

\caption{군집 과정에 따른 통계량 추이}\label{fig:cluster-statistic}
\end{figure}

그림 \ref{fig:cluster-statistic}에서 보듯이 Iteration 6부터 3가지 통계량 모두 급격하게 변화하는 것을 알 수 있다. 따라서 군집수는 Iteration 5까지 3개가 가장 적당하다고 하겠다.

\hypertarget{nonhierarchical-clustering}{%
\chapter{비계층적 군집방법}\label{nonhierarchical-clustering}}

비계층적 군집방법(Nonhierarchical clustering)은 분할방법(Partitioning method)이라고도 하는데, 군집의 수 \(K\)를 사전에 지정하고 대상 객체들을 적절한 군집에 배정하는 방법이다. 즉, 이 방법은 \(n\)개의 객체를 \(K\)개의 군집에 할당하는 최적화 문제로 간주할 수 있다. 본 장에서는 분할방법의 대표적인 K-means 알고리즘, K-medoids 군집방법, 퍼지 K-means 알고리즘, 그리고 모형기반 군집방법에 대하여 주로 알아본다.

\hypertarget{nonhierarchical-clustering-packages-install}{%
\section{필요 R package 설치}\label{nonhierarchical-clustering-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.3.1\\
\hline
stats & 4.1.0\\
\hline
cluster & 2.1.2\\
\hline
flexclust & 1.4-0\\
\hline
mclust & 5.4.7\\
\hline
mvtnorm & 1.1-2\\
\hline
\end{tabular}

\hypertarget{kmeans}{%
\section{K-means 알고리즘}\label{kmeans}}

K-means 알고리즘은 비계층적 군집방법 중 가장 널리 사용되는 것으로 \(K\)개 군집의 중심좌표를 고려하여 각 객체를 가까운 군집에 배정하는 반복적 알고리즘이다.

\hypertarget{kmeans-basic-script}{%
\subsection{기본 R 스크립트}\label{kmeans-basic-script}}

10명에 대한 PC의 사용경력(\(x_1\))과 주당 사용시간(\(x_2\))이 다음과 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{id, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x2,}
  \DecValTok{1}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{14}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{13}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{14}\NormalTok{, }\DecValTok{6}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{8}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{7}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{15}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{6}\NormalTok{,}
  \DecValTok{8}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \DecValTok{9}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{10}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}
\NormalTok{)}

\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}
      \StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }
      \StringTok{\textquotesingle{}사용경력($x\_1$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}사용시간($x\_2$)\textquotesingle{}}
\NormalTok{      ),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}PC 사용 데이터\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:kmeans-train-data}PC 사용 데이터}
\centering
\begin{tabular}[t]{rrr}
\toprule
객체번호 & 사용경력(\$x\_1\$) & 사용시간(\$x\_2\$)\\
\midrule
1 & 6 & 14\\
2 & 8 & 13\\
3 & 14 & 6\\
4 & 11 & 8\\
5 & 15 & 7\\
\addlinespace
6 & 7 & 15\\
7 & 13 & 6\\
8 & 5 & 4\\
9 & 3 & 3\\
10 & 3 & 2\\
\bottomrule
\end{tabular}
\end{table}

아래와 같이 \texttt{stats} 패키지의 \texttt{kmeans} 함수를 이용하여 K-means 알고리즘 수행 결과를 얻을 수 있다. 아래 스크립트는 군집 수가 \(K = 3\)라 가정하여 수행한 예이다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\NormalTok{kmeans\_solution }\OtherTok{\textless{}{-}} \FunctionTok{kmeans}\NormalTok{(}\AttributeTok{x =}\NormalTok{ df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{centers =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

위 스크립트 실행 결과 도출된 군집 중심좌표는 위에서 얻어진 \texttt{kmeans} 클래스 객체의 \texttt{centers}값에 저장된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kmeans\_solution}\SpecialCharTok{$}\NormalTok{centers}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          x1    x2
## 1 13.250000  6.75
## 2  3.666667  3.00
## 3  7.000000 14.00
\end{verbatim}

또한 각 학습 데이터가 속한 군집은 \texttt{cluster}값에 저장된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kmeans\_solution}\SpecialCharTok{$}\NormalTok{cluster}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 3 3 1 1 1 3 1 2 2 2
\end{verbatim}

객체의 군집결과는 아래와 같이 도식화하여 보일 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{cluster =} \FunctionTok{as.factor}\NormalTok{(kmeans\_solution}\SpecialCharTok{$}\NormalTok{cluster)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ x1, }\AttributeTok{y =}\NormalTok{ x2)) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{label =}\NormalTok{ id, }\AttributeTok{color =}\NormalTok{ cluster))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/kmeans-cluster-1} 

}

\caption{K-means 수행 결과}\label{fig:kmeans-cluster}
\end{figure}

\hypertarget{kmeans-algorithm}{%
\subsection{알고리즘}\label{kmeans-algorithm}}

K-means 알고리즘의 구체적 절차는 아래와 같다. Table \ref{tab:kmeans-train-data}에 대한 각 단계의 결과를 함께 살펴보자.

\textbf{{[}단계 0{]} (초기 객체 선정)} 어떤 규칙에 의하여 \(K\)개의 객체의 좌표를 초기 군집의 중심좌표(centroid)로 선정한다. 군집 \(j\)의 중심좌표를 \(\mathbf{c}_j = \left(\bar{x}^{(j)}_1, \cdots, \bar{x}^{(j)}_p\right)^\top\)라 하자. 초기 군집 중심좌표 \(\mathbf{c}_1, \cdots, \mathbf{c}_K\)를 선정하는 방법은 예를 들어 다음과 같은 규칙이 사용된다.

\begin{itemize}
\tightlist
\item
  무작위 방법: 대상 객체 중 무작위로 \(K\)개를 선정한다.
\item
  외각 객체 선정: 전체 객체의 중심좌표에서 가장 멀리 위치하는 \(K\)개의 객체를 선정한다.
\end{itemize}

{[}단계 0{]} 무작위 방법을 이용하여 Table \ref{tab:kmeans-train-data}으로부터 3개의 객체를 초기 군집 중심좌표로 선정하자.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}

\NormalTok{init\_cluster }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, }\AttributeTok{k =} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  k }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(k, }\FunctionTok{nrow}\NormalTok{(df))}
  
\NormalTok{  df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{sample\_n}\NormalTok{(k)}
\NormalTok{\}}

\NormalTok{cluster\_df }\OtherTok{\textless{}{-}} \FunctionTok{init\_cluster}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\DecValTok{3}\NormalTok{)}

\NormalTok{cluster\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##      x1    x2
##   <dbl> <dbl>
## 1    14     6
## 2     3     2
## 3     8    13
\end{verbatim}

\textbf{{[}단계 1{]} (객체의 군집 배정)} 각 객체에 대하여 \(K\)개의 군집 중심좌표(centroid)와의 거리(주로 유클리드 거리 사용)를 산출한 후 가장 가까운 군집에 그 객체를 배정한다.

\begin{equation*}
a_{ij} = \begin{cases}
1 & \text{if } j = \arg\,\max_k d(\mathbf{x}_i, \mathbf{c}_k)\\
0 & \text{otherwise}
\end{cases}, \, i = 1, \cdots, n, \, j = 1, \cdots, K
\end{equation*}

각 객체에 대하여 3개의 군집 중심좌표와의 거리를 산출해보면 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{flexclust}\SpecialCharTok{::}\FunctionTok{dist2}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], cluster\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            [,1]      [,2]      [,3]
##  [1,] 11.313708 12.369317  2.236068
##  [2,]  9.219544 12.083046  0.000000
##  [3,]  0.000000 11.704700  9.219544
##  [4,]  3.605551 10.000000  5.830952
##  [5,]  1.414214 13.000000  9.219544
##  [6,] 11.401754 13.601471  2.236068
##  [7,]  1.000000 10.770330  8.602325
##  [8,]  9.219544  2.828427  9.486833
##  [9,] 11.401754  1.000000 11.180340
## [10,] 11.704700  0.000000 12.083046
\end{verbatim}

이에 각 객체들에 대해 거리가 가장 가까운 군집에 그 객체를 배정한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{assign\_cluster }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, cluster\_df) \{}
\NormalTok{  cluster\_ind }\OtherTok{\textless{}{-}}\NormalTok{ flexclust}\SpecialCharTok{::}\FunctionTok{dist2}\NormalTok{(df, cluster\_df) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{apply}\NormalTok{(}\DecValTok{1}\NormalTok{, which.min)}
  
  \FunctionTok{map}\NormalTok{(}\FunctionTok{unique}\NormalTok{(cluster\_ind), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{which}\NormalTok{(cluster\_ind }\SpecialCharTok{==}\NormalTok{ .))}
\NormalTok{\}}

\NormalTok{cluster\_objects }\OtherTok{\textless{}{-}} \FunctionTok{assign\_cluster}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], cluster\_df)}

\NormalTok{cluster\_objects}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] 1 2 6
## 
## [[2]]
## [1] 3 4 5 7
## 
## [[3]]
## [1]  8  9 10
\end{verbatim}

\textbf{{[}단계 2{]} (군집 중심좌표의 산출)} 새로운 군집에 대한 중심좌표를 산출한다.

\begin{equation*}
\bar{x}^{(j)}_l = \frac{\sum_{i} a_{ij} x_{li}}{\sum_{i} a_{ij}}, \, l = 1, \cdots, p, \, j = 1, \cdots, K
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{find\_center }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, cluster) \{}
  \FunctionTok{map\_dfr}\NormalTok{(cluster, }\SpecialCharTok{\textasciitilde{}}\NormalTok{df[., ] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{summarize\_all}\NormalTok{(mean)) }
\NormalTok{\}}

\NormalTok{new\_cluster\_df }\OtherTok{\textless{}{-}} \FunctionTok{find\_center}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], cluster\_objects)}

\NormalTok{new\_cluster\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##      x1    x2
##   <dbl> <dbl>
## 1  7    14   
## 2 13.2   6.75
## 3  3.67  3
\end{verbatim}

\textbf{{[}단계 3{]} (수렴 조건 점검)} 새로 산출된 중심좌표값과 이전 좌표값을 비교하여 수렴 조건 내에 들면 마치며, 그렇지 않으면 단계 1을 반복한다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{identical}\NormalTok{(cluster\_df, new\_cluster\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

위의 경우, 군집 중심좌표가 다르므로 다음 iteration을 진행한다.

\hypertarget{kmeans-user-defined-functions}{%
\subsection{R 스크립트 구현}\label{kmeans-user-defined-functions}}

위의 과정을 군집해가 수렴할 때까지 반복하도록 아래와 같이 R 스크립트를 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{init\_cluster }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, }\AttributeTok{k =} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  k }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(k, }\FunctionTok{nrow}\NormalTok{(df))}
  
\NormalTok{  df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{sample\_n}\NormalTok{(k)}
\NormalTok{\}}

\NormalTok{assign\_cluster }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, cluster\_df) \{}
\NormalTok{  cluster\_ind }\OtherTok{\textless{}{-}}\NormalTok{ flexclust}\SpecialCharTok{::}\FunctionTok{dist2}\NormalTok{(df, cluster\_df) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{apply}\NormalTok{(}\DecValTok{1}\NormalTok{, which.min)}
  
  \FunctionTok{map}\NormalTok{(}\FunctionTok{unique}\NormalTok{(cluster\_ind), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{which}\NormalTok{(cluster\_ind }\SpecialCharTok{==}\NormalTok{ .))}
\NormalTok{\}}

\NormalTok{find\_center }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, cluster) \{}
  \FunctionTok{map\_dfr}\NormalTok{(cluster, }\SpecialCharTok{\textasciitilde{}}\NormalTok{df[., ] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{summarize\_all}\NormalTok{(mean)) }
\NormalTok{\}}

\NormalTok{kmeans\_cluster }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, }\AttributeTok{k =} \DecValTok{1}\NormalTok{, }\AttributeTok{verbose =} \ConstantTok{FALSE}\NormalTok{) \{}
\NormalTok{  k }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(k, }\FunctionTok{nrow}\NormalTok{(df))}
  
\NormalTok{  i }\OtherTok{\textless{}{-}}\NormalTok{ 0L}
  
  \DocumentationTok{\#\# 단계 0}
\NormalTok{  cluster\_df }\OtherTok{\textless{}{-}} \FunctionTok{init\_cluster}\NormalTok{(df, k)}
  
  \ControlFlowTok{while}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{) \{}
\NormalTok{    i }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{+}\NormalTok{ 1L}
    
    \DocumentationTok{\#\# 단계 1}
\NormalTok{    cluster\_objects }\OtherTok{\textless{}{-}} \FunctionTok{assign\_cluster}\NormalTok{(df, cluster\_df)}
    \ControlFlowTok{if}\NormalTok{ (verbose) \{ }\CommentTok{\# 군집해 출력}
      \FunctionTok{cat}\NormalTok{(}\StringTok{"Iteration"}\NormalTok{, i, }\StringTok{":"}\NormalTok{, }
          \FunctionTok{map}\NormalTok{(cluster\_objects, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{str\_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{str\_c}\NormalTok{(., }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
            \FunctionTok{str\_c}\NormalTok{(}\AttributeTok{collapse =} \StringTok{", "}\NormalTok{),}
          \StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}
\NormalTok{      )}
\NormalTok{    \}}
    
    \DocumentationTok{\#\# 단계 2}
\NormalTok{    new\_cluster\_df }\OtherTok{\textless{}{-}} \FunctionTok{find\_center}\NormalTok{(df, cluster\_objects)}

    \DocumentationTok{\#\# 단계 3}
    \ControlFlowTok{if}\NormalTok{(}\FunctionTok{identical}\NormalTok{(cluster\_df, new\_cluster\_df)) }\ControlFlowTok{break}
    
\NormalTok{    cluster\_df }\OtherTok{\textless{}{-}}\NormalTok{ new\_cluster\_df}
\NormalTok{  \}}
  
\NormalTok{  res }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{cluster\_centers =}\NormalTok{ cluster\_df,}
    \AttributeTok{assgined\_objects =}\NormalTok{ cluster\_objects,}
    \AttributeTok{n\_iteration =}\NormalTok{ i}
\NormalTok{  )}
  
  \FunctionTok{return}\NormalTok{ (res)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}

\NormalTok{kmeans\_solution }\OtherTok{\textless{}{-}} \FunctionTok{kmeans\_cluster}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{k =} \DecValTok{3}\NormalTok{, }\AttributeTok{verbose =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Iteration 1 : {1, 2, 6}, {3, 4, 5, 7}, {8, 9, 10} 
## Iteration 2 : {1, 2, 6}, {3, 4, 5, 7}, {8, 9, 10}
\end{verbatim}

위와 같이 2번째 Iteration에서 군집해가 수렴하였으며, 최종 군집해는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{kmeans\_solution}\SpecialCharTok{$}\NormalTok{assgined\_objects}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] 1 2 6
## 
## [[2]]
## [1] 3 4 5 7
## 
## [[3]]
## [1]  8  9 10
\end{verbatim}

\hypertarget{kmedoids}{%
\section{K-medoids 군집방법}\label{kmedoids}}

K-means 알고리즘에서는 각 군집의 중심좌표(centroid)를 군집 중심으로 고려하고 있는 반면, K-medoids 군집방법에서는 각 군집의 대표객체를 군집 중심으로 고려한다.

K-medoids 군집방법의 알고리즘으로 잘 알려진 것에는 다음과 같은 것들이 있다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  PAM(Partitioning Around Medoids)
\item
  CLARA(Clustering LARge Applications)
\item
  CLARANS(Clustering Large Applications based on RANdomized Search)
\item
  K-means-like 알고리즘
\end{enumerate}

\hypertarget{pam}{%
\subsection{PAM 알고리즘}\label{pam}}

PAM 알고리즘은 \citet{kaufman1990finding} 에 의하여 발표된 것으로, 초기 대표객체를 선정하는 방법인 \textbf{BUILD}와 더 나은 군집해를 찾아나가는 과정인 \textbf{SWAP}의 두 부분으로 구성되어 있다.

\hypertarget{pam-basic-script}{%
\subsubsection{기본 R 스크립트}\label{pam-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{id, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x2,}
  \DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{8}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{6}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{14}\NormalTok{, }\DecValTok{6}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{7}
\NormalTok{)}

\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}
      \StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }
      \StringTok{\textquotesingle{}사용경력($x\_1$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}사용시간($x\_2$)\textquotesingle{}}
\NormalTok{      ),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}PC 사용자 데이터\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:pam-train-data}PC 사용자 데이터}
\centering
\begin{tabular}[t]{rrr}
\toprule
객체번호 & 사용경력(\$x\_1\$) & 사용시간(\$x\_2\$)\\
\midrule
1 & 3 & 3\\
2 & 5 & 4\\
3 & 11 & 8\\
4 & 13 & 6\\
5 & 14 & 6\\
\addlinespace
6 & 15 & 7\\
\bottomrule
\end{tabular}
\end{table}

PAM 알고리즘은 \texttt{cluster} 패키지 내의 함수 \texttt{pam}을 이용하여 아래와 같이 간단하게 실행할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pam\_solution }\OtherTok{\textless{}{-}}\NormalTok{ cluster}\SpecialCharTok{::}\FunctionTok{pam}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{k =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

얻어진 \texttt{pam} 객체의 원소 \texttt{id.med}는 몇 번째 객체가 군집의 대표객체로 선정되었는지를 나타낸다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pam\_solution}\SpecialCharTok{$}\NormalTok{id.med}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2 5
\end{verbatim}

또한 \texttt{pam} 객체의 원소 \texttt{clustering}은 각 객체가 어떠한 군집에 할당되었는지를 보여준다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pam\_solution}\SpecialCharTok{$}\NormalTok{clustering}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 1 2 2 2 2
\end{verbatim}

\hypertarget{pam-algorithm}{%
\subsubsection{PAM 알고리즘}\label{pam-algorithm}}

PAM 알고리즘의 각 단계를 Table \ref{tab:pam-train-data}의 예제 데이터에 적용하여 살펴보기로 하자.

\hypertarget{pam-build}{%
\paragraph{BUILD}\label{pam-build}}

BUILD는 다음 절차들을 거쳐서 \(K\)개의 초기 대표객체를 구하는 과정이다.

\textbf{{[}단계 0{]}} 우선 각 객체별로 다른 객체 간의 거리를 구한 후, 그 합이 가장 작은 객체 하나를 대표객체로 선정한다. 선정된 대표객체집합을 \(M\)이라 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pairwise\_distance\_df }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{upper =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate\_if}\NormalTok{(is.factor, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(.)))}

\NormalTok{M\_idx }\OtherTok{\textless{}{-}}\NormalTok{ pairwise\_distance\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{sum\_distance =} \FunctionTok{sum}\NormalTok{(distance)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{top\_n}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, sum\_distance) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  .}\SpecialCharTok{$}\NormalTok{item1}

\NormalTok{M }\OtherTok{\textless{}{-}}\NormalTok{ df[M\_idx, ]}

\NormalTok{M}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
##      id    x1    x2
##   <dbl> <dbl> <dbl>
## 1     4    13     6
\end{verbatim}

\textbf{{[}단계 1{]}} 대표객체로 선정되지 않은 객체 \(j\)에 대하여, 이전에 대표객체로 선정된 객체들 중 객체 \(j\)에 가장 가까운 거리 \(D_j\)를 구한다. 즉,

\begin{equation*}
D_j = \min_{k \in M} d(j, k), \, j \notin M
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{D\_j }\OtherTok{\textless{}{-}}\NormalTok{ pairwise\_distance\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}
    \SpecialCharTok{!}\NormalTok{item1 }\SpecialCharTok{\%in\%}\NormalTok{ M}\SpecialCharTok{$}\NormalTok{id,}
\NormalTok{    item2 }\SpecialCharTok{\%in\%}\NormalTok{ M}\SpecialCharTok{$}\NormalTok{id}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{top\_n}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, distance) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{D\_j =}\NormalTok{ distance) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{item2)}

\NormalTok{D\_j}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 2
##   item1   D_j
##   <int> <dbl>
## 1     1 10.4 
## 2     2  8.25
## 3     3  2.83
## 4     5  1   
## 5     6  2.24
\end{verbatim}

그리고 대표객체로 선정되지 않은 두 객체 \(i\), \(j\)에 대하여 다음을 산출한다.

\begin{equation*}
C_{ji} = \max \left(D_j - d(j, i), 0\right)
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d\_ji }\OtherTok{\textless{}{-}}\NormalTok{ pairwise\_distance\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}
    \SpecialCharTok{!}\NormalTok{item1 }\SpecialCharTok{\%in\%}\NormalTok{ M}\SpecialCharTok{$}\NormalTok{id,}
    \SpecialCharTok{!}\NormalTok{item2 }\SpecialCharTok{\%in\%}\NormalTok{ M}\SpecialCharTok{$}\NormalTok{id}
\NormalTok{  )}

\NormalTok{C\_ji }\OtherTok{\textless{}{-}}\NormalTok{ D\_j }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(d\_ji, }\AttributeTok{by =} \StringTok{"item1"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{C\_ji =} \FunctionTok{pmax}\NormalTok{(D\_j }\SpecialCharTok{{-}}\NormalTok{ distance, }\DecValTok{0}\NormalTok{))}

\NormalTok{C\_ji}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 20 x 5
##    item1   D_j item2 distance  C_ji
##    <int> <dbl> <int>    <dbl> <dbl>
##  1     1 10.4      2     2.24 8.20 
##  2     1 10.4      3     9.43 1.01 
##  3     1 10.4      5    11.4  0    
##  4     1 10.4      6    12.6  0    
##  5     2  8.25     1     2.24 6.01 
##  6     2  8.25     3     7.21 1.04 
##  7     2  8.25     5     9.22 0    
##  8     2  8.25     6    10.4  0    
##  9     3  2.83     1     9.43 0    
## 10     3  2.83     2     7.21 0    
## 11     3  2.83     5     3.61 0    
## 12     3  2.83     6     4.12 0    
## 13     5  1        1    11.4  0    
## 14     5  1        2     9.22 0    
## 15     5  1        3     3.61 0    
## 16     5  1        6     1.41 0    
## 17     6  2.24     1    12.6  0    
## 18     6  2.24     2    10.4  0    
## 19     6  2.24     3     4.12 0    
## 20     6  2.24     5     1.41 0.822
\end{verbatim}

이는 객체 \(i\)가 추가로 대표객체가 된다고 할 때, 객체 \(j\)의 입장에서 거리 감소량이다.

\textbf{{[}단계 2{]}} 다음과 같이 거리감소량이 가장 큰 객체 \(m\)을 대표객체에 포함시키고,

\begin{equation*}
m = \arg\,\max_{i \notin M} \sum_{j \notin M} C_{ji}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m }\OtherTok{\textless{}{-}}\NormalTok{ C\_ji }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(item2) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{sum\_C\_ji =} \FunctionTok{sum}\NormalTok{(C\_ji)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{top\_n}\NormalTok{(}\DecValTok{1}\NormalTok{, sum\_C\_ji) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  .}\SpecialCharTok{$}\NormalTok{item2}

\NormalTok{m}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2
\end{verbatim}

대표객체집합을 수정한다.

\begin{equation*}
M \leftarrow M \cup \{m\}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}}\NormalTok{ M }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_rows}\NormalTok{(df[m, ])}
\end{Highlighting}
\end{Shaded}

\textbf{{[}단계 3{]}} \(K\)개의 대표객체가 선정되었으면 Stop, 그렇지 않은 경우에는 {[}단계 1{]}로 되돌아간다.

\hypertarget{pam-swap}{%
\paragraph{SWAP}\label{pam-swap}}

SWAP은 대표객체로 선정되어 있는 객체 \(i\)와 선정되지 않은 객체 \(h\)를 교환할 때 목적함수의 변화량을 산출해 더 나은 목적함수값을 찾아가는 과정이다.

\textbf{{[}단계 1{]}} 객체 \(i\)와 객체 \(h\)를 교환할 때 목적함수의 변화량을 산출하기 위하여 우선, 대표객체로 선정되지 않은 임의의 객체 \(j \neq h\)에서의 변화량을 다음과 같이 산출한다.

\begin{eqnarray*}
C_{jih} &=& \text{($i$와 $h$를 교환 후 객체 $j$와 대표객체와의 거리)}\\
 & & - \text{(교환 전 객체 $j$와 대표객체와의 거리)},\\
 & & \, (j \notin M, i \in M, h \notin M)
\end{eqnarray*}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 교환 전 각 객체와 대표 객체와의 거리}
\NormalTok{D\_j }\OtherTok{\textless{}{-}}\NormalTok{ pairwise\_distance\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}
    \SpecialCharTok{!}\NormalTok{item1 }\SpecialCharTok{\%in\%}\NormalTok{ M}\SpecialCharTok{$}\NormalTok{id,}
\NormalTok{    item2 }\SpecialCharTok{\%in\%}\NormalTok{ M}\SpecialCharTok{$}\NormalTok{id}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{top\_n}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, distance) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{j =}\NormalTok{ item1) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{item2)}

\NormalTok{D\_j}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 2
##       j distance
##   <int>    <dbl>
## 1     1     2.24
## 2     3     2.83
## 3     5     1   
## 4     6     2.24
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 교환할 객체}
\NormalTok{swap\_ids }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{i =} \FunctionTok{rep}\NormalTok{(M}\SpecialCharTok{$}\NormalTok{id, }\AttributeTok{each =} \FunctionTok{nrow}\NormalTok{(df) }\SpecialCharTok{{-}} \FunctionTok{nrow}\NormalTok{(M)),}
  \AttributeTok{h =} \FunctionTok{rep}\NormalTok{(}\FunctionTok{setdiff}\NormalTok{(df}\SpecialCharTok{$}\NormalTok{id, M}\SpecialCharTok{$}\NormalTok{id), }\FunctionTok{nrow}\NormalTok{(M))}
\NormalTok{)}

\CommentTok{\# 교환 후 각 객체와 대표 객체와의 거리}
\NormalTok{update\_distance }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(i, h, distance\_df, center\_ids) \{}
\NormalTok{  new\_center\_ids }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{setdiff}\NormalTok{(center\_ids, i), h)}

\NormalTok{  res }\OtherTok{\textless{}{-}}\NormalTok{ distance\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(}
      \SpecialCharTok{!}\NormalTok{item1 }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(center\_ids, h),}
\NormalTok{      item2 }\SpecialCharTok{\%in\%}\NormalTok{ new\_center\_ids}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{top\_n}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, distance) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{rename}\NormalTok{(}\AttributeTok{j =}\NormalTok{ item1) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{item2) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}
      \AttributeTok{i =}\NormalTok{ i,}
      \AttributeTok{h =}\NormalTok{ h}
\NormalTok{    )}
  
  \FunctionTok{return}\NormalTok{(res)}
\NormalTok{\}}

\NormalTok{D\_jih }\OtherTok{\textless{}{-}} \FunctionTok{pmap\_dfr}\NormalTok{(}
\NormalTok{  swap\_ids, }
\NormalTok{  update\_distance,}
  \AttributeTok{distance\_df =}\NormalTok{ pairwise\_distance\_df,}
  \AttributeTok{center\_ids =}\NormalTok{ M}\SpecialCharTok{$}\NormalTok{id}
\NormalTok{  )}

\NormalTok{D\_jih}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 24 x 4
##        j distance     i     h
##    <int>    <dbl> <dbl> <dbl>
##  1     3     7.21     4     1
##  2     5     9.22     4     1
##  3     6    10.4      4     1
##  4     1     2.24     4     3
##  5     5     3.61     4     3
##  6     6     4.12     4     3
##  7     1     2.24     4     5
##  8     3     3.61     4     5
##  9     6     1.41     4     5
## 10     1     2.24     4     6
## # ... with 14 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 거리의 변화량}
\NormalTok{C\_jih }\OtherTok{\textless{}{-}}\NormalTok{ D\_j }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(D\_jih, }\AttributeTok{by =} \StringTok{"j"}\NormalTok{, }\AttributeTok{suffix =} \FunctionTok{c}\NormalTok{(}\StringTok{""}\NormalTok{, }\StringTok{"\_new"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{diff\_distance =}\NormalTok{ distance\_new }\SpecialCharTok{{-}}\NormalTok{ distance)}

\NormalTok{C\_jih}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 24 x 6
##        j distance distance_new     i     h diff_distance
##    <int>    <dbl>        <dbl> <dbl> <dbl>         <dbl>
##  1     1     2.24         2.24     4     3         0    
##  2     1     2.24         2.24     4     5         0    
##  3     1     2.24         2.24     4     6         0    
##  4     1     2.24         9.43     2     3         7.20 
##  5     1     2.24        10.4      2     5         8.20 
##  6     1     2.24        10.4      2     6         8.20 
##  7     3     2.83         7.21     4     1         4.38 
##  8     3     2.83         3.61     4     5         0.777
##  9     3     2.83         4.12     4     6         1.29 
## 10     3     2.83         2.83     2     1         0    
## # ... with 14 more rows
\end{verbatim}

\textbf{{[}단계 2{]}} 대표객체 \(i\)를 \(h\)로 교환하는 경우 총 변화량은 다음과 같다.

\begin{equation*}
T_{ih} = \sum_{j} C_{jih}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{T\_ih }\OtherTok{\textless{}{-}}\NormalTok{ C\_jih }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(i, h) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{total\_diff\_distance =} \FunctionTok{sum}\NormalTok{(diff\_distance))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'i'. You can override using the `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{T\_ih}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 8 x 3
## # Groups:   i [2]
##       i     h total_diff_distance
##   <dbl> <dbl>               <dbl>
## 1     2     1              0     
## 2     2     3              7.20  
## 3     2     5              7.38  
## 4     2     6              8.20  
## 5     4     1             20.8   
## 6     4     3              4.49  
## 7     4     5             -0.0447
## 8     4     6              1.71
\end{verbatim}

이 때 \(\min_{i, h} T_{ih}\)에 대응하는 객체 \(i^*\)와 \(h^*\)를 찾아 \(T_{i^*h^*} < 0\)이면 교환한 후에 다시 {[}단계 1{]}으로 돌아가고, \(T_{i^*h^*} \geq 0\)이면 교환하지 않고 stop.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{swap\_ih }\OtherTok{\textless{}{-}}\NormalTok{ T\_ih }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(total\_diff\_distance }\SpecialCharTok{\textless{}} \DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{top\_n}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, total\_diff\_distance)}

\NormalTok{swap\_ih}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 3
## # Groups:   i [1]
##       i     h total_diff_distance
##   <dbl> <dbl>               <dbl>
## 1     4     5             -0.0447
\end{verbatim}

본 예제의 경우 객체 4 대신 객체 5가 새로운 대표객체로 선택되고, 다시 {[}단계 1{]}로 넘어간다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}}\NormalTok{ M }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{anti\_join}\NormalTok{(df[swap\_ih}\SpecialCharTok{$}\NormalTok{i, ]) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_rows}\NormalTok{(df[swap\_ih}\SpecialCharTok{$}\NormalTok{h, ])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining, by = c("id", "x1", "x2")
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 3
##      id    x1    x2
##   <dbl> <dbl> <dbl>
## 1     2     5     4
## 2     5    14     6
\end{verbatim}

SWAP 과정이 종료된 후, 최종 군집해는 각 객체를 가장 가까운 대표객체가 속한 군집에 할당함으로써 얻어진다.

\hypertarget{pam-user-defined-functions}{%
\subsubsection{R 스크립트 구현}\label{pam-user-defined-functions}}

일련의 과정을 함수로 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 각 객체로부터 가장 가까운 대표객체까지의 거리}
\NormalTok{distance\_from\_medoids }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(distance\_df, medoids\_ids) \{}
\NormalTok{  distance\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(}
      \SpecialCharTok{!}\NormalTok{item1 }\SpecialCharTok{\%in\%}\NormalTok{ medoids\_ids,}
\NormalTok{      item2 }\SpecialCharTok{\%in\%}\NormalTok{ medoids\_ids}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(distance) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{rename}\NormalTok{(}\AttributeTok{j =}\NormalTok{ item1) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{item2)}
\NormalTok{\}}

\CommentTok{\# k개의 초기 대표객체를 선정}
\NormalTok{build\_medoids }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(distance\_df, }\AttributeTok{k =}\NormalTok{ 1L) \{}
\NormalTok{  k  }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(k, }\FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(distance\_df}\SpecialCharTok{$}\NormalTok{item1)))}

  \CommentTok{\# 첫 번째 대표객체 선정}
\NormalTok{  medoids\_ids }\OtherTok{\textless{}{-}}\NormalTok{ distance\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarize}\NormalTok{(}\AttributeTok{sum\_distance =} \FunctionTok{sum}\NormalTok{(distance)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(sum\_distance) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    .}\SpecialCharTok{$}\NormalTok{item1}
  
  \ControlFlowTok{while}\NormalTok{ (}\FunctionTok{length}\NormalTok{(medoids\_ids) }\SpecialCharTok{\textless{}}\NormalTok{ k) \{}
\NormalTok{    D\_j }\OtherTok{\textless{}{-}} \FunctionTok{distance\_from\_medoids}\NormalTok{(distance\_df, medoids\_ids)}

\NormalTok{    d\_ji }\OtherTok{\textless{}{-}}\NormalTok{ distance\_df }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{filter}\NormalTok{(}
        \SpecialCharTok{!}\NormalTok{item1 }\SpecialCharTok{\%in\%}\NormalTok{ medoids\_ids,}
        \SpecialCharTok{!}\NormalTok{item2 }\SpecialCharTok{\%in\%}\NormalTok{ medoids\_ids}
\NormalTok{      ) }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{rename}\NormalTok{(}\AttributeTok{j =}\NormalTok{ item1, }\AttributeTok{i =}\NormalTok{ item2)}

    \CommentTok{\# 거리 감소량}
\NormalTok{    C\_ji }\OtherTok{\textless{}{-}}\NormalTok{ D\_j }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{inner\_join}\NormalTok{(d\_ji, }\AttributeTok{by =} \StringTok{"j"}\NormalTok{,}
                 \AttributeTok{suffix =} \FunctionTok{c}\NormalTok{(}\StringTok{""}\NormalTok{, }\StringTok{"\_new"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{mutate}\NormalTok{(}\AttributeTok{diff\_distance =} \FunctionTok{pmax}\NormalTok{(distance }\SpecialCharTok{{-}}\NormalTok{ distance\_new, }\DecValTok{0}\NormalTok{))}
    
    \CommentTok{\# 거리 감소량이 가장 큰 객체 선택}
\NormalTok{    m }\OtherTok{\textless{}{-}}\NormalTok{ C\_ji }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{group\_by}\NormalTok{(i) }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{summarize}\NormalTok{(}\AttributeTok{total\_diff\_distance =} \FunctionTok{sum}\NormalTok{(diff\_distance)) }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(total\_diff\_distance)) }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{      .}\SpecialCharTok{$}\NormalTok{i}
    
    \CommentTok{\# 대표객체에 추가}
\NormalTok{    medoids\_ids }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(medoids\_ids, m)}
\NormalTok{  \}}
  
  \FunctionTok{return}\NormalTok{(medoids\_ids)}
\NormalTok{\}}

\CommentTok{\# 교환 후 각 객체와 대표 객체와의 거리}
\NormalTok{update\_distance }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(i, h, distance\_df, medoids\_ids) \{}
\NormalTok{  new\_medoids\_ids }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{setdiff}\NormalTok{(medoids\_ids, i), h)}

\NormalTok{  res }\OtherTok{\textless{}{-}} \FunctionTok{distance\_from\_medoids}\NormalTok{(distance\_df, new\_medoids\_ids) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(j }\SpecialCharTok{!=}\NormalTok{ h) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}
      \AttributeTok{i =}\NormalTok{ i,}
      \AttributeTok{h =}\NormalTok{ h}
\NormalTok{    )}

  \FunctionTok{return}\NormalTok{(res)}
\NormalTok{\}}

\CommentTok{\# 교환할 medoid 선택}
\NormalTok{swap\_medoids }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(distance\_df, medoids\_ids) \{}
\NormalTok{  observation\_ids }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(distance\_df}\SpecialCharTok{$}\NormalTok{item1)}
  
  \CommentTok{\# 교환 전 각 객체와 대표 객체와의 거리}
\NormalTok{  D\_j }\OtherTok{\textless{}{-}} \FunctionTok{distance\_from\_medoids}\NormalTok{(distance\_df, medoids\_ids)}
  
  \CommentTok{\# 교환할 객체}
\NormalTok{  swap\_ids }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{i =} \FunctionTok{rep}\NormalTok{(medoids\_ids, }
            \AttributeTok{each =} \FunctionTok{length}\NormalTok{(observation\_ids) }\SpecialCharTok{{-}} \FunctionTok{length}\NormalTok{(medoids\_ids)),}
    \AttributeTok{h =} \FunctionTok{rep}\NormalTok{(}\FunctionTok{setdiff}\NormalTok{(observation\_ids, medoids\_ids), }
            \FunctionTok{length}\NormalTok{(medoids\_ids))}
\NormalTok{  )}
  
\NormalTok{  D\_jih }\OtherTok{\textless{}{-}} \FunctionTok{pmap\_dfr}\NormalTok{(}
\NormalTok{    swap\_ids, }
\NormalTok{    update\_distance,}
    \AttributeTok{distance\_df =}\NormalTok{ distance\_df,}
    \AttributeTok{medoids\_ids =}\NormalTok{ medoids\_ids}
\NormalTok{  )}
  
  \CommentTok{\# 거리의 변화량}
\NormalTok{  C\_jih }\OtherTok{\textless{}{-}}\NormalTok{ D\_j }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{inner\_join}\NormalTok{(D\_jih, }\AttributeTok{by =} \StringTok{"j"}\NormalTok{, }\AttributeTok{suffix =} \FunctionTok{c}\NormalTok{(}\StringTok{""}\NormalTok{, }\StringTok{"\_new"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{diff\_distance =}\NormalTok{ distance\_new }\SpecialCharTok{{-}}\NormalTok{ distance)}
  
\NormalTok{  T\_ih }\OtherTok{\textless{}{-}}\NormalTok{ C\_jih }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(i, h) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarize}\NormalTok{(}\AttributeTok{total\_diff\_distance =} \FunctionTok{sum}\NormalTok{(diff\_distance))}
  
\NormalTok{  swap\_ih }\OtherTok{\textless{}{-}}\NormalTok{ T\_ih }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(total\_diff\_distance }\SpecialCharTok{\textless{}} \DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(total\_diff\_distance) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{)}
  
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{remove =}\NormalTok{ swap\_ih}\SpecialCharTok{$}\NormalTok{i, }\AttributeTok{add =}\NormalTok{ swap\_ih}\SpecialCharTok{$}\NormalTok{h))}
\NormalTok{\}}

\CommentTok{\# 전체 PAM 알고리즘}
\NormalTok{pam\_medoids }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(distance\_df, }\AttributeTok{k =}\NormalTok{ 1L) \{}
  \CommentTok{\# BUILD}
\NormalTok{  medoids\_ids }\OtherTok{\textless{}{-}} \FunctionTok{build\_medoids}\NormalTok{(distance\_df, k)}
\NormalTok{  k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(medoids\_ids)}
  
  \CommentTok{\# SWAP}
  \ControlFlowTok{while}\NormalTok{ (}\ConstantTok{TRUE}\NormalTok{) \{}
\NormalTok{    swap\_medoids }\OtherTok{\textless{}{-}} \FunctionTok{swap\_medoids}\NormalTok{(distance\_df, medoids\_ids)}
    \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{is\_empty}\NormalTok{(swap\_medoids}\SpecialCharTok{$}\NormalTok{remove)) \{}
      \ControlFlowTok{break}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
\NormalTok{      medoids\_ids }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}
        \FunctionTok{setdiff}\NormalTok{(medoids\_ids, swap\_medoids}\SpecialCharTok{$}\NormalTok{remove),}
\NormalTok{        swap\_medoids}\SpecialCharTok{$}\NormalTok{add}
\NormalTok{      )}
\NormalTok{    \}}
\NormalTok{  \}}
  
  \FunctionTok{return}\NormalTok{ (medoids\_ids)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 구현한 함수를 이용하여 아래와 같이 PAM을 실행해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pairwise\_distance\_df }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{upper =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate\_if}\NormalTok{(is.factor, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(.)))}

\NormalTok{medoids\_ids }\OtherTok{\textless{}{-}} \FunctionTok{pam\_medoids}\NormalTok{(pairwise\_distance\_df, }\AttributeTok{k =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'i'. You can override using the `.groups` argument.
## `summarise()` has grouped output by 'i'. You can override using the `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df[medoids\_ids, ]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 3
##      id    x1    x2
##   <dbl> <dbl> <dbl>
## 1     2     5     4
## 2     5    14     6
\end{verbatim}

위와 같이 2개의 대표객체 2, 5가 선정된다.

최종 군집해는 각 객체를 가장 가까운 대표객체가 속한 군집에 할당함으로써 얻어진다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{assign\_cluster }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(distance\_df, medoids\_ids) \{}
\NormalTok{  distance\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(}
      \SpecialCharTok{!}\NormalTok{item1 }\SpecialCharTok{\%in\%}\NormalTok{ medoids\_ids,}
\NormalTok{      item2 }\SpecialCharTok{\%in\%}\NormalTok{ medoids\_ids}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(distance) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{bind\_rows}\NormalTok{(}
      \FunctionTok{tibble}\NormalTok{(}
        \AttributeTok{item1 =}\NormalTok{ medoids\_ids,}
        \AttributeTok{item2 =}\NormalTok{ medoids\_ids,}
        \AttributeTok{distance =} \DecValTok{0}
\NormalTok{      )}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{rename}\NormalTok{(}\AttributeTok{object =}\NormalTok{ item1) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(object) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(item2) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{cluster =} \FunctionTok{str\_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{str\_c}\NormalTok{(object, }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{item2)}
\NormalTok{\}}

\FunctionTok{assign\_cluster}\NormalTok{(pairwise\_distance\_df, medoids\_ids)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   object distance cluster     
##    <int>    <dbl> <chr>       
## 1      1     2.24 {1, 2}      
## 2      2     0    {1, 2}      
## 3      3     3.61 {3, 4, 5, 6}
## 4      4     1    {3, 4, 5, 6}
## 5      5     0    {3, 4, 5, 6}
## 6      6     1.41 {3, 4, 5, 6}
\end{verbatim}

\hypertarget{clara}{%
\subsection{CLARA 알고리즘}\label{clara}}

PAM 알고리즘은 SWAP 부분에서 모든 가능한 경우를 고려하기 때문에, 전체 객체 수가 많은 경우 계산 시간이 매우 길다는 단점이 있다. 이를 보완하기 위해 CLARA는 적절한 수의 객체를 샘플링한 후 이들에 대해 PAM 알고리즘을 적용하여 중심객체를 선정하는 방법이다. 이러한 샘플링을 여러 번 한 후, 이 중 가장 좋은 결과를 택하는 것인데, 반복수는 5번으로 충분한 것으로 분석되고 있다.

자세한 내용은 교재 \citep{jun2012datamining} 참조

\hypertarget{clara-basic-script}{%
\subsubsection{기본 R 스크립트}\label{clara-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clara\_solution }\OtherTok{\textless{}{-}}\NormalTok{ cluster}\SpecialCharTok{::}\FunctionTok{clara}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{k =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

얻어진 \texttt{clara} 객체의 원소 \texttt{i.med}는 몇 번째 객체가 군집의 대표객체로 선정되었는지를 나타낸다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clara\_solution}\SpecialCharTok{$}\NormalTok{i.med}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2 5
\end{verbatim}

또한 \texttt{clara} 객체의 원소 \texttt{clustering}은 각 객체가 어떠한 군집에 할당되었는지를 보여준다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clara\_solution}\SpecialCharTok{$}\NormalTok{clustering}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 1 2 2 2 2
\end{verbatim}

\hypertarget{clarans}{%
\subsection{CLARANS 알고리즘}\label{clarans}}

교재 \citep{jun2012datamining} 참조

\hypertarget{kmeans-like}{%
\subsection{K-means-like 알고리즘}\label{kmeans-like}}

본 알고리즘은 PAM 알고리즘의 단점을 보완하고자 \citet{park2009simple} 에 의해 제안된 것으로, 대표객체를 반복적으로 수정하는데 K-means 알고리즘의 작동 원리를 모방한 K-medoids 군집 방법이다. 따라서 간단하며 계산 시간이 빠른 것이 장점이라 하겠다. 이 알고리즘은 다음과 같이 3단계로 구성되어 있다. 알고리즘의 각 단계를 Table \ref{tab:pam-train-data}의 예제 데이터에 적용하여 살펴보기로 하자.

\textbf{{[}단계 1{]}} (초기 대표객체 선정) \(K\)개의 초기 대표객체를 선정하며, 각 객체를 가장 가까운 대표객체에 배정하여 초기 군집해를 얻는다.

객체들 간의 거리 \(d(i, j), \, i, j = 1, \cdots, n\)를 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pairwise\_distance\_df }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{upper =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate\_if}\NormalTok{(is.factor, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(.)))}
\end{Highlighting}
\end{Shaded}

각 객체 \(j = 1, \cdots, n\)에 대하여 다음을 산출한다.

\begin{equation*}
v_j = \sum_{i = 1}^{n} \frac{d(i, j)}{\sum_{k = 1}^{n} d(i, k)}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{v\_j }\OtherTok{\textless{}{-}}\NormalTok{ pairwise\_distance\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(item2) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{prop =}\NormalTok{ distance }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(distance)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{sum\_prop =} \FunctionTok{sum}\NormalTok{(prop)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{j =}\NormalTok{ item1)}

\NormalTok{v\_j}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##       j sum_prop
##   <int>    <dbl>
## 1     1    1.67 
## 2     2    1.33 
## 3     3    0.781
## 4     4    0.661
## 5     5    0.713
## 6     6    0.849
\end{verbatim}

이후 \(v_j\)값들을 오름차순으로 정렬하여 가장 작은 \(K\)개의 값을 초기 대표객체로 선정한다. 본 예에서는 \(K = 2\)로 가정하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{medoids\_ids }\OtherTok{\textless{}{-}}\NormalTok{ v\_j }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(sum\_prop) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  .}\SpecialCharTok{$}\NormalTok{j}

\NormalTok{medoids\_ids}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4 5
\end{verbatim}

이후 객체를 배정하여 군집해를 얻는다. 위에서 정의했던 \texttt{assign\_cluster} 함수를 재사용하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster\_solution }\OtherTok{\textless{}{-}} \FunctionTok{assign\_cluster}\NormalTok{(}
\NormalTok{  pairwise\_distance\_df, }
\NormalTok{  medoids\_ids}
\NormalTok{  )}

\NormalTok{cluster\_solution}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   object distance cluster     
##    <int>    <dbl> <chr>       
## 1      1    10.4  {1, 2, 3, 4}
## 2      2     8.25 {1, 2, 3, 4}
## 3      3     2.83 {1, 2, 3, 4}
## 4      4     0    {1, 2, 3, 4}
## 5      5     0    {5, 6}      
## 6      6     1.41 {5, 6}
\end{verbatim}

\textbf{{[}단계 2{]}} (대표객체의 수정) 현재의 군집에 배정된 객체들의 대표객체를 구하여 새로운 대표객체로 삼는다. 새로운 대표객체는 같은 군집에 배정된 다른 객체들로부터의 거리의 합이 최소가 되는 객체이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{find\_medoids }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(distance\_df, ids) \{}
\NormalTok{  distance\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(}
\NormalTok{      item1 }\SpecialCharTok{\%in\%}\NormalTok{ ids, }
\NormalTok{      item2 }\SpecialCharTok{\%in\%}\NormalTok{ ids}
\NormalTok{      ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarize}\NormalTok{(}\AttributeTok{total\_distance =} \FunctionTok{sum}\NormalTok{(distance)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(total\_distance) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    .}\SpecialCharTok{$}\NormalTok{item1}
\NormalTok{\}}

\NormalTok{cluster\_objects }\OtherTok{\textless{}{-}}\NormalTok{ cluster\_solution }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{split}\NormalTok{(.}\SpecialCharTok{$}\NormalTok{cluster) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{map}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{.}\SpecialCharTok{$}\NormalTok{object)}

\NormalTok{medoids\_ids }\OtherTok{\textless{}{-}} \FunctionTok{map\_int}\NormalTok{(}
\NormalTok{  cluster\_objects, }
\NormalTok{  find\_medoids,}
  \AttributeTok{distance\_df =}\NormalTok{ pairwise\_distance\_df}
\NormalTok{)}

\NormalTok{medoids\_ids}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## {1, 2, 3, 4}       {5, 6} 
##            2            5
\end{verbatim}

\textbf{{[}단계 3{]}} (객체의 배정) 각 객체를 가장 가까운 대표객체에 배정하여 군집해를 얻는다. 군집해가 이전과 동일하면 Stop하고, 그렇지 않으면 {[}단계 2{]}를 반복한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new\_cluster\_solution }\OtherTok{\textless{}{-}} \FunctionTok{assign\_cluster}\NormalTok{(}
\NormalTok{  pairwise\_distance\_df, }
\NormalTok{  medoids\_ids}
\NormalTok{  )}

\NormalTok{is\_converge }\OtherTok{\textless{}{-}} \FunctionTok{near}\NormalTok{(}
  \DecValTok{1}\NormalTok{, }
  \CommentTok{\# clusteval::cluster\_similarity(}
  \CommentTok{\#   as.factor(cluster\_solution$cluster),}
  \CommentTok{\#   as.factor(new\_cluster\_solution$cluster),}
  \CommentTok{\#   similarity = "rand"}
  \CommentTok{\# )}
\NormalTok{  flexclust}\SpecialCharTok{::}\FunctionTok{randIndex}\NormalTok{(}
    \FunctionTok{as.factor}\NormalTok{(cluster\_solution}\SpecialCharTok{$}\NormalTok{cluster),}
    \FunctionTok{as.factor}\NormalTok{(new\_cluster\_solution}\SpecialCharTok{$}\NormalTok{cluster)}
\NormalTok{  )}
\NormalTok{)}

\FunctionTok{print}\NormalTok{(is\_converge)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   ARI 
## FALSE
\end{verbatim}

위의 경우 첫 번째 iteration에서 군집해가 수정되었으므로 다음 iteration을 수행한다.

\hypertarget{kmeans-like-user-defined-functions}{%
\subsubsection{R 스크립트 구현}\label{kmeans-like-user-defined-functions}}

위 일련의 과정들을 수행하는 R 함수 스크립트를 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{init\_medoids }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(distance\_df, }\AttributeTok{k =} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  object\_ids }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(distance\_df}\SpecialCharTok{$}\NormalTok{item1)}
\NormalTok{  k }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(k, }\FunctionTok{length}\NormalTok{(object\_ids))}
  
\NormalTok{  v\_j }\OtherTok{\textless{}{-}}\NormalTok{ distance\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(item2) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{prop =}\NormalTok{ distance }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(distance)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarize}\NormalTok{(}\AttributeTok{sum\_prop =} \FunctionTok{sum}\NormalTok{(prop)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{rename}\NormalTok{(}\AttributeTok{j =}\NormalTok{ item1)}
  
\NormalTok{  medoids\_ids }\OtherTok{\textless{}{-}}\NormalTok{ v\_j }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(sum\_prop) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{k) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    .}\SpecialCharTok{$}\NormalTok{j}
  
  \FunctionTok{return}\NormalTok{(medoids\_ids)}
\NormalTok{\}}

\NormalTok{assign\_cluster }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(distance\_df, medoids\_ids) \{}
\NormalTok{  distance\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(}
      \SpecialCharTok{!}\NormalTok{item1 }\SpecialCharTok{\%in\%}\NormalTok{ medoids\_ids,}
\NormalTok{      item2 }\SpecialCharTok{\%in\%}\NormalTok{ medoids\_ids}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(distance) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{bind\_rows}\NormalTok{(}
      \FunctionTok{tibble}\NormalTok{(}
        \AttributeTok{item1 =}\NormalTok{ medoids\_ids,}
        \AttributeTok{item2 =}\NormalTok{ medoids\_ids,}
        \AttributeTok{distance =} \DecValTok{0}
\NormalTok{      )}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{rename}\NormalTok{(}\AttributeTok{object =}\NormalTok{ item1) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(object) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(item2) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{cluster =} \FunctionTok{str\_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{str\_c}\NormalTok{(object, }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{item2)}
\NormalTok{\}}

\NormalTok{find\_medoids }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(distance\_df, ids) \{}
\NormalTok{  distance\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(}
\NormalTok{      item1 }\SpecialCharTok{\%in\%}\NormalTok{ ids, }
\NormalTok{      item2 }\SpecialCharTok{\%in\%}\NormalTok{ ids}
\NormalTok{      ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarize}\NormalTok{(}\AttributeTok{total\_distance =} \FunctionTok{sum}\NormalTok{(distance)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{arrange}\NormalTok{(total\_distance) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    .}\SpecialCharTok{$}\NormalTok{item1}
\NormalTok{\}}

\NormalTok{kmeans\_like\_kmedoids }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(distance\_df, }\AttributeTok{k =} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  medoids\_ids }\OtherTok{\textless{}{-}} \FunctionTok{init\_medoids}\NormalTok{(distance\_df, k)}
  
  \ControlFlowTok{while}\NormalTok{ (}\ConstantTok{TRUE}\NormalTok{) \{}
\NormalTok{    cluster\_solution }\OtherTok{\textless{}{-}} \FunctionTok{assign\_cluster}\NormalTok{(distance\_df, medoids\_ids)}
    
\NormalTok{    cluster\_objects }\OtherTok{\textless{}{-}}\NormalTok{ cluster\_solution }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{split}\NormalTok{(.}\SpecialCharTok{$}\NormalTok{cluster) }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{map}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{.}\SpecialCharTok{$}\NormalTok{object)}
    
\NormalTok{    medoids\_ids }\OtherTok{\textless{}{-}} \FunctionTok{map\_int}\NormalTok{(}
\NormalTok{      cluster\_objects, }
\NormalTok{      find\_medoids,}
      \AttributeTok{distance\_df =}\NormalTok{ distance\_df}
\NormalTok{    )}
    
\NormalTok{    new\_cluster\_solution }\OtherTok{\textless{}{-}} \FunctionTok{assign\_cluster}\NormalTok{(distance\_df, medoids\_ids)}
    
\NormalTok{    is\_converge }\OtherTok{\textless{}{-}} \FunctionTok{near}\NormalTok{(}
      \DecValTok{1}\NormalTok{, }
\NormalTok{      flexclust}\SpecialCharTok{::}\FunctionTok{randIndex}\NormalTok{(}
        \FunctionTok{as.factor}\NormalTok{(cluster\_solution}\SpecialCharTok{$}\NormalTok{cluster),}
        \FunctionTok{as.factor}\NormalTok{(new\_cluster\_solution}\SpecialCharTok{$}\NormalTok{cluster)}
\NormalTok{      )}
\NormalTok{    )}
    
    \ControlFlowTok{if}\NormalTok{ (is\_converge) }\ControlFlowTok{break}
\NormalTok{  \}}
  
  \FunctionTok{return}\NormalTok{(medoids\_ids)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위에서 정의한 함수 \texttt{kmeans\_like\_kmedoids}를 Table \ref{tab:pam-train-data}의 데이터에 적용한 군집결과 및 군집 대표객체는 아래와 같이 얻어진다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pairwise\_distance\_df }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{upper =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate\_if}\NormalTok{(is.factor, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(.)))}

\NormalTok{medoids\_ids }\OtherTok{\textless{}{-}} \FunctionTok{kmeans\_like\_kmedoids}\NormalTok{(pairwise\_distance\_df, }\AttributeTok{k =} \DecValTok{2}\NormalTok{)}

\NormalTok{medoids\_ids}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##       {1, 2} {3, 4, 5, 6} 
##            1            5
\end{verbatim}

\hypertarget{fuzzy-kmeans}{%
\section{퍼지 K-means 알고리즘}\label{fuzzy-kmeans}}

이 방법은 K-means 알고리즘과 유사하나, 하나의 객체가 여러 군집에 속할 가능성을 허용하는 확률 또는 이를 확장한 퍼지(fuzzy) 개념을 도입한 것이다. 객체 \(i\)가 군집 \(j\)에 속할 확률 \(P_{ij}\)를 구하는 문제이다.

\hypertarget{fuzzy-kmeans-basic-script}{%
\subsection{기본 R 스크립트}\label{fuzzy-kmeans-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{id =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{),}
  \AttributeTok{x1 =} \FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{14}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{),}
  \AttributeTok{x2 =} \FunctionTok{c}\NormalTok{(}\DecValTok{14}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{7}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{)}

\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}
      \StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }
      \StringTok{\textquotesingle{}사용경력($x\_1$)\textquotesingle{}}\NormalTok{, }
      \StringTok{\textquotesingle{}사용시간($x\_2$)\textquotesingle{}}
\NormalTok{      ),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}PC 사용자 데이터\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:fuzzy-kmeans-data}PC 사용자 데이터}
\centering
\begin{tabular}[t]{rrr}
\toprule
객체번호 & 사용경력(\$x\_1\$) & 사용시간(\$x\_2\$)\\
\midrule
1 & 6 & 14\\
2 & 8 & 13\\
3 & 14 & 6\\
4 & 11 & 8\\
5 & 15 & 7\\
\addlinespace
6 & 7 & 15\\
7 & 13 & 6\\
8 & 5 & 4\\
9 & 3 & 3\\
10 & 3 & 2\\
\bottomrule
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster}\SpecialCharTok{::}\FunctionTok{fanny}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{k =} \DecValTok{3}\NormalTok{, }\AttributeTok{metric =} \StringTok{"SqEuclidean"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Fuzzy Clustering object of class 'fanny' :                      
## m.ship.expon.        2
## objective     18.37061
## tolerance        1e-15
## iterations          12
## converged            1
## maxit              500
## n                   10
## Membership coefficients (in %, rounded):
##       [,1] [,2] [,3]
##  [1,]   98    1    1
##  [2,]   96    3    2
##  [3,]    1   99    1
##  [4,]   12   80    8
##  [5,]    2   96    2
##  [6,]   98    1    1
##  [7,]    1   99    1
##  [8,]    3    3   94
##  [9,]    0    0   99
## [10,]    1    1   98
## Fuzzyness coefficients:
## dunn_coeff normalized 
##  0.9225653  0.8838480 
## Closest hard clustering:
##  [1] 1 1 2 2 2 1 2 3 3 3
## 
## Available components:
##  [1] "membership"  "coeff"       "memb.exp"    "clustering"  "k.crisp"    
##  [6] "objective"   "convergence" "diss"        "call"        "silinfo"    
## [11] "data"
\end{verbatim}

\hypertarget{fuzzy-kmeans-algorithm}{%
\subsection{알고리즘}\label{fuzzy-kmeans-algorithm}}

\textbf{{[}단계 0{]}} 초기 \(K\)개의 군집을 임의로 결정한다.

\begin{equation*}
P_{ij} = \begin{cases}
1 & \text{ if object $i$ belongs to cluster $j$}\\
0 & \text{ otherwise}
\end{cases}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{init\_cluster }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, }\AttributeTok{k =} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  k }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(k, }\FunctionTok{nrow}\NormalTok{(df))}
  
  \ControlFlowTok{while}\NormalTok{ (}\ConstantTok{TRUE}\NormalTok{) \{}
\NormalTok{    cluster\_ind }\OtherTok{\textless{}{-}} \FunctionTok{sample.int}\NormalTok{(k, }\AttributeTok{size =} \FunctionTok{nrow}\NormalTok{(df), }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(cluster\_ind)) }\SpecialCharTok{==}\NormalTok{ k) }\ControlFlowTok{break}
\NormalTok{  \}}
  
  \FunctionTok{map\_dfc}\NormalTok{(}\FunctionTok{unique}\NormalTok{(cluster\_ind), }\SpecialCharTok{\textasciitilde{}} \FunctionTok{as.double}\NormalTok{(cluster\_ind }\SpecialCharTok{==}\NormalTok{ .))}
\NormalTok{\}}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{4000}\NormalTok{)}

\NormalTok{cluster\_membership }\OtherTok{\textless{}{-}} \FunctionTok{init\_cluster}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{k =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * NA -> ...1
## * NA -> ...2
## * NA -> ...3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster\_membership}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 3
##     ...1  ...2  ...3
##    <dbl> <dbl> <dbl>
##  1     1     0     0
##  2     1     0     0
##  3     0     1     0
##  4     1     0     0
##  5     0     0     1
##  6     0     1     0
##  7     0     0     1
##  8     0     1     0
##  9     1     0     0
## 10     1     0     0
\end{verbatim}

\textbf{{[}단계 1{]}} 각 군집의 중심좌표를 산출한다.

\begin{equation*}
\mathbf{c}_j = \frac{\sum_{i = 1}^{n} P_{ij}^{m} \mathbf{x}_i}{\sum_{i = 1}^{n} P_{ij}^{m}}
\end{equation*}

여기에서 상수 \(m\)은 1보다 큰 값을 사용한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{find\_center }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, p, m) \{}
\NormalTok{  wt }\OtherTok{\textless{}{-}}\NormalTok{ p }\SpecialCharTok{\^{}}\NormalTok{ m}
\NormalTok{  df }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{summarize\_all}\NormalTok{(weighted.mean, }\AttributeTok{w =}\NormalTok{ wt)}
\NormalTok{\}}

\NormalTok{cluster\_df }\OtherTok{\textless{}{-}} \FunctionTok{map\_dfr}\NormalTok{(cluster\_membership, find\_center, }\AttributeTok{df =}\NormalTok{ df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{m =} \DecValTok{2}\NormalTok{)}

\NormalTok{cluster\_df}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##      x1    x2
##   <dbl> <dbl>
## 1  6.2   8   
## 2  8.67  8.33
## 3 14     6.5
\end{verbatim}

\textbf{{[}단계 2{]}} 군집 membership 계수 \(P_{ij}\)를 업데이트한다.

\begin{equation*}
P_{ij} = \frac{d(\mathbf{x}_i, \mathbf{c}_j)^{-\frac{1}{m - 1}}}{\sum_{a = 1}^{K} d(\mathbf{x}_i, \mathbf{c}_a)^{-\frac{1}{m - 1}}}
\end{equation*}

여기에서 거리함수 \(d()\)는 제곱 유클리드 거리를 사용한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{update\_membership }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, cluster\_df, m) \{}
\NormalTok{  distance\_mat }\OtherTok{\textless{}{-}}\NormalTok{ flexclust}\SpecialCharTok{::}\FunctionTok{dist2}\NormalTok{(df, cluster\_df)  }\SpecialCharTok{\^{}} \DecValTok{2}
  
\NormalTok{  p }\OtherTok{\textless{}{-}}\NormalTok{ distance\_mat }\SpecialCharTok{\^{}}\NormalTok{ (}\SpecialCharTok{{-}}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ (m }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
    \StringTok{\textasciigrave{}}\AttributeTok{/}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{rowSums}\NormalTok{(.)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{as\_tibble}\NormalTok{(}\AttributeTok{.name\_repair =} \StringTok{"minimal"}\NormalTok{)}
  
\NormalTok{  p}
\NormalTok{\}}

\FunctionTok{update\_membership}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], cluster\_df, }\AttributeTok{m =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 3
##         ``      ``    ``
##      <dbl>   <dbl> <dbl>
##  1 0.451   0.414   0.135
##  2 0.380   0.483   0.137
##  3 0.00381 0.00730 0.989
##  4 0.139   0.576   0.285
##  5 0.0152  0.0285  0.956
##  6 0.406   0.427   0.166
##  7 0.0231  0.0479  0.929
##  8 0.574   0.311   0.115
##  9 0.542   0.315   0.143
## 10 0.508   0.325   0.166
\end{verbatim}

\hypertarget{fuzzy-kmeans-script-implement}{%
\subsection{R 스크립트 구현}\label{fuzzy-kmeans-script-implement}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fuzzy\_kmeans }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, }\AttributeTok{k =} \DecValTok{1}\NormalTok{, }\AttributeTok{m =} \DecValTok{2}\NormalTok{, }\AttributeTok{max\_iter =}\NormalTok{ 1000L, }\AttributeTok{tol =} \FloatTok{1e{-}9}\NormalTok{) \{}
\NormalTok{  k }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(k, }\FunctionTok{nrow}\NormalTok{(df))}
\NormalTok{  i }\OtherTok{\textless{}{-}}\NormalTok{ 0L}
  
\NormalTok{  cluster\_membership }\OtherTok{\textless{}{-}} \FunctionTok{init\_cluster}\NormalTok{(df, k)}
  
  \ControlFlowTok{while}\NormalTok{ (i }\SpecialCharTok{\textless{}}\NormalTok{ max\_iter) \{}
\NormalTok{    i }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{+}\NormalTok{ 1L}
    
\NormalTok{    cluster\_df }\OtherTok{\textless{}{-}} \FunctionTok{map\_dfr}\NormalTok{(cluster\_membership, find\_center, }\AttributeTok{df =}\NormalTok{ df, }\AttributeTok{m =}\NormalTok{ m)}
    
\NormalTok{    new\_cluster\_membership }\OtherTok{\textless{}{-}} \FunctionTok{update\_membership}\NormalTok{(df, cluster\_df, m)}
    
    \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(cluster\_membership }\SpecialCharTok{{-}}\NormalTok{ new\_cluster\_membership)) }\SpecialCharTok{\textless{}}\NormalTok{ tol) }\ControlFlowTok{break}
    
\NormalTok{    cluster\_membership }\OtherTok{\textless{}{-}}\NormalTok{ new\_cluster\_membership}
\NormalTok{  \}}
  
\NormalTok{  res }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{n\_iteration =}\NormalTok{ i,}
    \AttributeTok{center =}\NormalTok{ cluster\_df,}
    \AttributeTok{membership =}\NormalTok{ cluster\_membership }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{as.matrix}\NormalTok{()}
\NormalTok{  )}
  
  \FunctionTok{return}\NormalTok{ (res)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{4000}\NormalTok{)}

\NormalTok{fuzzy\_kmeans\_solution }\OtherTok{\textless{}{-}} \FunctionTok{fuzzy\_kmeans}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{k =} \DecValTok{3}\NormalTok{, }\AttributeTok{m =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## New names:
## * NA -> ...1
## * NA -> ...2
## * NA -> ...3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fuzzy\_kmeans\_solution}\SpecialCharTok{$}\NormalTok{n\_iteration}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fuzzy\_kmeans\_solution}\SpecialCharTok{$}\NormalTok{center}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##      x1    x2
##   <dbl> <dbl>
## 1  3.64  2.98
## 2  7.00 14.0 
## 3 13.4   6.63
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fuzzy\_kmeans\_solution}\SpecialCharTok{$}\NormalTok{membership}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                                          
##  [1,] 0.007809655 0.983147737 0.009042608
##  [2,] 0.015726915 0.957515486 0.026757600
##  [3,] 0.006068358 0.006268614 0.987663029
##  [4,] 0.078772454 0.120672309 0.800555237
##  [5,] 0.017165082 0.022105992 0.960728926
##  [6,] 0.006532987 0.984345339 0.009121674
##  [7,] 0.005945712 0.005766360 0.988287928
##  [8,] 0.939278603 0.026072757 0.034648640
##  [9,] 0.993661877 0.002989486 0.003348637
## [10,] 0.981125198 0.008481303 0.010393499
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fuzzy\_kmeans\_solution}\SpecialCharTok{$}\NormalTok{membership }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{apply}\NormalTok{(}\DecValTok{1}\NormalTok{, which.max)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 2 2 3 3 3 2 3 1 1 1
\end{verbatim}

\hypertarget{model-based-clustering}{%
\section{모형기반 군집방법}\label{model-based-clustering}}

모형기반 군집방법(model-based clustering)에서는 각 객체가 혼합분포(mixture)를 따른다고 가정하여 객체의 군집배정변수를 통계적으로 추정하는 것이다.

\hypertarget{model-based-clustering-basic-script}{%
\subsection{기본 R script}\label{model-based-clustering-basic-script}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{id =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{7}\NormalTok{),}
  \AttributeTok{x1 =} \FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{12}\NormalTok{, }\DecValTok{12}\NormalTok{),}
  \AttributeTok{x2 =} \FunctionTok{c}\NormalTok{(}\DecValTok{12}\NormalTok{, }\DecValTok{13}\NormalTok{, }\DecValTok{15}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{)}
\NormalTok{)}

\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}
      \StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }
      \StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }
      \StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}
\NormalTok{      ),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}모형기반 군집 학습 데이터\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:model-based-clustering-data}모형기반 군집 학습 데이터}
\centering
\begin{tabular}[t]{rrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$\\
\midrule
1 & 4 & 12\\
2 & 6 & 13\\
3 & 6 & 15\\
4 & 10 & 4\\
5 & 11 & 3\\
\addlinespace
6 & 12 & 2\\
7 & 12 & 5\\
\bottomrule
\end{tabular}
\end{table}

Table \ref{tab:model-based-clustering-data}의 7개의 객체를 두 개의 군집에 배정하는 간단한 R 스크립트는 아래와 같다. 여기에서 \texttt{mclust::meVII}는 각 군집의 분산-공분산 행렬은 서로 다르되, 각 변수의 분산이 동일하며 공분산은 0이라 가정한다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1024}\NormalTok{)}

\CommentTok{\# 군집 개수}
\NormalTok{K }\OtherTok{\textless{}{-}} \DecValTok{2}

\CommentTok{\# z\_ik 값 초기화}
\NormalTok{init\_z }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{runif}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(df) }\SpecialCharTok{*}\NormalTok{ K), }\AttributeTok{ncol =}\NormalTok{ K) }\SpecialCharTok{\%\textgreater{}\%}
  \StringTok{\textasciigrave{}}\AttributeTok{/}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{apply}\NormalTok{(., }\DecValTok{1}\NormalTok{, sum))}

\CommentTok{\# EM 알고리즘 {-} 분산{-}공분산 행렬: unequal volume (V), spherical(II) }
\NormalTok{sol }\OtherTok{\textless{}{-}}\NormalTok{ mclust}\SpecialCharTok{::}\FunctionTok{meVII}\NormalTok{(}\AttributeTok{data =}\NormalTok{ df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{z =}\NormalTok{ init\_z)}

\CommentTok{\# 군집 사후확률}
\NormalTok{sol}\SpecialCharTok{$}\NormalTok{z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              [,1]         [,2]
## [1,] 7.596402e-28 1.000000e+00
## [2,] 8.254183e-27 1.000000e+00
## [3,] 9.463816e-36 1.000000e+00
## [4,] 1.000000e+00 6.832084e-20
## [5,] 1.000000e+00 1.473491e-25
## [6,] 1.000000e+00 4.876251e-31
## [7,] 1.000000e+00 1.480388e-20
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 혼합분포}
\NormalTok{sol}\SpecialCharTok{$}\NormalTok{parameters}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $pro
## [1] 0.5714286 0.4285714
## 
## $mean
##     [,1]      [,2]
## x1 11.25  5.333333
## x2  3.50 13.333333
## 
## $variance
## $variance$modelName
## [1] "VII"
## 
## $variance$d
## [1] 2
## 
## $variance$G
## [1] 2
## 
## $variance$sigma
## , , 1
## 
##         x1      x2
## x1 0.96875 0.00000
## x2 0.00000 0.96875
## 
## , , 2
## 
##          x1       x2
## x1 1.222222 0.000000
## x2 0.000000 1.222222
## 
## 
## $variance$sigmasq
## [1] 0.968750 1.222222
## 
## $variance$scale
## [1] 0.968750 1.222222
## 
## 
## $Vinv
## NULL
\end{verbatim}

\hypertarget{model-based-clustering-em}{%
\subsection{EM 알고리즘}\label{model-based-clustering-em}}

우선, 필요한 기호를 다음과 같이 정의하자.

\begin{itemize}
\tightlist
\item
  \(f_k(\mathbf{x} \, | \, \theta_k)\): 군집 \(k\)에 속하는 객체 \(\mathbf{x}\)의 확률밀도함수(\(\theta_k\)는 관련 파라미터)
\item
  \(\tau_k\): 임의의 객체가 군집 \(k\)에 속할 사전확률 (\(\tau_k \geq 0, \, \sum_{k = 1}^{K} \tau = 1\))
\end{itemize}

이 때, 임의의 객체 \(\mathbf{x}\)는 다음과 같은 혼합 확률밀도함수를 갖는다.

\begin{equation*}
f(\mathbf{x} \, | \, \boldsymbol\theta) = \sum_{k = 1}^{K} \tau_k f_k(\mathbf{x} \, | \, \theta_k)
\end{equation*}

본 장에서는 \(f_k\)가 다변량 정규분포를 나타낸다고 가정하자.

추가로, 각 객체가 속하는 군집에 대한 지시변수 \(z_{ik}\)를 아래와 같이 정의하자.

\begin{equation*}
z_{ik} = \begin{cases}
1 & \text{ if object $i$ belongs to cluster $k$} \\
0 & \text{ otherwise}
\end{cases}
\end{equation*}

이 \(z_{ik}\) 변수는 실제값이 관측되지 않는 변수이므로, 최우추정법을 이용하여 그 기대값, 즉 객체 \(i\)가 군집 \(k\)에 속할 확률을 추정한다. 보다 자세한 설명은 교재 \citep{jun2012datamining} 참조.

앞의 \ref{model-based-clustering-basic-script}장에서 수행했던 예제를 단계별로 살펴보기로 하자.

\textbf{{[}단계 0{]}} \(\hat{z}_{ik}\)를 초기화한다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1024}\NormalTok{)}

\CommentTok{\# 군집 개수}
\NormalTok{K }\OtherTok{\textless{}{-}} \DecValTok{2}

\CommentTok{\# z\_ik 추정값 초기화}
\NormalTok{z\_hat }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{runif}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(df) }\SpecialCharTok{*}\NormalTok{ K), }\AttributeTok{ncol =}\NormalTok{ K) }\SpecialCharTok{\%\textgreater{}\%}
  \StringTok{\textasciigrave{}}\AttributeTok{/}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{apply}\NormalTok{(., }\DecValTok{1}\NormalTok{, sum)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \StringTok{\textasciigrave{}}\AttributeTok{names\textless{}{-}}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{str\_c}\NormalTok{(}\StringTok{"C"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{K))}

\NormalTok{z\_hat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 7 x 2
##       C1     C2
##    <dbl>  <dbl>
## 1 0.406  0.594 
## 2 0.623  0.377 
## 3 0.372  0.628 
## 4 0.956  0.0444
## 5 0.0214 0.979 
## 6 0.681  0.319 
## 7 0.264  0.736
\end{verbatim}

\textbf{{[}단계 1{]}} (M-step) \(\hat{z}_{ik}\)를 바탕으로 파라미터를 추정한다.

우선 \(\tau_k\)와 \(\boldsymbol\mu_k\)를 다음과 같이 추정한다.

\begin{equation*}
\hat{\tau}_k = \frac{\sum_{i = 1}^{n} \hat{z}_{ik}}{n}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tau\_hat }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(z\_hat, mean)}
\NormalTok{tau\_hat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $C1
## [1] 0.4746762
## 
## $C2
## [1] 0.5253238
\end{verbatim}

\begin{equation*}
\hat{\boldsymbol\mu}_k = \frac{\sum_{i = 1}^{n} \hat{z}_{ik} \mathbf{x}_i}{\sum_{i = 1}^{n} \hat{z}_{ik}}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mu\_hat }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(z\_hat, }\SpecialCharTok{\textasciitilde{}}\FunctionTok{colSums}\NormalTok{(.}\SpecialCharTok{*}\NormalTok{df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(.))}
\NormalTok{mu\_hat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $C1
##       x1       x2 
## 8.644042 7.559792 
## 
## $C2
##       x1       x2 
## 8.777757 7.853884
\end{verbatim}

분산-공분산 행렬 \(\boldsymbol\Sigma_k\)의 추정은 분산-공분산 구조를 어떻게 가정하느냐에 따라 다르다. 우선, 일반적으로 분산-공분산 행렬 \(\boldsymbol\Sigma_k\)는 아래와 같이 decompose할 수 있다 \citep{banfield1993model}.

\begin{equation*}
\boldsymbol\Sigma_k = \lambda_k \mathbf{D}_k \mathbf{A}_k \mathbf{D}_k^\top
\end{equation*}

여기에서

\begin{itemize}
\tightlist
\item
  \(\lambda_k = \det{\boldsymbol\Sigma_k}^{1 / 2}\); 군집 \(k\)이 크기와 관련
\item
  \(\mathbf{D}_k\): matrix of eigenvectors of \(\boldsymbol\Sigma_k\); 군집 \(k\)의 방향(orientation)과 관련
\item
  \(\mathbf{A}_k\): diagonal matrix s.t. \(\det{\mathbf{A}_k} = 1\); 군집 \(k\)의 형태와 관련
\end{itemize}

이다. \(\lambda_k\), \(\mathbf{D}_k\) 및 \(\mathbf{A}_k\)에 적용되는 제약조건에 따라 분산-공분산 모형을 정의할 수 있다. 아래는 본 장에서 다룰 세 가지 모형이다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{model, }\SpecialCharTok{\textasciitilde{}}\NormalTok{sigma,}
  \StringTok{"VII"}\NormalTok{, }\StringTok{"$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{lambda\_k }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{I\}$"}\NormalTok{,}
  \StringTok{"VEI"}\NormalTok{, }\StringTok{"$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{lambda\_k }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{A\}$"}\NormalTok{,}
  \StringTok{"VEE"}\NormalTok{, }\StringTok{"$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{lambda\_k }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{D\} }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{A\} }\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{mathbf\{D\}\^{}}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{top$"}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}
      \StringTok{\textquotesingle{}분산{-}공분산 모형\textquotesingle{}}\NormalTok{, }
      \StringTok{\textquotesingle{}$}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{boldsymbol}\SpecialCharTok{\textbackslash{}\textbackslash{}}\StringTok{Sigma\_k$\textquotesingle{}}
\NormalTok{      ),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}Within{-}group 분산{-}공분산 모형\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:within-group-cov-models}Within-group 분산-공분산 모형}
\centering
\begin{tabular}[t]{cc}
\toprule
분산-공분산 모형 & \$\textbackslash{}boldsymbol\textbackslash{}Sigma\_k\$\\
\midrule
VII & \$\textbackslash{}lambda\_k \textbackslash{}mathbf\{I\}\$\\
VEI & \$\textbackslash{}lambda\_k \textbackslash{}mathbf\{A\}\$\\
VEE & \$\textbackslash{}lambda\_k \textbackslash{}mathbf\{D\} \textbackslash{}mathbf\{A\} \textbackslash{}mathbf\{D\}\textasciicircum{}\textbackslash{}top\$\\
\bottomrule
\end{tabular}
\end{table}

즉,

\begin{itemize}
\tightlist
\item
  ``VII''

  \begin{itemize}
  \tightlist
  \item
    for all \(k\),\(\mathbf{D}_k = \mathbf{I}\)
  \item
    for all \(k\), \(\mathbf{A}_k = \mathbf{I}\)
  \end{itemize}
\item
  ``VEI''

  \begin{itemize}
  \tightlist
  \item
    for all \(k\), \(\mathbf{D}_k = \mathbf{I}\)
  \item
    for all \(k\), \(\mathbf{A}_k = \mathbf{A}\)
  \end{itemize}
\item
  ``VEE''

  \begin{itemize}
  \tightlist
  \item
    for all \(k\), \(\mathbf{D}_k = \mathbf{D}\)
  \item
    for all \(k\), \(\mathbf{A}_k = \mathbf{A}\)
  \end{itemize}
\end{itemize}

\citet{celeux1995gaussian} 에 각 분산-공분산 모형에 대한 추정값을 얻는 반복적 알고리즘이 소개되어 있으며, 이는 교재 \citep{jun2012datamining}에도 설명되어 있다.

우선, 각 군집 \(k\) 내에서의 scatter matrix를 아래와 같이 계산한다.

\begin{equation*}
\mathbf{W}_k = \sum_{i = 1}^{n} \hat{z}_{ik} (\mathbf{x}_i - \hat{\boldsymbol\mu}_k)(\mathbf{x}_i - \hat{\boldsymbol\mu}_k)^\top
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{ncol}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{])}
\NormalTok{W }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(mu\_hat, }
    \SpecialCharTok{\textasciitilde{}}\FunctionTok{pmap\_dfc}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{x =}\NormalTok{ df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{mu =}\NormalTok{ .),}
             \ControlFlowTok{function}\NormalTok{(x, mu) x }\SpecialCharTok{{-}}\NormalTok{ mu)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{map}\NormalTok{(as.matrix, }\AttributeTok{nrow =}\NormalTok{ p, }\AttributeTok{ncol =}\NormalTok{ p) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{map2}\NormalTok{(z\_hat, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{t}\NormalTok{(.x) }\SpecialCharTok{\%*\%}\NormalTok{ (.y }\SpecialCharTok{*}\NormalTok{ .x))}

\NormalTok{W}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $C1
##           x1        x2
## x1  28.22794 -44.46516
## x2 -44.46516  82.36848
## 
## $C2
##           x1        x2
## x1  37.16942 -53.17491
## x2 -53.17491  92.90912
\end{verbatim}

이후 분산-공분산 모형에 따라 아래와 같이 각 군집의 분산-공분산 행렬을 추정한다.

{[}VII의 경우{]} 반복 업데이트의 과정 없이 closed-form으로 해가 존재한다.

\begin{equation*}
\lambda_k = \frac{Tr(\mathbf{W}_k)}{p \sum_{i = 1}^{n} \hat{z}_{ik}}
\end{equation*}

\begin{equation*}
\boldsymbol\Sigma_k = \lambda_k \mathbf{I}
\end{equation*}

이 때 \(p\)는 관측값의 차원수이다 (\(\mathbf{x} \in \mathbb{R}^p\)).

{[}VEI의 경우{]}

VEI-0. 행렬 \(\mathbf{B} = \mathbf{I}\)로 초기화한다.

VEI-1. \(\lambda_k\)값을 아래와 같이 계산한다.

\begin{equation*}
\lambda_k = \frac{Tr(\mathbf{W}_k \mathbf{B}^{-1})}{p \sum_{i = 1}^{n} \hat{z}_{ik}}
\end{equation*}

VEI-2. 행렬 \(\mathbf{B}\)를 아래와 같이 업데이트한다.

\begin{equation*}
\mathbf{B} = \frac{diag\left( \sum_{k = 1}^{K} \frac{\mathbf{W}_k}{\lambda_k} \right)}{\left( \det diag\left( \sum_{k = 1}^{K} \frac{\mathbf{W}_k}{\lambda_k} \right) \right)^{1 / p}}
\end{equation*}

VEI-3. 결과가 수렴하면 종료, 그렇지 않으면 VEI-1로 돌아간다. 최종 수렴한 결과를 통해 각 군집의 분산-공분산 행렬을 아래와 같이 얻는다.

\begin{equation*}
\boldsymbol\Sigma_k = \lambda_k \mathbf{B}
\end{equation*}

{[}VEE의 경우{]}

VEE-0. 행렬 \(\mathbf{C} = \mathbf{I}\)로 초기화한다.

VEE-1. \(\lambda_k\)값을 아래와 같이 계산한다.

\begin{equation*}
\lambda_k = \frac{Tr(\mathbf{W}_k \mathbf{C}^{-1})}{p \sum_{i = 1}^{n} \hat{z}_{ik}}
\end{equation*}

VEE-2. 행렬 \(\mathbf{C}\)를 아래와 같이 업데이트한다.

\begin{equation*}
\mathbf{C} = \frac{\sum_{k = 1}^{K} \frac{\mathbf{W}_k}{\lambda_k}}{\left( \det \sum_{k = 1}^{K} \frac{\mathbf{W}_k}{\lambda_k} \right)^{1 / p}}
\end{equation*}

VEE-3. 결과가 수렴하면 종료, 그렇지 않으면 VEE-1로 돌아간다. 최종 수렴한 결과를 통해 각 군집의 분산-공분산 행렬을 아래와 같이 얻는다.

\begin{equation*}
\boldsymbol\Sigma_k = \lambda_k \mathbf{C}
\end{equation*}

위 각 분산-공분산 모형을 추정 과정에 대한 설명은, 보다 일반화된 분산-공분산 구조 \(\lambda_k \mathbf{D}_k \mathbf{A}_k \mathbf{D}_k^\top\)을 추정하는 과정을 각 모형에 추가되는 제약에 따라 조금 더 단순하게 표현한 것이다. 보다 자세한 내용은 \citet{celeux1995gaussian} 참조.

아래와 같이 군집 내 분산-공분산 행렬을 추정하는 함수 \texttt{estimate\_mixture\_cov}를 구현해보자. 해당 함수는 3개의 입력변수를 사용한다.

\begin{itemize}
\tightlist
\item
  \texttt{modelName}: 분산-공분산 모형 이름. ``VII'', ``VEI'', ``VEE'' 중 하나를 선택한다.
\item
  \texttt{W}: \texttt{K}개의 scatter matrix (\(\mathbf{W}_1, \cdots, \mathbf{W}_K\))를 원소로 지니는 리스트 (\texttt{list})
\item
  \texttt{z}: \(z_{ik}\) 값을 지닌 데이터 프레임 (\texttt{data.frame}). \(n\)개의 행과 \(K\)개의 열로 이루어진다. 즉, 행은 각 관측객체를 나타내며, 열은 각 군집을 나타낸다.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{estimate\_mixture\_cov }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(modelName, W, z) \{}
\NormalTok{  K }\OtherTok{\textless{}{-}} \FunctionTok{ncol}\NormalTok{(z)}
\NormalTok{  p }\OtherTok{\textless{}{-}} \FunctionTok{ncol}\NormalTok{(W[[}\DecValTok{1}\NormalTok{]])}

  \CommentTok{\# 초기화}
\NormalTok{  D }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{diag}\NormalTok{(}\DecValTok{1}\NormalTok{, p))}
\NormalTok{  A }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{diag}\NormalTok{(}\DecValTok{1}\NormalTok{, p))}
  
\NormalTok{  get\_lambda }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(W, z, D, A, p) \{}
    \FunctionTok{pmap}\NormalTok{(}
      \FunctionTok{list}\NormalTok{(W, z, D, A),}
      \ControlFlowTok{function}\NormalTok{(W, z, D, A, p)}
        \FunctionTok{sum}\NormalTok{(}\FunctionTok{diag}\NormalTok{(W }\SpecialCharTok{\%*\%}\NormalTok{ D }\SpecialCharTok{\%*\%} \FunctionTok{solve}\NormalTok{(A) }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(D))) }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{sum}\NormalTok{(z) }\SpecialCharTok{*}\NormalTok{ p),}
      \AttributeTok{p =}\NormalTok{ p}
\NormalTok{      )}
\NormalTok{  \}}
  
\NormalTok{  objective\_value }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(W, z, lambda, D, A, p) \{}
    \FunctionTok{pmap\_dbl}\NormalTok{(}
      \FunctionTok{list}\NormalTok{(W, z, lambda, D, A),}
      \ControlFlowTok{function}\NormalTok{(W, z, lambda, D, A, p)}
        \FunctionTok{sum}\NormalTok{(}\FunctionTok{diag}\NormalTok{(W }\SpecialCharTok{\%*\%}\NormalTok{ D }\SpecialCharTok{\%*\%} \FunctionTok{solve}\NormalTok{(A) }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(D))) }\SpecialCharTok{/}\NormalTok{ lambda }\SpecialCharTok{+}
\NormalTok{        p }\SpecialCharTok{*} \FunctionTok{sum}\NormalTok{(z) }\SpecialCharTok{*} \FunctionTok{log}\NormalTok{(lambda),}
      \AttributeTok{p =}\NormalTok{ p}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
      \FunctionTok{sum}\NormalTok{()}
\NormalTok{  \}}
  
\NormalTok{  i }\OtherTok{\textless{}{-}}\NormalTok{ 0L}
\NormalTok{  obj }\OtherTok{\textless{}{-}} \ConstantTok{Inf}
  
  \ControlFlowTok{while}\NormalTok{(}\ConstantTok{TRUE}\NormalTok{) \{}
\NormalTok{    i }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{+}\NormalTok{ 1L}
    
\NormalTok{    lambda }\OtherTok{\textless{}{-}} \FunctionTok{get\_lambda}\NormalTok{(W, z, D, A, p)}
\NormalTok{    new\_obj }\OtherTok{\textless{}{-}} \FunctionTok{objective\_value}\NormalTok{(W, z, lambda, D, A, p)}
    
    \ControlFlowTok{if}\NormalTok{ (obj }\SpecialCharTok{{-}}\NormalTok{ new\_obj }\SpecialCharTok{\textless{}} \FloatTok{1e{-}9}\NormalTok{) }\ControlFlowTok{break}
    
    \ControlFlowTok{if}\NormalTok{ (modelName }\SpecialCharTok{==} \StringTok{"VII"}\NormalTok{) \{}
      
\NormalTok{    \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (modelName }\SpecialCharTok{==} \StringTok{"VEI"}\NormalTok{) \{}
\NormalTok{      B }\OtherTok{\textless{}{-}} \FunctionTok{map2}\NormalTok{(W, lambda, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{diag}\NormalTok{(.x) }\SpecialCharTok{/}\NormalTok{ .y) }\SpecialCharTok{\%\textgreater{}\%} 
        \FunctionTok{reduce}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{+}\StringTok{\textasciigrave{}}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
        \FunctionTok{diag}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
        \StringTok{\textasciigrave{}}\AttributeTok{/}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{det}\NormalTok{(.) }\SpecialCharTok{\^{}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ p))}
\NormalTok{      A }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\SpecialCharTok{\textasciitilde{}}\NormalTok{ B)}
\NormalTok{    \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (modelName }\SpecialCharTok{==} \StringTok{"VEE"}\NormalTok{) \{}
\NormalTok{      C }\OtherTok{\textless{}{-}} \FunctionTok{map2}\NormalTok{(W, lambda, }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .x }\SpecialCharTok{/}\NormalTok{ .y) }\SpecialCharTok{\%\textgreater{}\%} 
        \FunctionTok{reduce}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{+}\StringTok{\textasciigrave{}}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
        \StringTok{\textasciigrave{}}\AttributeTok{/}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{det}\NormalTok{(.) }\SpecialCharTok{\^{}}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{/}\NormalTok{ p))}
      
\NormalTok{      s }\OtherTok{\textless{}{-}} \FunctionTok{svd}\NormalTok{(C)}
\NormalTok{      A }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{diag}\NormalTok{(s}\SpecialCharTok{$}\NormalTok{d))}
\NormalTok{      D }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{K, }\SpecialCharTok{\textasciitilde{}}\NormalTok{ s}\SpecialCharTok{$}\NormalTok{u)}
\NormalTok{    \} }\ControlFlowTok{else}\NormalTok{ \{}
      \FunctionTok{stop}\NormalTok{(}\StringTok{"Model "}\NormalTok{, modelName, }\StringTok{" is not supported yet."}\NormalTok{)}
\NormalTok{    \}}
    
\NormalTok{    obj }\OtherTok{\textless{}{-}}\NormalTok{ new\_obj}
\NormalTok{  \}}

\NormalTok{  Sigma }\OtherTok{\textless{}{-}} \FunctionTok{pmap}\NormalTok{(}
    \FunctionTok{list}\NormalTok{(lambda, D, A),}
    \ControlFlowTok{function}\NormalTok{(lambda, D, A) lambda }\SpecialCharTok{*}\NormalTok{ (D }\SpecialCharTok{\%*\%}\NormalTok{ A }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(D))}
\NormalTok{    )}

  \FunctionTok{return}\NormalTok{ (}\FunctionTok{list}\NormalTok{(}
    \AttributeTok{volume =}\NormalTok{ lambda,}
    \AttributeTok{shape =}\NormalTok{ A,}
    \AttributeTok{orientation =}\NormalTok{ D,}
    \AttributeTok{Sigma =}\NormalTok{ Sigma}
\NormalTok{  ))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

초기값으로 주어진 \(\hat{z}_{ik}\) 를 이용하여 ``VII'' 구조의 분산-공분산 행렬을 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{estimate\_mixture\_cov}\NormalTok{(}\StringTok{"VII"}\NormalTok{, W, z\_hat)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $volume
## $volume$C1
## [1] 16.64239
## 
## $volume$C2
## [1] 17.68685
## 
## 
## $shape
## $shape[[1]]
##      [,1] [,2]
## [1,]    1    0
## [2,]    0    1
## 
## $shape[[2]]
##      [,1] [,2]
## [1,]    1    0
## [2,]    0    1
## 
## 
## $orientation
## $orientation[[1]]
##      [,1] [,2]
## [1,]    1    0
## [2,]    0    1
## 
## $orientation[[2]]
##      [,1] [,2]
## [1,]    1    0
## [2,]    0    1
## 
## 
## $Sigma
## $Sigma$C1
##          [,1]     [,2]
## [1,] 16.64239  0.00000
## [2,]  0.00000 16.64239
## 
## $Sigma$C2
##          [,1]     [,2]
## [1,] 17.68685  0.00000
## [2,]  0.00000 17.68685
\end{verbatim}

위 \texttt{estimate\_mixture\_cov} 함수에서 ``VII''보다 일반화된 ``VEI''와 ``VEE'' 분산-공분산 모형에 대한 추정도 구현되어 있다.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# estimate\_mixture\_cov("VEI", W, z\_hat)}
\CommentTok{\# estimate\_mixture\_cov("VEE", W, z\_hat)}
\end{Highlighting}
\end{Shaded}

위 일련의 파리미터 추정을 하나의 함수 \texttt{GMM\_Mstep}으로 아래와 같이 구성해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{GMM\_Mstep }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, z, }\AttributeTok{modelName =} \StringTok{"VII"}\NormalTok{) \{}
\NormalTok{  tau }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(z, mean)}
\NormalTok{  mu }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(z, }\SpecialCharTok{\textasciitilde{}}\FunctionTok{colSums}\NormalTok{(. }\SpecialCharTok{*}\NormalTok{ df) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(.))}
  
\NormalTok{  p }\OtherTok{\textless{}{-}} \FunctionTok{ncol}\NormalTok{(df)}
\NormalTok{  W }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(mu, }\SpecialCharTok{\textasciitilde{}}\FunctionTok{pmap\_dfc}\NormalTok{(}
    \FunctionTok{list}\NormalTok{(}\AttributeTok{x =}\NormalTok{ df, }\AttributeTok{mu =}\NormalTok{ .), }\ControlFlowTok{function}\NormalTok{(x, mu) x }\SpecialCharTok{{-}}\NormalTok{ mu)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{map}\NormalTok{(as.matrix, }\AttributeTok{nrow =}\NormalTok{ p, }\AttributeTok{ncol =}\NormalTok{ p) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{map2}\NormalTok{(z, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{t}\NormalTok{(.x) }\SpecialCharTok{\%*\%}\NormalTok{ (.y }\SpecialCharTok{*}\NormalTok{ .x))}
  
\NormalTok{  var\_cov }\OtherTok{\textless{}{-}} \FunctionTok{estimate\_mixture\_cov}\NormalTok{(modelName, W, z)}
  
\NormalTok{  res }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{tau =}\NormalTok{ tau,}
    \AttributeTok{mu =}\NormalTok{ mu,}
    \AttributeTok{Sigma =}\NormalTok{ var\_cov}\SpecialCharTok{$}\NormalTok{Sigma}
\NormalTok{  )}
  
  \FunctionTok{return}\NormalTok{ (res)}
\NormalTok{\}}

\NormalTok{Mstep\_res }\OtherTok{\textless{}{-}} \FunctionTok{GMM\_Mstep}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], z\_hat)}

\NormalTok{Mstep\_res}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $tau
## $tau$C1
## [1] 0.4746762
## 
## $tau$C2
## [1] 0.5253238
## 
## 
## $mu
## $mu$C1
##       x1       x2 
## 8.644042 7.559792 
## 
## $mu$C2
##       x1       x2 
## 8.777757 7.853884 
## 
## 
## $Sigma
## $Sigma$C1
##          [,1]     [,2]
## [1,] 16.64239  0.00000
## [2,]  0.00000 16.64239
## 
## $Sigma$C2
##          [,1]     [,2]
## [1,] 17.68685  0.00000
## [2,]  0.00000 17.68685
\end{verbatim}

\textbf{{[}단계 2{]}} (E-step) M-step에서의 파라미터 추정치를 바탕으로 \(\hat{z}_{ik}\)를 산출한다.

\begin{equation*}
\hat{z}_{ik} = \frac{\hat{\tau}_k f_k(\mathbf{x}_i \, | \, \hat{\boldsymbol{\mu}}_k, \hat{\boldsymbol{\Sigma}}_k)}{\sum_{l = 1}^{K} \hat{\tau}_l f_l(\mathbf{x}_i \, | \, \hat{\boldsymbol{\mu}}_l, \hat{\boldsymbol{\Sigma}}_l)}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{GMM\_Estep }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, tau, mu, Sigma) \{}
  \FunctionTok{pmap\_dfc}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{tau =}\NormalTok{ tau, }\AttributeTok{mu =}\NormalTok{ mu, }\AttributeTok{Sigma =}\NormalTok{ Sigma),}
       \ControlFlowTok{function}\NormalTok{(df, tau, mu, Sigma) }
\NormalTok{         tau }\SpecialCharTok{*}\NormalTok{ mvtnorm}\SpecialCharTok{::}\FunctionTok{dmvnorm}\NormalTok{(df, }\AttributeTok{mean =}\NormalTok{ mu, }\AttributeTok{sigma =}\NormalTok{ Sigma),}
       \AttributeTok{df =}\NormalTok{ df) }\SpecialCharTok{\%\textgreater{}\%}
    \StringTok{\textasciigrave{}}\AttributeTok{/}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{rowSums}\NormalTok{(.))}
\NormalTok{\}}

\NormalTok{new\_z\_hat }\OtherTok{\textless{}{-}} \FunctionTok{GMM\_Estep}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], Mstep\_res}\SpecialCharTok{$}\NormalTok{tau, Mstep\_res}\SpecialCharTok{$}\NormalTok{mu, Mstep\_res}\SpecialCharTok{$}\NormalTok{Sigma)}

\NormalTok{new\_z\_hat}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          C1        C2
## 1 0.4626878 0.5373122
## 2 0.4568716 0.5431284
## 3 0.4373551 0.5626449
## 4 0.4964082 0.5035918
## 5 0.4934276 0.5065724
## 6 0.4886741 0.5113259
## 7 0.4870085 0.5129915
\end{verbatim}

\textbf{{[}단계 3{]}} 수렴조건을 만족하면 stop, 그렇지 않으면 {[}단계 1{]}을 반복한다. 일반적으로는 우도함수값의 변화량을 수렴조건으로 사용하나, 본 장에서는 간단하게 \(z_{ik}\)값의 변화량을 기준으로 수렴을 판단하도록 하자.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(z\_hat }\SpecialCharTok{{-}}\NormalTok{ new\_z\_hat)) }\SpecialCharTok{\textless{}} \FloatTok{1e{-}9}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

위 수식의 값이 \texttt{TRUE}이면 수렴, \texttt{FALSE}이면 {[}단계 1{]}을 반복한다.

\hypertarget{model-based-clustering-script-implement}{%
\subsection{R 스크립트 구현}\label{model-based-clustering-script-implement}}

위 일련의 과정들을 포함하는 하나의 함수 \texttt{GMM\_EM}을 아래와 같이 구현해보자. 앞에서 정의했던 함수 \texttt{GMM\_Mstep} 및 \texttt{GMM\_Estep}을 재사용한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{GMM\_EM }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(df, K, }\AttributeTok{modelName =} \StringTok{"VII"}\NormalTok{, }\AttributeTok{tol =} \FloatTok{1e{-}9}\NormalTok{) \{}
\NormalTok{  K }\OtherTok{\textless{}{-}} \FunctionTok{min}\NormalTok{(K, }\FunctionTok{nrow}\NormalTok{(df))}
  
\NormalTok{  i }\OtherTok{\textless{}{-}}\NormalTok{ 0L  }
  
  \CommentTok{\# [단계 0] z\_ik 추정값 초기화}
\NormalTok{  z\_hat }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{runif}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(df) }\SpecialCharTok{*}\NormalTok{ K), }\AttributeTok{ncol =}\NormalTok{ K) }\SpecialCharTok{\%\textgreater{}\%}
    \StringTok{\textasciigrave{}}\AttributeTok{/}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{apply}\NormalTok{(., }\DecValTok{1}\NormalTok{, sum)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \StringTok{\textasciigrave{}}\AttributeTok{names\textless{}{-}}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{str\_c}\NormalTok{(}\StringTok{"C"}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\NormalTok{K))}
  
  \ControlFlowTok{while}\NormalTok{ (}\ConstantTok{TRUE}\NormalTok{) \{}
\NormalTok{    i }\OtherTok{\textless{}{-}}\NormalTok{ i }\SpecialCharTok{+}\NormalTok{ 1L}
    
    \CommentTok{\# [단계 1] M{-}step}
\NormalTok{    Mstep\_res }\OtherTok{\textless{}{-}} \FunctionTok{GMM\_Mstep}\NormalTok{(df, z\_hat, modelName)}
    
    \CommentTok{\# [단계 2] E{-}step}
\NormalTok{    new\_z\_hat }\OtherTok{\textless{}{-}} \FunctionTok{GMM\_Estep}\NormalTok{(df, Mstep\_res}\SpecialCharTok{$}\NormalTok{tau, Mstep\_res}\SpecialCharTok{$}\NormalTok{mu, Mstep\_res}\SpecialCharTok{$}\NormalTok{Sigma)}
    
    \CommentTok{\# [단계 3] 수렴조건 확인}
    \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(z\_hat }\SpecialCharTok{{-}}\NormalTok{ new\_z\_hat)) }\SpecialCharTok{\textless{}}\NormalTok{ tol) }\ControlFlowTok{break}
    
\NormalTok{    z\_hat }\OtherTok{\textless{}{-}}\NormalTok{ new\_z\_hat}
\NormalTok{  \}}
  
  \FunctionTok{return}\NormalTok{ (}\FunctionTok{list}\NormalTok{(}\AttributeTok{z =}\NormalTok{ z\_hat, }
               \AttributeTok{parameters =}\NormalTok{ Mstep\_res,}
               \AttributeTok{n\_iteration =}\NormalTok{ i))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 함수를 학습데이터 Table \ref{tab:model-based-clustering-data}에 적용한 결과는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{VII\_res }\OtherTok{\textless{}{-}} \FunctionTok{GMM\_EM}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\DecValTok{2}\NormalTok{, }\StringTok{"VII"}\NormalTok{)}

\CommentTok{\# 군집 멤버쉽}
\NormalTok{VII\_res}\SpecialCharTok{$}\NormalTok{z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             C1           C2
## 1 1.000000e+00 6.786307e-28
## 2 1.000000e+00 8.771316e-27
## 3 1.000000e+00 8.895007e-36
## 4 5.251505e-17 1.000000e+00
## 5 7.046079e-22 1.000000e+00
## 6 1.843399e-26 1.000000e+00
## 7 1.544788e-17 1.000000e+00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# 혼합분포}
\NormalTok{VII\_res}\SpecialCharTok{$}\NormalTok{parameters}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $tau
## $tau$C1
## [1] 0.4285714
## 
## $tau$C2
## [1] 0.5714286
## 
## 
## $mu
## $mu$C1
##        x1        x2 
##  5.333333 13.333333 
## 
## $mu$C2
##    x1    x2 
## 11.25  3.50 
## 
## 
## $Sigma
## $Sigma$C1
##          [,1]     [,2]
## [1,] 1.222222 0.000000
## [2,] 0.000000 1.222222
## 
## $Sigma$C2
##         [,1]    [,2]
## [1,] 0.96875 0.00000
## [2,] 0.00000 0.96875
\end{verbatim}

\hypertarget{r-packages-model-based-clustering}{%
\subsection{R 패키지 내 모형기반 군집분석}\label{r-packages-model-based-clustering}}

R 패키지 \texttt{mclust}를 통해, 위에서 살펴본 VII, VEI, VEE 외에 보다 다양한 분산-공분산 모형을 가정한 군집분석을 수행할 수 있다 \citep{scrucca2016mclust}. 다음은 ``EEI'' 구조에 대한 수행 예이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_mclust\_EEI }\OtherTok{\textless{}{-}}\NormalTok{ mclust}\SpecialCharTok{::}\FunctionTok{meEEI}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], z\_hat)}
\end{Highlighting}
\end{Shaded}

위 수행 결과 객체는 리스트 형태이며, 그 원소 중 \texttt{z}는 \(\hat{z}_{ik}\)값을, \texttt{parameters}는 혼합분포 파라미터 추정값 (\(\hat{\tau}_k\), \(\hat{\boldsymbol\mu}_k\), \(\hat{\boldsymbol\Sigma}_k\))을 나타낸다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_mclust\_EEI}\SpecialCharTok{$}\NormalTok{z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##              [,1]         [,2]
## [1,] 6.198742e-26 1.000000e+00
## [2,] 2.193775e-22 1.000000e+00
## [3,] 1.432979e-28 1.000000e+00
## [4,] 1.000000e+00 3.497777e-20
## [5,] 1.000000e+00 1.350932e-26
## [6,] 1.000000e+00 5.217649e-33
## [7,] 1.000000e+00 9.883335e-24
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_mclust\_EEI}\SpecialCharTok{$}\NormalTok{parameters}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $pro
## [1] 0.5714286 0.4285714
## 
## $mean
##     [,1]      [,2]
## x1 11.25  5.333333
## x2  3.50 13.333333
## 
## $variance
## $variance$modelName
## [1] "EEI"
## 
## $variance$d
## [1] 2
## 
## $variance$G
## [1] 2
## 
## $variance$sigma
## , , 1
## 
##           x1       x2
## x1 0.7738095 0.000000
## x2 0.0000000 1.380952
## 
## , , 2
## 
##           x1       x2
## x1 0.7738095 0.000000
## x2 0.0000000 1.380952
## 
## 
## $variance$Sigma
##           x1       x2
## x1 0.7738095 0.000000
## x2 0.0000000 1.380952
## 
## $variance$scale
## [1] 1.033728
## 
## $variance$shape
## [1] 0.7485618 1.3358950
## 
## 
## $Vinv
## NULL
\end{verbatim}

\texttt{mclust} 패키지 내의 함수 \texttt{densityMclust}는 Bayesian information criterion (BIC)을 기준으로 최적의 혼합분포를 찾는 함수이다. 즉, 내부적으로 여러가지 분산-공분산 모형과 군집 수의 조합에 대한 군집분석을 수행한 뒤, 각 조합의 최종결과에서 얻어진 BIC 값을 기준으로 최적의 조합을 선정한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_mclust\_opt }\OtherTok{\textless{}{-}}\NormalTok{ mclust}\SpecialCharTok{::}\FunctionTok{densityMclust}\NormalTok{(df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{verbose =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

함수 수행결과 객체의 \texttt{BIC} 원소가 나타내는 결과는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res\_mclust\_opt}\SpecialCharTok{$}\NormalTok{BIC}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Bayesian Information Criterion (BIC): 
##         EII       VII       EEI       VEI       EVI       VVI       EEE
## 1 -85.40006 -85.40006 -85.70851 -85.70851 -85.70851 -85.70851 -75.27433
## 2 -62.00992 -63.86240 -63.37677 -65.22485 -65.32204 -67.17013 -64.66516
## 3 -65.47796        NA -66.01911        NA        NA        NA -67.87781
## 4 -69.04346        NA -70.17240        NA        NA        NA -67.31282
## 5 -72.02226        NA -73.96817        NA        NA        NA        NA
## 6 -62.27998        NA -64.22589        NA        NA        NA        NA
## 7        NA        NA        NA        NA        NA        NA        NA
##         VEE       EVE       VVE       EEV       VEV       EVV       VVV
## 1 -75.27433 -75.27433 -75.27433 -75.27433 -75.27433 -75.27433 -75.27433
## 2 -66.60332 -65.06811 -66.92481 -65.42506 -67.34154 -66.55375 -68.44666
## 3        NA        NA        NA -71.48895        NA        NA        NA
## 4        NA        NA        NA        NA        NA        NA        NA
## 5        NA        NA        NA        NA        NA        NA        NA
## 6        NA        NA        NA        NA        NA        NA        NA
## 7        NA        NA        NA        NA        NA        NA        NA
## 
## Top 3 models based on the BIC criterion: 
##     EII,2     EII,6     EEI,2 
## -62.00992 -62.27998 -63.37677
\end{verbatim}

수행 결과 가장 큰 BIC 값을 지닌 최적의 조합은 EII 분산-공분산 모형으로 2개의 군집을 가정했을 때 얻어진다.

\texttt{densityMclust} 함수 수행 결과 얻어진 혼합분포를 plotting해보자.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(res\_mclust\_opt, }\AttributeTok{what =} \StringTok{"density"}\NormalTok{,}
     \AttributeTok{data =}\NormalTok{ df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{points.cex =} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/mclust-opt-result-plot-1} 

}

\caption{mclust::densityMclust 수행 결과 얻어진 혼합분포}\label{fig:mclust-opt-result-plot}
\end{figure}

\hypertarget{cluster-solution-evaluation}{%
\chapter{군집해의 평가 및 해석}\label{cluster-solution-evaluation}}

군집분석 수행 시에는 분류분석과 달리 각 객체가 속하는 군집에 대하여 알려진 학습표본이 없기 때문에 어떤 군집해의 성능을 평가하기가 곤란하다. 각 객체가 이차원 또는 삼차원의 변수로 이루어진 경우에는 각 객체를 좌표축에 나타내어 도식화함으로써 어느 정도 군집해의 타당성을 정성적으로 평가가 가능할 것이나, 이보다 높은 차원의 경우에는 도식화가 불가능하다. 따라서 응용분야에 따라 전문가의 견해가 군집해의 평가에 필요할 수도 있다.

\hypertarget{cluster-solution-evaluation-packages-install}{%
\section{필요 R package 설치}\label{cluster-solution-evaluation-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.3.1\\
\hline
cluster & 2.1.2\\
\hline
flexclust & 1.4-0\\
\hline
clValid & 0.7\\
\hline
\end{tabular}

\hypertarget{cluster-solution-evaluation-metric}{%
\section{군집해의 평가}\label{cluster-solution-evaluation-metric}}

군집해의 정량적인 평가척도에 대한 연구는 지속적으로 이루어지고 있으며, 크게 외부평가지수(external index)와 내부평가지수(internal index)로 구분되고 있다.

\hypertarget{cluster-evaluation-external-index}{%
\subsection{외부평가지수}\label{cluster-evaluation-external-index}}

이미 잘 알려진 군집해가 있다고 가정할 때, 새로 제안된 군집해를 기존에 알려진 군집해와 비교하는 평가척도이다.

\(n\)개의 객체에 대하여 알려진 기준 군집해를 다음과 같다고 하자.

\begin{equation*}
\mathbf{U} = \{ U_1, U_2, \cdots, U_r \}
\end{equation*}

즉, 기준 군집해 \(\mathbf{U}\)는 \(r\)개의 군집으로 구성되며, \(k\)번째 군집을 \(U_k\)로 나타낸다.

유사하게, 비교 대상의 군집해를 다음과 같이 \(s\)개의 군집으로 구성된 \(\mathbf{V}\)로 나타내자.

\begin{equation*}
\mathbf{V} = \{ V_1, V_2, \cdots, V_s \}
\end{equation*}

\hypertarget{cluster-external-index-basic-script}{%
\subsubsection{기본 R 스크립트}\label{cluster-external-index-basic-script}}

다음의 두 군집해 간의 유사도를 랜드지수 및 수정랜드지수를 이용하여 표현할 수 있다.

\begin{eqnarray*}
U &=& \{ \{1, 2, 3, 4\}, \{5, 6, 7\}, \{8, 9, 10\} \}\\
V &=& \{ \{1, 2, 5, 8\}, \{3, 6, 9\}, \{4, 7, 10\} \}
\end{eqnarray*}

랜드지수 및 수정랜드지수는 \texttt{flexclust} 패키지의 \texttt{randIndex} 함수를 호출하여 계산할 수 있으며, 랜드지수를 계산할 때는 \texttt{correct\ =\ FALSE}, 수정랜드지수를 계산할 때는 \texttt{correct\ =\ TRUE}로 파라미터 값을 지정하여야 한다. 파라미터값을 지정하지 않을 때는 기본값으로 수정랜드지수를 계산한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sol\_1 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{sol\_2 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\FunctionTok{map}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\ConstantTok{FALSE}\NormalTok{, }\ConstantTok{TRUE}\NormalTok{), }
    \SpecialCharTok{\textasciitilde{}}\NormalTok{ flexclust}\SpecialCharTok{::}\FunctionTok{randIndex}\NormalTok{(}\AttributeTok{x =}\NormalTok{ sol\_1, }\AttributeTok{y =}\NormalTok{ sol\_2, }\AttributeTok{correct =}\NormalTok{ .x))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
##        RI 
## 0.5111111 
## 
## [[2]]
##   ARI 
## -0.25
\end{verbatim}

\hypertarget{cluster-external-rand-index}{%
\subsubsection{랜드지수}\label{cluster-external-rand-index}}

두 군집해 \(U, V\) 내 에서 각 객체가 속한 군집을 나타내기 위한membership 변수를 아래와 같이 정의하자.

\begin{equation*}
u_{ik} = \begin{cases}
1 & \text{ if object $i$ belongs to cluster $U_k$, i.e. } i \in U_k \\
0 & \text{ otherwise}
\end{cases}, \, i = 1, \cdots, n, \, k = 1, \cdots, r
\end{equation*}

\begin{equation*}
v_{ik} = \begin{cases}
1 & \text{ if object $i$ belongs to cluster $V_k$, i.e. } i \in V_k \\
0 & \text{ otherwise}
\end{cases}, \, i = 1, \cdots, n, \, k = 1, \cdots, s
\end{equation*}

랜드지수를 산출하기 위해, 우선 다음과 같은 네 가지 값을 정의한다.

\begin{eqnarray*}
a &=& \sum_{i = 1}^{n - 1} \sum_{j = i + 1}^{n} \sum_{k = 1}^{r} \sum_{l = 1}^{s} u_{ik} u_{jk} v_{il} v_{jl}\\
b &=& \sum_{i = 1}^{n - 1} \sum_{j = i + 1}^{n} \sum_{k = 1}^{r} \sum_{l = 1}^{s} u_{ik} u_{jk} v_{il} (1 - v_{jl})\\
c &=& \sum_{i = 1}^{n - 1} \sum_{j = i + 1}^{n} \sum_{k = 1}^{r} \sum_{l = 1}^{s} u_{ik} (1 - u_{jk}) v_{il} v_{jl}\\
d &=& \sum_{i = 1}^{n - 1} \sum_{j = i + 1}^{n} \sum_{k = 1}^{r} \sum_{l = 1}^{s} u_{ik} (1 - u_{jk}) v_{il} (1 - v_{jl})
\end{eqnarray*}

이 때, \citet{rand1971objective} 가 제안한 랜드지수(Rand index)는 다음과 같이 정의된다.

\begin{equation}
RI = \frac{a + d}{a + b + c + d} \label{eq:rand-index}
\end{equation}

여기서, \(a + b + c + d\)는 객체 쌍의 전체 수를 의미하므로 다음과 같다.

\begin{equation*}
a + b + c + d = {n \choose 2}
\end{equation*}

식 \eqref{eq:rand-index}는 0에서 1 사이의 값을 갖게 되며, 0에 가까울수록 두 군집해가 일치하지 않음을, 1에 가까울수록 두 군집해가 일치함을 나타낸다. 또한 랜드지수는 랜덤하게 작성한 두 군집해 간의 유사도의 기대값이 0보다 크다.

\citet{hubert1985comparing} 는 수정랜드지수(adjusted Rand index)를 아래와 같이 제안하였다.

\begin{equation}
RI_{adj} = \frac{2 (ad - bc)}{(a + b)(b + d) + (a + c)(c + d)} \label{eq:adj-rand-index}
\end{equation}

식 \eqref{eq:adj-rand-index}는 랜덤한 군집해 간의 비교의 경우 0에 가까운 값을 갖는다.

아래 구현한 \texttt{rand\_index} 함수는 임의의 두 군집해 \texttt{u}와 \texttt{v}에 대한 랜드지수 및 수정랜드지수를 계산하는 함수이다.

\begin{itemize}
\tightlist
\item
  \texttt{u}, \texttt{v}: 서로 비교할 두 개의 군집해 벡터. 각 원소값은 각 객체가 속한 군집을 나타낸다.
\item
  다음과 같은 두 개의 component를 지닌 list를 리턴한다.

  \begin{itemize}
  \tightlist
  \item
    \texttt{ri}: 랜드지수
  \item
    \texttt{adj\_ri}: 수정랜드지수
  \end{itemize}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rand\_index }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(u, v) \{}
  \ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{is\_vector}\NormalTok{(u) }\SpecialCharTok{||} \SpecialCharTok{!}\FunctionTok{is\_vector}\NormalTok{(v)) \{}
    \FunctionTok{stop}\NormalTok{(}\StringTok{"Input needs to be vector"}\NormalTok{)}
\NormalTok{  \} }\ControlFlowTok{else} \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(u) }\SpecialCharTok{!=} \FunctionTok{length}\NormalTok{(v)) \{}
    \FunctionTok{stop}\NormalTok{(}\StringTok{"Vectors u and v must have the same length."}\NormalTok{)}
\NormalTok{  \}}
  
\NormalTok{  U }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{i =} \FunctionTok{seq\_along}\NormalTok{(u),}
    \AttributeTok{cluster =}\NormalTok{ u}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{inner\_join}\NormalTok{(}
      \FunctionTok{rename}\NormalTok{(., }\AttributeTok{j =}\NormalTok{ i),}
      \AttributeTok{by =} \StringTok{"cluster"}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{cluster) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(i }\SpecialCharTok{\textless{}}\NormalTok{ j) }
  
\NormalTok{  V }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{i =} \FunctionTok{seq\_along}\NormalTok{(v),}
    \AttributeTok{cluster =}\NormalTok{ v}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{inner\_join}\NormalTok{(}
      \FunctionTok{rename}\NormalTok{(., }\AttributeTok{j =}\NormalTok{ i),}
      \AttributeTok{by =} \StringTok{"cluster"}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{cluster) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(i }\SpecialCharTok{\textless{}}\NormalTok{ j) }
  
\NormalTok{  a }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(}\FunctionTok{inner\_join}\NormalTok{(U, V, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"i"}\NormalTok{, }\StringTok{"j"}\NormalTok{)))}
\NormalTok{  b }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(}\FunctionTok{anti\_join}\NormalTok{(U, V, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"i"}\NormalTok{, }\StringTok{"j"}\NormalTok{)))}
\NormalTok{  c }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(}\FunctionTok{anti\_join}\NormalTok{(V, U, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"i"}\NormalTok{, }\StringTok{"j"}\NormalTok{)))}
\NormalTok{  d }\OtherTok{\textless{}{-}} \FunctionTok{choose}\NormalTok{(}\FunctionTok{length}\NormalTok{(u), }\DecValTok{2}\NormalTok{) }\SpecialCharTok{{-}}\NormalTok{ (a }\SpecialCharTok{+}\NormalTok{ b }\SpecialCharTok{+}\NormalTok{ c)}
  
\NormalTok{  ri }\OtherTok{\textless{}{-}}\NormalTok{ (a }\SpecialCharTok{+}\NormalTok{ d) }\SpecialCharTok{/}\NormalTok{ (a }\SpecialCharTok{+}\NormalTok{ b }\SpecialCharTok{+}\NormalTok{ c }\SpecialCharTok{+}\NormalTok{ d)}
\NormalTok{  adj\_ri }\OtherTok{\textless{}{-}} \DecValTok{2} \SpecialCharTok{*}\NormalTok{ (a }\SpecialCharTok{*}\NormalTok{ d }\SpecialCharTok{{-}}\NormalTok{ b }\SpecialCharTok{*}\NormalTok{ c) }\SpecialCharTok{/} 
\NormalTok{    ((a }\SpecialCharTok{+}\NormalTok{ b) }\SpecialCharTok{*}\NormalTok{ (b }\SpecialCharTok{+}\NormalTok{ d) }\SpecialCharTok{+}\NormalTok{ (a }\SpecialCharTok{+}\NormalTok{ c) }\SpecialCharTok{*}\NormalTok{ (c }\SpecialCharTok{+}\NormalTok{ d))}

  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{ri =}\NormalTok{ ri, }\AttributeTok{adj\_ri =}\NormalTok{ adj\_ri))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

50개의 객체에 대해 랜덤하게 할당된 군집해(\texttt{K\ =\ 3}) 두 개를 비교하여 랜드지수와 수정랜드지수를 구해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{random\_rand\_index }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(n, r, s) \{}
\NormalTok{  u }\OtherTok{\textless{}{-}} \FunctionTok{sample.int}\NormalTok{(r, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{  v }\OtherTok{\textless{}{-}} \FunctionTok{sample.int}\NormalTok{(s, }\AttributeTok{size =}\NormalTok{ n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)}
  \FunctionTok{rand\_index}\NormalTok{(u, v)}
\NormalTok{\}}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{500}\NormalTok{)}

\FunctionTok{rerun}\NormalTok{(}\DecValTok{200}\NormalTok{, }\FunctionTok{random\_rand\_index}\NormalTok{(}\DecValTok{50}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_rows}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{gather}\NormalTok{(}\AttributeTok{key =} \StringTok{"metric"}\NormalTok{, }\AttributeTok{value =} \StringTok{"value"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =}\NormalTok{ value, }\AttributeTok{fill =}\NormalTok{ metric)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{binwidth =} \FloatTok{0.05}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{limits =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_discrete}\NormalTok{(}
    \AttributeTok{name =} \StringTok{"index"}\NormalTok{,}
    \AttributeTok{breaks =} \FunctionTok{c}\NormalTok{(}\StringTok{"ri"}\NormalTok{, }\StringTok{"adj\_ri"}\NormalTok{),}
    \AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"Rand Index"}\NormalTok{, }\StringTok{"adjusted Rand Index"}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}
    \AttributeTok{title =} \StringTok{"Distribution of index values from 200 random assignments"}\NormalTok{,}
    \AttributeTok{x =} \StringTok{"index value"}\NormalTok{,}
    \AttributeTok{y =} \StringTok{"frequency"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Removed 4 rows containing missing values (geom_bar).
\end{verbatim}

\begin{figure}

{\centering \includegraphics{data-mining-book_files/figure-latex/rand-index-random-1} 

}

\caption{랜덤한 군집해 간 비교: 랜드지수 및 수정랜드지수}\label{fig:rand-index-random}
\end{figure}

Figure \ref{fig:rand-index-random}에 보이듯이, 랜덤한 군집해 간 비교에서 랜드지수는 0보다 큰 값을 나타내는 반면, 수정랜드지수는 0을 중심으로 분포되어 있다.

다음의 두 군집해에 대하여 랜드지수와 수정랜드지수를 구해보자.

\begin{eqnarray*}
U &=& \{(1, 2, 3, 4), (5, 6, 7), (8, 9, 10) \}\\
V &=& \{(1, 2, 5, 8), (3, 6, 9), (4, 7, 10) \}
\end{eqnarray*}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rand\_index}\NormalTok{(}
  \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{),}
  \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $ri
## [1] 0.5111111
## 
## $adj_ri
## [1] -0.25
\end{verbatim}

\hypertarget{cluster-evaluation-internal-index}{%
\subsection{내부평가지수}\label{cluster-evaluation-internal-index}}

군집해에 대한 내부평가지수는 외부 정보의 도움 없이 입력 데이터만으로 군집해를 평가하는 척도로써, 주로 밀집성(compactness), 연결성(connectedness), 분리성(spatial separation) 등 세 가지 관점에서 평가한다.

우선 \(K\)개의 군집으로 이루어진 군집해 \(C\)가 다음과 같다고 하자.

\begin{equation*}
C = \{ C_1, C_2, \cdots, C_K \}
\end{equation*}

\hypertarget{cluster-evaluation-internal-index-basic-script}{%
\subsubsection{기본 R 스크립트}\label{cluster-evaluation-internal-index-basic-script}}

아래와 같이 두 개의 변수 \(x_1\) 및 \(x_2\)로 표현되는 객체 데이터에 대해 군집을 찾고자 한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{id, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x1, }\SpecialCharTok{\textasciitilde{}}\NormalTok{x2,}
  \DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{15}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{13}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{13}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{17}\NormalTok{, }\DecValTok{17}\NormalTok{,}
  \DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{11}\NormalTok{,}
  \DecValTok{7}\NormalTok{, }\DecValTok{19}\NormalTok{, }\DecValTok{12}\NormalTok{,}
  \DecValTok{8}\NormalTok{, }\DecValTok{18}\NormalTok{, }\DecValTok{6}
\NormalTok{)}

\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}r\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}
      \StringTok{\textquotesingle{}객체번호\textquotesingle{}}\NormalTok{, }
      \StringTok{\textquotesingle{}$x\_1$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}$x\_2$\textquotesingle{}}
\NormalTok{      ),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}군집 대상 데이터\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:cluster-eval-data}군집 대상 데이터}
\centering
\begin{tabular}[t]{rrr}
\toprule
객체번호 & \$x\_1\$ & \$x\_2\$\\
\midrule
1 & 4 & 15\\
2 & 20 & 13\\
3 & 3 & 13\\
4 & 19 & 4\\
5 & 17 & 17\\
\addlinespace
6 & 8 & 11\\
7 & 19 & 12\\
8 & 18 & 6\\
\bottomrule
\end{tabular}
\end{table}

위 데이터에 대해 다음과 같은 두 개의 다른 군집해를 얻었다고 하자.

\begin{equation}
\begin{split}
U =& \{ \{1, 3, 6\}, \{2, 5, 7\}, \{4, 8\} \}\\
V =& \{ \{1, 3, 6\}, \{2, 4, 5, 7, 8\} \}
\end{split}
\label{eq:cluster-eval-two-solutions}
\end{equation}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sol\_1 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\NormalTok{sol\_2 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

본 장에서는 4가지 내부 평가지수를 다룬다. 아래는 R 패키지들에 속한 각각의 함수를 실행하여 그 결과를 리스트 형태로 리턴하는 사용자 정의 함수 \texttt{cluster\_eval}를 구현한 것이다. 해당 함수에서 호출하는 R 패키지 함수들은 아래와 같다.

\begin{itemize}
\tightlist
\item
  Dunn index \citep{dunn1973fuzzy}: \texttt{clValid::dunn}
\item
  CH index \citep{calinski1974dendrite}: \texttt{fpc::calinhara}
\item
  Connectivity \citep{handl2005exploiting}: \texttt{clValid::connectivity}
\item
  Silhouettes \citep{rousseeuw1987silhouettes}: \texttt{cluster::silhouette}
\end{itemize}

각각의 평가지수에 대한 자세한 설명은 다음 장에서 하기로 한다.

아래 구현한 사용자 정의함수는 아래와 같은 입력 파라미터를 요구한다.

\begin{itemize}
\tightlist
\item
  \texttt{cluster}: 군집 해를 나타내는 길이 \(n\), 최대값 \(K\)의 정수형 벡터
\item
  \texttt{df}: 군집 데이터
\item
  \texttt{dist\_method}: 거리 척도; Dunn, Connectivity, Silhouettes 지수 측정에 사용된다.
\item
  \texttt{nn}: 최근 객체 수 (\textgreater= 2); Connectivity 측정에 사용된다.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cluster\_eval }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(cluster, df, }\AttributeTok{dist\_method =} \StringTok{"euclidean"}\NormalTok{, }\AttributeTok{nn =} \DecValTok{2}\NormalTok{) \{}
\NormalTok{  dunn\_index }\OtherTok{\textless{}{-}}\NormalTok{ clValid}\SpecialCharTok{::}\FunctionTok{dunn}\NormalTok{(}
    \AttributeTok{Data =}\NormalTok{ df, }
    \AttributeTok{clusters =}\NormalTok{ cluster, }
    \AttributeTok{method =}\NormalTok{ dist\_method}
\NormalTok{  )}
  
\NormalTok{  ch\_index }\OtherTok{\textless{}{-}}\NormalTok{ fpc}\SpecialCharTok{::}\FunctionTok{calinhara}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ df, }
    \AttributeTok{clustering =}\NormalTok{ cluster}
\NormalTok{  )}
  
\NormalTok{  connectivity }\OtherTok{\textless{}{-}}\NormalTok{ clValid}\SpecialCharTok{::}\FunctionTok{connectivity}\NormalTok{(}
    \AttributeTok{Data =}\NormalTok{ df, }
    \AttributeTok{clusters =}\NormalTok{ cluster, }
    \AttributeTok{neighbSize =}\NormalTok{ nn}
\NormalTok{  )}
  
\NormalTok{  asw }\OtherTok{\textless{}{-}}\NormalTok{ cluster}\SpecialCharTok{::}\FunctionTok{silhouette}\NormalTok{(}
    \AttributeTok{x =}\NormalTok{ cluster, }
    \AttributeTok{dist =} \FunctionTok{dist}\NormalTok{(df, }\AttributeTok{method =}\NormalTok{ dist\_method)}
\NormalTok{  )[, }\StringTok{"sil\_width"}\NormalTok{] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mean}\NormalTok{()}
  
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}
    \AttributeTok{dunn\_index =}\NormalTok{ dunn\_index,}
    \AttributeTok{ch\_index =}\NormalTok{ ch\_index,}
    \AttributeTok{connectivity =}\NormalTok{ connectivity,}
    \AttributeTok{asw =}\NormalTok{ asw}
\NormalTok{  ))}
\NormalTok{\}}

\FunctionTok{map\_dfr}\NormalTok{(}\FunctionTok{list}\NormalTok{(sol\_1, sol\_2), cluster\_eval, }\AttributeTok{df =}\NormalTok{ df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{.id =} \StringTok{"solution"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 5
##   solution dunn_index ch_index connectivity   asw
##   <chr>         <dbl>    <dbl>        <dbl> <dbl>
## 1 1             1.08      26.5            1 0.651
## 2 2             0.822     15.4            0 0.586
\end{verbatim}

\hypertarget{cluster-evaluation-internal-index-explanation}{%
\subsubsection{대표 내부평가지수}\label{cluster-evaluation-internal-index-explanation}}

\citet{dunn1973fuzzy} 은 아래와 같은 지수를 제안하였다.

\begin{equation}
DI = \frac{\min_{\mathbf{x} \in C_i, \, \mathbf{y} \in C_j \, 1 \leq i \neq j \leq K} d(\mathbf{x}, \mathbf{y})}{\max_{\mathbf{x} \in C_i, \mathbf{y} \in C_i, \, 1 \leq i \leq K} d(\mathbf{x}, \mathbf{y})} \label{eq:cluster-dunn-index}
\end{equation}

여기서 분자는 군집 간의 분리성(클수록 분리성이 큼), 분모는 군집의 밀집성(작을수록 밀집성이 높음)을 반영하는 것이라 볼 수 있다. 따라서 분리성과 밀집성이 높을 때 식 \eqref{eq:cluster-dunn-index}는 큰 값을 갖게 되며 해당 군집해가 상대적으로 좋게 평가된다.

군집해로부터 식 \eqref{eq:cluster-dunn-index}를 계산하는 함수 \texttt{dunn\_index}를 아래와 같이 구현해보자. 입력 파라미터는 아래와 같다.

\begin{itemize}
\tightlist
\item
  \texttt{cluster}: 각 객체가 속한 군집을 나타내는 길이 \(n\)의 벡터
\item
  \texttt{df}: 객체 데이터를 나타내는 \(n\)행의 프레임
\item
  \texttt{dist\_method}: \texttt{base::dist} 함수의 \texttt{method} 파라미터값으로 사용할 거리 척도
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dunn\_index }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(cluster, df, }\AttributeTok{dist\_method =} \StringTok{"euclidean"}\NormalTok{) \{}
  \CommentTok{\# 객체 수}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}
  
  \CommentTok{\# 각 객체의 군집해}
\NormalTok{  cluster\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{id =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{n,}
    \AttributeTok{cluster =}\NormalTok{ cluster}
\NormalTok{  )}
  
  \CommentTok{\# 각 객체 간 거리 데이터 프레임}
  \CommentTok{\# 위 군집해 데이터 프레임과 \textasciigrave{}inner\_join\textasciigrave{} 을 통해}
  \CommentTok{\# 두 객체가 동일 군집에 속하는지 서로 다른 군집에 속하는 지 표현}
\NormalTok{  dist\_df }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(df, }\AttributeTok{method =}\NormalTok{ dist\_method, }\AttributeTok{upper =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{    broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate\_if}\NormalTok{(is.factor, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(.))) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{inner\_join}\NormalTok{(}
\NormalTok{      cluster\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{rename}\NormalTok{(}\AttributeTok{item1 =}\NormalTok{ id, }\AttributeTok{item1\_cluster =}\NormalTok{ cluster),}
      \AttributeTok{by =} \StringTok{"item1"}
\NormalTok{      ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{inner\_join}\NormalTok{(}
\NormalTok{      cluster\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{rename}\NormalTok{(}\AttributeTok{item2 =}\NormalTok{ id, }\AttributeTok{item2\_cluster =}\NormalTok{ cluster),}
      \AttributeTok{by =} \StringTok{"item2"}
\NormalTok{    )}
  
  \CommentTok{\# 서로 다른 군집에 속한 객체 쌍 중}
  \CommentTok{\# 가장 가까운 객체 간의 거리}
\NormalTok{  numerator }\OtherTok{\textless{}{-}}\NormalTok{ dist\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(item1\_cluster }\SpecialCharTok{!=}\NormalTok{ item2\_cluster) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{top\_n}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, distance) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    .}\SpecialCharTok{$}\NormalTok{distance}
  
  \CommentTok{\# 서로 같은 군집에 속한 객체 쌍 중}
  \CommentTok{\# 가장 먼 객체 간의 거리}
\NormalTok{  denominator }\OtherTok{\textless{}{-}}\NormalTok{ dist\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(item1\_cluster }\SpecialCharTok{==}\NormalTok{ item2\_cluster) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{top\_n}\NormalTok{(}\DecValTok{1}\NormalTok{, distance) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    .}\SpecialCharTok{$}\NormalTok{distance}
  
\NormalTok{  res }\OtherTok{\textless{}{-}}\NormalTok{ numerator }\SpecialCharTok{/}\NormalTok{ denominator}
  
  \FunctionTok{return}\NormalTok{(res)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{map\_dbl}\NormalTok{(}\FunctionTok{list}\NormalTok{(sol\_1, sol\_2), dunn\_index, }\AttributeTok{df =}\NormalTok{ df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.075291 0.822375
\end{verbatim}

\citet{calinski1974dendrite} 는 다음과 같은 지수를 제안하였다.

\begin{equation}
CH = \frac{\frac{1}{K - 1} \sum_{k = 1}^{K} n_k (\mathbf{c}_k - \mathbf{c})^\top (\mathbf{c}_k - \mathbf{c})}{\frac{1}{n - K} \sum_{k = 1}^{K} \sum_{i \in C_k} (\mathbf{x}_i - \mathbf{c}_k)^\top (\mathbf{x}_i - \mathbf{c}_k)} \label{eq:cluster-ch-index}
\end{equation}

여기에서 \(\mathbf{c}_k\)는 군집 \(k\)의 중심좌표(centroid), \(\mathbf{c}\)는 전체 객체들의 중심좌표, \(n_k\)는 군집 \(C_k\)내의 객체 수, \(n\)은 전체 객체 수를 나타낸다. 식 \eqref{eq:cluster-ch-index} 또한 분자는 분리성, 분모는 밀집성을 평가하며, 값이 클수록 좋은 군집해로 평가된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ch\_index }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(cluster, df) \{}
  \CommentTok{\# 전체 데이터 중심}
\NormalTok{  centroid }\OtherTok{\textless{}{-}}\NormalTok{ df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{summarize\_all}\NormalTok{(mean)}
  
\NormalTok{  cluster\_df }\OtherTok{\textless{}{-}}\NormalTok{ df }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{cluster =}\NormalTok{ cluster) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(cluster) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{nest}\NormalTok{()}
  
  \CommentTok{\# 군집 중심}
\NormalTok{  cluster\_centroid\_df }\OtherTok{\textless{}{-}} \FunctionTok{map\_dfr}\NormalTok{(cluster\_df}\SpecialCharTok{$}\NormalTok{data, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{summarize\_all}\NormalTok{(., mean))}
  
  \CommentTok{\# 각 군집 중심과 전체 데이터 중심 간 제곱 유클리드 거리}
\NormalTok{  centroid\_dist }\OtherTok{\textless{}{-}}\NormalTok{ flexclust}\SpecialCharTok{::}\FunctionTok{dist2}\NormalTok{(}
\NormalTok{    cluster\_centroid\_df, }
\NormalTok{    centroid}
\NormalTok{    )}\SpecialCharTok{\^{}}\DecValTok{2}
  
  \CommentTok{\# 각 군집 크기}
\NormalTok{  cluster\_size }\OtherTok{\textless{}{-}} \FunctionTok{map\_dbl}\NormalTok{(cluster\_df}\SpecialCharTok{$}\NormalTok{data, nrow)}
  
\NormalTok{  numerator }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(centroid\_dist }\SpecialCharTok{*}\NormalTok{ cluster\_size) }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{nrow}\NormalTok{(cluster\_df) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
  
\NormalTok{  denominator }\OtherTok{\textless{}{-}} \FunctionTok{map\_dbl}\NormalTok{(}
\NormalTok{    cluster\_df}\SpecialCharTok{$}\NormalTok{data,}
    \CommentTok{\# 각 군집 내의 객체와 군집 중심 간 제곱 유클리드 거리의 합}
    \SpecialCharTok{\textasciitilde{}}\NormalTok{ flexclust}\SpecialCharTok{::}\FunctionTok{dist2}\NormalTok{(., }\FunctionTok{summarize\_all}\NormalTok{(., mean))}\SpecialCharTok{\^{}}\DecValTok{2} \SpecialCharTok{\%\textgreater{}\%} \FunctionTok{sum}\NormalTok{()}
\NormalTok{    ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{sum}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \StringTok{\textasciigrave{}}\AttributeTok{/}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(df) }\SpecialCharTok{{-}} \FunctionTok{nrow}\NormalTok{(cluster\_df))}

\NormalTok{  res }\OtherTok{\textless{}{-}}\NormalTok{ numerator }\SpecialCharTok{/}\NormalTok{ denominator}
  
  \FunctionTok{return}\NormalTok{(res)}
\NormalTok{\}}

\FunctionTok{map\_dbl}\NormalTok{(}\FunctionTok{list}\NormalTok{(sol\_1, sol\_2), ch\_index, }\AttributeTok{df =}\NormalTok{ df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 26.45029 15.36218
\end{verbatim}

\citet{handl2005exploiting} 은 연결성을 반영한 아래와 같은 지수를 제시하고 있다.

\begin{equation}
Conn = \sum_{i = 1}^{n} \sum_{j = 1}^{L} v_{i, nn_{i}(j)} \label{eq:cluster-connectivity}
\end{equation}

이 때, \(nn_{i}(j)\)는 객체 \(i\)의 \(j\)번째 최근 객체(nearest neighbor)를 나타내며, \(L\)은 연결성 척도 측정을 위한 사용자 지정 파라미터값이다. 또한 변수 \(v_{i, nn_i(j)}\)는 아래와 같이 정의된다.

\begin{equation*}
v_{i, nn_i(j)} = \begin{cases}
0 & \text{ if } \exists C_k : i, nn_i(j) \in C_k \\
1 / j & \text{ otherwise} 
\end{cases}
\end{equation*}

즉, 식 \eqref{eq:cluster-connectivity}는 각 객체가 \(j (\leq L)\)번째 최근 객체와 다른 객체에 속하면 \(1 / j\)의 벌점을 부여하는 방식으로, 작은 값일수록 좋은 군집으로 평가될 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{connectivity }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(cluster, df, }\AttributeTok{dist\_method =} \StringTok{"euclidean"}\NormalTok{, }\AttributeTok{n\_neighbor =} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}
  
\NormalTok{  cluster\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{id =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{n,}
    \AttributeTok{cluster =}\NormalTok{ cluster}
\NormalTok{  )}

  \CommentTok{\# 객체간 거리}
\NormalTok{  distance\_df }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(df, }\AttributeTok{method =}\NormalTok{ dist\_method, }\AttributeTok{upper =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate\_if}\NormalTok{(is.factor, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(.)))}
  
  \CommentTok{\# 최근 객체}
\NormalTok{  nn\_df }\OtherTok{\textless{}{-}}\NormalTok{ distance\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(item1) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{nearest =} \FunctionTok{rank}\NormalTok{(distance, }\AttributeTok{ties.method =} \StringTok{"random"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(nearest }\SpecialCharTok{\textless{}=}\NormalTok{ n\_neighbor) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{inner\_join}\NormalTok{(}
\NormalTok{      cluster\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{rename}\NormalTok{(}\AttributeTok{item1 =}\NormalTok{ id, }\AttributeTok{item1\_cluster =}\NormalTok{ cluster),}
      \AttributeTok{by =} \StringTok{"item1"}
\NormalTok{      ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{inner\_join}\NormalTok{(}
\NormalTok{      cluster\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{rename}\NormalTok{(}\AttributeTok{item2 =}\NormalTok{ id, }\AttributeTok{item2\_cluster =}\NormalTok{ cluster),}
      \AttributeTok{by =} \StringTok{"item2"}
\NormalTok{    )}
  
  \CommentTok{\# 연결성 계산}
\NormalTok{  nn\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(item1\_cluster }\SpecialCharTok{!=}\NormalTok{ item2\_cluster) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{v =} \DecValTok{1} \SpecialCharTok{/}\NormalTok{ nearest) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    .}\SpecialCharTok{$}\NormalTok{v }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{sum}\NormalTok{()}
  
\NormalTok{\}}

\FunctionTok{map\_dbl}\NormalTok{(}\FunctionTok{list}\NormalTok{(sol\_1, sol\_2), connectivity, }\AttributeTok{df =}\NormalTok{ df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{n\_neighbor =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{map\_dbl}\NormalTok{(}\FunctionTok{list}\NormalTok{(sol\_1, sol\_2), connectivity, }\AttributeTok{df =}\NormalTok{ df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{n\_neighbor =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 0
\end{verbatim}

\citet{rousseeuw1987silhouettes} 은 실루엣(silhouettes)이라는 내부평가지수를 제안하였다. 우선 다음과 같은 기호를 정의하자.

\begin{itemize}
\tightlist
\item
  \(a(i)\): 객체 \(i\)와 동일 군집에 속한 다른 객체들과의 평균 거리
\item
  \(d(i, C_k)\): 객체 \(i\)와 다른 군집 \(C_k\)에 속한 모든 객체들과의 평균 거리, \(i \notin C_k\)
\item
  \(b(i) = \min_{k: i \notin C_k} d(i, C_k)\)
\end{itemize}

객체의 군집 멤버쉽 변수 \(z_{ik}\)를

\begin{equation*}
z_{ik} = \begin{cases}
1 & \text{ if } i \in C_k\\
0 & \text{ otherwise }
\end{cases}
\end{equation*}

라 정의하면, 위 \(a(i)\)와 \(b(i)\)를 아래와 같이 수식화할 수 있다.

\begin{eqnarray*}
a(i) &=& \sum_{k = 1}^{K} z_{ik} \frac{\sum_{j \neq i} z_{jk} d(\mathbf{x}_i, \mathbf{x}_j)}{\sum_{j \neq i} z_{jk}}\\
b(i) &=& \max_{k: z_{ik} \neq 1} \frac{\sum_{j \neq i} z_{jk} d(\mathbf{x}_i, \mathbf{x}_j)}{\sum_{j \neq i} z_{jk}}
\end{eqnarray*}

이 때 객체 \(i\)에 대한 실루엣은 아래와 같이 정의된다.

\begin{equation}
s(i) = \frac{b(i) - a(i)}{\max \{ a(i), b(i) \}} \label{eq:cluster-silhouette}
\end{equation}

식 \eqref{eq:cluster-silhouette}은 -1과 1 사이의 값을 갖는데, 1에 가까울수록 객체 \(i\)가 비슷한 객체들과 군집된 것으로, -1에 가까울수록 먼 객체들과 군집된 것으로 판단할 수 있다.

객체 \(i\)가 어떠한 다른 객체와도 같은 군집에 속하지 않는 경우가 발생할 수 있다 (\(i \in C_k, \, \left| C_k \right| = 1\)). 이 경우 \(a(i)\)가 정의되지 않으므로 \(s(i)\)값이 식 \eqref{eq:cluster-silhouette}에 의해서 정의되지 않는다. 이러한 경우에는 \(s(i) = 0\)이라고 실루엣을 정의한다.

\begin{equation}
s(i) = \begin{cases}
\frac{b(i) - a(i)}{\max \{ a(i), b(i) \}} & \text{ if $a(i)$ is defined}\\
0 & \text{ otherwise }
\end{cases}
\label{eq:cluster-silhouette-single}
\end{equation}

이후 군집해의 평가지표로써 평균실루엣(overall average silhouette width; ASW)을 다음과 같이 정의하여 사용한다.

\begin{equation}
ASW = \frac{1}{n} \sum_{i = 1}^{n} s(i) \label{eq:cluster-average-silhouette}
\end{equation}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{asw }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(cluster, df, }\AttributeTok{dist\_method =} \StringTok{"euclidean"}\NormalTok{) \{}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(df)}
  
\NormalTok{  cluster\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
    \AttributeTok{id =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{n,}
    \AttributeTok{cluster =}\NormalTok{ cluster}
\NormalTok{  )}
  
\NormalTok{  dist\_df }\OtherTok{\textless{}{-}} \FunctionTok{dist}\NormalTok{(df, }\AttributeTok{method =}\NormalTok{ dist\_method, }\AttributeTok{upper =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
\NormalTok{    broom}\SpecialCharTok{::}\FunctionTok{tidy}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate\_if}\NormalTok{(is.factor, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{as.integer}\NormalTok{(}\FunctionTok{as.character}\NormalTok{(.))) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{inner\_join}\NormalTok{(}
\NormalTok{      cluster\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{rename}\NormalTok{(}\AttributeTok{item1 =}\NormalTok{ id, }\AttributeTok{item1\_cluster =}\NormalTok{ cluster),}
      \AttributeTok{by =} \StringTok{"item1"}
\NormalTok{      ) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{inner\_join}\NormalTok{(}
\NormalTok{      cluster\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{rename}\NormalTok{(}\AttributeTok{item2 =}\NormalTok{ id, }\AttributeTok{item2\_cluster =}\NormalTok{ cluster),}
      \AttributeTok{by =} \StringTok{"item2"}
\NormalTok{    )}
  
\NormalTok{  dist\_df }\OtherTok{\textless{}{-}}\NormalTok{ dist\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{group\_by}\NormalTok{(item1, item1\_cluster, item2\_cluster) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarize}\NormalTok{(}
      \AttributeTok{avg\_distance =} \FunctionTok{mean}\NormalTok{(distance)}
\NormalTok{    )}
  
\NormalTok{  a }\OtherTok{\textless{}{-}}\NormalTok{ dist\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(item1\_cluster }\SpecialCharTok{==}\NormalTok{ item2\_cluster) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    .}\SpecialCharTok{$}\NormalTok{avg\_distance}
  
\NormalTok{  b }\OtherTok{\textless{}{-}}\NormalTok{ dist\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{filter}\NormalTok{(item1\_cluster }\SpecialCharTok{!=}\NormalTok{ item2\_cluster) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{top\_n}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{, avg\_distance) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    .}\SpecialCharTok{$}\NormalTok{avg\_distance}
  
\NormalTok{  s }\OtherTok{\textless{}{-}} \FunctionTok{map2\_dbl}\NormalTok{(a, b, }\SpecialCharTok{\textasciitilde{}}\NormalTok{ (.y }\SpecialCharTok{{-}}\NormalTok{ .x) }\SpecialCharTok{/} \FunctionTok{max}\NormalTok{(.x, .y))}
  
  \FunctionTok{mean}\NormalTok{(s)}
\NormalTok{\}}

\FunctionTok{map\_dbl}\NormalTok{(}\FunctionTok{list}\NormalTok{(sol\_1, sol\_2), asw, }\AttributeTok{df =}\NormalTok{ df[, }\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{], }\AttributeTok{dist\_method =} \StringTok{"euclidean"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'item1', 'item1_cluster'. You can override using the `.groups` argument.
## `summarise()` has grouped output by 'item1', 'item1_cluster'. You can override using the `.groups` argument.
\end{verbatim}

\begin{verbatim}
## [1] 0.6507364 0.5864226
\end{verbatim}

\hypertarget{cluster-solution-interpretation}{%
\section{군집해의 해석}\label{cluster-solution-interpretation}}

군집분석의 주목적을 달성하기 위해서는 군집해를 얻은 후 이에 대한 해석이 가능하여야 할 것이다. 즉, 각 군집의 특성을 파악할 수 있어야 실제 문제에 적용할 수 있을 것이다. 이를 위해서는 특정 응용분야의 전문가 지식을 요하는 경우가 많다. 그러나 첫 출발은 각 군집의 중심좌표, 즉 군집 별 변수별 평균치를 산출하는 것이다. 대부분의 경우 변수별 평균치로 군집들을 비교함으로써 군집의 특성을 파악할 수 있다. 다변량을 처리할 수 있는 그래프 역시 도움이 되며, 특히 다변량인 경우 요인분석(factor analysis)를 활용하기도 한다. 최종적으로 각 군집에 대한 특성이 파악되면 명명(naming)하는 것이 추천된다.

\hypertarget{part-4uxbd80---uxc5f0uxad00uxaddcuxce59}{%
\part{4부 - 연관규칙}\label{part-4uxbd80---uxc5f0uxad00uxaddcuxce59}}

\hypertarget{association-rule}{%
\chapter{연관규칙}\label{association-rule}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

연관규칙(association rule)이란 간단히 말하면 항목들 간의 조건-결과 식으로 표현되는 유용한 패턴을 말한다. 연관규칙 탐사는 기업의 활동, 특히 마케팅에서 가장 널리 사용되고 있다.

\hypertarget{association-packages-install}{%
\section{필요 R package 설치}\label{association-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.3.1\\
\hline
arules & 1.6-8\\
\hline
\end{tabular}

\hypertarget{association-rule-definition-metric}{%
\section{연관규칙의 정의 및 성능척도}\label{association-rule-definition-metric}}

데이터베이스가 총 \(n\)개의 트랜잭션 데이터로 구성되며, 전체 \(m\)개의 항목을 포함한다 하자. 전체 항목집합 \(I\)를 다음과 같이 정의하자.

\begin{equation*}
I = \{ i_1, \cdots, i_m \}
\end{equation*}

이 때, 각 트랜잭션 \(Z_j\)는 \(I\)의 부분집합이 된다.

\begin{equation*}
Z_j \subseteq I, \, j = 1, \cdots, n
\end{equation*}

연관규칙 \(R\)은 조건부 \(X\)와 결과부 \(Y\)로 구성되어 (\(X, Y \subseteq I\), \(X \cap Y = \emptyset\)) ``\(X\)가 일어나면 \(Y\)도 일어난다''는 의미로 아래와 같이 표현된다.

\begin{equation}
R: X \Rightarrow Y \label{eq:association-rule}
\end{equation}

식 \eqref{eq:association-rule}의 연관규칙 \(R\)에 대한 성능척도로 지지도(support), 신뢰도(confidence) 및 개선도(lift)가 널리 사용된다.

\hypertarget{association-rule-support}{%
\subsection{지지도}\label{association-rule-support}}

지지도는 전체 트랜잭션 중 관심있는 항목집합을 포함하는 트랜잭션의 비율을 나타낸다.

항목 \(X \subseteq I\)에 대한 지지도는 아래와 같이 계산된다.

\begin{equation*}
supp(X) = \frac{1}{n} \sum_{j = 1}^{n} \mathbb{I}(X \subseteq Z_j)
\end{equation*}

이 때, \(\mathbb{I}(a)\)는 지시함수로 \(a\)가 참일 때 1, 거짓일 때 0의 함수값을 가진다.

식 \eqref{eq:association-rule}의 연관규칙 \(R\)에 대한 지지도는 아래와 같이 정의된다.

\begin{equation*}
supp(R) = supp(X \cup Y)
\end{equation*}

다음과 같은 5개의 트랜잭션을 고려해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{transaction\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{transaction\_id, }\SpecialCharTok{\textasciitilde{}}\NormalTok{item,}
  \DecValTok{1}\NormalTok{, }\StringTok{"b"}\NormalTok{,}
  \DecValTok{1}\NormalTok{, }\StringTok{"c"}\NormalTok{,}
  \DecValTok{1}\NormalTok{, }\StringTok{"g"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\StringTok{"a"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\StringTok{"b"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\StringTok{"d"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\StringTok{"e"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\StringTok{"f"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\StringTok{"a"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\StringTok{"b"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\StringTok{"c"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\StringTok{"g"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\StringTok{"b"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\StringTok{"c"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\StringTok{"e"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\StringTok{"f"}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\StringTok{"b"}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\StringTok{"c"}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\StringTok{"e"}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\StringTok{"f"}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\StringTok{"g"}
\NormalTok{)}

\NormalTok{transaction\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(transaction\_id) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{items =} \FunctionTok{str\_c}\NormalTok{(item, }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}트랜잭션\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}항목\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}트랜잭션 데이터\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:transaction-data}트랜잭션 데이터}
\centering
\begin{tabular}[t]{cc}
\toprule
트랜잭션 & 항목\\
\midrule
1 & b, c, g\\
2 & a, b, d, e, f\\
3 & a, b, c, g\\
4 & b, c, e, f\\
5 & b, c, e, f, g\\
\bottomrule
\end{tabular}
\end{table}

이 때, 전체 항목집합 \(I\)는 \(\{a, b, c, d, e, f, g\}\) 이다. 다음과 같은 규칙을 적용해보자.

\begin{equation*}
R: \{b, c\} \Rightarrow \{g\}
\end{equation*}

이 때, 조건부 \(X = \{b, c\}\)에 대한 지지도는 아래와 같이 산출된다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{support }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(group\_df, item, set) \{}
  \ControlFlowTok{if}\NormalTok{(}\FunctionTok{is\_empty}\NormalTok{(set)) }\FunctionTok{return}\NormalTok{(}\DecValTok{1}\NormalTok{)}
  
\NormalTok{  group\_df }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{unique}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{summarize}\NormalTok{(}\AttributeTok{n =} \FunctionTok{sum}\NormalTok{(}\SpecialCharTok{!!}\NormalTok{rlang}\SpecialCharTok{::}\FunctionTok{sym}\NormalTok{(item) }\SpecialCharTok{\%in\%}\NormalTok{ set)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{mutate}\NormalTok{(}\AttributeTok{is\_support =}\NormalTok{ (n }\SpecialCharTok{==} \FunctionTok{length}\NormalTok{(set))) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{    \{}\FunctionTok{mean}\NormalTok{(.}\SpecialCharTok{$}\NormalTok{is\_support)\}}
\NormalTok{\}}

\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"b"}\NormalTok{, }\StringTok{"c"}\NormalTok{)}
\NormalTok{group\_transaction\_df }\OtherTok{\textless{}{-}}\NormalTok{ transaction\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{group\_by}\NormalTok{(transaction\_id)}

\FunctionTok{support}\NormalTok{(group\_transaction\_df, }\AttributeTok{item =} \StringTok{"item"}\NormalTok{, }\AttributeTok{set =}\NormalTok{ X)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8
\end{verbatim}

또한, 규칙 \(R\)에 대한 지지도는 아래와 같이 산출할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Y }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"g"}\NormalTok{)}
\FunctionTok{support}\NormalTok{(group\_transaction\_df, }\AttributeTok{item =} \StringTok{"item"}\NormalTok{, }\AttributeTok{set =} \FunctionTok{union}\NormalTok{(X, Y))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6
\end{verbatim}

\hypertarget{association-rule-confidence}{%
\subsection{신뢰도}\label{association-rule-confidence}}

연관규칙 \(R\)의 가치를 평가할 때, 통상 다음과 같이 정의되는 신뢰도를 사용한다.

\begin{equation*}
conf(R) = \frac{supp(R)}{supp(X)} = \frac{supp(X \cup Y)}{supp(X)}
\end{equation*}

이 신뢰도는 조건부 확률의 개념으로, 집합 \(X\)(조건부)가 발생할 때 집합 \(Y\)(결과부)도 동시에 발생할 확률을 의미한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rule\_confidence }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(group\_df, item, x, y) \{}
  \FunctionTok{support}\NormalTok{(group\_df, item, }\FunctionTok{union}\NormalTok{(x, y)) }\SpecialCharTok{/} \FunctionTok{support}\NormalTok{(group\_df, item, x)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rule\_confidence}\NormalTok{(group\_transaction\_df, }\AttributeTok{item =} \StringTok{"item"}\NormalTok{, }\AttributeTok{x =}\NormalTok{ X, }\AttributeTok{y =}\NormalTok{ Y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.75
\end{verbatim}

\hypertarget{association-rule-lift}{%
\subsection{개선도}\label{association-rule-lift}}

결과가 단독으로 발생할 가능성에 비추어 조건과 연계하여 결과가 발생할 가능성의 빈도 비율로 정의한다.

\begin{equation*}
lift(R) = \frac{conf(R)}{supp(Y)} = \frac{supp(X \cup Y)}{supp(X)supp(Y)}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rule\_lift }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(group\_df, item, x, y) \{}
  \FunctionTok{rule\_confidence}\NormalTok{(group\_df, item, x, y) }\SpecialCharTok{/} \FunctionTok{support}\NormalTok{(group\_df, item, y)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{rule\_lift}\NormalTok{(group\_transaction\_df, }\AttributeTok{item =} \StringTok{"item"}\NormalTok{, }\AttributeTok{x =}\NormalTok{ X, }\AttributeTok{y =}\NormalTok{ Y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.25
\end{verbatim}

즉, 항목 \(b\), \(c\)가 발생할 때 \(g\)가 발생하는 빈도가 25\% 높아진다.

\hypertarget{association-rule-exploration}{%
\section{연관규칙의 탐사}\label{association-rule-exploration}}

연관규칙의 탐사는 결국 신뢰도 또는 개선도가 높은 규칙 \(R\)을 트랜잭션 데이터로부터 도출하는 과정이다. 알고리즘으로 가장 널리 사용되는 것이 Apriori 알고리즘\citep{agrawal1994fast}이다.

\hypertarget{apriori-large-itemsets}{%
\subsection{빈발항목집합 생성}\label{apriori-large-itemsets}}

빈발항목집합(large itemsets)이란 미리 결정한 최소 지지도 \(s_{\text{min}}\) 이상의 지지도를 같는 모든 항목집합들을 뜻한다.

빈발항목집합 생성 과정은 아래와 같다.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(k\)개의 항목을 지닌 빈발항목집합 후보군 \(C_{k}\) 중 최소지지도 \(s_{\text{min}}\) 이상의 지지도를 같는 모든 항목집합들을 빈발항목집합 \(L_{k}\)라 한다.
\item
  빈발항목집합들 \(L_{k}\)내의 각 쌍에 대해 합집합을 구하여 그 합집합의 크기(항목의 수)가 \(k + 1\)인 항목집합들을 빈발항목집합 후보군 \(C_{k + 1}\)라 한다.
\end{enumerate}

\(k\)를 1부터 증가시키면서 더 이상 빈발항목집합을 찾을 수 없을 때까지 위 과정을 반복한다. 이 때, 빈발항목집합 후보군을 생성하는 함수 \texttt{apriori\_gen}을 아래와 같이 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{apriori\_gen }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(L) \{}
  \ControlFlowTok{if}\NormalTok{(}\FunctionTok{length}\NormalTok{(L) }\SpecialCharTok{\textless{}} \DecValTok{2}\NormalTok{) }\FunctionTok{return}\NormalTok{(}\ConstantTok{NULL}\NormalTok{)}
  
\NormalTok{  n\_sets }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(L)}
\NormalTok{  n\_item }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(}\FunctionTok{map\_dbl}\NormalTok{(L, length))}

  \ControlFlowTok{if}\NormalTok{(}\FunctionTok{length}\NormalTok{(n\_item) }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{) }\FunctionTok{stop}\NormalTok{(}\StringTok{"All itemsets must be the same length."}\NormalTok{)}
  
\NormalTok{  C }\OtherTok{\textless{}{-}} \FunctionTok{combn}\NormalTok{(L, }\AttributeTok{m =} \DecValTok{2}\NormalTok{, }\AttributeTok{simplify =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{t}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \StringTok{\textasciigrave{}}\AttributeTok{colnames\textless{}{-}}\StringTok{\textasciigrave{}}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"set1"}\NormalTok{, }\StringTok{"set2"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{as\_tibble}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{pmap}\NormalTok{(}\ControlFlowTok{function}\NormalTok{(set1, set2) \{}
      \ControlFlowTok{if}\NormalTok{(}\FunctionTok{length}\NormalTok{(}\FunctionTok{intersect}\NormalTok{(set1, set2)) }\SpecialCharTok{!=}\NormalTok{ n\_item }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\FunctionTok{return}\NormalTok{(}\ConstantTok{NULL}\NormalTok{)}
      \FunctionTok{sort}\NormalTok{(}\FunctionTok{union}\NormalTok{(set1, set2))}
\NormalTok{      \}) }\SpecialCharTok{\%\textgreater{}\%} 
    \FunctionTok{compact}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
    \FunctionTok{unique}\NormalTok{()}

\NormalTok{  C  }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 함수를 이용하여, Table \ref{tab:transaction-data}에서 최소 지지도 \(s_{\text{min}} = 0.4\)를 기준으로 빈발항목집합을 찾아보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s\_min }\OtherTok{\textless{}{-}} \FloatTok{0.4}
\NormalTok{group\_transaction\_df }\OtherTok{\textless{}{-}}\NormalTok{ transaction\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{group\_by}\NormalTok{(transaction\_id)}

\NormalTok{candidate\_itemsets }\OtherTok{\textless{}{-}} \FunctionTok{as.list}\NormalTok{(}\FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(transaction\_df}\SpecialCharTok{$}\NormalTok{item)))}
\NormalTok{large\_itemsets }\OtherTok{\textless{}{-}} \FunctionTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\AttributeTok{length =} \FunctionTok{length}\NormalTok{(candidate\_itemsets))}

\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \FunctionTok{seq\_along}\NormalTok{(large\_itemsets)) \{}
\NormalTok{  itemset\_support }\OtherTok{\textless{}{-}} \FunctionTok{map\_dbl}\NormalTok{(candidate\_itemsets, }
\NormalTok{                             support, }
                             \AttributeTok{group\_df =}\NormalTok{ group\_transaction\_df, }
                             \AttributeTok{item =} \StringTok{"item"}\NormalTok{)}

\NormalTok{  large\_itemsets[[i]] }\OtherTok{\textless{}{-}}\NormalTok{ candidate\_itemsets[itemset\_support }\SpecialCharTok{\textgreater{}=}\NormalTok{ s\_min]}
  
\NormalTok{  candidate\_itemsets }\OtherTok{\textless{}{-}} \FunctionTok{apriori\_gen}\NormalTok{(large\_itemsets[[i]])}
  
  \ControlFlowTok{if}\NormalTok{(}\FunctionTok{is.null}\NormalTok{(candidate\_itemsets)) }\ControlFlowTok{break}
\NormalTok{\}}

\NormalTok{large\_itemsets }\OtherTok{\textless{}{-}} \FunctionTok{compact}\NormalTok{(large\_itemsets)}
\end{Highlighting}
\end{Shaded}

찾아진 빈발항목집합들은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{map}\NormalTok{(large\_itemsets,}
    \SpecialCharTok{\textasciitilde{}}\FunctionTok{map\_chr}\NormalTok{(.x, }\SpecialCharTok{\textasciitilde{}}\FunctionTok{str\_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{str\_c}\NormalTok{(.x, }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] "{a}" "{b}" "{c}" "{e}" "{f}" "{g}"
## 
## [[2]]
## [1] "{a, b}" "{b, c}" "{b, e}" "{b, f}" "{b, g}" "{c, e}" "{c, f}" "{c, g}"
## [9] "{e, f}"
## 
## [[3]]
## [1] "{b, c, e}" "{b, c, f}" "{b, c, g}" "{b, e, f}" "{c, e, f}"
## 
## [[4]]
## [1] "{b, c, e, f}"
\end{verbatim}

\hypertarget{apriori-rule-exploration}{%
\subsection{규칙의 탐사}\label{apriori-rule-exploration}}

도출된 빈발항목집합 각각(\(L\))을 조건부(\(X\))와 결과부(\(Y = L \backslash A\))로 나눌 때 미리 결정된 최소 신뢰도 \(c_{\text{min}}\) 이상의 신뢰도를 지닌 규칙 \(R\)을 찾는다.

\begin{equation*}
R: X \Rightarrow L \backslash X
\end{equation*}

우선, 빈발항목집합 \(L\)으로부터 가능한 규칙들을 생성하는 함수 \texttt{generate\_rules}를 아래와 같이 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{generate\_rules }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(L, }\AttributeTok{n\_min\_item =} \DecValTok{1}\NormalTok{) \{}
\NormalTok{  n\_item }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(L)}
  \ControlFlowTok{if}\NormalTok{(n\_item }\SpecialCharTok{\textless{}}\NormalTok{ n\_min\_item) }\FunctionTok{return}\NormalTok{(}\ConstantTok{NULL}\NormalTok{) }\CommentTok{\# 항목 최소개수 제한}
  
\NormalTok{  X }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(}\FunctionTok{seq\_len}\NormalTok{(n\_item), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{combn}\NormalTok{(L, }\AttributeTok{m =}\NormalTok{ .x }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{, list)) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{flatten}\NormalTok{()}
\NormalTok{  Y }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(X, }\SpecialCharTok{\textasciitilde{}}\FunctionTok{setdiff}\NormalTok{(L, .x))}
  
  \FunctionTok{tibble}\NormalTok{(}\AttributeTok{X =}\NormalTok{ X, }\AttributeTok{Y =}\NormalTok{ Y)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

앞 장에서 추출한 모든 빈발항목집합들로부터 규칙을 생성해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rule\_list }\OtherTok{\textless{}{-}} \FunctionTok{map\_dfr}\NormalTok{(}
\NormalTok{  large\_itemsets }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{flatten}\NormalTok{(),}
\NormalTok{  generate\_rules}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

각각의 규칙에 대하여 신뢰도를 계산하여, 그 값이 최소 신뢰도 \(c_{\text{min}}\) 이상인 규칙만을 \texttt{conf\_rule\_list}라는 데이터 프레임으로 저장하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rule\_list}\SpecialCharTok{$}\NormalTok{confidence }\OtherTok{\textless{}{-}} \FunctionTok{pmap\_dbl}\NormalTok{(rule\_list, }\ControlFlowTok{function}\NormalTok{(X, Y) }
  \FunctionTok{rule\_confidence}\NormalTok{(group\_transaction\_df, }\AttributeTok{item =} \StringTok{"item"}\NormalTok{, }\AttributeTok{x =}\NormalTok{ X, }\AttributeTok{y =}\NormalTok{ Y)}
\NormalTok{  )}

\NormalTok{c\_min }\OtherTok{\textless{}{-}} \FloatTok{0.7}
\NormalTok{conf\_rule\_list }\OtherTok{\textless{}{-}}\NormalTok{ rule\_list }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(confidence }\SpecialCharTok{\textgreater{}=}\NormalTok{ c\_min)}
\end{Highlighting}
\end{Shaded}

이 결과 최종적으로 도출된 규칙들은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{conf\_rule\_list }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rowwise}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{X =} \FunctionTok{str\_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{str\_c}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(X), }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{),}
    \AttributeTok{Y =} \FunctionTok{str\_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{str\_c}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(Y), }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}조건부 $X$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}결과부 $Y$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}신뢰도\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}최종 연관규칙\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:confident-rules}최종 연관규칙}
\centering
\begin{tabular}[t]{ccc}
\toprule
조건부 \$X\$ & 결과부 \$Y\$ & 신뢰도\\
\midrule
\{\} & \{b\} & 1.00\\
\{\} & \{c\} & 0.80\\
\{a\} & \{b\} & 1.00\\
\{\} & \{b, c\} & 0.80\\
\{b\} & \{c\} & 0.80\\
\addlinespace
\{c\} & \{b\} & 1.00\\
\{e\} & \{b\} & 1.00\\
\{f\} & \{b\} & 1.00\\
\{g\} & \{b\} & 1.00\\
\{c\} & \{g\} & 0.75\\
\addlinespace
\{g\} & \{c\} & 1.00\\
\{e\} & \{f\} & 1.00\\
\{f\} & \{e\} & 1.00\\
\{c, e\} & \{b\} & 1.00\\
\{c, f\} & \{b\} & 1.00\\
\addlinespace
\{c\} & \{b, g\} & 0.75\\
\{g\} & \{b, c\} & 1.00\\
\{b, c\} & \{g\} & 0.75\\
\{b, g\} & \{c\} & 1.00\\
\{c, g\} & \{b\} & 1.00\\
\addlinespace
\{e\} & \{b, f\} & 1.00\\
\{f\} & \{b, e\} & 1.00\\
\{b, e\} & \{f\} & 1.00\\
\{b, f\} & \{e\} & 1.00\\
\{e, f\} & \{b\} & 1.00\\
\addlinespace
\{c, e\} & \{f\} & 1.00\\
\{c, f\} & \{e\} & 1.00\\
\{c, e\} & \{b, f\} & 1.00\\
\{c, f\} & \{b, e\} & 1.00\\
\{b, c, e\} & \{f\} & 1.00\\
\addlinespace
\{b, c, f\} & \{e\} & 1.00\\
\{c, e, f\} & \{b\} & 1.00\\
\bottomrule
\end{tabular}
\end{table}

항목의 수가 많은 경우, 생성 가능한 규칙의 수가 매우 많아, 보다 효율적인 탐사의 수행이 필요할 수 있다. 자세한 방법에 대해서는 교재 \citep{jun2012datamining} 참조.

\hypertarget{apriori-r-package}{%
\subsection{R 패키지 내 Apriori}\label{apriori-r-package}}

R 패키지 \texttt{arules}의 \texttt{apriori} 함수를 이용하여 위에서 살펴본 연관규칙 탐사를 수행할 수 있다.

우선, \ref{association-rule-support} 절에서 생성한 데이터 프레임 \texttt{transaction\_df}를 \texttt{arules} 패키지 내에 정의된 \texttt{transactions} 클래스 형태의 데이터로 변환한다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{requireNamespace}\NormalTok{(}\StringTok{"arules"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required namespace: arules
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{transaction\_df2 }\OtherTok{\textless{}{-}} \FunctionTok{as}\NormalTok{(}
  \FunctionTok{split}\NormalTok{(transaction\_df}\SpecialCharTok{$}\NormalTok{item, transaction\_df}\SpecialCharTok{$}\NormalTok{transaction\_id),}
  \StringTok{"transactions"}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

이후, \texttt{apriori} 함수를 호출하여 연관규칙 탐사를 수행한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rule\_results }\OtherTok{\textless{}{-}}\NormalTok{ arules}\SpecialCharTok{::}\FunctionTok{apriori}\NormalTok{(}
\NormalTok{  transaction\_df2,}
  \AttributeTok{parameter =} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{support =} \FloatTok{0.4}\NormalTok{,}
    \AttributeTok{confidence =} \FloatTok{0.7}\NormalTok{,}
    \AttributeTok{target =} \StringTok{"rules"}
\NormalTok{  ),}
  \AttributeTok{control =} \FunctionTok{list}\NormalTok{(}
    \AttributeTok{verbose =} \ConstantTok{FALSE}
\NormalTok{  )}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

결과로 얻어지는 \texttt{rules} 클래스 객체에서 필요한 정보를 추출하여 데이터 프레임으로 저장하자.

\begin{itemize}
\tightlist
\item
  \texttt{lhs}: 조건부
\item
  \texttt{rhs}: 결과부
\item
  \texttt{quality}: 평가척도 (지지도, 신뢰도, 개선도, 관측수)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rule\_results\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{X =} \FunctionTok{as}\NormalTok{(rule\_results}\SpecialCharTok{@}\NormalTok{lhs, }\StringTok{"list"}\NormalTok{),}
  \AttributeTok{Y =} \FunctionTok{as}\NormalTok{(rule\_results}\SpecialCharTok{@}\NormalTok{rhs, }\StringTok{"list"}\NormalTok{)}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_cols}\NormalTok{(rule\_results}\SpecialCharTok{@}\NormalTok{quality)}
\end{Highlighting}
\end{Shaded}

해당 데이터 프레임은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rule\_results\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rowwise}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{X =} \FunctionTok{str\_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{str\_c}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(X), }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{),}
    \AttributeTok{Y =} \FunctionTok{str\_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{str\_c}\NormalTok{(}\FunctionTok{unlist}\NormalTok{(Y), }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}조건부 $X$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}결과부 $Y$\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}지지도\textquotesingle{}}\NormalTok{,}
                  \StringTok{\textquotesingle{}신뢰도\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}포함률\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}개선도\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}관측수\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}최종 연관규칙 {-} arules::apriori\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:apriori-r-results}최종 연관규칙 - arules::apriori}
\centering
\begin{tabular}[t]{ccccccc}
\toprule
조건부 \$X\$ & 결과부 \$Y\$ & 지지도 & 신뢰도 & 포함률 & 개선도 & 관측수\\
\midrule
\{\} & \{c\} & 0.8 & 0.80 & 1.0 & 1.000000 & 4\\
\{\} & \{b\} & 1.0 & 1.00 & 1.0 & 1.000000 & 5\\
\{a\} & \{b\} & 0.4 & 1.00 & 0.4 & 1.000000 & 2\\
\{g\} & \{c\} & 0.6 & 1.00 & 0.6 & 1.250000 & 3\\
\{c\} & \{g\} & 0.6 & 0.75 & 0.8 & 1.250000 & 3\\
\addlinespace
\{g\} & \{b\} & 0.6 & 1.00 & 0.6 & 1.000000 & 3\\
\{e\} & \{f\} & 0.6 & 1.00 & 0.6 & 1.666667 & 3\\
\{f\} & \{e\} & 0.6 & 1.00 & 0.6 & 1.666667 & 3\\
\{e\} & \{b\} & 0.6 & 1.00 & 0.6 & 1.000000 & 3\\
\{f\} & \{b\} & 0.6 & 1.00 & 0.6 & 1.000000 & 3\\
\addlinespace
\{c\} & \{b\} & 0.8 & 1.00 & 0.8 & 1.000000 & 4\\
\{b\} & \{c\} & 0.8 & 0.80 & 1.0 & 1.000000 & 4\\
\{c, g\} & \{b\} & 0.6 & 1.00 & 0.6 & 1.000000 & 3\\
\{b, g\} & \{c\} & 0.6 & 1.00 & 0.6 & 1.250000 & 3\\
\{b, c\} & \{g\} & 0.6 & 0.75 & 0.8 & 1.250000 & 3\\
\addlinespace
\{c, e\} & \{f\} & 0.4 & 1.00 & 0.4 & 1.666667 & 2\\
\{c, f\} & \{e\} & 0.4 & 1.00 & 0.4 & 1.666667 & 2\\
\{e, f\} & \{b\} & 0.6 & 1.00 & 0.6 & 1.000000 & 3\\
\{b, e\} & \{f\} & 0.6 & 1.00 & 0.6 & 1.666667 & 3\\
\{b, f\} & \{e\} & 0.6 & 1.00 & 0.6 & 1.666667 & 3\\
\addlinespace
\{c, e\} & \{b\} & 0.4 & 1.00 & 0.4 & 1.000000 & 2\\
\{c, f\} & \{b\} & 0.4 & 1.00 & 0.4 & 1.000000 & 2\\
\{c, e, f\} & \{b\} & 0.4 & 1.00 & 0.4 & 1.000000 & 2\\
\{b, c, e\} & \{f\} & 0.4 & 1.00 & 0.4 & 1.666667 & 2\\
\{b, c, f\} & \{e\} & 0.4 & 1.00 & 0.4 & 1.666667 & 2\\
\bottomrule
\end{tabular}
\end{table}

위 Table \ref{tab:apriori-r-results}를 살펴보면, 결과부에는 오직 하나의 항목만 존재하는 것을 알 수 있다. 이는 Apriori 알고리즘이 제안된 원 논문 \citep{agrawal1993mining}에 따른 것이며, 위 \ref{apriori-rule-exploration} 절에서 여러 개의 항목이 결과부에 존재하는 방식은 이 Apriori 알고리즘을 보다 일반화한 것이라 생각할 수 있겠다.

\hypertarget{association-sequential-pattern}{%
\section{순차적 패턴의 탐사}\label{association-sequential-pattern}}

순차적 패턴(sequential pattern)이란 고객들의 시간에 따른 구매 행태를 말하는데, 예를 들어 ``냉장고를 구입한 후 김치냉장고를 구매한다''는 식이다.

순차적 패턴의 탐사를 위해서는 고객별, 시간별 트랜잭션 데이터가 필요하다. 항목 집합을 순서적으로 나열한 리스트를 시퀀스(sequence)라 하는데, \(A_j\)를 \(j\)번째의 항목집합이라 할 때, 시퀀스는 다음과 같이 표기한다.

\begin{equation*}
s = < A_1, A_2, \cdots, A_n >
\end{equation*}

시퀀스에 포함된 항목집합의 수를 시퀀스의 길이라 하며, 길이가 \(k\)인 시퀀스를 \(k\)-시퀀스라 한다.

\begin{equation*}
length(< A_1, A_2, \cdots, A_n >) = n
\end{equation*}

두 시퀀스 \(s_1 = < A_1, A_2, \cdots, A_n >\)과 \(s_2 = < B_1, B_2, \cdots, B_m >\)에 대하여 (\(n \leq m\)),

\begin{equation*}
A_1 \subseteq B_{i_1}, A_2 \subseteq B_{i_2}, \cdots,  A_n \subseteq B_{i_n}
\end{equation*}

이 성립하는 \(i_1 < i_2 < \cdots < i_n\)이 존재할 때, \(s_1\)은 \(s_2\)에 포함된다고 하며, 이 때 \(s_1\)을 \(s_2\)의 부분 시퀀스라 하며, 아래와 같이 표현한다.

\begin{equation*}
s_1 \prec s_2
\end{equation*}

시퀀스 \(s\)가 어떤 다른 시퀀스에 포함되지 않을 경우 최대 시퀀스(maximal sequence)라 한다.

\(N\)명의 고객 각자에 대한 트랜잭션 시퀀스를 고객 시퀀스(customer sequence)라 하며, \(i\)번째 고객에 대한 고객 시퀀스를 \(s_i\)라 할 때 (\(i = 1, \cdots, N\)), 임의의 시퀀스 \(s\)에 대한 지지도를 다음과 같이 정의한다.

\begin{equation*}
supp(s) = \frac{1}{N} \sum_{i = 1}^{N} I(s \prec s_i)
\end{equation*}

그리고, 미리 정한 최소 지지도 이상을 갖는 시퀀스를 빈발 시퀀스(large sequence)라 한다. 따라서, 순차적 패턴 탐사 문제는 빈발 시퀀스 중 최대 시퀀스(maximal sequence)들을 찾는 것이라 할 수 있다.

\hypertarget{association-aprioriall}{%
\subsection{AprioriAll 알고리즘}\label{association-aprioriall}}

AprioriAll 알고리즘은 빈발 시퀀스를 탐색하나, 탐색된 시퀀스가 최대 빈발 시퀀스임을 보장하지는 못한다. 따라서, 후에 최대화 단계를 요한다.

아래와 같은 고객 시퀀스가 존재한다고 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sequential\_transaction\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{customer\_id, }\SpecialCharTok{\textasciitilde{}}\NormalTok{transaction\_seq, }\SpecialCharTok{\textasciitilde{}}\NormalTok{item,}
  \DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"a"}\NormalTok{,}
  \DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"b"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"c"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"d"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"a"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"e"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"f"}\NormalTok{,}
  \DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"g"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"a"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"h"}\NormalTok{,}
  \DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"g"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"a"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"e"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{, }\StringTok{"g"}\NormalTok{,}
  \DecValTok{4}\NormalTok{, }\DecValTok{3}\NormalTok{, }\StringTok{"b"}\NormalTok{,}
  \DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\StringTok{"b"}
\NormalTok{)}

\NormalTok{sequential\_transaction\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(customer\_id, transaction\_seq) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{itemset =} \FunctionTok{str\_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{str\_c}\NormalTok{(item, }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{sequence =} \FunctionTok{str\_c}\NormalTok{(}\StringTok{"\textless{}"}\NormalTok{, }\FunctionTok{str\_c}\NormalTok{(itemset, }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\textgreater{}"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{"c"}\NormalTok{, }\StringTok{"c"}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{"고객ID ($i$)"}\NormalTok{, }\StringTok{"고객 시퀀스 ($s\_i$)"}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{"고객별 시퀀스"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'customer_id'. You can override using the `.groups` argument.
\end{verbatim}

\begin{table}

\caption{\label{tab:sequential-transaction-data}고객별 시퀀스}
\centering
\begin{tabular}[t]{cc}
\toprule
고객ID (\$i\$) & 고객 시퀀스 (\$s\_i\$)\\
\midrule
1 & <\{a\}, \{b\}>\\
2 & <\{c, d\}, \{a\}, \{e, f, g\}>\\
3 & <\{a, h, g\}>\\
4 & <\{a\}, \{e, g\}, \{b\}>\\
5 & <\{b\}>\\
\bottomrule
\end{tabular}
\end{table}

고객 시퀀스의 항목집합 또는 이의 부분집합 중 최소 지지도 이상인 것들을 빈발항목 집합으로 도출한다.

우선 시퀀스가 특정 패턴을 포함하는지 여부를 판단하는 사용자 정의 함수 \texttt{is\_contained}와 고객 시퀀스 집합의 특정 패턴에 대한 지지도를 산출하는 사용자 정의 함수 \texttt{support\_sequence}를 아래와 같이 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{is\_contained }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x, pattern) \{}
\NormalTok{  n\_x }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(x)}
\NormalTok{  n\_pattern }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(pattern)}
  \ControlFlowTok{if}\NormalTok{ (n\_pattern }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) }\FunctionTok{return}\NormalTok{ (}\ConstantTok{TRUE}\NormalTok{)}
  
\NormalTok{  rtn }\OtherTok{\textless{}{-}} \ConstantTok{FALSE}
  
\NormalTok{  location }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(}\ConstantTok{NA\_integer\_}\NormalTok{, n\_pattern)}

  \ControlFlowTok{if}\NormalTok{ (n\_x }\SpecialCharTok{\textgreater{}=}\NormalTok{ n\_pattern) \{}
\NormalTok{    j }\OtherTok{\textless{}{-}}\NormalTok{ 1L}
    \ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(n\_x)) \{}
      \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{is\_empty}\NormalTok{(}\FunctionTok{setdiff}\NormalTok{(pattern[[j]], x[[i]]))) \{}
\NormalTok{        location[j] }\OtherTok{\textless{}{-}}\NormalTok{ i}
\NormalTok{        j }\OtherTok{\textless{}{-}}\NormalTok{ j }\SpecialCharTok{+} \DecValTok{1}
        \ControlFlowTok{if}\NormalTok{ (j }\SpecialCharTok{\textgreater{}}\NormalTok{ n\_pattern) \{}
\NormalTok{          rtn }\OtherTok{\textless{}{-}} \ConstantTok{TRUE}
          \ControlFlowTok{break}
\NormalTok{        \}}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}

\NormalTok{  rtn}
\NormalTok{\}}

\NormalTok{support\_sequence }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(sequence\_list, pattern) \{}
  \FunctionTok{map\_lgl}\NormalTok{(sequence\_list, is\_contained, }\AttributeTok{pattern =}\NormalTok{ pattern) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{mean}\NormalTok{()}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

앞 \ref{apriori-large-itemsets}절에서와 같이 사용자 정의 함수 \texttt{apriori\_gen}을 이용하여 빈발항목집합(시퀀스 지지도 기준)을 아래와 같이 얻는다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s\_min }\OtherTok{\textless{}{-}} \FloatTok{0.4}

\NormalTok{customer\_sequence }\OtherTok{\textless{}{-}}\NormalTok{ sequential\_transaction\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(customer\_id, transaction\_seq) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{itemset =} \FunctionTok{list}\NormalTok{(item)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{sequence =} \FunctionTok{list}\NormalTok{(itemset))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'customer_id'. You can override using the `.groups` argument.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{candidate\_itemsets }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(}\FunctionTok{sort}\NormalTok{(}\FunctionTok{unique}\NormalTok{(sequential\_transaction\_df}\SpecialCharTok{$}\NormalTok{item)), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{list}\NormalTok{(.x))}
\NormalTok{large\_itemsets }\OtherTok{\textless{}{-}} \FunctionTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\AttributeTok{length =} \FunctionTok{length}\NormalTok{(candidate\_itemsets))}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_along}\NormalTok{(large\_itemsets)) \{}
\NormalTok{  large\_itemsets[[i]] }\OtherTok{\textless{}{-}}\NormalTok{ candidate\_itemsets[}
    \FunctionTok{map\_dbl}\NormalTok{(candidate\_itemsets,}
            \SpecialCharTok{\textasciitilde{}}\FunctionTok{support\_sequence}\NormalTok{(customer\_sequence}\SpecialCharTok{$}\NormalTok{sequence, }\AttributeTok{pattern =}\NormalTok{ .x)) }\SpecialCharTok{\textgreater{}=}\NormalTok{ s\_min}
\NormalTok{    ] }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{flatten}\NormalTok{()}

\NormalTok{  candidate\_itemsets }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(}\FunctionTok{apriori\_gen}\NormalTok{(large\_itemsets[[i]]), }\SpecialCharTok{\textasciitilde{}}\FunctionTok{list}\NormalTok{(.x))}
\NormalTok{\}}

\NormalTok{large\_itemsets }\OtherTok{\textless{}{-}}\NormalTok{ large\_itemsets }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{flatten}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

위 결과, 아래와 같은 빈발항목집합이 얻어진다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{large\_itemsets}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [[1]]
## [1] "a"
## 
## [[2]]
## [1] "b"
## 
## [[3]]
## [1] "e"
## 
## [[4]]
## [1] "g"
## 
## [[5]]
## [1] "e" "g"
\end{verbatim}

위 빈발항목집합에 일련번호를 부여한 뒤, 고객 시퀀스를 해당 일련번호를 이용한 시퀀스로 변환한다. 우선 아래와 같이 일련번호를 부여해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{large\_itemset\_df }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{itemset =}\NormalTok{ large\_itemsets,}
  \AttributeTok{mapped\_to =} \FunctionTok{seq\_along}\NormalTok{(large\_itemsets)}
\NormalTok{)}

\NormalTok{large\_itemset\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rowwise}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{itemset =} \FunctionTok{str\_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{str\_c}\NormalTok{(itemset, }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{"c"}\NormalTok{, }\StringTok{"c"}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{"빈발항목집합"}\NormalTok{, }\StringTok{"일련번호"}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{"고객 시퀀스 빈발항목집합"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:association-sequence-large-itemsets}고객 시퀀스 빈발항목집합}
\centering
\begin{tabular}[t]{cc}
\toprule
빈발항목집합 & 일련번호\\
\midrule
\{a\} & 1\\
\{b\} & 2\\
\{e\} & 3\\
\{g\} & 4\\
\{e, g\} & 5\\
\bottomrule
\end{tabular}
\end{table}

원 고객 시퀀스에 대해, 각 항목집합이 위 빈발항목집합을 포함하는 경우, 해당 일련번호가 항목으로 포함되는 형태로 변환 시퀀스를 생성한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{customer\_sequence}\SpecialCharTok{$}\NormalTok{transformed\_sequence }\OtherTok{\textless{}{-}}\NormalTok{ customer\_sequence}\SpecialCharTok{$}\NormalTok{sequence }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{map}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\FunctionTok{map}\NormalTok{(.x, }\ControlFlowTok{function}\NormalTok{(x) \{}
\NormalTok{    large\_itemset\_df}\SpecialCharTok{$}\NormalTok{mapped\_to[}
      \FunctionTok{map\_lgl}\NormalTok{(large\_itemset\_df}\SpecialCharTok{$}\NormalTok{itemset, }\SpecialCharTok{\textasciitilde{}}\FunctionTok{is\_contained}\NormalTok{(x, .x))}
\NormalTok{      ]}
\NormalTok{  \}) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{compact}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

원 고객 시퀀스와 변환 시퀀스는 아래와 같이 표현될 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{print\_sequence }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(sequence) \{}
  \FunctionTok{str\_c}\NormalTok{(}\StringTok{"\textless{}"}\NormalTok{, }\FunctionTok{str\_c}\NormalTok{(}
    \FunctionTok{map}\NormalTok{(sequence, }\ControlFlowTok{function}\NormalTok{(x) }
      \FunctionTok{str\_c}\NormalTok{(}\FunctionTok{map\_chr}\NormalTok{(x, }\SpecialCharTok{\textasciitilde{}}\FunctionTok{str\_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{str\_c}\NormalTok{(.x, }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\}"}\NormalTok{)), }
            \AttributeTok{collapse =} \StringTok{", "}\NormalTok{)),}
    \StringTok{"\textgreater{}"}\NormalTok{))}
\NormalTok{\}}

\NormalTok{customer\_sequence }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(customer\_id) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{sequence =} \FunctionTok{print\_sequence}\NormalTok{(sequence),}
    \AttributeTok{transformed\_sequence =} \FunctionTok{print\_sequence}\NormalTok{(transformed\_sequence)}
\NormalTok{  ) }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{"c"}\NormalTok{, }\StringTok{"c"}\NormalTok{, }\StringTok{"c"}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{"고객ID"}\NormalTok{, }\StringTok{"고객 시퀀스"}\NormalTok{, }\StringTok{"변환 시퀀스"}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{"고객 시퀀스의 변환"}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:association-transformed-sequence}고객 시퀀스의 변환}
\centering
\begin{tabular}[t]{ccc}
\toprule
고객ID & 고객 시퀀스 & 변환 시퀀스\\
\midrule
1 & <\{a\}, \{b\}> & <\{1\}, \{2\}>\\
2 & <\{c, d\}, \{a\}, \{e, f, g\}> & <\{1\}, \{3, 4, 5\}>\\
3 & <\{a, h, g\}> & <\{1, 4\}>\\
4 & <\{a\}, \{e, g\}, \{b\}> & <\{1\}, \{3, 4, 5\}, \{2\}>\\
5 & <\{b\}> & <\{2\}>\\
\bottomrule
\end{tabular}
\end{table}

변환 시퀀스를 기준으로, 길이가 1인 빈발 시퀀스를 구한다. 최소 지지도를 앞에서 빈발항목집합을 구할 때와 동일하게 설정할 때, 길이가 1인 빈발 시퀀스는 빈발항목집합(의 변환된 일련번호)과 동일하다.

우선, 최대 시퀀스 길이를 구하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{max\_sequence\_length }\OtherTok{\textless{}{-}} \FunctionTok{max}\NormalTok{(}\FunctionTok{map\_int}\NormalTok{(customer\_sequence}\SpecialCharTok{$}\NormalTok{transformed\_sequence, }\SpecialCharTok{\textasciitilde{}}\FunctionTok{length}\NormalTok{(.x)))}
\end{Highlighting}
\end{Shaded}

1-시퀀스인 빈발시퀀스는 빈발항목집합과 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{large\_sequences }\OtherTok{\textless{}{-}} \FunctionTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\AttributeTok{length =}\NormalTok{ max\_sequence\_length)}
\NormalTok{large\_sequences[[}\DecValTok{1}\NormalTok{]] }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(large\_itemset\_df}\SpecialCharTok{$}\NormalTok{mapped\_to, }\SpecialCharTok{\textasciitilde{}}\FunctionTok{list}\NormalTok{(.x))}
\end{Highlighting}
\end{Shaded}

같은 길이의 두 시퀀스를 이용해서 길이가 1 증가한 새로운 시퀀스를 생성하는 함수 \texttt{generate\_sequence}를 아래와 같이 구현해보자. 새로운 시퀀스는 첫 번째 시퀀스 후에 두 번째 시퀀스의 가장 마지막 트랜잭션을 추가한 시퀀스이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{generate\_sequence }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(seq1, seq2) \{}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(seq1) }\SpecialCharTok{!=} \FunctionTok{length}\NormalTok{(seq2)) }\FunctionTok{stop}\NormalTok{(}\StringTok{"Two sequences must be the same length."}\NormalTok{)}
  
  \CommentTok{\# two k{-}sequences needs to be the same for first k{-}1 items to generate new sequence}
\NormalTok{  new\_sequence }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\NormalTok{  k }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(seq1)}
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{identical}\NormalTok{(seq1[}\FunctionTok{seq\_len}\NormalTok{(k }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)], seq2[}\FunctionTok{seq\_len}\NormalTok{(k }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)])) \{}
\NormalTok{    new\_sequence }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(seq1, seq2[[k]])}
\NormalTok{  \}}
  
\NormalTok{  new\_sequence}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

빈발 \(k\)-시퀀스들로부터 \((k+1)\)-시퀀스들을 생성하는 함수 \texttt{apriori\_seq\_gen}을 아래와 같이 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{apriori\_seq\_gen }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(L) \{}
\NormalTok{  n\_seqs }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(L)}
\NormalTok{  n\_item }\OtherTok{\textless{}{-}} \FunctionTok{unique}\NormalTok{(}\FunctionTok{map\_dbl}\NormalTok{(L, length))}
  
  \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(n\_item) }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{) }\FunctionTok{stop}\NormalTok{(}\StringTok{"All sequences must be the same length."}\NormalTok{)}
  
\NormalTok{  k }\OtherTok{\textless{}{-}}\NormalTok{ n\_item}
  
  \CommentTok{\# generate large new sequences with length (k+1)}
\NormalTok{  C }\OtherTok{\textless{}{-}} \FunctionTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\AttributeTok{length =}\NormalTok{ n\_seqs }\SpecialCharTok{*}\NormalTok{ n\_seqs)}
  \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq\_along}\NormalTok{(L)) \{}
    \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \FunctionTok{seq\_along}\NormalTok{(L)) \{}
\NormalTok{      candidate\_sequence }\OtherTok{\textless{}{-}} \FunctionTok{generate\_sequence}\NormalTok{(L[[i]], L[[j]])}
      
      \CommentTok{\# check whether all subsequences with length k are element of L}
      \ControlFlowTok{if}\NormalTok{ (}
        \FunctionTok{all}\NormalTok{(}\FunctionTok{map\_lgl}\NormalTok{(}\FunctionTok{seq\_len}\NormalTok{(k), }\ControlFlowTok{function}\NormalTok{(x) }
          \FunctionTok{any}\NormalTok{(}\FunctionTok{map\_lgl}\NormalTok{(L, }\SpecialCharTok{\textasciitilde{}}\FunctionTok{identical}\NormalTok{(.x, candidate\_sequence[}\SpecialCharTok{{-}}\NormalTok{x])))}
\NormalTok{        ))}
\NormalTok{      ) \{}
\NormalTok{        C[[n\_seqs }\SpecialCharTok{*}\NormalTok{ (i }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{) }\SpecialCharTok{+}\NormalTok{ j]] }\OtherTok{\textless{}{-}}\NormalTok{ candidate\_sequence}
\NormalTok{      \}}
\NormalTok{    \}}
\NormalTok{  \}}
  
  \FunctionTok{compact}\NormalTok{(C)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 \texttt{apriori\_seq\_gen} 함수 수행결과로 얻어지는 \((k+1)\)-시퀀스들이 모두 빈발 시퀀스라는 보장은 없으므로, 새로 생성된 각 시퀀스가 최소 지지도 이상의 지지도를 갖는지 검토하여, 빈발 시퀀스만을 남기기로 하자. 앞에서 정의했던 함수 \texttt{support\_sequence}를 활용하여, 새로운 함수 \texttt{get\_large\_sequence}를 정의하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{get\_large\_sequence }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(sequence\_list, C, s\_min) \{}
\NormalTok{  is\_large }\OtherTok{\textless{}{-}} \FunctionTok{map\_lgl}\NormalTok{(}
\NormalTok{    C, }\SpecialCharTok{\textasciitilde{}} \FunctionTok{support\_sequence}\NormalTok{(sequence\_list, .x) }\SpecialCharTok{\textgreater{}=}\NormalTok{ s\_min}
\NormalTok{  )}
  
\NormalTok{  C[is\_large]}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

위 빈발 \(k\)-시퀀스를 과정을 \(k\)값을 1씩 증가시켜가며 더 이상 빈발 시퀀스를 찾을 수 없을 때까지 반복한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s\_min }\OtherTok{\textless{}{-}} \FloatTok{0.4}

\NormalTok{large\_sequences }\OtherTok{\textless{}{-}} \FunctionTok{vector}\NormalTok{(}\StringTok{"list"}\NormalTok{, }\AttributeTok{length =}\NormalTok{ max\_sequence\_length)}
\NormalTok{large\_sequences[[}\DecValTok{1}\NormalTok{]] }\OtherTok{\textless{}{-}} \FunctionTok{map}\NormalTok{(large\_itemset\_df}\SpecialCharTok{$}\NormalTok{mapped\_to, }\SpecialCharTok{\textasciitilde{}}\FunctionTok{list}\NormalTok{(.x))}

\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \FunctionTok{seq\_len}\NormalTok{(max\_sequence\_length }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)) \{}
\NormalTok{  large\_sequences[[i }\SpecialCharTok{+} \DecValTok{1}\NormalTok{]] }\OtherTok{\textless{}{-}} \FunctionTok{get\_large\_sequence}\NormalTok{(}
\NormalTok{    customer\_sequence}\SpecialCharTok{$}\NormalTok{transformed\_sequence,}
    \FunctionTok{apriori\_seq\_gen}\NormalTok{(large\_sequences[[i]]),}
\NormalTok{    s\_min}
\NormalTok{  )}
  
  \ControlFlowTok{if}\NormalTok{(}\FunctionTok{is\_empty}\NormalTok{(large\_sequences[[i }\SpecialCharTok{+} \DecValTok{1}\NormalTok{]])) }\ControlFlowTok{break}
\NormalTok{\}}

\NormalTok{large\_sequences }\OtherTok{\textless{}{-}} \FunctionTok{flatten}\NormalTok{(}\FunctionTok{compact}\NormalTok{(large\_sequences))}
\end{Highlighting}
\end{Shaded}

결과적으로 찾아진 빈발 시퀀스들은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{map\_chr}\NormalTok{(large\_sequences, }
    \SpecialCharTok{\textasciitilde{}}\FunctionTok{str\_c}\NormalTok{(}\StringTok{"\textless{}"}\NormalTok{, }\FunctionTok{str\_c}\NormalTok{(}\FunctionTok{str\_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{unlist}\NormalTok{(.x), }\StringTok{"\}"}\NormalTok{), }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\textgreater{}"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "<{1}>"      "<{2}>"      "<{3}>"      "<{4}>"      "<{5}>"     
## [6] "<{1}, {2}>" "<{1}, {3}>" "<{1}, {4}>" "<{1}, {5}>"
\end{verbatim}

이후 최대화 단계를 통해, 빈발 시퀀스 중 최대 시퀀스들만 추출한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{maximal\_large\_sequences }\OtherTok{\textless{}{-}}\NormalTok{ large\_sequences}

\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \FunctionTok{seq}\NormalTok{(}\AttributeTok{from =} \FunctionTok{length}\NormalTok{(large\_sequences), }\AttributeTok{to =} \DecValTok{2}\NormalTok{)) \{}
  \ControlFlowTok{if}\NormalTok{(}\SpecialCharTok{!}\FunctionTok{is\_empty}\NormalTok{(maximal\_large\_sequences[i])) \{}
\NormalTok{    is\_subsequence }\OtherTok{\textless{}{-}} \FunctionTok{map\_lgl}\NormalTok{(maximal\_large\_sequences[}\FunctionTok{seq\_len}\NormalTok{(i }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)],}
                              \SpecialCharTok{\textasciitilde{}}\FunctionTok{is\_contained}\NormalTok{(maximal\_large\_sequences[i], .x))}
    
    \FunctionTok{walk}\NormalTok{(}\FunctionTok{which}\NormalTok{(is\_subsequence), }\ControlFlowTok{function}\NormalTok{(x) maximal\_large\_sequences[[x]] }\OtherTok{\textless{}\textless{}{-}} \FunctionTok{list}\NormalTok{())}
\NormalTok{  \}}
\NormalTok{\}}

\NormalTok{maximal\_large\_sequences }\OtherTok{\textless{}{-}} \FunctionTok{compact}\NormalTok{(maximal\_large\_sequences)}
\end{Highlighting}
\end{Shaded}

최대 빈발 시퀀스(변환 시퀀스 기준)은 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{map\_chr}\NormalTok{(maximal\_large\_sequences, }
    \SpecialCharTok{\textasciitilde{}}\FunctionTok{str\_c}\NormalTok{(}\StringTok{"\textless{}"}\NormalTok{, }\FunctionTok{str\_c}\NormalTok{(}\FunctionTok{str\_c}\NormalTok{(}\StringTok{"\{"}\NormalTok{, }\FunctionTok{unlist}\NormalTok{(.x), }\StringTok{"\}"}\NormalTok{), }\AttributeTok{collapse =} \StringTok{", "}\NormalTok{), }\StringTok{"\textgreater{}"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "<{1}, {2}>" "<{1}, {3}>" "<{1}, {4}>" "<{1}, {5}>"
\end{verbatim}

이외에도 AprioriSome 알고리즘, DynamicSome 알고리즘 등의 시퀀스 탐사 알고리즘 들이 존재한다. 보다 자세한 내용은 \citet{jun2012datamining} 및 \citet{agrawal1995mining} 참고.

\hypertarget{recommender-system}{%
\chapter{추천시스템}\label{recommender-system}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

추천시스템(recommender system)은 상품, 웹페이지, 신문 기사 등에 대한 소비자의 성향을 파악하여 그에 부합하는 새로운 상품 등을 추천하고자 하는 목적으로 개발되며, 접근 방식에 따라 내용기반(content-based) 방법, 협업 필터링(collaborative filtering), 결합방식(hybrid) 등으로 분류된다.

\hypertarget{recommender-packages-install}{%
\section{필요 R package 설치}\label{recommender-packages-install}}

본 장에서 필요한 R 패키지들은 아래와 같다.

\begin{tabular}{l|l}
\hline
package & version\\
\hline
tidyverse & 1.3.1\\
\hline
tidytext & 0.3.1\\
\hline
\end{tabular}

\hypertarget{content-based-recommender}{%
\section{내용기반 추천시스템}\label{content-based-recommender}}

내용기반 추천시스템은 주로 문서 등의 추천에 활용되고 있다.

\begin{itemize}
\tightlist
\item
  \(N\): 전체 문서의 수
\item
  \(f_{ij}\): 문서 \(j\)에 나타난 단어 \(i\)의 빈도수
\item
  \(n_i\): 단어 \(i\)가 한 번 이상 나타난 문서의 수
\end{itemize}

우선 \texttt{tidytext} 패키지를 로드하자.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidytext)}
\end{Highlighting}
\end{Shaded}

\texttt{janeaustenr} 패키지에 있는 Jane Austen의 6개 소설에 대한 텍스트 데이터를 로드하자. 해당 데이터는 책 내용이 담긴 \texttt{text}라는 컬럼과 책 제목인 \texttt{book} 컬럼으로 이루어진 데이터 프레임이다.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(janeaustenr)}
\NormalTok{tidy\_books }\OtherTok{\textless{}{-}} \FunctionTok{austen\_books}\NormalTok{()}
\FunctionTok{head}\NormalTok{(tidy\_books)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   text                    book               
##   <chr>                   <fct>              
## 1 "SENSE AND SENSIBILITY" Sense & Sensibility
## 2 ""                      Sense & Sensibility
## 3 "by Jane Austen"        Sense & Sensibility
## 4 ""                      Sense & Sensibility
## 5 "(1811)"                Sense & Sensibility
## 6 ""                      Sense & Sensibility
\end{verbatim}

해당 데이터 프레임에 담긴 책의 수는 아래와 같다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n\_book }\OtherTok{\textless{}{-}} \FunctionTok{nlevels}\NormalTok{(tidy\_books}\SpecialCharTok{$}\NormalTok{book)}
\FunctionTok{print}\NormalTok{(n\_book)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 6
\end{verbatim}

책의 내용 text를 단어 단위로 나누어 각 행으로 저장하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy\_words }\OtherTok{\textless{}{-}}\NormalTok{ tidy\_books }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{unnest\_tokens}\NormalTok{(word, text)}
  
\FunctionTok{head}\NormalTok{(tidy\_words)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   book                word       
##   <fct>               <chr>      
## 1 Sense & Sensibility sense      
## 2 Sense & Sensibility and        
## 3 Sense & Sensibility sensibility
## 4 Sense & Sensibility by         
## 5 Sense & Sensibility jane       
## 6 Sense & Sensibility austen
\end{verbatim}

이 데이터 프레임을 기반으로, 단어 \(i\)가 문서 \(j\)에 나타난 단어 빈도수(term frequency)를 모든 단어 \(i\)와 모든 문서 \(j\)에 대해 계산하자.

\begin{equation*}
TF_{ij} = \frac{f_{ij}}{\sum_k f_{kj}}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tf\_results }\OtherTok{\textless{}{-}}\NormalTok{ tidy\_words }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(book, word) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{n =} \FunctionTok{n}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{tf =}\NormalTok{ n }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(n)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{n) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{complete}\NormalTok{(book, word, }\AttributeTok{fill =} \FunctionTok{list}\NormalTok{(}\AttributeTok{tf =} \DecValTok{0}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'book'. You can override using the `.groups` argument.
\end{verbatim}

이 때, 단어 빈도수가 높은 단어들은 대체로 너무 흔한 단어들이어서 중요한 의미를 지니지 않은 경우가 많다. 아래와 같이, ``the'', ``to'', ``and'' 등의 단어들이 사용 빈도가 매우 높은 단어들이다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tf\_results }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(tf)) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 3
##    book                word      tf
##    <fct>               <chr>  <dbl>
##  1 Northanger Abbey    the   0.0409
##  2 Persuasion          the   0.0398
##  3 Mansfield Park      the   0.0387
##  4 Pride & Prejudice   the   0.0354
##  5 Sense & Sensibility to    0.0343
##  6 Sense & Sensibility the   0.0342
##  7 Mansfield Park      to    0.0341
##  8 Pride & Prejudice   to    0.0341
##  9 Mansfield Park      and   0.0339
## 10 Persuasion          to    0.0336
\end{verbatim}

따라서, 단어의 중요도를 정의할 때 단어 \(i\)의 역문서 빈도수(inverse document frequency)를 함께 고려한다.

\begin{equation*}
IDF_{i} = \log \frac{N}{n_i}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{idf\_results }\OtherTok{\textless{}{-}}\NormalTok{ tf\_results }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(tf }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(word) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{n =} \FunctionTok{n}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{idf =} \FunctionTok{log}\NormalTok{(n\_book }\SpecialCharTok{/}\NormalTok{ n)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{n)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{idf\_results }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(idf)) }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 2
##    word           idf
##    <chr>        <dbl>
##  1 _accepted_    1.79
##  2 _accident_    1.79
##  3 _adair_       1.79
##  4 _addition_    1.79
##  5 _advantages_  1.79
##  6 _affect_      1.79
##  7 _against_     1.79
##  8 _agreeable_   1.79
##  9 _air_         1.79
## 10 _allow_       1.79
\end{verbatim}

최종적으로 단어의 중요도를 위에서 정의한 단어 빈도수와 역문서 빈도수의 곱으로 아래와 같이 구하며, 이를 TF-IDF 가중치라 한다.

\begin{equation*}
w_{ij} = TF_{ij} \times IDF_{i}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tf\_idf\_results }\OtherTok{\textless{}{-}} \FunctionTok{inner\_join}\NormalTok{(tf\_results, idf\_results, }\AttributeTok{by =} \StringTok{"word"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{tf\_idf =}\NormalTok{ tf }\SpecialCharTok{*}\NormalTok{ idf)}
\end{Highlighting}
\end{Shaded}

TF-IDF 가중치가 높은 단어들을 살펴보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tf\_idf\_results }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(tf\_idf)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 10 x 5
##    book                word           tf   idf  tf_idf
##    <fct>               <chr>       <dbl> <dbl>   <dbl>
##  1 Sense & Sensibility elinor    0.00519  1.79 0.00931
##  2 Sense & Sensibility marianne  0.00410  1.79 0.00735
##  3 Mansfield Park      crawford  0.00307  1.79 0.00551
##  4 Pride & Prejudice   darcy     0.00305  1.79 0.00547
##  5 Persuasion          elliot    0.00304  1.79 0.00544
##  6 Emma                emma      0.00488  1.10 0.00536
##  7 Northanger Abbey    tilney    0.00252  1.79 0.00452
##  8 Emma                weston    0.00242  1.79 0.00433
##  9 Pride & Prejudice   bennet    0.00241  1.79 0.00431
## 10 Persuasion          wentworth 0.00228  1.79 0.00409
\end{verbatim}

대체로 소설에 나타나는 인물의 이름이 높은 가중치를 보이는데, 이는 인물의 이름이 소설 한 권에 걸쳐 여러 번 나타나 단어 빈도수가 높으며, 또한 각각의 소설이 서로 다른 인물명을 등장시킴으로써 역문서 빈도수 또한 높기 때문이다.

위와 같은 TF-IDF 가중치 계산은 \texttt{tidytext} 패키지의 \texttt{bind\_tf\_idf} 함수를 이용하여 간편하게 구할 수 있다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tidy\_words }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(book, word) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{n =} \FunctionTok{n}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{bind\_tf\_idf}\NormalTok{(word, book, n) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(tf\_idf)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{head}\NormalTok{(}\DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` has grouped output by 'book'. You can override using the `.groups` argument.
\end{verbatim}

\begin{verbatim}
## # A tibble: 10 x 6
##    book                word          n      tf   idf  tf_idf
##    <fct>               <chr>     <int>   <dbl> <dbl>   <dbl>
##  1 Sense & Sensibility elinor      623 0.00519  1.79 0.00931
##  2 Sense & Sensibility marianne    492 0.00410  1.79 0.00735
##  3 Mansfield Park      crawford    493 0.00307  1.79 0.00551
##  4 Pride & Prejudice   darcy       373 0.00305  1.79 0.00547
##  5 Persuasion          elliot      254 0.00304  1.79 0.00544
##  6 Emma                emma        786 0.00488  1.10 0.00536
##  7 Northanger Abbey    tilney      196 0.00252  1.79 0.00452
##  8 Emma                weston      389 0.00242  1.79 0.00433
##  9 Pride & Prejudice   bennet      294 0.00241  1.79 0.00431
## 10 Persuasion          wentworth   191 0.00228  1.79 0.00409
\end{verbatim}

임의의 사용자 \(u\)가 아래와 같이 다섯 가지 단어에 각기 다른 관심도 \(w_{iu}\)를 지닌다고 하자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{words\_of\_interest }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}
  \AttributeTok{word =} \FunctionTok{c}\NormalTok{(}\StringTok{"kitty"}\NormalTok{, }\StringTok{"cottage"}\NormalTok{, }\StringTok{"judgment"}\NormalTok{, }\StringTok{"war"}\NormalTok{, }\StringTok{"sea"}\NormalTok{),}
  \AttributeTok{weight =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.3}\NormalTok{, }\FloatTok{0.3}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.2}\NormalTok{)}
\NormalTok{)}

\NormalTok{words\_of\_interest }\SpecialCharTok{\%\textgreater{}\%}
\NormalTok{  knitr}\SpecialCharTok{::}\FunctionTok{kable}\NormalTok{(}
    \AttributeTok{booktabs =} \ConstantTok{TRUE}\NormalTok{,}
    \AttributeTok{align =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}c\textquotesingle{}}\NormalTok{),}
    \AttributeTok{col.names =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}단어 ($i$)\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}가중치 ($w\_\{iu\}$\textquotesingle{}}\NormalTok{),}
    \AttributeTok{caption =} \StringTok{\textquotesingle{}목표 사용자의 관심 단어 및 가중치\textquotesingle{}}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:word-of-interest}목표 사용자의 관심 단어 및 가중치}
\centering
\begin{tabular}[t]{cc}
\toprule
단어 (\$i\$) & 가중치 (\$w\_\{iu\}\$\\
\midrule
kitty & 0.3\\
cottage & 0.3\\
judgment & 0.1\\
war & 0.1\\
sea & 0.2\\
\bottomrule
\end{tabular}
\end{table}

이 때, 목표 사용자 \(u\)의 문서 \(j\)에 대한 유용도(utility)를 다음과 같이 코사인 유사성 척도(cosine similarity measure)로 산출한다.

\begin{equation*}
u(a, j) = \frac{\sum_{i = 1}^{K} w_{iu} w_{ij}}{\sqrt{\sum_{i = 1}^{K} w_{iu}^2} \sqrt{\sum_{i = 1}^{K} w_{ij}^2}}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{utility\_results }\OtherTok{\textless{}{-}}\NormalTok{ tf\_idf\_results }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(words\_of\_interest, }\AttributeTok{by =} \StringTok{"word"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(book) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{utility =} \FunctionTok{sum}\NormalTok{(weight }\SpecialCharTok{*}\NormalTok{ tf\_idf) }\SpecialCharTok{/} 
\NormalTok{              (}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(weight }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{)) }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(tf\_idf }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{)))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(utility))}

\FunctionTok{print}\NormalTok{(utility\_results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   book                utility
##   <fct>                 <dbl>
## 1 Persuasion            0.753
## 2 Emma                  0.710
## 3 Sense & Sensibility   0.640
## 4 Pride & Prejudice     0.615
## 5 Northanger Abbey      0.529
## 6 Mansfield Park        0.404
\end{verbatim}

위 결과 Persuasion이 목표 사용자의 관심에 가장 유용도 높은 문서로 추천된다.

교재 \citet{jun2012datamining} 에 있는 예제에 대한 R 스크립트를 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{words\_of\_interest }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{word, }\SpecialCharTok{\textasciitilde{}}\NormalTok{weight,}
  \StringTok{"word1"}\NormalTok{, }\FloatTok{0.124}\NormalTok{,}
  \StringTok{"word2"}\NormalTok{, }\FloatTok{0.275}\NormalTok{,}
  \StringTok{"word3"}\NormalTok{, }\FloatTok{0.019}\NormalTok{,}
  \StringTok{"word4"}\NormalTok{, }\FloatTok{0.182}\NormalTok{,}
  \StringTok{"word5"}\NormalTok{, }\FloatTok{0.223}
\NormalTok{)}

\NormalTok{tf\_idf\_results }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{document, }\SpecialCharTok{\textasciitilde{}}\NormalTok{word, }\SpecialCharTok{\textasciitilde{}}\NormalTok{tf\_idf,}
  \StringTok{"doc1"}\NormalTok{, }\StringTok{"word1"}\NormalTok{, }\FloatTok{0.0194}\NormalTok{,}
  \StringTok{"doc1"}\NormalTok{, }\StringTok{"word2"}\NormalTok{, }\FloatTok{0.0043}\NormalTok{,}
  \StringTok{"doc1"}\NormalTok{, }\StringTok{"word3"}\NormalTok{, }\FloatTok{0.0054}\NormalTok{,}
  \StringTok{"doc1"}\NormalTok{, }\StringTok{"word4"}\NormalTok{, }\FloatTok{0.0155}\NormalTok{,}
  \StringTok{"doc1"}\NormalTok{, }\StringTok{"word5"}\NormalTok{, }\FloatTok{0.0028}\NormalTok{,}
  \StringTok{"doc2"}\NormalTok{, }\StringTok{"word1"}\NormalTok{, }\FloatTok{0.0082}\NormalTok{,}
  \StringTok{"doc2"}\NormalTok{, }\StringTok{"word2"}\NormalTok{, }\FloatTok{0.0032}\NormalTok{,}
  \StringTok{"doc2"}\NormalTok{, }\StringTok{"word3"}\NormalTok{, }\FloatTok{0.0007}\NormalTok{,}
  \StringTok{"doc2"}\NormalTok{, }\StringTok{"word4"}\NormalTok{, }\FloatTok{0.0104}\NormalTok{,}
  \StringTok{"doc2"}\NormalTok{, }\StringTok{"word5"}\NormalTok{, }\FloatTok{0.0073}\NormalTok{,}
  \StringTok{"doc3"}\NormalTok{, }\StringTok{"word1"}\NormalTok{, }\FloatTok{0.0087}\NormalTok{,}
  \StringTok{"doc3"}\NormalTok{, }\StringTok{"word2"}\NormalTok{, }\FloatTok{0.0174}\NormalTok{,}
  \StringTok{"doc3"}\NormalTok{, }\StringTok{"word3"}\NormalTok{, }\FloatTok{0.0091}\NormalTok{,}
  \StringTok{"doc3"}\NormalTok{, }\StringTok{"word4"}\NormalTok{, }\FloatTok{0.0086}\NormalTok{,}
  \StringTok{"doc3"}\NormalTok{, }\StringTok{"word5"}\NormalTok{, }\FloatTok{0.0268}\NormalTok{,}
  \StringTok{"doc4"}\NormalTok{, }\StringTok{"word1"}\NormalTok{, }\FloatTok{0.0093}\NormalTok{,}
  \StringTok{"doc4"}\NormalTok{, }\StringTok{"word2"}\NormalTok{, }\FloatTok{0.0061}\NormalTok{,}
  \StringTok{"doc4"}\NormalTok{, }\StringTok{"word3"}\NormalTok{, }\FloatTok{0.0172}\NormalTok{,}
  \StringTok{"doc4"}\NormalTok{, }\StringTok{"word4"}\NormalTok{, }\FloatTok{0.0028}\NormalTok{,}
  \StringTok{"doc4"}\NormalTok{, }\StringTok{"word5"}\NormalTok{, }\FloatTok{0.0009}\NormalTok{,}
  \StringTok{"doc5"}\NormalTok{, }\StringTok{"word1"}\NormalTok{, }\FloatTok{0.0185}\NormalTok{,}
  \StringTok{"doc5"}\NormalTok{, }\StringTok{"word2"}\NormalTok{, }\FloatTok{0.0249}\NormalTok{,}
  \StringTok{"doc5"}\NormalTok{, }\StringTok{"word3"}\NormalTok{, }\FloatTok{0.0084}\NormalTok{,}
  \StringTok{"doc5"}\NormalTok{, }\StringTok{"word4"}\NormalTok{, }\FloatTok{0.0167}\NormalTok{,}
  \StringTok{"doc5"}\NormalTok{, }\StringTok{"word5"}\NormalTok{, }\FloatTok{0.0193}\NormalTok{,}
  \StringTok{"doc6"}\NormalTok{, }\StringTok{"word1"}\NormalTok{, }\FloatTok{0.0028}\NormalTok{,}
  \StringTok{"doc6"}\NormalTok{, }\StringTok{"word2"}\NormalTok{, }\FloatTok{0.0003}\NormalTok{,}
  \StringTok{"doc6"}\NormalTok{, }\StringTok{"word3"}\NormalTok{, }\FloatTok{0.0202}\NormalTok{,}
  \StringTok{"doc6"}\NormalTok{, }\StringTok{"word4"}\NormalTok{, }\FloatTok{0.0083}\NormalTok{,}
  \StringTok{"doc6"}\NormalTok{, }\StringTok{"word5"}\NormalTok{, }\FloatTok{0.0054}
\NormalTok{)}

\NormalTok{utility\_results }\OtherTok{\textless{}{-}}\NormalTok{ tf\_idf\_results }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(words\_of\_interest, }\AttributeTok{by =} \StringTok{"word"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(document) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{utility =} \FunctionTok{sum}\NormalTok{(weight }\SpecialCharTok{*}\NormalTok{ tf\_idf) }\SpecialCharTok{/} 
\NormalTok{              (}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(weight }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{)) }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(tf\_idf }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{)))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(utility))}

\FunctionTok{print}\NormalTok{(utility\_results)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   document utility
##   <chr>      <dbl>
## 1 doc5       0.972
## 2 doc3       0.919
## 3 doc2       0.841
## 4 doc1       0.659
## 5 doc4       0.448
## 6 doc6       0.373
\end{verbatim}

위 결과, 두 건의 문서를 추천할 경우 doc5, doc3를 추천할 수 있다.

\hypertarget{collaborative-filtering}{%
\section{협업 필터링}\label{collaborative-filtering}}

총 \(m\)개의 상품에 대한 \(n\)명의 소비자의 평점이 있다고 할 때, 관련 기호를 다음과 같이 정의하자.

\begin{itemize}
\tightlist
\item
  \(v_{ij}\): 고객 \(i\)의 상품 \(j\)에 대한 평점
\item
  \(I_i\): 고객 \(i\)가 평점을 매긴 상품집합
\item
  \(\left| I_i \right|\): 집합 \(I_i\)에 포함된 상품 수
\end{itemize}

이 때, 고객 \(i\)의 평균 평점은 다음과 같이 산출된다.

\begin{equation*}
\bar{v}_i  = \frac{1}{\left| I_i \right|} \sum_{j \in I_i} v_{ij}
\end{equation*}

이 때, 목표고객 \(a\)와 \(i\)번째 고객과의 유사성은 아래와 같이 평점에서 고객 평점을 뺀(mean-centering) 값에 대한 코사인 유사성 척도를 이용하여 정의한다.

\begin{equation*}
w(a, i) = \frac{\sum_{j \in I_a \cap I_i} (v_{aj} - \bar{v}_a) (v_{ij} - \bar{v}_i)}{\sqrt{\sum_{j \in I_a \cap I_i} (v_{aj} - \bar{v}_a)^2} \sqrt{\sum_{j \in I_a \cap I_i} (v_{ij} - \bar{v}_i)^2}}
\end{equation*}

이를 이용하여, 목표고객 \(a\)가 아직 구매하지 않은 상품 \(j\)에 매길 평점을 아래와 같이 추정한다.

\begin{equation*}
\hat{v}_{aj} = \bar{v}_a + \frac{1}{\sum_{i = 1}^{n} \left| w(a, i) \right|} \sum_{i = 1}^{n} w(a, i) (v_{ij} - \bar{v}_i)
\end{equation*}

교재 @jun2012datamining 에 있는 예제에 대한 R 스크립트를 구현해보자.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rating\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{customer, }\SpecialCharTok{\textasciitilde{}}\NormalTok{item, }\SpecialCharTok{\textasciitilde{}}\NormalTok{rating,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{5}\NormalTok{,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 3"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 6"}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 3"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{5}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 3"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 6"}\NormalTok{, }\DecValTok{5}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{0}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{3}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{5}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 6"}\NormalTok{, }\DecValTok{5}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 6"}\NormalTok{, }\DecValTok{4}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{2}\NormalTok{,}
  \StringTok{"목표고객"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{5}\NormalTok{,}
  \StringTok{"목표고객"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"목표고객"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{2}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

우선, 각 고객이 매긴 평균 평점 \(\bar{v}_i\)을 각 아이템에 대한 평점 \(v_{ij}\)에서 제외하여 mean\_centered rating을 아래와 같이 구한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{centered\_rating\_df }\OtherTok{\textless{}{-}}\NormalTok{ rating\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(customer) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{centered\_rating =}\NormalTok{ rating }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(rating)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ungroup}\NormalTok{()}

\FunctionTok{print}\NormalTok{(centered\_rating\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 33 x 4
##    customer item   rating centered_rating
##    <chr>    <chr>   <dbl>           <dbl>
##  1 고객 1   상품 1      5            2.4 
##  2 고객 1   상품 3      4            1.4 
##  3 고객 1   상품 5      1           -1.6 
##  4 고객 1   상품 6      0           -2.6 
##  5 고객 1   상품 7      3            0.4 
##  6 고객 2   상품 1      4            0.75
##  7 고객 2   상품 2      4            0.75
##  8 고객 2   상품 3      4            0.75
##  9 고객 2   상품 7      1           -2.25
## 10 고객 3   상품 1      5            2   
## # ... with 23 more rows
\end{verbatim}

목표 고객과 다른 고객들간의 유사성 척도를 계산한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{similarity\_df }\OtherTok{\textless{}{-}}\NormalTok{ centered\_rating\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(customer }\SpecialCharTok{==} \StringTok{"목표고객"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{inner\_join}\NormalTok{(centered\_rating\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(customer }\SpecialCharTok{!=} \StringTok{"목표고객"}\NormalTok{), }\AttributeTok{by =} \StringTok{"item"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(customer.y) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{similarity =} \FunctionTok{sum}\NormalTok{(centered\_rating.x }\SpecialCharTok{*}\NormalTok{ centered\_rating.y) }\SpecialCharTok{/}
\NormalTok{              (}\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(centered\_rating.x }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{)) }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(centered\_rating.y }\SpecialCharTok{\^{}} \DecValTok{2}\NormalTok{)))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{customer =}\NormalTok{ customer.y)}

\FunctionTok{print}\NormalTok{(similarity\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 2
##   customer similarity
##   <chr>         <dbl>
## 1 고객 1        0.903
## 2 고객 2        0.565
## 3 고객 3        0.961
## 4 고객 4       -0.875
## 5 고객 5       -0.853
## 6 고객 6        1
\end{verbatim}

유사성 척도의 절대값의 합이 1이 되도록 normalize한다.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{normalized\_similarity\_df }\OtherTok{\textless{}{-}}\NormalTok{ similarity\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{normalized\_similarity =}\NormalTok{ similarity }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(}\FunctionTok{abs}\NormalTok{(similarity)))}

\FunctionTok{print}\NormalTok{(normalized\_similarity\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   customer similarity normalized_similarity
##   <chr>         <dbl>                 <dbl>
## 1 고객 1        0.903                 0.175
## 2 고객 2        0.565                 0.109
## 3 고객 3        0.961                 0.186
## 4 고객 4       -0.875                -0.170
## 5 고객 5       -0.853                -0.165
## 6 고객 6        1                     0.194
\end{verbatim}

이후 목표고객이 아직 평점을 매기지 않은 상품들에 대해 평점을 추정한다. 이 때, 상품 \(j\)에 대해 평점을 매기지 않은 고객의 경우, \(v_{ij} - \bar{v}_i = 0\)이라 가정하자.

\begin{equation*}
\hat{v}_{aj} = \bar{v}_a + \frac{1}{\sum_{i = 1}^{n} \left| w(a, i) \right|} \sum_{i = 1}^{n} w(a, i) (v_{ij} - \bar{v}_i)
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{items }\OtherTok{\textless{}{-}} \FunctionTok{sort}\NormalTok{(}\FunctionTok{setdiff}\NormalTok{(}\FunctionTok{unique}\NormalTok{(rating\_df}\SpecialCharTok{$}\NormalTok{item), }
\NormalTok{                      rating\_df}\SpecialCharTok{$}\NormalTok{item[rating\_df}\SpecialCharTok{$}\NormalTok{customer }\SpecialCharTok{==} \StringTok{"목표고객"}\NormalTok{]))}

\NormalTok{target\_mean }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(rating\_df}\SpecialCharTok{$}\NormalTok{rating[rating\_df}\SpecialCharTok{$}\NormalTok{customer }\SpecialCharTok{==} \StringTok{"목표고객"}\NormalTok{])}

\NormalTok{centered\_rating\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(item }\SpecialCharTok{\%in\%}\NormalTok{ items) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(normalized\_similarity\_df, }\AttributeTok{by =} \StringTok{"customer"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(item) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{predicted\_rating =}\NormalTok{ target\_mean }\SpecialCharTok{+} 
              \FunctionTok{sum}\NormalTok{(normalized\_similarity }\SpecialCharTok{*}\NormalTok{ centered\_rating)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(predicted\_rating))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 2
##   item   predicted_rating
##   <chr>             <dbl>
## 1 상품 3             3.26
## 2 상품 2             3.14
## 3 상품 5             1.96
## 4 상품 6             1.63
\end{verbatim}

이번에는, 목표상품 \(j\)에 대한 평점을 추정할 때, 상품 \(j\)에 대해 평점을 매긴 고객과의 유사성만을 아래와 같이 고려하기로 하자.

\begin{equation*}
\hat{v}_{aj} = \bar{v}_a + \frac{1}{\sum_{i: j \in I_i} \left| w(a, i) \right|} \sum_{i: j \in I_i} w(a, i) (v_{ij} - \bar{v}_i)
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{centered\_rating\_df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(item }\SpecialCharTok{\%in\%}\NormalTok{ items) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(similarity\_df, }\AttributeTok{by =} \StringTok{"customer"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(item) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{predicted\_rating =}\NormalTok{ target\_mean }\SpecialCharTok{+} 
              \FunctionTok{sum}\NormalTok{(similarity }\SpecialCharTok{*}\NormalTok{ centered\_rating) }\SpecialCharTok{/} \FunctionTok{sum}\NormalTok{(}\FunctionTok{abs}\NormalTok{(similarity))) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(predicted\_rating))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 2
##   item   predicted_rating
##   <chr>             <dbl>
## 1 상품 3             3.97
## 2 상품 2             3.24
## 3 상품 5             1.87
## 4 상품 6             1.19
\end{verbatim}

\hypertarget{market-basket}{%
\section{시장바구니 데이터를 이용한 협업 필터링}\label{market-basket}}

아래와 같은 시장바구니 데이터가 있다.

\begin{equation*}
v_{ij} = \begin{cases}
1 & \text{ 고객 $i$가 상품 $j$를 구매한 경우}\\
0 & \text{ 그렇지 않은 경우}
\end{cases}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{market\_basket\_df }\OtherTok{\textless{}{-}} \FunctionTok{tribble}\NormalTok{(}
  \SpecialCharTok{\textasciitilde{}}\NormalTok{customer, }\SpecialCharTok{\textasciitilde{}}\NormalTok{item, }\SpecialCharTok{\textasciitilde{}}\NormalTok{purchase,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 3"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 1"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 3"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 2"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 3"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 3"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 6"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 4"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 5"}\NormalTok{, }\StringTok{"상품 6"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 2"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 5"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 6"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"고객 6"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"목표고객"}\NormalTok{, }\StringTok{"상품 1"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"목표고객"}\NormalTok{, }\StringTok{"상품 4"}\NormalTok{, }\DecValTok{1}\NormalTok{,}
  \StringTok{"목표고객"}\NormalTok{, }\StringTok{"상품 7"}\NormalTok{, }\DecValTok{1}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

이 때, 총 상품의 개수를 \(m\)이라 하고, 고객 \(i\)에 대해

\begin{equation*}
p_i = \frac{|I_i|}{m}
\end{equation*}

이라 정의하자. 즉, \(p_i\)는 전체 상품 중 고객 \(i\)가 구입한 상품의 비율을 뜻한다. 또한, 두 고객 \(i\)와 \(k\)가 공통적으로 구입한 상품의 비율을 아래와 같이 \(p_{ik}\)라 정의하자.

\begin{equation*}
p_{ik} = \frac{|I_i \cap I_k|}{m}
\end{equation*}

우선 아래와 같이 가중치 \(w(a, i)\)를 계산해보자. 이 가중치는 목표고객 \(a\)과 각 고객 \(i\)간의 유사성 척도이다.

\begin{equation*}
w(a, i) = \frac{p_{ai} - p_a p_i}{\sqrt{p_a (1 - p_a)} \sqrt{p_i (1 - p_i)}}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(}\FunctionTok{unique}\NormalTok{(market\_basket\_df}\SpecialCharTok{$}\NormalTok{item))}

\NormalTok{n\_df }\OtherTok{\textless{}{-}}\NormalTok{ market\_basket\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{group\_by}\NormalTok{(customer) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{p =} \FunctionTok{n}\NormalTok{() }\SpecialCharTok{/}\NormalTok{ m)}

\NormalTok{common\_df }\OtherTok{\textless{}{-}}\NormalTok{ market\_basket\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(customer }\SpecialCharTok{==} \StringTok{"목표고객"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{inner\_join}\NormalTok{(market\_basket\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{filter}\NormalTok{(customer }\SpecialCharTok{!=} \StringTok{"목표고객"}\NormalTok{), }
             \AttributeTok{by =} \StringTok{"item"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(customer.y) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{p =} \FunctionTok{n}\NormalTok{() }\SpecialCharTok{/}\NormalTok{ m) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename}\NormalTok{(}\AttributeTok{customer =}\NormalTok{ customer.y)}

\NormalTok{similarity\_df }\OtherTok{\textless{}{-}} \FunctionTok{crossing}\NormalTok{(}
  \AttributeTok{target\_customer =} \StringTok{"목표고객"}\NormalTok{,}
  \AttributeTok{ref\_customer =}\NormalTok{ n\_df}\SpecialCharTok{$}\NormalTok{customer[n\_df}\SpecialCharTok{$}\NormalTok{customer }\SpecialCharTok{!=} \StringTok{"목표고객"}\NormalTok{]}
\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(n\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{rename}\NormalTok{(}\AttributeTok{target\_p =}\NormalTok{ p),}
             \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"target\_customer"} \OtherTok{=} \StringTok{"customer"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(n\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{rename}\NormalTok{(}\AttributeTok{ref\_p =}\NormalTok{ p),}
             \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"ref\_customer"} \OtherTok{=} \StringTok{"customer"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{inner\_join}\NormalTok{(common\_df }\SpecialCharTok{\%\textgreater{}\%} \FunctionTok{rename}\NormalTok{(}\AttributeTok{common\_p =}\NormalTok{ p),}
             \AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"ref\_customer"} \OtherTok{=} \StringTok{"customer"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}
    \AttributeTok{similarity =}\NormalTok{ (common\_p }\SpecialCharTok{{-}}\NormalTok{ target\_p }\SpecialCharTok{*}\NormalTok{ ref\_p) }\SpecialCharTok{/}
\NormalTok{      (}\FunctionTok{sqrt}\NormalTok{(target\_p }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ target\_p)) }\SpecialCharTok{*} \FunctionTok{sqrt}\NormalTok{(ref\_p }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ ref\_p)))}
\NormalTok{  )}

\FunctionTok{print}\NormalTok{(similarity\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 6
##   target_customer ref_customer target_p ref_p common_p similarity
##   <chr>           <chr>           <dbl> <dbl>    <dbl>      <dbl>
## 1 목표고객        고객 1          0.429 0.571    0.286      0.167
## 2 목표고객        고객 2          0.429 0.571    0.286      0.167
## 3 목표고객        고객 3          0.429 0.714    0.429      0.548
## 4 목표고객        고객 4          0.429 0.857    0.429      0.354
## 5 목표고객        고객 5          0.429 0.571    0.143     -0.417
## 6 목표고객        고객 6          0.429 0.571    0.143     -0.417
\end{verbatim}

이후 목표고객이 아직 구매하지 않은 상품에 대해 평점을 추정한다. 목표고객 \(a\)의 상품 \(j\)에 대한 평점 추정치는 다음과 같이 산출한다.

\begin{equation*}
P_{aj} = \frac{\sum_{i = 1}^{n} w(a, i) v_{ij}}{\sum_{i = 1}^{n} | w(a, i) |}
\end{equation*}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{denom }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(}\FunctionTok{abs}\NormalTok{(similarity\_df}\SpecialCharTok{$}\NormalTok{similarity))}

\NormalTok{pred\_df }\OtherTok{\textless{}{-}}\NormalTok{ similarity\_df }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{inner\_join}\NormalTok{(market\_basket\_df, }\AttributeTok{by =} \FunctionTok{c}\NormalTok{(}\StringTok{"ref\_customer"} \OtherTok{=} \StringTok{"customer"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{anti\_join}\NormalTok{(market\_basket\_df }\SpecialCharTok{\%\textgreater{}\%} 
              \FunctionTok{filter}\NormalTok{(customer }\SpecialCharTok{==} \StringTok{"목표고객"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
              \FunctionTok{select}\NormalTok{(item),}
            \AttributeTok{by =} \StringTok{"item"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(item) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarize}\NormalTok{(}\AttributeTok{est\_score =} \FunctionTok{sum}\NormalTok{(similarity }\SpecialCharTok{*}\NormalTok{ purchase) }\SpecialCharTok{/}\NormalTok{ denom) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{arrange}\NormalTok{(}\FunctionTok{desc}\NormalTok{(est\_score))}

\FunctionTok{print}\NormalTok{(pred\_df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 2
##   item   est_score
##   <chr>      <dbl>
## 1 상품 3    0.332 
## 2 상품 2    0.113 
## 3 상품 5   -0.0575
## 4 상품 6   -0.232
\end{verbatim}

  \bibliography{book.bib,packages.bib}

\end{document}
